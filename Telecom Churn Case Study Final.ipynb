{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "<br>\n",
    " \n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business goal.\n",
    "<br>\n",
    " \n",
    "\n",
    "To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.\n",
    "<br>\n",
    " \n",
    "\n",
    "In this project, you will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries for EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 300)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data\n",
    "df=pd.read_csv(\"telecom_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 226)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_rech_2g_6             74.85\n",
      "date_of_last_rech_data_6    74.85\n",
      "count_rech_3g_6             74.85\n",
      "av_rech_amt_data_6          74.85\n",
      "max_rech_data_6             74.85\n",
      "total_rech_data_6           74.85\n",
      "arpu_3g_6                   74.85\n",
      "arpu_2g_6                   74.85\n",
      "night_pck_user_6            74.85\n",
      "fb_user_6                   74.85\n",
      "arpu_3g_7                   74.43\n",
      "count_rech_2g_7             74.43\n",
      "fb_user_7                   74.43\n",
      "count_rech_3g_7             74.43\n",
      "arpu_2g_7                   74.43\n",
      "av_rech_amt_data_7          74.43\n",
      "max_rech_data_7             74.43\n",
      "night_pck_user_7            74.43\n",
      "total_rech_data_7           74.43\n",
      "date_of_last_rech_data_7    74.43\n",
      "night_pck_user_9            74.08\n",
      "date_of_last_rech_data_9    74.08\n",
      "fb_user_9                   74.08\n",
      "arpu_2g_9                   74.08\n",
      "max_rech_data_9             74.08\n",
      "arpu_3g_9                   74.08\n",
      "total_rech_data_9           74.08\n",
      "av_rech_amt_data_9          74.08\n",
      "count_rech_3g_9             74.08\n",
      "count_rech_2g_9             74.08\n",
      "fb_user_8                   73.66\n",
      "av_rech_amt_data_8          73.66\n",
      "count_rech_3g_8             73.66\n",
      "count_rech_2g_8             73.66\n",
      "date_of_last_rech_data_8    73.66\n",
      "total_rech_data_8           73.66\n",
      "max_rech_data_8             73.66\n",
      "arpu_3g_8                   73.66\n",
      "arpu_2g_8                   73.66\n",
      "night_pck_user_8            73.66\n",
      "std_ic_t2m_mou_9             7.75\n",
      "spl_ic_mou_9                 7.75\n",
      "loc_ic_mou_9                 7.75\n",
      "isd_ic_mou_9                 7.75\n",
      "std_ic_t2o_mou_9             7.75\n",
      "loc_ic_t2f_mou_9             7.75\n",
      "ic_others_9                  7.75\n",
      "loc_og_t2f_mou_9             7.75\n",
      "loc_ic_t2m_mou_9             7.75\n",
      "loc_og_t2c_mou_9             7.75\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking missing values\n",
    "cl=round(df.isnull().sum()/len(df)*100,2)\n",
    "print(cl.sort_values(ascending=False).iloc[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop all the columns with more than 8% null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 186)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop=list(cl.loc[cl>8].index)\n",
    "df=df.drop(cols_to_drop,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc_ic_t2m_mou_9        7.75\n",
      "std_og_t2t_mou_9        7.75\n",
      "std_ic_t2f_mou_9        7.75\n",
      "std_ic_t2t_mou_9        7.75\n",
      "roam_og_mou_9           7.75\n",
      "loc_ic_mou_9            7.75\n",
      "loc_og_t2t_mou_9        7.75\n",
      "loc_ic_t2f_mou_9        7.75\n",
      "roam_ic_mou_9           7.75\n",
      "ic_others_9             7.75\n",
      "loc_og_mou_9            7.75\n",
      "std_ic_t2o_mou_9        7.75\n",
      "offnet_mou_9            7.75\n",
      "loc_ic_t2t_mou_9        7.75\n",
      "std_ic_mou_9            7.75\n",
      "onnet_mou_9             7.75\n",
      "og_others_9             7.75\n",
      "std_og_mou_9            7.75\n",
      "isd_ic_mou_9            7.75\n",
      "std_og_t2m_mou_9        7.75\n",
      "std_og_t2f_mou_9        7.75\n",
      "loc_og_t2f_mou_9        7.75\n",
      "std_og_t2c_mou_9        7.75\n",
      "spl_ic_mou_9            7.75\n",
      "isd_og_mou_9            7.75\n",
      "loc_og_t2c_mou_9        7.75\n",
      "spl_og_mou_9            7.75\n",
      "loc_og_t2m_mou_9        7.75\n",
      "std_ic_t2m_mou_9        7.75\n",
      "spl_ic_mou_8            5.38\n",
      "std_ic_t2f_mou_8        5.38\n",
      "isd_ic_mou_8            5.38\n",
      "std_ic_t2o_mou_8        5.38\n",
      "loc_og_mou_8            5.38\n",
      "loc_ic_t2f_mou_8        5.38\n",
      "std_ic_t2m_mou_8        5.38\n",
      "std_ic_t2t_mou_8        5.38\n",
      "loc_ic_mou_8            5.38\n",
      "loc_ic_t2m_mou_8        5.38\n",
      "loc_ic_t2t_mou_8        5.38\n",
      "std_og_t2t_mou_8        5.38\n",
      "og_others_8             5.38\n",
      "spl_og_mou_8            5.38\n",
      "isd_og_mou_8            5.38\n",
      "std_og_mou_8            5.38\n",
      "std_og_t2c_mou_8        5.38\n",
      "std_og_t2f_mou_8        5.38\n",
      "std_og_t2m_mou_8        5.38\n",
      "ic_others_8             5.38\n",
      "std_ic_mou_8            5.38\n",
      "loc_og_t2c_mou_8        5.38\n",
      "loc_og_t2f_mou_8        5.38\n",
      "roam_ic_mou_8           5.38\n",
      "roam_og_mou_8           5.38\n",
      "onnet_mou_8             5.38\n",
      "loc_og_t2t_mou_8        5.38\n",
      "loc_og_t2m_mou_8        5.38\n",
      "offnet_mou_8            5.38\n",
      "date_of_last_rech_9     4.76\n",
      "std_ic_t2f_mou_6        3.94\n",
      "onnet_mou_6             3.94\n",
      "std_ic_t2m_mou_6        3.94\n",
      "loc_og_t2t_mou_6        3.94\n",
      "loc_og_t2c_mou_6        3.94\n",
      "std_ic_t2t_mou_6        3.94\n",
      "std_og_t2f_mou_6        3.94\n",
      "offnet_mou_6            3.94\n",
      "std_og_t2c_mou_6        3.94\n",
      "roam_og_mou_6           3.94\n",
      "ic_others_6             3.94\n",
      "std_og_t2t_mou_6        3.94\n",
      "loc_ic_t2f_mou_6        3.94\n",
      "loc_ic_t2t_mou_6        3.94\n",
      "roam_ic_mou_6           3.94\n",
      "loc_ic_t2m_mou_6        3.94\n",
      "loc_ic_mou_6            3.94\n",
      "og_others_6             3.94\n",
      "isd_ic_mou_6            3.94\n",
      "spl_ic_mou_6            3.94\n",
      "loc_og_t2f_mou_6        3.94\n",
      "std_ic_t2o_mou_6        3.94\n",
      "spl_og_mou_6            3.94\n",
      "loc_og_mou_6            3.94\n",
      "loc_og_t2m_mou_6        3.94\n",
      "std_ic_mou_6            3.94\n",
      "std_og_mou_6            3.94\n",
      "isd_og_mou_6            3.94\n",
      "std_og_t2m_mou_6        3.94\n",
      "og_others_7             3.86\n",
      "loc_ic_t2t_mou_7        3.86\n",
      "std_og_t2t_mou_7        3.86\n",
      "std_og_mou_7            3.86\n",
      "std_og_t2c_mou_7        3.86\n",
      "isd_og_mou_7            3.86\n",
      "onnet_mou_7             3.86\n",
      "spl_og_mou_7            3.86\n",
      "offnet_mou_7            3.86\n",
      "std_og_t2f_mou_7        3.86\n",
      "loc_ic_t2f_mou_7        3.86\n",
      "loc_ic_t2m_mou_7        3.86\n",
      "std_ic_t2o_mou_7        3.86\n",
      "loc_og_t2c_mou_7        3.86\n",
      "isd_ic_mou_7            3.86\n",
      "loc_og_t2f_mou_7        3.86\n",
      "spl_ic_mou_7            3.86\n",
      "loc_og_mou_7            3.86\n",
      "loc_og_t2m_mou_7        3.86\n",
      "std_ic_mou_7            3.86\n",
      "roam_ic_mou_7           3.86\n",
      "std_og_t2m_mou_7        3.86\n",
      "ic_others_7             3.86\n",
      "loc_ic_mou_7            3.86\n",
      "std_ic_t2f_mou_7        3.86\n",
      "std_ic_t2m_mou_7        3.86\n",
      "loc_og_t2t_mou_7        3.86\n",
      "std_ic_t2t_mou_7        3.86\n",
      "roam_og_mou_7           3.86\n",
      "date_of_last_rech_8     3.62\n",
      "date_of_last_rech_7     1.77\n",
      "last_date_of_month_9    1.66\n",
      "date_of_last_rech_6     1.61\n",
      "last_date_of_month_8    1.10\n",
      "loc_ic_t2o_mou          1.02\n",
      "loc_og_t2o_mou          1.02\n",
      "std_og_t2o_mou          1.02\n",
      "last_date_of_month_7    0.60\n",
      "last_date_of_month_6    0.00\n",
      "arpu_6                  0.00\n",
      "arpu_7                  0.00\n",
      "arpu_9                  0.00\n",
      "circle_id               0.00\n",
      "arpu_8                  0.00\n",
      "sep_vbc_3g              0.00\n",
      "total_og_mou_6          0.00\n",
      "vol_2g_mb_8             0.00\n",
      "vol_3g_mb_6             0.00\n",
      "vol_3g_mb_7             0.00\n",
      "vol_3g_mb_8             0.00\n",
      "vol_3g_mb_9             0.00\n",
      "monthly_2g_6            0.00\n",
      "monthly_2g_7            0.00\n",
      "monthly_2g_8            0.00\n",
      "monthly_2g_9            0.00\n",
      "sachet_2g_6             0.00\n",
      "sachet_2g_7             0.00\n",
      "sachet_2g_8             0.00\n",
      "sachet_2g_9             0.00\n",
      "monthly_3g_6            0.00\n",
      "monthly_3g_7            0.00\n",
      "monthly_3g_8            0.00\n",
      "monthly_3g_9            0.00\n",
      "sachet_3g_6             0.00\n",
      "sachet_3g_7             0.00\n",
      "sachet_3g_8             0.00\n",
      "sachet_3g_9             0.00\n",
      "aon                     0.00\n",
      "aug_vbc_3g              0.00\n",
      "jul_vbc_3g              0.00\n",
      "vol_2g_mb_9             0.00\n",
      "vol_2g_mb_7             0.00\n",
      "total_og_mou_7          0.00\n",
      "vol_2g_mb_6             0.00\n",
      "total_og_mou_8          0.00\n",
      "total_og_mou_9          0.00\n",
      "jun_vbc_3g              0.00\n",
      "total_ic_mou_6          0.00\n",
      "total_ic_mou_7          0.00\n",
      "total_ic_mou_8          0.00\n",
      "total_ic_mou_9          0.00\n",
      "total_rech_num_6        0.00\n",
      "total_rech_num_7        0.00\n",
      "total_rech_num_8        0.00\n",
      "total_rech_num_9        0.00\n",
      "total_rech_amt_6        0.00\n",
      "total_rech_amt_7        0.00\n",
      "total_rech_amt_8        0.00\n",
      "total_rech_amt_9        0.00\n",
      "max_rech_amt_6          0.00\n",
      "max_rech_amt_7          0.00\n",
      "max_rech_amt_8          0.00\n",
      "max_rech_amt_9          0.00\n",
      "last_day_rch_amt_6      0.00\n",
      "last_day_rch_amt_7      0.00\n",
      "last_day_rch_amt_8      0.00\n",
      "last_day_rch_amt_9      0.00\n",
      "mobile_number           0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cl=round(df.isnull().sum()/len(df)*100,2)\n",
    "print(cl.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84185, 186)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have more than 80000 rows left if we drop the rows with null values. Thus, we have quite a large number of samples even when we drop the rows with all the null values and there is no need to impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>arpu_9</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>onnet_mou_9</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>offnet_mou_9</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_ic_mou_9</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>roam_og_mou_9</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_9</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_9</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_9</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_9</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>loc_og_mou_9</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2t_mou_9</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2m_mou_9</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2f_mou_9</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_t2c_mou_9</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>std_og_mou_9</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>isd_og_mou_9</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>spl_og_mou_9</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>og_others_9</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>total_og_mou_9</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_9</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_9</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_9</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>loc_ic_mou_9</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_9</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_9</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_9</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_9</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>std_ic_mou_9</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>total_ic_mou_9</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_9</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_9</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>ic_others_9</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_num_9</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_rech_amt_9</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>max_rech_amt_9</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>date_of_last_rech_9</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>last_day_rch_amt_9</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_2g_mb_9</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>vol_3g_mb_9</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>monthly_2g_9</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>sachet_2g_9</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>monthly_3g_9</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>355.074</td>\n",
       "      <td>268.321</td>\n",
       "      <td>86.285</td>\n",
       "      <td>24.11</td>\n",
       "      <td>78.68</td>\n",
       "      <td>7.68</td>\n",
       "      <td>18.34</td>\n",
       "      <td>15.74</td>\n",
       "      <td>99.84</td>\n",
       "      <td>304.76</td>\n",
       "      <td>53.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.88</td>\n",
       "      <td>74.56</td>\n",
       "      <td>7.68</td>\n",
       "      <td>18.34</td>\n",
       "      <td>11.51</td>\n",
       "      <td>75.94</td>\n",
       "      <td>291.86</td>\n",
       "      <td>53.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.39</td>\n",
       "      <td>150.51</td>\n",
       "      <td>299.54</td>\n",
       "      <td>72.11</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>23.43</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.31</td>\n",
       "      <td>178.53</td>\n",
       "      <td>312.44</td>\n",
       "      <td>72.11</td>\n",
       "      <td>1.61</td>\n",
       "      <td>29.91</td>\n",
       "      <td>29.23</td>\n",
       "      <td>116.09</td>\n",
       "      <td>17.48</td>\n",
       "      <td>65.38</td>\n",
       "      <td>375.58</td>\n",
       "      <td>56.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.93</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.09</td>\n",
       "      <td>104.23</td>\n",
       "      <td>408.43</td>\n",
       "      <td>173.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.49</td>\n",
       "      <td>15.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.84</td>\n",
       "      <td>15.01</td>\n",
       "      <td>26.83</td>\n",
       "      <td>104.23</td>\n",
       "      <td>423.28</td>\n",
       "      <td>188.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>384</td>\n",
       "      <td>283</td>\n",
       "      <td>121</td>\n",
       "      <td>44</td>\n",
       "      <td>154</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.07</td>\n",
       "      <td>365.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>189.058</td>\n",
       "      <td>210.226</td>\n",
       "      <td>290.714</td>\n",
       "      <td>11.54</td>\n",
       "      <td>55.24</td>\n",
       "      <td>37.26</td>\n",
       "      <td>74.81</td>\n",
       "      <td>143.33</td>\n",
       "      <td>220.59</td>\n",
       "      <td>208.36</td>\n",
       "      <td>118.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.94</td>\n",
       "      <td>7.19</td>\n",
       "      <td>28.74</td>\n",
       "      <td>13.58</td>\n",
       "      <td>14.39</td>\n",
       "      <td>29.34</td>\n",
       "      <td>16.86</td>\n",
       "      <td>38.46</td>\n",
       "      <td>28.16</td>\n",
       "      <td>24.11</td>\n",
       "      <td>21.79</td>\n",
       "      <td>15.61</td>\n",
       "      <td>22.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.54</td>\n",
       "      <td>45.76</td>\n",
       "      <td>0.48</td>\n",
       "      <td>60.66</td>\n",
       "      <td>67.41</td>\n",
       "      <td>67.66</td>\n",
       "      <td>64.81</td>\n",
       "      <td>4.34</td>\n",
       "      <td>26.49</td>\n",
       "      <td>22.58</td>\n",
       "      <td>8.76</td>\n",
       "      <td>41.81</td>\n",
       "      <td>67.41</td>\n",
       "      <td>75.53</td>\n",
       "      <td>9.28</td>\n",
       "      <td>1.48</td>\n",
       "      <td>14.76</td>\n",
       "      <td>22.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.64</td>\n",
       "      <td>108.68</td>\n",
       "      <td>120.94</td>\n",
       "      <td>18.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.56</td>\n",
       "      <td>236.84</td>\n",
       "      <td>96.84</td>\n",
       "      <td>42.08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.33</td>\n",
       "      <td>412.94</td>\n",
       "      <td>285.46</td>\n",
       "      <td>124.94</td>\n",
       "      <td>115.69</td>\n",
       "      <td>71.11</td>\n",
       "      <td>67.46</td>\n",
       "      <td>148.23</td>\n",
       "      <td>14.38</td>\n",
       "      <td>15.44</td>\n",
       "      <td>38.89</td>\n",
       "      <td>38.98</td>\n",
       "      <td>99.48</td>\n",
       "      <td>122.29</td>\n",
       "      <td>49.63</td>\n",
       "      <td>158.19</td>\n",
       "      <td>229.56</td>\n",
       "      <td>208.86</td>\n",
       "      <td>155.99</td>\n",
       "      <td>345.41</td>\n",
       "      <td>72.41</td>\n",
       "      <td>71.29</td>\n",
       "      <td>28.69</td>\n",
       "      <td>49.44</td>\n",
       "      <td>45.18</td>\n",
       "      <td>177.01</td>\n",
       "      <td>167.09</td>\n",
       "      <td>118.18</td>\n",
       "      <td>21.73</td>\n",
       "      <td>58.34</td>\n",
       "      <td>43.23</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.33</td>\n",
       "      <td>306.66</td>\n",
       "      <td>239.03</td>\n",
       "      <td>171.49</td>\n",
       "      <td>370.04</td>\n",
       "      <td>519.53</td>\n",
       "      <td>395.03</td>\n",
       "      <td>517.74</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>315</td>\n",
       "      <td>116</td>\n",
       "      <td>358</td>\n",
       "      <td>86</td>\n",
       "      <td>200</td>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>7/24/2014</td>\n",
       "      <td>8/14/2014</td>\n",
       "      <td>9/29/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>251.102</td>\n",
       "      <td>508.054</td>\n",
       "      <td>389.500</td>\n",
       "      <td>99.91</td>\n",
       "      <td>54.39</td>\n",
       "      <td>310.98</td>\n",
       "      <td>241.71</td>\n",
       "      <td>123.31</td>\n",
       "      <td>109.01</td>\n",
       "      <td>71.68</td>\n",
       "      <td>113.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.86</td>\n",
       "      <td>44.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.09</td>\n",
       "      <td>39.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.68</td>\n",
       "      <td>34.81</td>\n",
       "      <td>10.61</td>\n",
       "      <td>15.49</td>\n",
       "      <td>107.43</td>\n",
       "      <td>83.21</td>\n",
       "      <td>22.46</td>\n",
       "      <td>65.46</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.91</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>183.03</td>\n",
       "      <td>118.68</td>\n",
       "      <td>37.99</td>\n",
       "      <td>83.03</td>\n",
       "      <td>26.23</td>\n",
       "      <td>14.89</td>\n",
       "      <td>289.58</td>\n",
       "      <td>226.21</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.73</td>\n",
       "      <td>6.53</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.23</td>\n",
       "      <td>16.63</td>\n",
       "      <td>296.11</td>\n",
       "      <td>236.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.09</td>\n",
       "      <td>43.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.23</td>\n",
       "      <td>135.31</td>\n",
       "      <td>352.21</td>\n",
       "      <td>362.54</td>\n",
       "      <td>62.08</td>\n",
       "      <td>19.98</td>\n",
       "      <td>8.04</td>\n",
       "      <td>41.73</td>\n",
       "      <td>113.96</td>\n",
       "      <td>64.51</td>\n",
       "      <td>20.28</td>\n",
       "      <td>52.86</td>\n",
       "      <td>57.43</td>\n",
       "      <td>27.09</td>\n",
       "      <td>19.84</td>\n",
       "      <td>65.59</td>\n",
       "      <td>233.48</td>\n",
       "      <td>111.59</td>\n",
       "      <td>48.18</td>\n",
       "      <td>160.19</td>\n",
       "      <td>43.48</td>\n",
       "      <td>66.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129.84</td>\n",
       "      <td>1.33</td>\n",
       "      <td>38.56</td>\n",
       "      <td>4.94</td>\n",
       "      <td>13.98</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.99</td>\n",
       "      <td>105.01</td>\n",
       "      <td>4.94</td>\n",
       "      <td>143.83</td>\n",
       "      <td>280.08</td>\n",
       "      <td>216.61</td>\n",
       "      <td>53.13</td>\n",
       "      <td>305.38</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>230</td>\n",
       "      <td>310</td>\n",
       "      <td>601</td>\n",
       "      <td>410</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>6/28/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>309.876</td>\n",
       "      <td>238.174</td>\n",
       "      <td>163.426</td>\n",
       "      <td>50.31</td>\n",
       "      <td>149.44</td>\n",
       "      <td>83.89</td>\n",
       "      <td>58.78</td>\n",
       "      <td>76.96</td>\n",
       "      <td>91.88</td>\n",
       "      <td>124.26</td>\n",
       "      <td>45.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.31</td>\n",
       "      <td>149.44</td>\n",
       "      <td>83.89</td>\n",
       "      <td>58.78</td>\n",
       "      <td>67.64</td>\n",
       "      <td>91.88</td>\n",
       "      <td>124.26</td>\n",
       "      <td>37.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.96</td>\n",
       "      <td>241.33</td>\n",
       "      <td>208.16</td>\n",
       "      <td>98.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.28</td>\n",
       "      <td>241.33</td>\n",
       "      <td>208.16</td>\n",
       "      <td>104.59</td>\n",
       "      <td>105.68</td>\n",
       "      <td>88.49</td>\n",
       "      <td>233.81</td>\n",
       "      <td>154.56</td>\n",
       "      <td>106.84</td>\n",
       "      <td>109.54</td>\n",
       "      <td>104.13</td>\n",
       "      <td>48.24</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>214.03</td>\n",
       "      <td>198.04</td>\n",
       "      <td>337.94</td>\n",
       "      <td>202.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.31</td>\n",
       "      <td>216.44</td>\n",
       "      <td>198.29</td>\n",
       "      <td>338.81</td>\n",
       "      <td>205.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>196</td>\n",
       "      <td>350</td>\n",
       "      <td>287</td>\n",
       "      <td>200</td>\n",
       "      <td>56</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/26/2014</td>\n",
       "      <td>7/28/2014</td>\n",
       "      <td>8/9/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7000286308</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>50.258</td>\n",
       "      <td>58.810</td>\n",
       "      <td>83.386</td>\n",
       "      <td>170.826</td>\n",
       "      <td>50.16</td>\n",
       "      <td>43.63</td>\n",
       "      <td>85.48</td>\n",
       "      <td>138.79</td>\n",
       "      <td>19.28</td>\n",
       "      <td>13.44</td>\n",
       "      <td>14.46</td>\n",
       "      <td>46.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.16</td>\n",
       "      <td>43.63</td>\n",
       "      <td>85.48</td>\n",
       "      <td>138.79</td>\n",
       "      <td>16.39</td>\n",
       "      <td>8.83</td>\n",
       "      <td>12.38</td>\n",
       "      <td>44.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.56</td>\n",
       "      <td>52.46</td>\n",
       "      <td>97.86</td>\n",
       "      <td>185.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.44</td>\n",
       "      <td>57.08</td>\n",
       "      <td>99.94</td>\n",
       "      <td>185.71</td>\n",
       "      <td>28.73</td>\n",
       "      <td>30.03</td>\n",
       "      <td>56.26</td>\n",
       "      <td>68.38</td>\n",
       "      <td>49.19</td>\n",
       "      <td>57.44</td>\n",
       "      <td>62.46</td>\n",
       "      <td>84.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>77.93</td>\n",
       "      <td>87.48</td>\n",
       "      <td>118.73</td>\n",
       "      <td>152.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>77.03</td>\n",
       "      <td>71.06</td>\n",
       "      <td>37.93</td>\n",
       "      <td>52.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.03</td>\n",
       "      <td>71.06</td>\n",
       "      <td>37.93</td>\n",
       "      <td>52.03</td>\n",
       "      <td>155.39</td>\n",
       "      <td>158.76</td>\n",
       "      <td>157.13</td>\n",
       "      <td>205.39</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/17/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "1     7001865778        109             0.0             0.0             0.0   \n",
       "2     7001625959        109             0.0             0.0             0.0   \n",
       "3     7001204172        109             0.0             0.0             0.0   \n",
       "4     7000142493        109             0.0             0.0             0.0   \n",
       "5     7000286308        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "5            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9   arpu_6   arpu_7   arpu_8   arpu_9  onnet_mou_6  \\\n",
       "1            9/30/2014   34.047  355.074  268.321   86.285        24.11   \n",
       "2            9/30/2014  167.690  189.058  210.226  290.714        11.54   \n",
       "3            9/30/2014  221.338  251.102  508.054  389.500        99.91   \n",
       "4            9/30/2014  261.636  309.876  238.174  163.426        50.31   \n",
       "5            9/30/2014   50.258   58.810   83.386  170.826        50.16   \n",
       "\n",
       "   onnet_mou_7  onnet_mou_8  onnet_mou_9  offnet_mou_6  offnet_mou_7  \\\n",
       "1        78.68         7.68        18.34         15.74         99.84   \n",
       "2        55.24        37.26        74.81        143.33        220.59   \n",
       "3        54.39       310.98       241.71        123.31        109.01   \n",
       "4       149.44        83.89        58.78         76.96         91.88   \n",
       "5        43.63        85.48       138.79         19.28         13.44   \n",
       "\n",
       "   offnet_mou_8  offnet_mou_9  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "1        304.76         53.76            0.0           0.00           0.00   \n",
       "2        208.36        118.91            0.0           0.00           0.00   \n",
       "3         71.68        113.54            0.0          54.86          44.38   \n",
       "4        124.26         45.81            0.0           0.00           0.00   \n",
       "5         14.46         46.91            0.0           0.00           0.00   \n",
       "\n",
       "   roam_ic_mou_9  roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  roam_og_mou_9  \\\n",
       "1           0.00            0.0           0.00           0.00           0.00   \n",
       "2          38.49            0.0           0.00           0.00          70.94   \n",
       "3           0.00            0.0          28.09          39.04           0.00   \n",
       "4           0.00            0.0           0.00           0.00           0.00   \n",
       "5           0.00            0.0           0.00           0.00           0.00   \n",
       "\n",
       "   loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2t_mou_9  \\\n",
       "1             23.88             74.56              7.68             18.34   \n",
       "2              7.19             28.74             13.58             14.39   \n",
       "3             73.68             34.81             10.61             15.49   \n",
       "4             50.31            149.44             83.89             58.78   \n",
       "5             50.16             43.63             85.48            138.79   \n",
       "\n",
       "   loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2m_mou_9  \\\n",
       "1             11.51             75.94            291.86             53.76   \n",
       "2             29.34             16.86             38.46             28.16   \n",
       "3            107.43             83.21             22.46             65.46   \n",
       "4             67.64             91.88            124.26             37.89   \n",
       "5             16.39              8.83             12.38             44.78   \n",
       "\n",
       "   loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  loc_og_t2f_mou_9  \\\n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             24.11             21.79             15.61             22.24   \n",
       "3              1.91              0.65              4.91              2.06   \n",
       "4              0.00              0.00              0.00              1.93   \n",
       "5              0.00              0.00              0.00              2.13   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_t2c_mou_9  \\\n",
       "1               0.0              2.91              0.00              0.00   \n",
       "2               0.0            135.54             45.76              0.48   \n",
       "3               0.0              0.00              0.00              0.00   \n",
       "4               0.0              0.00              0.00              0.00   \n",
       "5               0.0              0.00              0.00              0.00   \n",
       "\n",
       "   loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  loc_og_mou_9  std_og_t2t_mou_6  \\\n",
       "1         35.39        150.51        299.54         72.11              0.23   \n",
       "2         60.66         67.41         67.66         64.81              4.34   \n",
       "3        183.03        118.68         37.99         83.03             26.23   \n",
       "4        117.96        241.33        208.16         98.61              0.00   \n",
       "5         66.56         52.46         97.86        185.71              0.00   \n",
       "\n",
       "   std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2t_mou_9  std_og_t2m_mou_6  \\\n",
       "1              4.11              0.00              0.00              0.00   \n",
       "2             26.49             22.58              8.76             41.81   \n",
       "3             14.89            289.58            226.21              2.99   \n",
       "4              0.00              0.00              0.00              9.31   \n",
       "5              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_og_t2m_mou_7  std_og_t2m_mou_8  std_og_t2m_mou_9  std_og_t2f_mou_6  \\\n",
       "1              0.46              0.13              0.00              0.00   \n",
       "2             67.41             75.53              9.28              1.48   \n",
       "3              1.73              6.53              9.99              0.00   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "5              0.00              0.00              0.00              2.88   \n",
       "\n",
       "   std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2f_mou_9  std_og_t2c_mou_6  \\\n",
       "1              0.00              0.00               0.0               0.0   \n",
       "2             14.76             22.83               0.0               0.0   \n",
       "3              0.00              0.00               0.0               0.0   \n",
       "4              0.00              0.00               0.0               0.0   \n",
       "5              4.61              2.08               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_t2c_mou_9  std_og_mou_6  \\\n",
       "1               0.0               0.0               0.0          0.23   \n",
       "2               0.0               0.0               0.0         47.64   \n",
       "3               0.0               0.0               0.0         29.23   \n",
       "4               0.0               0.0               0.0          9.31   \n",
       "5               0.0               0.0               0.0          2.88   \n",
       "\n",
       "   std_og_mou_7  std_og_mou_8  std_og_mou_9  isd_og_mou_6  isd_og_mou_7  \\\n",
       "1          4.58          0.13          0.00           0.0           0.0   \n",
       "2        108.68        120.94         18.04           0.0           0.0   \n",
       "3         16.63        296.11        236.21           0.0           0.0   \n",
       "4          0.00          0.00          0.00           0.0           0.0   \n",
       "5          4.61          2.08          0.00           0.0           0.0   \n",
       "\n",
       "   isd_og_mou_8  isd_og_mou_9  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  \\\n",
       "1           0.0           0.0          4.68         23.43         12.76   \n",
       "2           0.0           0.0         46.56        236.84         96.84   \n",
       "3           0.0           0.0         10.96          0.00         18.09   \n",
       "4           0.0           0.0          0.00          0.00          0.00   \n",
       "5           0.0           0.0          0.00          0.00          0.00   \n",
       "\n",
       "   spl_og_mou_9  og_others_6  og_others_7  og_others_8  og_others_9  \\\n",
       "1          0.00         0.00          0.0          0.0          0.0   \n",
       "2         42.08         0.45          0.0          0.0          0.0   \n",
       "3         43.29         0.00          0.0          0.0          0.0   \n",
       "4          5.98         0.00          0.0          0.0          0.0   \n",
       "5          0.00         0.00          0.0          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  total_og_mou_9  \\\n",
       "1           40.31          178.53          312.44           72.11   \n",
       "2          155.33          412.94          285.46          124.94   \n",
       "3          223.23          135.31          352.21          362.54   \n",
       "4          127.28          241.33          208.16          104.59   \n",
       "5           69.44           57.08           99.94          185.71   \n",
       "\n",
       "   loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2t_mou_9  \\\n",
       "1              1.61             29.91             29.23            116.09   \n",
       "2            115.69             71.11             67.46            148.23   \n",
       "3             62.08             19.98              8.04             41.73   \n",
       "4            105.68             88.49            233.81            154.56   \n",
       "5             28.73             30.03             56.26             68.38   \n",
       "\n",
       "   loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2m_mou_9  \\\n",
       "1             17.48             65.38            375.58             56.93   \n",
       "2             14.38             15.44             38.89             38.98   \n",
       "3            113.96             64.51             20.28             52.86   \n",
       "4            106.84            109.54            104.13             48.24   \n",
       "5             49.19             57.44             62.46             84.01   \n",
       "\n",
       "   loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_t2f_mou_9  \\\n",
       "1              0.00              8.93              3.61              0.00   \n",
       "2             99.48            122.29             49.63            158.19   \n",
       "3             57.43             27.09             19.84             65.59   \n",
       "4              1.50              0.00              0.00              0.00   \n",
       "5              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  loc_ic_mou_9  std_ic_t2t_mou_6  \\\n",
       "1         19.09        104.23        408.43        173.03              0.00   \n",
       "2        229.56        208.86        155.99        345.41             72.41   \n",
       "3        233.48        111.59         48.18        160.19             43.48   \n",
       "4        214.03        198.04        337.94        202.81              0.00   \n",
       "5         77.93         87.48        118.73        152.39              0.00   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2t_mou_9  std_ic_t2m_mou_6  \\\n",
       "1              0.00              2.35              0.00              5.90   \n",
       "2             71.29             28.69             49.44             45.18   \n",
       "3             66.44              0.00            129.84              1.33   \n",
       "4              0.00              0.86              2.31              1.93   \n",
       "5              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2m_mou_9  std_ic_t2f_mou_6  \\\n",
       "1              0.00             12.49             15.01              0.00   \n",
       "2            177.01            167.09            118.18             21.73   \n",
       "3             38.56              4.94             13.98              1.18   \n",
       "4              0.25              0.00              0.00              0.00   \n",
       "5              0.00              0.00              0.00             77.03   \n",
       "\n",
       "   std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_t2f_mou_9  std_ic_t2o_mou_6  \\\n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2             58.34             43.23              3.86               0.0   \n",
       "3              0.00              0.00              0.00               0.0   \n",
       "4              0.00              0.00              0.00               0.0   \n",
       "5             71.06             37.93             52.03               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_t2o_mou_9  std_ic_mou_6  \\\n",
       "1               0.0               0.0               0.0          5.90   \n",
       "2               0.0               0.0               0.0        139.33   \n",
       "3               0.0               0.0               0.0         45.99   \n",
       "4               0.0               0.0               0.0          1.93   \n",
       "5               0.0               0.0               0.0         77.03   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  std_ic_mou_9  total_ic_mou_6  total_ic_mou_7  \\\n",
       "1          0.00         14.84         15.01           26.83          104.23   \n",
       "2        306.66        239.03        171.49          370.04          519.53   \n",
       "3        105.01          4.94        143.83          280.08          216.61   \n",
       "4          0.25          0.86          2.31          216.44          198.29   \n",
       "5         71.06         37.93         52.03          155.39          158.76   \n",
       "\n",
       "   total_ic_mou_8  total_ic_mou_9  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  \\\n",
       "1          423.28          188.04          0.00          0.00          0.00   \n",
       "2          395.03          517.74          0.21          0.00          0.00   \n",
       "3           53.13          305.38          0.59          0.00          0.00   \n",
       "4          338.81          205.31          0.00          0.00          0.00   \n",
       "5          157.13          205.39          0.43          0.21          0.23   \n",
       "\n",
       "   spl_ic_mou_9  isd_ic_mou_6  isd_ic_mou_7  isd_ic_mou_8  isd_ic_mou_9  \\\n",
       "1          0.00          1.83          0.00           0.0          0.00   \n",
       "2          0.45          0.00          0.85           0.0          0.01   \n",
       "3          0.55          0.00          0.00           0.0          0.00   \n",
       "4          0.18          0.00          0.00           0.0          0.00   \n",
       "5          0.53          0.00          0.00           0.0          0.00   \n",
       "\n",
       "   ic_others_6  ic_others_7  ic_others_8  ic_others_9  total_rech_num_6  \\\n",
       "1         0.00         0.00         0.00         0.00                 4   \n",
       "2         0.93         3.14         0.00         0.36                 5   \n",
       "3         0.00         0.00         0.00         0.80                10   \n",
       "4         0.48         0.00         0.00         0.00                 5   \n",
       "5         0.00         0.00         0.23         0.43                 2   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_num_9  total_rech_amt_6  \\\n",
       "1                 9                11                 5                74   \n",
       "2                 4                 2                 7               168   \n",
       "3                11                18                14               230   \n",
       "4                 6                 3                 4               196   \n",
       "5                 2                 3                 3               120   \n",
       "\n",
       "   total_rech_amt_7  total_rech_amt_8  total_rech_amt_9  max_rech_amt_6  \\\n",
       "1               384               283               121              44   \n",
       "2               315               116               358              86   \n",
       "3               310               601               410              60   \n",
       "4               350               287               200              56   \n",
       "5                 0               130               130             120   \n",
       "\n",
       "   max_rech_amt_7  max_rech_amt_8  max_rech_amt_9 date_of_last_rech_6  \\\n",
       "1             154              65              50           6/29/2014   \n",
       "2             200              86             100           6/17/2014   \n",
       "3              50              50              50           6/28/2014   \n",
       "4             110             110              50           6/26/2014   \n",
       "5               0             130             130           6/19/2014   \n",
       "\n",
       "  date_of_last_rech_7 date_of_last_rech_8 date_of_last_rech_9  \\\n",
       "1           7/31/2014           8/28/2014           9/30/2014   \n",
       "2           7/24/2014           8/14/2014           9/29/2014   \n",
       "3           7/31/2014           8/31/2014           9/30/2014   \n",
       "4           7/28/2014            8/9/2014           9/28/2014   \n",
       "5           7/17/2014           8/24/2014           9/28/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "1                  44                  23                  30   \n",
       "2                   0                 200                  86   \n",
       "3                  30                  50                  50   \n",
       "4                  50                 110                 110   \n",
       "5                 120                   0                   0   \n",
       "\n",
       "   last_day_rch_amt_9  vol_2g_mb_6  vol_2g_mb_7  vol_2g_mb_8  vol_2g_mb_9  \\\n",
       "1                   0          0.0       108.07       365.47          0.0   \n",
       "2                   0          0.0         0.00         0.00          0.0   \n",
       "3                  30          0.0         0.00         0.00          0.0   \n",
       "4                  50          0.0         0.00         0.00          0.0   \n",
       "5                   0          0.0         0.00         0.00          0.0   \n",
       "\n",
       "   vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  vol_3g_mb_9  monthly_2g_6  \\\n",
       "1          0.0          0.0          0.0         0.00             0   \n",
       "2          0.0          0.0          0.0         8.42             0   \n",
       "3          0.0          0.0          0.0         0.00             0   \n",
       "4          0.0          0.0          0.0         0.00             0   \n",
       "5          0.0          0.0          0.0         0.00             0   \n",
       "\n",
       "   monthly_2g_7  monthly_2g_8  monthly_2g_9  sachet_2g_6  sachet_2g_7  \\\n",
       "1             1             0             0            0            0   \n",
       "2             0             0             0            0            0   \n",
       "3             0             0             0            0            0   \n",
       "4             0             0             0            1            0   \n",
       "5             0             0             0            0            0   \n",
       "\n",
       "   sachet_2g_8  sachet_2g_9  monthly_3g_6  monthly_3g_7  monthly_3g_8  \\\n",
       "1            2            0             0             0             0   \n",
       "2            0            1             0             0             0   \n",
       "3            0            0             0             0             0   \n",
       "4            0            0             0             0             0   \n",
       "5            0            0             0             0             0   \n",
       "\n",
       "   monthly_3g_9  sachet_3g_6  sachet_3g_7  sachet_3g_8  sachet_3g_9   aon  \\\n",
       "1             0            0            0            0            0  1006   \n",
       "2             0            0            0            0            0  1103   \n",
       "3             0            0            0            0            0  2491   \n",
       "4             0            0            0            0            0  1526   \n",
       "5             0            0            0            0            0  1471   \n",
       "\n",
       "   aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  \n",
       "1         0.0         0.0        0.00         0.0  \n",
       "2         0.0         0.0        4.17         0.0  \n",
       "3         0.0         0.0        0.00         0.0  \n",
       "4         0.0         0.0        0.00         0.0  \n",
       "5         0.0         0.0        0.00         0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering High Value Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the High Value Data on the basis of average recharge amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to predict churn only for the high value customers. The definition for the high value customers as per the problem statement is as follows:\n",
    "<br>\n",
    "**High Value Customers**: Those who have recharged with an amount more than or equal to X, where X is the **70th percentile** of the average recharge amount in the first two months (the good phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_num_9</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_rech_amt_9</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>max_rech_amt_9</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>date_of_last_rech_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>384</td>\n",
       "      <td>283</td>\n",
       "      <td>121</td>\n",
       "      <td>44</td>\n",
       "      <td>154</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>315</td>\n",
       "      <td>116</td>\n",
       "      <td>358</td>\n",
       "      <td>86</td>\n",
       "      <td>200</td>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>7/24/2014</td>\n",
       "      <td>8/14/2014</td>\n",
       "      <td>9/29/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>230</td>\n",
       "      <td>310</td>\n",
       "      <td>601</td>\n",
       "      <td>410</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>6/28/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>196</td>\n",
       "      <td>350</td>\n",
       "      <td>287</td>\n",
       "      <td>200</td>\n",
       "      <td>56</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/26/2014</td>\n",
       "      <td>7/28/2014</td>\n",
       "      <td>8/9/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/17/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99991</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>200</td>\n",
       "      <td>260</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>50</td>\n",
       "      <td>6/27/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99992</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>180</td>\n",
       "      <td>240</td>\n",
       "      <td>220</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>6/27/2014</td>\n",
       "      <td>7/30/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99994</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6/3/2014</td>\n",
       "      <td>7/20/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>9/25/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99995</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>182</td>\n",
       "      <td>30</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>149</td>\n",
       "      <td>30</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>7/17/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>9/26/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99997</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>381</td>\n",
       "      <td>358</td>\n",
       "      <td>716</td>\n",
       "      <td>862</td>\n",
       "      <td>202</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>252</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>7/19/2014</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>9/17/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84185 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_rech_num_6  total_rech_num_7  total_rech_num_8  total_rech_num_9  \\\n",
       "1                     4                 9                11                 5   \n",
       "2                     5                 4                 2                 7   \n",
       "3                    10                11                18                14   \n",
       "4                     5                 6                 3                 4   \n",
       "5                     2                 2                 3                 3   \n",
       "...                 ...               ...               ...               ...   \n",
       "99991                 3                 4                 2                 3   \n",
       "99992                 3                 9                19                17   \n",
       "99994                 2                 3                 2                 2   \n",
       "99995                 5                 3                 2                 1   \n",
       "99997                 3                 4                 4                 6   \n",
       "\n",
       "       total_rech_amt_6  total_rech_amt_7  total_rech_amt_8  total_rech_amt_9  \\\n",
       "1                    74               384               283               121   \n",
       "2                   168               315               116               358   \n",
       "3                   230               310               601               410   \n",
       "4                   196               350               287               200   \n",
       "5                   120                 0               130               130   \n",
       "...                 ...               ...               ...               ...   \n",
       "99991               120               200               260               110   \n",
       "99992                60               180               240               220   \n",
       "99994                60               110                 0                50   \n",
       "99995               110               110               182                30   \n",
       "99997               381               358               716               862   \n",
       "\n",
       "       max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  max_rech_amt_9  \\\n",
       "1                  44             154              65              50   \n",
       "2                  86             200              86             100   \n",
       "3                  60              50              50              50   \n",
       "4                  56             110             110              50   \n",
       "5                 120               0             130             130   \n",
       "...               ...             ...             ...             ...   \n",
       "99991              60             110             130              50   \n",
       "99992              30              30              20              20   \n",
       "99994              60             110               0              50   \n",
       "99995             110             110             149              30   \n",
       "99997             202             179             179             252   \n",
       "\n",
       "      date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "1               6/29/2014           7/31/2014           8/28/2014   \n",
       "2               6/17/2014           7/24/2014           8/14/2014   \n",
       "3               6/28/2014           7/31/2014           8/31/2014   \n",
       "4               6/26/2014           7/28/2014            8/9/2014   \n",
       "5               6/19/2014           7/17/2014           8/24/2014   \n",
       "...                   ...                 ...                 ...   \n",
       "99991           6/27/2014           7/31/2014           8/25/2014   \n",
       "99992           6/27/2014           7/30/2014           8/30/2014   \n",
       "99994            6/3/2014           7/20/2014           8/26/2014   \n",
       "99995           6/17/2014           7/17/2014           8/24/2014   \n",
       "99997           6/17/2014           7/19/2014           8/20/2014   \n",
       "\n",
       "      date_of_last_rech_9  \n",
       "1               9/30/2014  \n",
       "2               9/29/2014  \n",
       "3               9/30/2014  \n",
       "4               9/28/2014  \n",
       "5               9/28/2014  \n",
       "...                   ...  \n",
       "99991           9/28/2014  \n",
       "99992           9/30/2014  \n",
       "99994           9/25/2014  \n",
       "99995           9/26/2014  \n",
       "99997           9/17/2014  \n",
       "\n",
       "[84185 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the columns which contain 'rech' keyword\n",
    "df.loc[:, df.columns.str.contains('rech')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_rech_amt_g']=(df['total_rech_amt_6']+df['total_rech_amt_7'])/2\n",
    "x=df['average_rech_amt_g'].quantile(0.70)\n",
    "fdf=df.loc[df['average_rech_amt_g']>=x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25335, 187)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25335 entries, 8 to 99988\n",
      "Data columns (total 187 columns):\n",
      "mobile_number           int64\n",
      "circle_id               int64\n",
      "loc_og_t2o_mou          float64\n",
      "std_og_t2o_mou          float64\n",
      "loc_ic_t2o_mou          float64\n",
      "last_date_of_month_6    object\n",
      "last_date_of_month_7    object\n",
      "last_date_of_month_8    object\n",
      "last_date_of_month_9    object\n",
      "arpu_6                  float64\n",
      "arpu_7                  float64\n",
      "arpu_8                  float64\n",
      "arpu_9                  float64\n",
      "onnet_mou_6             float64\n",
      "onnet_mou_7             float64\n",
      "onnet_mou_8             float64\n",
      "onnet_mou_9             float64\n",
      "offnet_mou_6            float64\n",
      "offnet_mou_7            float64\n",
      "offnet_mou_8            float64\n",
      "offnet_mou_9            float64\n",
      "roam_ic_mou_6           float64\n",
      "roam_ic_mou_7           float64\n",
      "roam_ic_mou_8           float64\n",
      "roam_ic_mou_9           float64\n",
      "roam_og_mou_6           float64\n",
      "roam_og_mou_7           float64\n",
      "roam_og_mou_8           float64\n",
      "roam_og_mou_9           float64\n",
      "loc_og_t2t_mou_6        float64\n",
      "loc_og_t2t_mou_7        float64\n",
      "loc_og_t2t_mou_8        float64\n",
      "loc_og_t2t_mou_9        float64\n",
      "loc_og_t2m_mou_6        float64\n",
      "loc_og_t2m_mou_7        float64\n",
      "loc_og_t2m_mou_8        float64\n",
      "loc_og_t2m_mou_9        float64\n",
      "loc_og_t2f_mou_6        float64\n",
      "loc_og_t2f_mou_7        float64\n",
      "loc_og_t2f_mou_8        float64\n",
      "loc_og_t2f_mou_9        float64\n",
      "loc_og_t2c_mou_6        float64\n",
      "loc_og_t2c_mou_7        float64\n",
      "loc_og_t2c_mou_8        float64\n",
      "loc_og_t2c_mou_9        float64\n",
      "loc_og_mou_6            float64\n",
      "loc_og_mou_7            float64\n",
      "loc_og_mou_8            float64\n",
      "loc_og_mou_9            float64\n",
      "std_og_t2t_mou_6        float64\n",
      "std_og_t2t_mou_7        float64\n",
      "std_og_t2t_mou_8        float64\n",
      "std_og_t2t_mou_9        float64\n",
      "std_og_t2m_mou_6        float64\n",
      "std_og_t2m_mou_7        float64\n",
      "std_og_t2m_mou_8        float64\n",
      "std_og_t2m_mou_9        float64\n",
      "std_og_t2f_mou_6        float64\n",
      "std_og_t2f_mou_7        float64\n",
      "std_og_t2f_mou_8        float64\n",
      "std_og_t2f_mou_9        float64\n",
      "std_og_t2c_mou_6        float64\n",
      "std_og_t2c_mou_7        float64\n",
      "std_og_t2c_mou_8        float64\n",
      "std_og_t2c_mou_9        float64\n",
      "std_og_mou_6            float64\n",
      "std_og_mou_7            float64\n",
      "std_og_mou_8            float64\n",
      "std_og_mou_9            float64\n",
      "isd_og_mou_6            float64\n",
      "isd_og_mou_7            float64\n",
      "isd_og_mou_8            float64\n",
      "isd_og_mou_9            float64\n",
      "spl_og_mou_6            float64\n",
      "spl_og_mou_7            float64\n",
      "spl_og_mou_8            float64\n",
      "spl_og_mou_9            float64\n",
      "og_others_6             float64\n",
      "og_others_7             float64\n",
      "og_others_8             float64\n",
      "og_others_9             float64\n",
      "total_og_mou_6          float64\n",
      "total_og_mou_7          float64\n",
      "total_og_mou_8          float64\n",
      "total_og_mou_9          float64\n",
      "loc_ic_t2t_mou_6        float64\n",
      "loc_ic_t2t_mou_7        float64\n",
      "loc_ic_t2t_mou_8        float64\n",
      "loc_ic_t2t_mou_9        float64\n",
      "loc_ic_t2m_mou_6        float64\n",
      "loc_ic_t2m_mou_7        float64\n",
      "loc_ic_t2m_mou_8        float64\n",
      "loc_ic_t2m_mou_9        float64\n",
      "loc_ic_t2f_mou_6        float64\n",
      "loc_ic_t2f_mou_7        float64\n",
      "loc_ic_t2f_mou_8        float64\n",
      "loc_ic_t2f_mou_9        float64\n",
      "loc_ic_mou_6            float64\n",
      "loc_ic_mou_7            float64\n",
      "loc_ic_mou_8            float64\n",
      "loc_ic_mou_9            float64\n",
      "std_ic_t2t_mou_6        float64\n",
      "std_ic_t2t_mou_7        float64\n",
      "std_ic_t2t_mou_8        float64\n",
      "std_ic_t2t_mou_9        float64\n",
      "std_ic_t2m_mou_6        float64\n",
      "std_ic_t2m_mou_7        float64\n",
      "std_ic_t2m_mou_8        float64\n",
      "std_ic_t2m_mou_9        float64\n",
      "std_ic_t2f_mou_6        float64\n",
      "std_ic_t2f_mou_7        float64\n",
      "std_ic_t2f_mou_8        float64\n",
      "std_ic_t2f_mou_9        float64\n",
      "std_ic_t2o_mou_6        float64\n",
      "std_ic_t2o_mou_7        float64\n",
      "std_ic_t2o_mou_8        float64\n",
      "std_ic_t2o_mou_9        float64\n",
      "std_ic_mou_6            float64\n",
      "std_ic_mou_7            float64\n",
      "std_ic_mou_8            float64\n",
      "std_ic_mou_9            float64\n",
      "total_ic_mou_6          float64\n",
      "total_ic_mou_7          float64\n",
      "total_ic_mou_8          float64\n",
      "total_ic_mou_9          float64\n",
      "spl_ic_mou_6            float64\n",
      "spl_ic_mou_7            float64\n",
      "spl_ic_mou_8            float64\n",
      "spl_ic_mou_9            float64\n",
      "isd_ic_mou_6            float64\n",
      "isd_ic_mou_7            float64\n",
      "isd_ic_mou_8            float64\n",
      "isd_ic_mou_9            float64\n",
      "ic_others_6             float64\n",
      "ic_others_7             float64\n",
      "ic_others_8             float64\n",
      "ic_others_9             float64\n",
      "total_rech_num_6        int64\n",
      "total_rech_num_7        int64\n",
      "total_rech_num_8        int64\n",
      "total_rech_num_9        int64\n",
      "total_rech_amt_6        int64\n",
      "total_rech_amt_7        int64\n",
      "total_rech_amt_8        int64\n",
      "total_rech_amt_9        int64\n",
      "max_rech_amt_6          int64\n",
      "max_rech_amt_7          int64\n",
      "max_rech_amt_8          int64\n",
      "max_rech_amt_9          int64\n",
      "date_of_last_rech_6     object\n",
      "date_of_last_rech_7     object\n",
      "date_of_last_rech_8     object\n",
      "date_of_last_rech_9     object\n",
      "last_day_rch_amt_6      int64\n",
      "last_day_rch_amt_7      int64\n",
      "last_day_rch_amt_8      int64\n",
      "last_day_rch_amt_9      int64\n",
      "vol_2g_mb_6             float64\n",
      "vol_2g_mb_7             float64\n",
      "vol_2g_mb_8             float64\n",
      "vol_2g_mb_9             float64\n",
      "vol_3g_mb_6             float64\n",
      "vol_3g_mb_7             float64\n",
      "vol_3g_mb_8             float64\n",
      "vol_3g_mb_9             float64\n",
      "monthly_2g_6            int64\n",
      "monthly_2g_7            int64\n",
      "monthly_2g_8            int64\n",
      "monthly_2g_9            int64\n",
      "sachet_2g_6             int64\n",
      "sachet_2g_7             int64\n",
      "sachet_2g_8             int64\n",
      "sachet_2g_9             int64\n",
      "monthly_3g_6            int64\n",
      "monthly_3g_7            int64\n",
      "monthly_3g_8            int64\n",
      "monthly_3g_9            int64\n",
      "sachet_3g_6             int64\n",
      "sachet_3g_7             int64\n",
      "sachet_3g_8             int64\n",
      "sachet_3g_9             int64\n",
      "aon                     int64\n",
      "aug_vbc_3g              float64\n",
      "jul_vbc_3g              float64\n",
      "jun_vbc_3g              float64\n",
      "sep_vbc_3g              float64\n",
      "average_rech_amt_g      float64\n",
      "dtypes: float64(144), int64(35), object(8)\n",
      "memory usage: 36.3+ MB\n"
     ]
    }
   ],
   "source": [
    "fdf.info(verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>arpu_9</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>onnet_mou_9</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>offnet_mou_9</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_ic_mou_9</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>roam_og_mou_9</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_9</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_9</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_9</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_9</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>loc_og_mou_9</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2t_mou_9</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2m_mou_9</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2f_mou_9</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_t2c_mou_9</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>std_og_mou_9</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>isd_og_mou_9</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>spl_og_mou_9</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>og_others_9</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>total_og_mou_9</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_9</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_9</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_9</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>loc_ic_mou_9</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_9</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_9</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_9</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_9</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>std_ic_mou_9</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>total_ic_mou_9</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_9</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_9</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>ic_others_9</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_num_9</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_rech_amt_9</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>max_rech_amt_9</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>last_day_rch_amt_9</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_2g_mb_9</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>vol_3g_mb_9</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>monthly_2g_9</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>sachet_2g_9</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>monthly_3g_9</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>average_rech_amt_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2.533500e+04</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>7.001231e+09</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>605.381915</td>\n",
       "      <td>618.668251</td>\n",
       "      <td>580.047979</td>\n",
       "      <td>539.711103</td>\n",
       "      <td>308.772567</td>\n",
       "      <td>323.663869</td>\n",
       "      <td>294.68391</td>\n",
       "      <td>269.313954</td>\n",
       "      <td>434.100403</td>\n",
       "      <td>448.695341</td>\n",
       "      <td>410.454928</td>\n",
       "      <td>375.18889</td>\n",
       "      <td>18.061622</td>\n",
       "      <td>14.346624</td>\n",
       "      <td>14.582006</td>\n",
       "      <td>12.838677</td>\n",
       "      <td>30.56156</td>\n",
       "      <td>23.280403</td>\n",
       "      <td>23.590945</td>\n",
       "      <td>19.478126</td>\n",
       "      <td>99.960790</td>\n",
       "      <td>103.126631</td>\n",
       "      <td>95.763798</td>\n",
       "      <td>89.748857</td>\n",
       "      <td>190.822741</td>\n",
       "      <td>193.354505</td>\n",
       "      <td>183.183204</td>\n",
       "      <td>174.409525</td>\n",
       "      <td>7.326504</td>\n",
       "      <td>7.524519</td>\n",
       "      <td>7.006037</td>\n",
       "      <td>6.902271</td>\n",
       "      <td>1.608491</td>\n",
       "      <td>1.905115</td>\n",
       "      <td>1.811716</td>\n",
       "      <td>1.550170</td>\n",
       "      <td>298.119074</td>\n",
       "      <td>304.014879</td>\n",
       "      <td>285.961925</td>\n",
       "      <td>271.069297</td>\n",
       "      <td>196.812613</td>\n",
       "      <td>211.379736</td>\n",
       "      <td>189.782722</td>\n",
       "      <td>171.691855</td>\n",
       "      <td>208.44343</td>\n",
       "      <td>224.532096</td>\n",
       "      <td>197.083311</td>\n",
       "      <td>174.495441</td>\n",
       "      <td>2.083931</td>\n",
       "      <td>2.132881</td>\n",
       "      <td>1.899306</td>\n",
       "      <td>1.800965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>407.344440</td>\n",
       "      <td>438.049207</td>\n",
       "      <td>388.769519</td>\n",
       "      <td>347.992249</td>\n",
       "      <td>2.125238</td>\n",
       "      <td>2.191998</td>\n",
       "      <td>2.156291</td>\n",
       "      <td>1.945745</td>\n",
       "      <td>6.030383</td>\n",
       "      <td>7.639063</td>\n",
       "      <td>7.345974</td>\n",
       "      <td>6.176769</td>\n",
       "      <td>0.704512</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.049230</td>\n",
       "      <td>0.094892</td>\n",
       "      <td>714.333663</td>\n",
       "      <td>751.943194</td>\n",
       "      <td>684.291694</td>\n",
       "      <td>627.287414</td>\n",
       "      <td>71.333108</td>\n",
       "      <td>73.848361</td>\n",
       "      <td>71.173280</td>\n",
       "      <td>68.356177</td>\n",
       "      <td>166.124937</td>\n",
       "      <td>169.562449</td>\n",
       "      <td>166.215392</td>\n",
       "      <td>158.136124</td>\n",
       "      <td>16.339769</td>\n",
       "      <td>17.317704</td>\n",
       "      <td>15.785543</td>\n",
       "      <td>16.258380</td>\n",
       "      <td>253.807895</td>\n",
       "      <td>260.738785</td>\n",
       "      <td>253.184272</td>\n",
       "      <td>242.760671</td>\n",
       "      <td>16.844002</td>\n",
       "      <td>17.88079</td>\n",
       "      <td>16.471824</td>\n",
       "      <td>15.634095</td>\n",
       "      <td>32.600116</td>\n",
       "      <td>34.782159</td>\n",
       "      <td>32.666067</td>\n",
       "      <td>29.869764</td>\n",
       "      <td>3.025538</td>\n",
       "      <td>3.149795</td>\n",
       "      <td>2.881318</td>\n",
       "      <td>2.962192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.473777</td>\n",
       "      <td>55.816969</td>\n",
       "      <td>52.023210</td>\n",
       "      <td>48.469934</td>\n",
       "      <td>318.424015</td>\n",
       "      <td>330.484101</td>\n",
       "      <td>318.718816</td>\n",
       "      <td>304.456263</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>0.143782</td>\n",
       "      <td>10.841112</td>\n",
       "      <td>12.306502</td>\n",
       "      <td>12.156147</td>\n",
       "      <td>11.640142</td>\n",
       "      <td>1.225623</td>\n",
       "      <td>1.596091</td>\n",
       "      <td>1.317898</td>\n",
       "      <td>1.433080</td>\n",
       "      <td>12.369213</td>\n",
       "      <td>12.339925</td>\n",
       "      <td>10.954529</td>\n",
       "      <td>10.530255</td>\n",
       "      <td>717.326071</td>\n",
       "      <td>730.384054</td>\n",
       "      <td>669.618315</td>\n",
       "      <td>628.554727</td>\n",
       "      <td>170.440300</td>\n",
       "      <td>176.367397</td>\n",
       "      <td>171.691455</td>\n",
       "      <td>168.035485</td>\n",
       "      <td>103.618394</td>\n",
       "      <td>106.819814</td>\n",
       "      <td>101.055181</td>\n",
       "      <td>73.296428</td>\n",
       "      <td>80.828362</td>\n",
       "      <td>80.695662</td>\n",
       "      <td>74.095703</td>\n",
       "      <td>66.970864</td>\n",
       "      <td>259.031232</td>\n",
       "      <td>285.911329</td>\n",
       "      <td>286.022239</td>\n",
       "      <td>292.322928</td>\n",
       "      <td>0.131202</td>\n",
       "      <td>0.138701</td>\n",
       "      <td>0.122913</td>\n",
       "      <td>0.107953</td>\n",
       "      <td>0.508861</td>\n",
       "      <td>0.606315</td>\n",
       "      <td>0.647642</td>\n",
       "      <td>0.563726</td>\n",
       "      <td>0.176436</td>\n",
       "      <td>0.192856</td>\n",
       "      <td>0.185554</td>\n",
       "      <td>0.194237</td>\n",
       "      <td>0.142333</td>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.154411</td>\n",
       "      <td>0.149398</td>\n",
       "      <td>1290.944622</td>\n",
       "      <td>139.401235</td>\n",
       "      <td>142.534482</td>\n",
       "      <td>126.035382</td>\n",
       "      <td>7.215953</td>\n",
       "      <td>723.855062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>6.800902e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>437.843670</td>\n",
       "      <td>464.965572</td>\n",
       "      <td>502.170458</td>\n",
       "      <td>505.824898</td>\n",
       "      <td>467.783907</td>\n",
       "      <td>494.784885</td>\n",
       "      <td>487.04074</td>\n",
       "      <td>464.580570</td>\n",
       "      <td>470.461181</td>\n",
       "      <td>494.027416</td>\n",
       "      <td>491.009571</td>\n",
       "      <td>459.10733</td>\n",
       "      <td>79.379923</td>\n",
       "      <td>79.562310</td>\n",
       "      <td>79.311801</td>\n",
       "      <td>73.212563</td>\n",
       "      <td>120.77578</td>\n",
       "      <td>101.356114</td>\n",
       "      <td>112.585652</td>\n",
       "      <td>96.627672</td>\n",
       "      <td>245.564009</td>\n",
       "      <td>262.585641</td>\n",
       "      <td>249.911233</td>\n",
       "      <td>242.902259</td>\n",
       "      <td>256.217219</td>\n",
       "      <td>247.363734</td>\n",
       "      <td>242.759117</td>\n",
       "      <td>243.334144</td>\n",
       "      <td>22.025513</td>\n",
       "      <td>22.588417</td>\n",
       "      <td>21.293992</td>\n",
       "      <td>21.498673</td>\n",
       "      <td>6.989765</td>\n",
       "      <td>9.246516</td>\n",
       "      <td>7.658958</td>\n",
       "      <td>6.572505</td>\n",
       "      <td>390.703307</td>\n",
       "      <td>390.011607</td>\n",
       "      <td>381.771064</td>\n",
       "      <td>379.753460</td>\n",
       "      <td>415.838101</td>\n",
       "      <td>438.203399</td>\n",
       "      <td>428.727579</td>\n",
       "      <td>404.208737</td>\n",
       "      <td>414.50022</td>\n",
       "      <td>448.737359</td>\n",
       "      <td>436.163646</td>\n",
       "      <td>392.676262</td>\n",
       "      <td>12.723130</td>\n",
       "      <td>13.952247</td>\n",
       "      <td>11.992246</td>\n",
       "      <td>12.465551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>609.228997</td>\n",
       "      <td>651.051194</td>\n",
       "      <td>640.513506</td>\n",
       "      <td>593.202566</td>\n",
       "      <td>47.841689</td>\n",
       "      <td>48.191701</td>\n",
       "      <td>48.117680</td>\n",
       "      <td>39.440580</td>\n",
       "      <td>18.869381</td>\n",
       "      <td>23.583356</td>\n",
       "      <td>23.659722</td>\n",
       "      <td>19.541272</td>\n",
       "      <td>2.330394</td>\n",
       "      <td>1.862022</td>\n",
       "      <td>2.733586</td>\n",
       "      <td>5.977913</td>\n",
       "      <td>659.239073</td>\n",
       "      <td>692.061684</td>\n",
       "      <td>699.416899</td>\n",
       "      <td>669.294780</td>\n",
       "      <td>159.764080</td>\n",
       "      <td>167.999534</td>\n",
       "      <td>162.414297</td>\n",
       "      <td>168.704613</td>\n",
       "      <td>222.977501</td>\n",
       "      <td>222.864795</td>\n",
       "      <td>223.408317</td>\n",
       "      <td>212.539206</td>\n",
       "      <td>47.329733</td>\n",
       "      <td>50.779238</td>\n",
       "      <td>45.608537</td>\n",
       "      <td>56.591804</td>\n",
       "      <td>313.758944</td>\n",
       "      <td>318.977995</td>\n",
       "      <td>316.417005</td>\n",
       "      <td>315.233280</td>\n",
       "      <td>82.455660</td>\n",
       "      <td>90.11867</td>\n",
       "      <td>77.316442</td>\n",
       "      <td>74.839966</td>\n",
       "      <td>98.893301</td>\n",
       "      <td>105.551242</td>\n",
       "      <td>109.024813</td>\n",
       "      <td>97.472437</td>\n",
       "      <td>21.174910</td>\n",
       "      <td>21.633461</td>\n",
       "      <td>21.648678</td>\n",
       "      <td>21.458616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.642485</td>\n",
       "      <td>153.424340</td>\n",
       "      <td>147.512098</td>\n",
       "      <td>137.805366</td>\n",
       "      <td>361.531618</td>\n",
       "      <td>373.960638</td>\n",
       "      <td>370.339577</td>\n",
       "      <td>368.825023</td>\n",
       "      <td>0.157630</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.113819</td>\n",
       "      <td>0.481188</td>\n",
       "      <td>66.542701</td>\n",
       "      <td>76.654492</td>\n",
       "      <td>77.125182</td>\n",
       "      <td>78.966015</td>\n",
       "      <td>14.871170</td>\n",
       "      <td>16.591331</td>\n",
       "      <td>13.609714</td>\n",
       "      <td>14.653972</td>\n",
       "      <td>9.478604</td>\n",
       "      <td>9.636941</td>\n",
       "      <td>9.581220</td>\n",
       "      <td>9.177389</td>\n",
       "      <td>535.704258</td>\n",
       "      <td>562.700046</td>\n",
       "      <td>615.007473</td>\n",
       "      <td>594.838126</td>\n",
       "      <td>164.154017</td>\n",
       "      <td>173.003988</td>\n",
       "      <td>169.981003</td>\n",
       "      <td>168.862541</td>\n",
       "      <td>131.004585</td>\n",
       "      <td>133.878195</td>\n",
       "      <td>143.671631</td>\n",
       "      <td>125.580816</td>\n",
       "      <td>279.498393</td>\n",
       "      <td>284.506065</td>\n",
       "      <td>278.235033</td>\n",
       "      <td>253.897541</td>\n",
       "      <td>810.698076</td>\n",
       "      <td>848.283045</td>\n",
       "      <td>861.636669</td>\n",
       "      <td>892.571162</td>\n",
       "      <td>0.382467</td>\n",
       "      <td>0.397484</td>\n",
       "      <td>0.369948</td>\n",
       "      <td>0.350807</td>\n",
       "      <td>1.706819</td>\n",
       "      <td>1.910562</td>\n",
       "      <td>1.886947</td>\n",
       "      <td>1.591092</td>\n",
       "      <td>0.579352</td>\n",
       "      <td>0.641568</td>\n",
       "      <td>0.605907</td>\n",
       "      <td>0.602066</td>\n",
       "      <td>0.881705</td>\n",
       "      <td>0.984721</td>\n",
       "      <td>1.033961</td>\n",
       "      <td>0.985798</td>\n",
       "      <td>978.149101</td>\n",
       "      <td>405.205464</td>\n",
       "      <td>421.298082</td>\n",
       "      <td>395.788710</td>\n",
       "      <td>50.055596</td>\n",
       "      <td>500.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>7.000000e+09</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-810.661000</td>\n",
       "      <td>-622.509000</td>\n",
       "      <td>-345.129000</td>\n",
       "      <td>-1474.195000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.000653e+09</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>383.939000</td>\n",
       "      <td>391.220000</td>\n",
       "      <td>334.649000</td>\n",
       "      <td>291.030000</td>\n",
       "      <td>46.445000</td>\n",
       "      <td>47.740000</td>\n",
       "      <td>37.66000</td>\n",
       "      <td>29.810000</td>\n",
       "      <td>149.680000</td>\n",
       "      <td>153.120000</td>\n",
       "      <td>121.825000</td>\n",
       "      <td>98.31000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.730000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>6.790000</td>\n",
       "      <td>34.110000</td>\n",
       "      <td>38.880000</td>\n",
       "      <td>30.635000</td>\n",
       "      <td>26.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.770000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>51.520000</td>\n",
       "      <td>44.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.38000</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>7.790000</td>\n",
       "      <td>4.535000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>291.950000</td>\n",
       "      <td>309.570000</td>\n",
       "      <td>241.720000</td>\n",
       "      <td>199.820000</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>9.130000</td>\n",
       "      <td>8.290000</td>\n",
       "      <td>37.135000</td>\n",
       "      <td>42.635000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>33.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.315000</td>\n",
       "      <td>71.730000</td>\n",
       "      <td>62.880000</td>\n",
       "      <td>57.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>97.540000</td>\n",
       "      <td>109.360000</td>\n",
       "      <td>96.135000</td>\n",
       "      <td>85.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>453.500000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>474.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>7.001246e+09</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.599000</td>\n",
       "      <td>520.648000</td>\n",
       "      <td>489.762000</td>\n",
       "      <td>455.884000</td>\n",
       "      <td>135.880000</td>\n",
       "      <td>139.330000</td>\n",
       "      <td>118.04000</td>\n",
       "      <td>103.310000</td>\n",
       "      <td>299.190000</td>\n",
       "      <td>305.130000</td>\n",
       "      <td>271.480000</td>\n",
       "      <td>241.33000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.310000</td>\n",
       "      <td>37.060000</td>\n",
       "      <td>33.890000</td>\n",
       "      <td>30.580000</td>\n",
       "      <td>109.310000</td>\n",
       "      <td>114.260000</td>\n",
       "      <td>104.030000</td>\n",
       "      <td>94.590000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.840000</td>\n",
       "      <td>188.190000</td>\n",
       "      <td>170.930000</td>\n",
       "      <td>156.130000</td>\n",
       "      <td>15.390000</td>\n",
       "      <td>17.130000</td>\n",
       "      <td>9.950000</td>\n",
       "      <td>7.730000</td>\n",
       "      <td>42.41000</td>\n",
       "      <td>43.780000</td>\n",
       "      <td>32.010000</td>\n",
       "      <td>25.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.740000</td>\n",
       "      <td>155.510000</td>\n",
       "      <td>103.240000</td>\n",
       "      <td>81.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>542.580000</td>\n",
       "      <td>570.810000</td>\n",
       "      <td>495.260000</td>\n",
       "      <td>445.680000</td>\n",
       "      <td>31.380000</td>\n",
       "      <td>33.090000</td>\n",
       "      <td>30.390000</td>\n",
       "      <td>28.810000</td>\n",
       "      <td>99.930000</td>\n",
       "      <td>103.810000</td>\n",
       "      <td>100.730000</td>\n",
       "      <td>93.780000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>2.240000</td>\n",
       "      <td>160.530000</td>\n",
       "      <td>166.990000</td>\n",
       "      <td>159.790000</td>\n",
       "      <td>149.480000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.53000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.130000</td>\n",
       "      <td>17.610000</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>216.910000</td>\n",
       "      <td>225.110000</td>\n",
       "      <td>213.330000</td>\n",
       "      <td>199.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.001814e+09</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>718.534500</td>\n",
       "      <td>728.702500</td>\n",
       "      <td>712.486000</td>\n",
       "      <td>677.751000</td>\n",
       "      <td>373.975000</td>\n",
       "      <td>391.550000</td>\n",
       "      <td>339.67500</td>\n",
       "      <td>299.980000</td>\n",
       "      <td>546.900000</td>\n",
       "      <td>568.160000</td>\n",
       "      <td>522.885000</td>\n",
       "      <td>478.54500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.335000</td>\n",
       "      <td>98.285000</td>\n",
       "      <td>94.650000</td>\n",
       "      <td>87.775000</td>\n",
       "      <td>253.535000</td>\n",
       "      <td>257.235000</td>\n",
       "      <td>244.405000</td>\n",
       "      <td>230.130000</td>\n",
       "      <td>5.540000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>393.350000</td>\n",
       "      <td>404.120000</td>\n",
       "      <td>379.560000</td>\n",
       "      <td>360.370000</td>\n",
       "      <td>191.850000</td>\n",
       "      <td>211.660000</td>\n",
       "      <td>163.910000</td>\n",
       "      <td>138.875000</td>\n",
       "      <td>220.50000</td>\n",
       "      <td>241.395000</td>\n",
       "      <td>193.235000</td>\n",
       "      <td>164.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>599.365000</td>\n",
       "      <td>657.635000</td>\n",
       "      <td>547.335000</td>\n",
       "      <td>467.285000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>7.460000</td>\n",
       "      <td>7.110000</td>\n",
       "      <td>5.655000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>930.725000</td>\n",
       "      <td>980.185000</td>\n",
       "      <td>902.935000</td>\n",
       "      <td>830.910000</td>\n",
       "      <td>77.195000</td>\n",
       "      <td>79.450000</td>\n",
       "      <td>76.880000</td>\n",
       "      <td>72.810000</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>215.200000</td>\n",
       "      <td>212.100000</td>\n",
       "      <td>201.715000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>14.135000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>12.830000</td>\n",
       "      <td>328.350000</td>\n",
       "      <td>335.180000</td>\n",
       "      <td>325.825000</td>\n",
       "      <td>312.830000</td>\n",
       "      <td>10.930000</td>\n",
       "      <td>11.79000</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>9.130000</td>\n",
       "      <td>28.530000</td>\n",
       "      <td>31.030000</td>\n",
       "      <td>28.170000</td>\n",
       "      <td>25.640000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.985000</td>\n",
       "      <td>52.840000</td>\n",
       "      <td>47.640000</td>\n",
       "      <td>43.975000</td>\n",
       "      <td>407.050000</td>\n",
       "      <td>416.115000</td>\n",
       "      <td>406.200000</td>\n",
       "      <td>390.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>831.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>18.505000</td>\n",
       "      <td>14.395000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.585000</td>\n",
       "      <td>23.915000</td>\n",
       "      <td>12.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>17.595000</td>\n",
       "      <td>9.295000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>826.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>7.002411e+09</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>38805.617000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>10752.56000</td>\n",
       "      <td>10427.460000</td>\n",
       "      <td>8362.360000</td>\n",
       "      <td>9667.130000</td>\n",
       "      <td>14007.340000</td>\n",
       "      <td>10310.76000</td>\n",
       "      <td>2613.310000</td>\n",
       "      <td>3813.290000</td>\n",
       "      <td>4169.810000</td>\n",
       "      <td>3220.660000</td>\n",
       "      <td>3775.11000</td>\n",
       "      <td>2812.040000</td>\n",
       "      <td>5337.040000</td>\n",
       "      <td>4428.460000</td>\n",
       "      <td>6431.330000</td>\n",
       "      <td>7400.660000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>10389.240000</td>\n",
       "      <td>4729.740000</td>\n",
       "      <td>4557.140000</td>\n",
       "      <td>4961.330000</td>\n",
       "      <td>4429.880000</td>\n",
       "      <td>676.480000</td>\n",
       "      <td>1057.960000</td>\n",
       "      <td>928.490000</td>\n",
       "      <td>927.410000</td>\n",
       "      <td>342.860000</td>\n",
       "      <td>569.710000</td>\n",
       "      <td>351.830000</td>\n",
       "      <td>274.890000</td>\n",
       "      <td>10643.380000</td>\n",
       "      <td>7674.780000</td>\n",
       "      <td>11039.910000</td>\n",
       "      <td>11099.260000</td>\n",
       "      <td>7366.580000</td>\n",
       "      <td>8133.660000</td>\n",
       "      <td>8014.430000</td>\n",
       "      <td>7244.160000</td>\n",
       "      <td>8314.76000</td>\n",
       "      <td>9284.740000</td>\n",
       "      <td>13950.040000</td>\n",
       "      <td>10223.430000</td>\n",
       "      <td>628.560000</td>\n",
       "      <td>544.630000</td>\n",
       "      <td>516.910000</td>\n",
       "      <td>808.490000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8432.990000</td>\n",
       "      <td>10936.730000</td>\n",
       "      <td>13980.060000</td>\n",
       "      <td>10238.380000</td>\n",
       "      <td>5900.660000</td>\n",
       "      <td>5490.280000</td>\n",
       "      <td>5681.540000</td>\n",
       "      <td>4244.530000</td>\n",
       "      <td>1023.210000</td>\n",
       "      <td>1265.790000</td>\n",
       "      <td>1390.880000</td>\n",
       "      <td>1069.090000</td>\n",
       "      <td>100.610000</td>\n",
       "      <td>221.940000</td>\n",
       "      <td>394.930000</td>\n",
       "      <td>787.790000</td>\n",
       "      <td>10674.030000</td>\n",
       "      <td>11365.310000</td>\n",
       "      <td>14043.060000</td>\n",
       "      <td>11140.110000</td>\n",
       "      <td>6351.440000</td>\n",
       "      <td>5709.590000</td>\n",
       "      <td>4003.210000</td>\n",
       "      <td>7565.890000</td>\n",
       "      <td>4693.860000</td>\n",
       "      <td>4171.510000</td>\n",
       "      <td>5738.460000</td>\n",
       "      <td>4534.790000</td>\n",
       "      <td>1678.410000</td>\n",
       "      <td>1983.010000</td>\n",
       "      <td>1588.530000</td>\n",
       "      <td>4318.280000</td>\n",
       "      <td>6496.110000</td>\n",
       "      <td>6466.740000</td>\n",
       "      <td>5748.810000</td>\n",
       "      <td>7785.460000</td>\n",
       "      <td>5459.560000</td>\n",
       "      <td>5800.93000</td>\n",
       "      <td>4309.290000</td>\n",
       "      <td>3819.830000</td>\n",
       "      <td>4630.230000</td>\n",
       "      <td>3100.840000</td>\n",
       "      <td>5645.860000</td>\n",
       "      <td>5689.760000</td>\n",
       "      <td>1351.110000</td>\n",
       "      <td>1136.080000</td>\n",
       "      <td>1394.890000</td>\n",
       "      <td>1431.960000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5459.630000</td>\n",
       "      <td>6745.760000</td>\n",
       "      <td>5957.140000</td>\n",
       "      <td>5956.660000</td>\n",
       "      <td>6798.640000</td>\n",
       "      <td>7279.080000</td>\n",
       "      <td>5990.710000</td>\n",
       "      <td>7785.730000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>21.330000</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>21.560000</td>\n",
       "      <td>3965.690000</td>\n",
       "      <td>4747.910000</td>\n",
       "      <td>4100.380000</td>\n",
       "      <td>5057.740000</td>\n",
       "      <td>1344.140000</td>\n",
       "      <td>1495.940000</td>\n",
       "      <td>1209.860000</td>\n",
       "      <td>919.630000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>35190.000000</td>\n",
       "      <td>40335.000000</td>\n",
       "      <td>45320.000000</td>\n",
       "      <td>37235.000000</td>\n",
       "      <td>3559.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>3399.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>3399.000000</td>\n",
       "      <td>10285.900000</td>\n",
       "      <td>7873.550000</td>\n",
       "      <td>11117.610000</td>\n",
       "      <td>8993.950000</td>\n",
       "      <td>26826.130000</td>\n",
       "      <td>28144.120000</td>\n",
       "      <td>29651.830000</td>\n",
       "      <td>26857.040000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4321.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.210000</td>\n",
       "      <td>2618.570000</td>\n",
       "      <td>37762.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  \\\n",
       "count   2.533500e+04    25335.0         25335.0         25335.0   \n",
       "mean    7.001231e+09      109.0             0.0             0.0   \n",
       "std     6.800902e+05        0.0             0.0             0.0   \n",
       "min     7.000000e+09      109.0             0.0             0.0   \n",
       "25%     7.000653e+09      109.0             0.0             0.0   \n",
       "50%     7.001246e+09      109.0             0.0             0.0   \n",
       "75%     7.001814e+09      109.0             0.0             0.0   \n",
       "max     7.002411e+09      109.0             0.0             0.0   \n",
       "\n",
       "       loc_ic_t2o_mou        arpu_6        arpu_7        arpu_8        arpu_9  \\\n",
       "count         25335.0  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean              0.0    605.381915    618.668251    580.047979    539.711103   \n",
       "std               0.0    437.843670    464.965572    502.170458    505.824898   \n",
       "min               0.0   -810.661000   -622.509000   -345.129000  -1474.195000   \n",
       "25%               0.0    383.939000    391.220000    334.649000    291.030000   \n",
       "50%               0.0    512.599000    520.648000    489.762000    455.884000   \n",
       "75%               0.0    718.534500    728.702500    712.486000    677.751000   \n",
       "max               0.0  27731.088000  35145.834000  33543.624000  38805.617000   \n",
       "\n",
       "        onnet_mou_6   onnet_mou_7  onnet_mou_8   onnet_mou_9  offnet_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.00000  25335.000000  25335.000000   \n",
       "mean     308.772567    323.663869    294.68391    269.313954    434.100403   \n",
       "std      467.783907    494.784885    487.04074    464.580570    470.461181   \n",
       "min        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "25%       46.445000     47.740000     37.66000     29.810000    149.680000   \n",
       "50%      135.880000    139.330000    118.04000    103.310000    299.190000   \n",
       "75%      373.975000    391.550000    339.67500    299.980000    546.900000   \n",
       "max     7376.710000   8157.780000  10752.56000  10427.460000   8362.360000   \n",
       "\n",
       "       offnet_mou_7  offnet_mou_8  offnet_mou_9  roam_ic_mou_6  roam_ic_mou_7  \\\n",
       "count  25335.000000  25335.000000   25335.00000   25335.000000   25335.000000   \n",
       "mean     448.695341    410.454928     375.18889      18.061622      14.346624   \n",
       "std      494.027416    491.009571     459.10733      79.379923      79.562310   \n",
       "min        0.000000      0.000000       0.00000       0.000000       0.000000   \n",
       "25%      153.120000    121.825000      98.31000       0.000000       0.000000   \n",
       "50%      305.130000    271.480000     241.33000       0.000000       0.000000   \n",
       "75%      568.160000    522.885000     478.54500       0.000000       0.000000   \n",
       "max     9667.130000  14007.340000   10310.76000    2613.310000    3813.290000   \n",
       "\n",
       "       roam_ic_mou_8  roam_ic_mou_9  roam_og_mou_6  roam_og_mou_7  \\\n",
       "count   25335.000000   25335.000000    25335.00000   25335.000000   \n",
       "mean       14.582006      12.838677       30.56156      23.280403   \n",
       "std        79.311801      73.212563      120.77578     101.356114   \n",
       "min         0.000000       0.000000        0.00000       0.000000   \n",
       "25%         0.000000       0.000000        0.00000       0.000000   \n",
       "50%         0.000000       0.000000        0.00000       0.000000   \n",
       "75%         0.000000       0.000000        0.00000       0.000000   \n",
       "max      4169.810000    3220.660000     3775.11000    2812.040000   \n",
       "\n",
       "       roam_og_mou_8  roam_og_mou_9  loc_og_t2t_mou_6  loc_og_t2t_mou_7  \\\n",
       "count   25335.000000   25335.000000      25335.000000      25335.000000   \n",
       "mean       23.590945      19.478126         99.960790        103.126631   \n",
       "std       112.585652      96.627672        245.564009        262.585641   \n",
       "min         0.000000       0.000000          0.000000          0.000000   \n",
       "25%         0.000000       0.000000          9.730000         10.760000   \n",
       "50%         0.000000       0.000000         35.310000         37.060000   \n",
       "75%         0.000000       0.000000         97.335000         98.285000   \n",
       "max      5337.040000    4428.460000       6431.330000       7400.660000   \n",
       "\n",
       "       loc_og_t2t_mou_8  loc_og_t2t_mou_9  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          95.763798         89.748857        190.822741        193.354505   \n",
       "std          249.911233        242.902259        256.217219        247.363734   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            8.410000          6.790000         34.110000         38.880000   \n",
       "50%           33.890000         30.580000        109.310000        114.260000   \n",
       "75%           94.650000         87.775000        253.535000        257.235000   \n",
       "max        10752.560000      10389.240000       4729.740000       4557.140000   \n",
       "\n",
       "       loc_og_t2m_mou_8  loc_og_t2m_mou_9  loc_og_t2f_mou_6  loc_og_t2f_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         183.183204        174.409525          7.326504          7.524519   \n",
       "std          242.759117        243.334144         22.025513         22.588417   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%           30.635000         26.050000          0.000000          0.000000   \n",
       "50%          104.030000         94.590000          0.480000          0.560000   \n",
       "75%          244.405000        230.130000          5.540000          5.810000   \n",
       "max         4961.330000       4429.880000        676.480000       1057.960000   \n",
       "\n",
       "       loc_og_t2f_mou_8  loc_og_t2f_mou_9  loc_og_t2c_mou_6  loc_og_t2c_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean           7.006037          6.902271          1.608491          1.905115   \n",
       "std           21.293992         21.498673          6.989765          9.246516   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.410000          0.280000          0.000000          0.000000   \n",
       "75%            5.330000          4.980000          0.000000          0.160000   \n",
       "max          928.490000        927.410000        342.860000        569.710000   \n",
       "\n",
       "       loc_og_t2c_mou_8  loc_og_t2c_mou_9  loc_og_mou_6  loc_og_mou_7  \\\n",
       "count      25335.000000      25335.000000  25335.000000  25335.000000   \n",
       "mean           1.811716          1.550170    298.119074    304.014879   \n",
       "std            7.658958          6.572505    390.703307    390.011607   \n",
       "min            0.000000          0.000000      0.000000      0.000000   \n",
       "25%            0.000000          0.000000     57.770000     65.625000   \n",
       "50%            0.000000          0.000000    179.840000    188.190000   \n",
       "75%            0.160000          0.010000    393.350000    404.120000   \n",
       "max          351.830000        274.890000  10643.380000   7674.780000   \n",
       "\n",
       "       loc_og_mou_8  loc_og_mou_9  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "count  25335.000000  25335.000000      25335.000000      25335.000000   \n",
       "mean     285.961925    271.069297        196.812613        211.379736   \n",
       "std      381.771064    379.753460        415.838101        438.203399   \n",
       "min        0.000000      0.000000          0.000000          0.000000   \n",
       "25%       51.520000     44.230000          0.000000          0.000000   \n",
       "50%      170.930000    156.130000         15.390000         17.130000   \n",
       "75%      379.560000    360.370000        191.850000        211.660000   \n",
       "max    11039.910000  11099.260000       7366.580000       8133.660000   \n",
       "\n",
       "       std_og_t2t_mou_8  std_og_t2t_mou_9  std_og_t2m_mou_6  std_og_t2m_mou_7  \\\n",
       "count      25335.000000      25335.000000       25335.00000      25335.000000   \n",
       "mean         189.782722        171.691855         208.44343        224.532096   \n",
       "std          428.727579        404.208737         414.50022        448.737359   \n",
       "min            0.000000          0.000000           0.00000          0.000000   \n",
       "25%            0.000000          0.000000           2.38000          2.245000   \n",
       "50%            9.950000          7.730000          42.41000         43.780000   \n",
       "75%          163.910000        138.875000         220.50000        241.395000   \n",
       "max         8014.430000       7244.160000        8314.76000       9284.740000   \n",
       "\n",
       "       std_og_t2m_mou_8  std_og_t2m_mou_9  std_og_t2f_mou_6  std_og_t2f_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         197.083311        174.495441          2.083931          2.132881   \n",
       "std          436.163646        392.676262         12.723130         13.952247   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.930000          0.250000          0.000000          0.000000   \n",
       "50%           32.010000         25.440000          0.000000          0.000000   \n",
       "75%          193.235000        164.750000          0.000000          0.000000   \n",
       "max        13950.040000      10223.430000        628.560000        544.630000   \n",
       "\n",
       "       std_og_t2f_mou_8  std_og_t2f_mou_9  std_og_t2c_mou_6  std_og_t2c_mou_7  \\\n",
       "count      25335.000000      25335.000000           25335.0           25335.0   \n",
       "mean           1.899306          1.800965               0.0               0.0   \n",
       "std           11.992246         12.465551               0.0               0.0   \n",
       "min            0.000000          0.000000               0.0               0.0   \n",
       "25%            0.000000          0.000000               0.0               0.0   \n",
       "50%            0.000000          0.000000               0.0               0.0   \n",
       "75%            0.000000          0.000000               0.0               0.0   \n",
       "max          516.910000        808.490000               0.0               0.0   \n",
       "\n",
       "       std_og_t2c_mou_8  std_og_t2c_mou_9  std_og_mou_6  std_og_mou_7  \\\n",
       "count           25335.0           25335.0  25335.000000  25335.000000   \n",
       "mean                0.0               0.0    407.344440    438.049207   \n",
       "std                 0.0               0.0    609.228997    651.051194   \n",
       "min                 0.0               0.0      0.000000      0.000000   \n",
       "25%                 0.0               0.0      7.650000      7.790000   \n",
       "50%                 0.0               0.0    140.740000    155.510000   \n",
       "75%                 0.0               0.0    599.365000    657.635000   \n",
       "max                 0.0               0.0   8432.990000  10936.730000   \n",
       "\n",
       "       std_og_mou_8  std_og_mou_9  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     388.769519    347.992249      2.125238      2.191998      2.156291   \n",
       "std      640.513506    593.202566     47.841689     48.191701     48.117680   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        4.535000      2.790000      0.000000      0.000000      0.000000   \n",
       "50%      103.240000     81.940000      0.000000      0.000000      0.000000   \n",
       "75%      547.335000    467.285000      0.000000      0.000000      0.000000   \n",
       "max    13980.060000  10238.380000   5900.660000   5490.280000   5681.540000   \n",
       "\n",
       "       isd_og_mou_9  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  spl_og_mou_9  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       1.945745      6.030383      7.639063      7.345974      6.176769   \n",
       "std       39.440580     18.869381     23.583356     23.659722     19.541272   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.310000      0.900000      0.810000      0.510000   \n",
       "75%        0.000000      5.390000      7.460000      7.110000      5.655000   \n",
       "max     4244.530000   1023.210000   1265.790000   1390.880000   1069.090000   \n",
       "\n",
       "        og_others_6   og_others_7   og_others_8   og_others_9  total_og_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000    25335.000000   \n",
       "mean       0.704512      0.039078      0.049230      0.094892      714.333663   \n",
       "std        2.330394      1.862022      2.733586      5.977913      659.239073   \n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      291.950000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      542.580000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      930.725000   \n",
       "max      100.610000    221.940000    394.930000    787.790000    10674.030000   \n",
       "\n",
       "       total_og_mou_7  total_og_mou_8  total_og_mou_9  loc_ic_t2t_mou_6  \\\n",
       "count    25335.000000    25335.000000    25335.000000      25335.000000   \n",
       "mean       751.943194      684.291694      627.287414         71.333108   \n",
       "std        692.061684      699.416899      669.294780        159.764080   \n",
       "min          0.000000        0.000000        0.000000          0.000000   \n",
       "25%        309.570000      241.720000      199.820000          9.580000   \n",
       "50%        570.810000      495.260000      445.680000         31.380000   \n",
       "75%        980.185000      902.935000      830.910000         77.195000   \n",
       "max      11365.310000    14043.060000    11140.110000       6351.440000   \n",
       "\n",
       "       loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2t_mou_9  loc_ic_t2m_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          73.848361         71.173280         68.356177        166.124937   \n",
       "std          167.999534        162.414297        168.704613        222.977501   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%           11.110000          9.130000          8.290000         37.135000   \n",
       "50%           33.090000         30.390000         28.810000         99.930000   \n",
       "75%           79.450000         76.880000         72.810000        211.750000   \n",
       "max         5709.590000       4003.210000       7565.890000       4693.860000   \n",
       "\n",
       "       loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2m_mou_9  loc_ic_t2f_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         169.562449        166.215392        158.136124         16.339769   \n",
       "std          222.864795        223.408317        212.539206         47.329733   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%           42.635000         37.970000         33.610000          0.000000   \n",
       "50%          103.810000        100.730000         93.780000          2.250000   \n",
       "75%          215.200000        212.100000        201.715000         13.390000   \n",
       "max         4171.510000       5738.460000       4534.790000       1678.410000   \n",
       "\n",
       "       loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_t2f_mou_9  loc_ic_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000  25335.000000   \n",
       "mean          17.317704         15.785543         16.258380    253.807895   \n",
       "std           50.779238         45.608537         56.591804    313.758944   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000     63.315000   \n",
       "50%            2.590000          2.360000          2.240000    160.530000   \n",
       "75%           14.135000         12.910000         12.830000    328.350000   \n",
       "max         1983.010000       1588.530000       4318.280000   6496.110000   \n",
       "\n",
       "       loc_ic_mou_7  loc_ic_mou_8  loc_ic_mou_9  std_ic_t2t_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000      25335.000000   \n",
       "mean     260.738785    253.184272    242.760671         16.844002   \n",
       "std      318.977995    316.417005    315.233280         82.455660   \n",
       "min        0.000000      0.000000      0.000000          0.000000   \n",
       "25%       71.730000     62.880000     57.160000          0.000000   \n",
       "50%      166.990000    159.790000    149.480000          1.280000   \n",
       "75%      335.180000    325.825000    312.830000         10.930000   \n",
       "max     6466.740000   5748.810000   7785.460000       5459.560000   \n",
       "\n",
       "       std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2t_mou_9  std_ic_t2m_mou_6  \\\n",
       "count       25335.00000      25335.000000      25335.000000      25335.000000   \n",
       "mean           17.88079         16.471824         15.634095         32.600116   \n",
       "std            90.11867         77.316442         74.839966         98.893301   \n",
       "min             0.00000          0.000000          0.000000          0.000000   \n",
       "25%             0.00000          0.000000          0.000000          0.660000   \n",
       "50%             1.53000          0.960000          0.700000          7.690000   \n",
       "75%            11.79000         10.130000          9.130000         28.530000   \n",
       "max          5800.93000       4309.290000       3819.830000       4630.230000   \n",
       "\n",
       "       std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2m_mou_9  std_ic_t2f_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          34.782159         32.666067         29.869764          3.025538   \n",
       "std          105.551242        109.024813         97.472437         21.174910   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.750000          0.400000          0.200000          0.000000   \n",
       "50%            8.410000          6.980000          6.140000          0.000000   \n",
       "75%           31.030000         28.170000         25.640000          0.255000   \n",
       "max         3100.840000       5645.860000       5689.760000       1351.110000   \n",
       "\n",
       "       std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_t2f_mou_9  std_ic_t2o_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000           25335.0   \n",
       "mean           3.149795          2.881318          2.962192               0.0   \n",
       "std           21.633461         21.648678         21.458616               0.0   \n",
       "min            0.000000          0.000000          0.000000               0.0   \n",
       "25%            0.000000          0.000000          0.000000               0.0   \n",
       "50%            0.000000          0.000000          0.000000               0.0   \n",
       "75%            0.350000          0.300000          0.330000               0.0   \n",
       "max         1136.080000       1394.890000       1431.960000               0.0   \n",
       "\n",
       "       std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_t2o_mou_9  std_ic_mou_6  \\\n",
       "count           25335.0           25335.0           25335.0  25335.000000   \n",
       "mean                0.0               0.0               0.0     52.473777   \n",
       "std                 0.0               0.0               0.0    141.642485   \n",
       "min                 0.0               0.0               0.0      0.000000   \n",
       "25%                 0.0               0.0               0.0      3.180000   \n",
       "50%                 0.0               0.0               0.0     16.130000   \n",
       "75%                 0.0               0.0               0.0     48.985000   \n",
       "max                 0.0               0.0               0.0   5459.630000   \n",
       "\n",
       "       std_ic_mou_7  std_ic_mou_8  std_ic_mou_9  total_ic_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000    25335.000000   \n",
       "mean      55.816969     52.023210     48.469934      318.424015   \n",
       "std      153.424340    147.512098    137.805366      361.531618   \n",
       "min        0.000000      0.000000      0.000000        0.000000   \n",
       "25%        3.430000      2.510000      1.910000       97.540000   \n",
       "50%       17.610000     14.680000     13.110000      216.910000   \n",
       "75%       52.840000     47.640000     43.975000      407.050000   \n",
       "max     6745.760000   5957.140000   5956.660000     6798.640000   \n",
       "\n",
       "       total_ic_mou_7  total_ic_mou_8  total_ic_mou_9  spl_ic_mou_6  \\\n",
       "count    25335.000000    25335.000000    25335.000000  25335.000000   \n",
       "mean       330.484101      318.718816      304.456263      0.066769   \n",
       "std        373.960638      370.339577      368.825023      0.157630   \n",
       "min          0.000000        0.000000        0.000000      0.000000   \n",
       "25%        109.360000       96.135000       85.910000      0.000000   \n",
       "50%        225.110000      213.330000      199.480000      0.000000   \n",
       "75%        416.115000      406.200000      390.380000      0.000000   \n",
       "max       7279.080000     5990.710000     7785.730000      6.740000   \n",
       "\n",
       "       spl_ic_mou_7  spl_ic_mou_8  spl_ic_mou_9  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.017484      0.029158      0.143782     10.841112     12.306502   \n",
       "std        0.174782      0.113819      0.481188     66.542701     76.654492   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       21.330000      1.260000     21.560000   3965.690000   4747.910000   \n",
       "\n",
       "       isd_ic_mou_8  isd_ic_mou_9   ic_others_6   ic_others_7   ic_others_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean      12.156147     11.640142      1.225623      1.596091      1.317898   \n",
       "std       77.125182     78.966015     14.871170     16.591331     13.609714   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.080000      0.060000      0.080000   \n",
       "max     4100.380000   5057.740000   1344.140000   1495.940000   1209.860000   \n",
       "\n",
       "        ic_others_9  total_rech_num_6  total_rech_num_7  total_rech_num_8  \\\n",
       "count  25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean       1.433080         12.369213         12.339925         10.954529   \n",
       "std       14.653972          9.478604          9.636941          9.581220   \n",
       "min        0.000000          1.000000          1.000000          1.000000   \n",
       "25%        0.000000          7.000000          6.000000          5.000000   \n",
       "50%        0.000000         10.000000         10.000000          8.000000   \n",
       "75%        0.050000         15.000000         15.000000         14.000000   \n",
       "max      919.630000        307.000000        138.000000        138.000000   \n",
       "\n",
       "       total_rech_num_9  total_rech_amt_6  total_rech_amt_7  total_rech_amt_8  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          10.530255        717.326071        730.384054        669.618315   \n",
       "std            9.177389        535.704258        562.700046        615.007473   \n",
       "min            1.000000          0.000000          0.000000          0.000000   \n",
       "25%            5.000000        453.500000        458.000000        370.000000   \n",
       "50%            8.000000        602.000000        612.000000        566.000000   \n",
       "75%           13.000000        853.000000        865.000000        831.000000   \n",
       "max          131.000000      35190.000000      40335.000000      45320.000000   \n",
       "\n",
       "       total_rech_amt_9  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "count      25335.000000    25335.000000    25335.000000    25335.000000   \n",
       "mean         628.554727      170.440300      176.367397      171.691455   \n",
       "std          594.838126      164.154017      173.003988      169.981003   \n",
       "min            0.000000        0.000000        0.000000        0.000000   \n",
       "25%          322.000000      110.000000      110.000000      100.000000   \n",
       "50%          529.000000      120.000000      128.000000      130.000000   \n",
       "75%          800.000000      200.000000      200.000000      198.000000   \n",
       "max        37235.000000     3559.000000     3299.000000     4449.000000   \n",
       "\n",
       "       max_rech_amt_9  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "count    25335.000000        25335.000000        25335.000000   \n",
       "mean       168.035485          103.618394          106.819814   \n",
       "std        168.862541          131.004585          133.878195   \n",
       "min          0.000000            0.000000            0.000000   \n",
       "25%         77.000000           30.000000           30.000000   \n",
       "50%        130.000000          110.000000          100.000000   \n",
       "75%        200.000000          120.000000          130.000000   \n",
       "max       3399.000000         3299.000000         3100.000000   \n",
       "\n",
       "       last_day_rch_amt_8  last_day_rch_amt_9   vol_2g_mb_6   vol_2g_mb_7  \\\n",
       "count        25335.000000        25335.000000  25335.000000  25335.000000   \n",
       "mean           101.055181           73.296428     80.828362     80.695662   \n",
       "std            143.671631          125.580816    279.498393    284.506065   \n",
       "min              0.000000            0.000000      0.000000      0.000000   \n",
       "25%             20.000000            0.000000      0.000000      0.000000   \n",
       "50%             50.000000           30.000000      0.000000      0.000000   \n",
       "75%            130.000000          130.000000     17.320000     18.505000   \n",
       "max           4449.000000         3399.000000  10285.900000   7873.550000   \n",
       "\n",
       "        vol_2g_mb_8   vol_2g_mb_9   vol_3g_mb_6   vol_3g_mb_7   vol_3g_mb_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean      74.095703     66.970864    259.031232    285.911329    286.022239   \n",
       "std      278.235033    253.897541    810.698076    848.283045    861.636669   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       14.395000     11.200000      0.000000     30.585000     23.915000   \n",
       "max    11117.610000   8993.950000  26826.130000  28144.120000  29651.830000   \n",
       "\n",
       "        vol_3g_mb_9  monthly_2g_6  monthly_2g_7  monthly_2g_8  monthly_2g_9  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     292.322928      0.131202      0.138701      0.122913      0.107953   \n",
       "std      892.571162      0.382467      0.397484      0.369948      0.350807   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       12.620000      0.000000      0.000000      0.000000      0.000000   \n",
       "max    26857.040000      4.000000      5.000000      5.000000      4.000000   \n",
       "\n",
       "        sachet_2g_6   sachet_2g_7   sachet_2g_8   sachet_2g_9  monthly_3g_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.508861      0.606315      0.647642      0.563726      0.176436   \n",
       "std        1.706819      1.910562      1.886947      1.591092      0.579352   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       39.000000     48.000000     44.000000     40.000000     14.000000   \n",
       "\n",
       "       monthly_3g_7  monthly_3g_8  monthly_3g_9   sachet_3g_6   sachet_3g_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.192856      0.185554      0.194237      0.142333      0.157845   \n",
       "std        0.641568      0.605907      0.602066      0.881705      0.984721   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       16.000000     16.000000     11.000000     29.000000     33.000000   \n",
       "\n",
       "        sachet_3g_8   sachet_3g_9           aon    aug_vbc_3g    jul_vbc_3g  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.154411      0.149398   1290.944622    139.401235    142.534482   \n",
       "std        1.033961      0.985798    978.149101    405.205464    421.298082   \n",
       "min        0.000000      0.000000    180.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000    487.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000    950.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000   1980.000000     17.595000      9.295000   \n",
       "max       41.000000     49.000000   4321.000000  12916.220000   9165.600000   \n",
       "\n",
       "         jun_vbc_3g    sep_vbc_3g  average_rech_amt_g  \n",
       "count  25335.000000  25335.000000        25335.000000  \n",
       "mean     126.035382      7.215953          723.855062  \n",
       "std      395.788710     50.055596          500.600700  \n",
       "min        0.000000      0.000000          390.000000  \n",
       "25%        0.000000      0.000000          474.500000  \n",
       "50%        0.000000      0.000000          596.000000  \n",
       "75%        0.000000      0.000000          826.500000  \n",
       "max    11166.210000   2618.570000        37762.500000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25335"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf['mobile_number'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We notice many columns which have the same minimum and maximum values which implies that these columns do not have any variance. Thus, we drop these columns.\n",
    "- We also drop the mobile_number column since it is a unique ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the mobile_number column\n",
    "fdf=fdf.drop('mobile_number',axis=1)\n",
    "\n",
    "#dropping the columns with same min and max values\n",
    "num_col=list(fdf.select_dtypes(include=[np.int64,np.float64]).columns)\n",
    "for col in num_col:\n",
    "    mi=fdf[col].min()\n",
    "    ma=fdf[col].max()\n",
    "    if mi==ma:\n",
    "        fdf=fdf.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25335, 174)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>arpu_9</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>onnet_mou_9</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>offnet_mou_9</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_ic_mou_9</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>roam_og_mou_9</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_9</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_9</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_9</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_9</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>loc_og_mou_9</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2t_mou_9</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2m_mou_9</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2f_mou_9</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>std_og_mou_9</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>isd_og_mou_9</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>spl_og_mou_9</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>og_others_9</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>total_og_mou_9</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_9</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_9</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_9</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>loc_ic_mou_9</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_9</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_9</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_9</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>std_ic_mou_9</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>total_ic_mou_9</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_9</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_9</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>ic_others_9</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_num_9</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_rech_amt_9</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>max_rech_amt_9</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>last_day_rch_amt_9</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_2g_mb_9</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>vol_3g_mb_9</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>monthly_2g_9</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>sachet_2g_9</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>monthly_3g_9</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>average_rech_amt_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>605.381915</td>\n",
       "      <td>618.668251</td>\n",
       "      <td>580.047979</td>\n",
       "      <td>539.711103</td>\n",
       "      <td>308.772567</td>\n",
       "      <td>323.663869</td>\n",
       "      <td>294.68391</td>\n",
       "      <td>269.313954</td>\n",
       "      <td>434.100403</td>\n",
       "      <td>448.695341</td>\n",
       "      <td>410.454928</td>\n",
       "      <td>375.18889</td>\n",
       "      <td>18.061622</td>\n",
       "      <td>14.346624</td>\n",
       "      <td>14.582006</td>\n",
       "      <td>12.838677</td>\n",
       "      <td>30.56156</td>\n",
       "      <td>23.280403</td>\n",
       "      <td>23.590945</td>\n",
       "      <td>19.478126</td>\n",
       "      <td>99.960790</td>\n",
       "      <td>103.126631</td>\n",
       "      <td>95.763798</td>\n",
       "      <td>89.748857</td>\n",
       "      <td>190.822741</td>\n",
       "      <td>193.354505</td>\n",
       "      <td>183.183204</td>\n",
       "      <td>174.409525</td>\n",
       "      <td>7.326504</td>\n",
       "      <td>7.524519</td>\n",
       "      <td>7.006037</td>\n",
       "      <td>6.902271</td>\n",
       "      <td>1.608491</td>\n",
       "      <td>1.905115</td>\n",
       "      <td>1.811716</td>\n",
       "      <td>1.550170</td>\n",
       "      <td>298.119074</td>\n",
       "      <td>304.014879</td>\n",
       "      <td>285.961925</td>\n",
       "      <td>271.069297</td>\n",
       "      <td>196.812613</td>\n",
       "      <td>211.379736</td>\n",
       "      <td>189.782722</td>\n",
       "      <td>171.691855</td>\n",
       "      <td>208.44343</td>\n",
       "      <td>224.532096</td>\n",
       "      <td>197.083311</td>\n",
       "      <td>174.495441</td>\n",
       "      <td>2.083931</td>\n",
       "      <td>2.132881</td>\n",
       "      <td>1.899306</td>\n",
       "      <td>1.800965</td>\n",
       "      <td>407.344440</td>\n",
       "      <td>438.049207</td>\n",
       "      <td>388.769519</td>\n",
       "      <td>347.992249</td>\n",
       "      <td>2.125238</td>\n",
       "      <td>2.191998</td>\n",
       "      <td>2.156291</td>\n",
       "      <td>1.945745</td>\n",
       "      <td>6.030383</td>\n",
       "      <td>7.639063</td>\n",
       "      <td>7.345974</td>\n",
       "      <td>6.176769</td>\n",
       "      <td>0.704512</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.049230</td>\n",
       "      <td>0.094892</td>\n",
       "      <td>714.333663</td>\n",
       "      <td>751.943194</td>\n",
       "      <td>684.291694</td>\n",
       "      <td>627.287414</td>\n",
       "      <td>71.333108</td>\n",
       "      <td>73.848361</td>\n",
       "      <td>71.173280</td>\n",
       "      <td>68.356177</td>\n",
       "      <td>166.124937</td>\n",
       "      <td>169.562449</td>\n",
       "      <td>166.215392</td>\n",
       "      <td>158.136124</td>\n",
       "      <td>16.339769</td>\n",
       "      <td>17.317704</td>\n",
       "      <td>15.785543</td>\n",
       "      <td>16.258380</td>\n",
       "      <td>253.807895</td>\n",
       "      <td>260.738785</td>\n",
       "      <td>253.184272</td>\n",
       "      <td>242.760671</td>\n",
       "      <td>16.844002</td>\n",
       "      <td>17.88079</td>\n",
       "      <td>16.471824</td>\n",
       "      <td>15.634095</td>\n",
       "      <td>32.600116</td>\n",
       "      <td>34.782159</td>\n",
       "      <td>32.666067</td>\n",
       "      <td>29.869764</td>\n",
       "      <td>3.025538</td>\n",
       "      <td>3.149795</td>\n",
       "      <td>2.881318</td>\n",
       "      <td>2.962192</td>\n",
       "      <td>52.473777</td>\n",
       "      <td>55.816969</td>\n",
       "      <td>52.023210</td>\n",
       "      <td>48.469934</td>\n",
       "      <td>318.424015</td>\n",
       "      <td>330.484101</td>\n",
       "      <td>318.718816</td>\n",
       "      <td>304.456263</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>0.143782</td>\n",
       "      <td>10.841112</td>\n",
       "      <td>12.306502</td>\n",
       "      <td>12.156147</td>\n",
       "      <td>11.640142</td>\n",
       "      <td>1.225623</td>\n",
       "      <td>1.596091</td>\n",
       "      <td>1.317898</td>\n",
       "      <td>1.433080</td>\n",
       "      <td>12.369213</td>\n",
       "      <td>12.339925</td>\n",
       "      <td>10.954529</td>\n",
       "      <td>10.530255</td>\n",
       "      <td>717.326071</td>\n",
       "      <td>730.384054</td>\n",
       "      <td>669.618315</td>\n",
       "      <td>628.554727</td>\n",
       "      <td>170.440300</td>\n",
       "      <td>176.367397</td>\n",
       "      <td>171.691455</td>\n",
       "      <td>168.035485</td>\n",
       "      <td>103.618394</td>\n",
       "      <td>106.819814</td>\n",
       "      <td>101.055181</td>\n",
       "      <td>73.296428</td>\n",
       "      <td>80.828362</td>\n",
       "      <td>80.695662</td>\n",
       "      <td>74.095703</td>\n",
       "      <td>66.970864</td>\n",
       "      <td>259.031232</td>\n",
       "      <td>285.911329</td>\n",
       "      <td>286.022239</td>\n",
       "      <td>292.322928</td>\n",
       "      <td>0.131202</td>\n",
       "      <td>0.138701</td>\n",
       "      <td>0.122913</td>\n",
       "      <td>0.107953</td>\n",
       "      <td>0.508861</td>\n",
       "      <td>0.606315</td>\n",
       "      <td>0.647642</td>\n",
       "      <td>0.563726</td>\n",
       "      <td>0.176436</td>\n",
       "      <td>0.192856</td>\n",
       "      <td>0.185554</td>\n",
       "      <td>0.194237</td>\n",
       "      <td>0.142333</td>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.154411</td>\n",
       "      <td>0.149398</td>\n",
       "      <td>1290.944622</td>\n",
       "      <td>139.401235</td>\n",
       "      <td>142.534482</td>\n",
       "      <td>126.035382</td>\n",
       "      <td>7.215953</td>\n",
       "      <td>723.855062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>437.843670</td>\n",
       "      <td>464.965572</td>\n",
       "      <td>502.170458</td>\n",
       "      <td>505.824898</td>\n",
       "      <td>467.783907</td>\n",
       "      <td>494.784885</td>\n",
       "      <td>487.04074</td>\n",
       "      <td>464.580570</td>\n",
       "      <td>470.461181</td>\n",
       "      <td>494.027416</td>\n",
       "      <td>491.009571</td>\n",
       "      <td>459.10733</td>\n",
       "      <td>79.379923</td>\n",
       "      <td>79.562310</td>\n",
       "      <td>79.311801</td>\n",
       "      <td>73.212563</td>\n",
       "      <td>120.77578</td>\n",
       "      <td>101.356114</td>\n",
       "      <td>112.585652</td>\n",
       "      <td>96.627672</td>\n",
       "      <td>245.564009</td>\n",
       "      <td>262.585641</td>\n",
       "      <td>249.911233</td>\n",
       "      <td>242.902259</td>\n",
       "      <td>256.217219</td>\n",
       "      <td>247.363734</td>\n",
       "      <td>242.759117</td>\n",
       "      <td>243.334144</td>\n",
       "      <td>22.025513</td>\n",
       "      <td>22.588417</td>\n",
       "      <td>21.293992</td>\n",
       "      <td>21.498673</td>\n",
       "      <td>6.989765</td>\n",
       "      <td>9.246516</td>\n",
       "      <td>7.658958</td>\n",
       "      <td>6.572505</td>\n",
       "      <td>390.703307</td>\n",
       "      <td>390.011607</td>\n",
       "      <td>381.771064</td>\n",
       "      <td>379.753460</td>\n",
       "      <td>415.838101</td>\n",
       "      <td>438.203399</td>\n",
       "      <td>428.727579</td>\n",
       "      <td>404.208737</td>\n",
       "      <td>414.50022</td>\n",
       "      <td>448.737359</td>\n",
       "      <td>436.163646</td>\n",
       "      <td>392.676262</td>\n",
       "      <td>12.723130</td>\n",
       "      <td>13.952247</td>\n",
       "      <td>11.992246</td>\n",
       "      <td>12.465551</td>\n",
       "      <td>609.228997</td>\n",
       "      <td>651.051194</td>\n",
       "      <td>640.513506</td>\n",
       "      <td>593.202566</td>\n",
       "      <td>47.841689</td>\n",
       "      <td>48.191701</td>\n",
       "      <td>48.117680</td>\n",
       "      <td>39.440580</td>\n",
       "      <td>18.869381</td>\n",
       "      <td>23.583356</td>\n",
       "      <td>23.659722</td>\n",
       "      <td>19.541272</td>\n",
       "      <td>2.330394</td>\n",
       "      <td>1.862022</td>\n",
       "      <td>2.733586</td>\n",
       "      <td>5.977913</td>\n",
       "      <td>659.239073</td>\n",
       "      <td>692.061684</td>\n",
       "      <td>699.416899</td>\n",
       "      <td>669.294780</td>\n",
       "      <td>159.764080</td>\n",
       "      <td>167.999534</td>\n",
       "      <td>162.414297</td>\n",
       "      <td>168.704613</td>\n",
       "      <td>222.977501</td>\n",
       "      <td>222.864795</td>\n",
       "      <td>223.408317</td>\n",
       "      <td>212.539206</td>\n",
       "      <td>47.329733</td>\n",
       "      <td>50.779238</td>\n",
       "      <td>45.608537</td>\n",
       "      <td>56.591804</td>\n",
       "      <td>313.758944</td>\n",
       "      <td>318.977995</td>\n",
       "      <td>316.417005</td>\n",
       "      <td>315.233280</td>\n",
       "      <td>82.455660</td>\n",
       "      <td>90.11867</td>\n",
       "      <td>77.316442</td>\n",
       "      <td>74.839966</td>\n",
       "      <td>98.893301</td>\n",
       "      <td>105.551242</td>\n",
       "      <td>109.024813</td>\n",
       "      <td>97.472437</td>\n",
       "      <td>21.174910</td>\n",
       "      <td>21.633461</td>\n",
       "      <td>21.648678</td>\n",
       "      <td>21.458616</td>\n",
       "      <td>141.642485</td>\n",
       "      <td>153.424340</td>\n",
       "      <td>147.512098</td>\n",
       "      <td>137.805366</td>\n",
       "      <td>361.531618</td>\n",
       "      <td>373.960638</td>\n",
       "      <td>370.339577</td>\n",
       "      <td>368.825023</td>\n",
       "      <td>0.157630</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.113819</td>\n",
       "      <td>0.481188</td>\n",
       "      <td>66.542701</td>\n",
       "      <td>76.654492</td>\n",
       "      <td>77.125182</td>\n",
       "      <td>78.966015</td>\n",
       "      <td>14.871170</td>\n",
       "      <td>16.591331</td>\n",
       "      <td>13.609714</td>\n",
       "      <td>14.653972</td>\n",
       "      <td>9.478604</td>\n",
       "      <td>9.636941</td>\n",
       "      <td>9.581220</td>\n",
       "      <td>9.177389</td>\n",
       "      <td>535.704258</td>\n",
       "      <td>562.700046</td>\n",
       "      <td>615.007473</td>\n",
       "      <td>594.838126</td>\n",
       "      <td>164.154017</td>\n",
       "      <td>173.003988</td>\n",
       "      <td>169.981003</td>\n",
       "      <td>168.862541</td>\n",
       "      <td>131.004585</td>\n",
       "      <td>133.878195</td>\n",
       "      <td>143.671631</td>\n",
       "      <td>125.580816</td>\n",
       "      <td>279.498393</td>\n",
       "      <td>284.506065</td>\n",
       "      <td>278.235033</td>\n",
       "      <td>253.897541</td>\n",
       "      <td>810.698076</td>\n",
       "      <td>848.283045</td>\n",
       "      <td>861.636669</td>\n",
       "      <td>892.571162</td>\n",
       "      <td>0.382467</td>\n",
       "      <td>0.397484</td>\n",
       "      <td>0.369948</td>\n",
       "      <td>0.350807</td>\n",
       "      <td>1.706819</td>\n",
       "      <td>1.910562</td>\n",
       "      <td>1.886947</td>\n",
       "      <td>1.591092</td>\n",
       "      <td>0.579352</td>\n",
       "      <td>0.641568</td>\n",
       "      <td>0.605907</td>\n",
       "      <td>0.602066</td>\n",
       "      <td>0.881705</td>\n",
       "      <td>0.984721</td>\n",
       "      <td>1.033961</td>\n",
       "      <td>0.985798</td>\n",
       "      <td>978.149101</td>\n",
       "      <td>405.205464</td>\n",
       "      <td>421.298082</td>\n",
       "      <td>395.788710</td>\n",
       "      <td>50.055596</td>\n",
       "      <td>500.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-810.661000</td>\n",
       "      <td>-622.509000</td>\n",
       "      <td>-345.129000</td>\n",
       "      <td>-1474.195000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>383.939000</td>\n",
       "      <td>391.220000</td>\n",
       "      <td>334.649000</td>\n",
       "      <td>291.030000</td>\n",
       "      <td>46.445000</td>\n",
       "      <td>47.740000</td>\n",
       "      <td>37.66000</td>\n",
       "      <td>29.810000</td>\n",
       "      <td>149.680000</td>\n",
       "      <td>153.120000</td>\n",
       "      <td>121.825000</td>\n",
       "      <td>98.31000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.730000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>6.790000</td>\n",
       "      <td>34.110000</td>\n",
       "      <td>38.880000</td>\n",
       "      <td>30.635000</td>\n",
       "      <td>26.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.770000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>51.520000</td>\n",
       "      <td>44.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.38000</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>7.790000</td>\n",
       "      <td>4.535000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>291.950000</td>\n",
       "      <td>309.570000</td>\n",
       "      <td>241.720000</td>\n",
       "      <td>199.820000</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>9.130000</td>\n",
       "      <td>8.290000</td>\n",
       "      <td>37.135000</td>\n",
       "      <td>42.635000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>33.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.315000</td>\n",
       "      <td>71.730000</td>\n",
       "      <td>62.880000</td>\n",
       "      <td>57.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>97.540000</td>\n",
       "      <td>109.360000</td>\n",
       "      <td>96.135000</td>\n",
       "      <td>85.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>453.500000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>474.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>512.599000</td>\n",
       "      <td>520.648000</td>\n",
       "      <td>489.762000</td>\n",
       "      <td>455.884000</td>\n",
       "      <td>135.880000</td>\n",
       "      <td>139.330000</td>\n",
       "      <td>118.04000</td>\n",
       "      <td>103.310000</td>\n",
       "      <td>299.190000</td>\n",
       "      <td>305.130000</td>\n",
       "      <td>271.480000</td>\n",
       "      <td>241.33000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.310000</td>\n",
       "      <td>37.060000</td>\n",
       "      <td>33.890000</td>\n",
       "      <td>30.580000</td>\n",
       "      <td>109.310000</td>\n",
       "      <td>114.260000</td>\n",
       "      <td>104.030000</td>\n",
       "      <td>94.590000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.840000</td>\n",
       "      <td>188.190000</td>\n",
       "      <td>170.930000</td>\n",
       "      <td>156.130000</td>\n",
       "      <td>15.390000</td>\n",
       "      <td>17.130000</td>\n",
       "      <td>9.950000</td>\n",
       "      <td>7.730000</td>\n",
       "      <td>42.41000</td>\n",
       "      <td>43.780000</td>\n",
       "      <td>32.010000</td>\n",
       "      <td>25.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.740000</td>\n",
       "      <td>155.510000</td>\n",
       "      <td>103.240000</td>\n",
       "      <td>81.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>542.580000</td>\n",
       "      <td>570.810000</td>\n",
       "      <td>495.260000</td>\n",
       "      <td>445.680000</td>\n",
       "      <td>31.380000</td>\n",
       "      <td>33.090000</td>\n",
       "      <td>30.390000</td>\n",
       "      <td>28.810000</td>\n",
       "      <td>99.930000</td>\n",
       "      <td>103.810000</td>\n",
       "      <td>100.730000</td>\n",
       "      <td>93.780000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>2.240000</td>\n",
       "      <td>160.530000</td>\n",
       "      <td>166.990000</td>\n",
       "      <td>159.790000</td>\n",
       "      <td>149.480000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.53000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.130000</td>\n",
       "      <td>17.610000</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>216.910000</td>\n",
       "      <td>225.110000</td>\n",
       "      <td>213.330000</td>\n",
       "      <td>199.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>718.534500</td>\n",
       "      <td>728.702500</td>\n",
       "      <td>712.486000</td>\n",
       "      <td>677.751000</td>\n",
       "      <td>373.975000</td>\n",
       "      <td>391.550000</td>\n",
       "      <td>339.67500</td>\n",
       "      <td>299.980000</td>\n",
       "      <td>546.900000</td>\n",
       "      <td>568.160000</td>\n",
       "      <td>522.885000</td>\n",
       "      <td>478.54500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.335000</td>\n",
       "      <td>98.285000</td>\n",
       "      <td>94.650000</td>\n",
       "      <td>87.775000</td>\n",
       "      <td>253.535000</td>\n",
       "      <td>257.235000</td>\n",
       "      <td>244.405000</td>\n",
       "      <td>230.130000</td>\n",
       "      <td>5.540000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>393.350000</td>\n",
       "      <td>404.120000</td>\n",
       "      <td>379.560000</td>\n",
       "      <td>360.370000</td>\n",
       "      <td>191.850000</td>\n",
       "      <td>211.660000</td>\n",
       "      <td>163.910000</td>\n",
       "      <td>138.875000</td>\n",
       "      <td>220.50000</td>\n",
       "      <td>241.395000</td>\n",
       "      <td>193.235000</td>\n",
       "      <td>164.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>599.365000</td>\n",
       "      <td>657.635000</td>\n",
       "      <td>547.335000</td>\n",
       "      <td>467.285000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>7.460000</td>\n",
       "      <td>7.110000</td>\n",
       "      <td>5.655000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>930.725000</td>\n",
       "      <td>980.185000</td>\n",
       "      <td>902.935000</td>\n",
       "      <td>830.910000</td>\n",
       "      <td>77.195000</td>\n",
       "      <td>79.450000</td>\n",
       "      <td>76.880000</td>\n",
       "      <td>72.810000</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>215.200000</td>\n",
       "      <td>212.100000</td>\n",
       "      <td>201.715000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>14.135000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>12.830000</td>\n",
       "      <td>328.350000</td>\n",
       "      <td>335.180000</td>\n",
       "      <td>325.825000</td>\n",
       "      <td>312.830000</td>\n",
       "      <td>10.930000</td>\n",
       "      <td>11.79000</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>9.130000</td>\n",
       "      <td>28.530000</td>\n",
       "      <td>31.030000</td>\n",
       "      <td>28.170000</td>\n",
       "      <td>25.640000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>48.985000</td>\n",
       "      <td>52.840000</td>\n",
       "      <td>47.640000</td>\n",
       "      <td>43.975000</td>\n",
       "      <td>407.050000</td>\n",
       "      <td>416.115000</td>\n",
       "      <td>406.200000</td>\n",
       "      <td>390.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>831.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>18.505000</td>\n",
       "      <td>14.395000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.585000</td>\n",
       "      <td>23.915000</td>\n",
       "      <td>12.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>17.595000</td>\n",
       "      <td>9.295000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>826.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>38805.617000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>10752.56000</td>\n",
       "      <td>10427.460000</td>\n",
       "      <td>8362.360000</td>\n",
       "      <td>9667.130000</td>\n",
       "      <td>14007.340000</td>\n",
       "      <td>10310.76000</td>\n",
       "      <td>2613.310000</td>\n",
       "      <td>3813.290000</td>\n",
       "      <td>4169.810000</td>\n",
       "      <td>3220.660000</td>\n",
       "      <td>3775.11000</td>\n",
       "      <td>2812.040000</td>\n",
       "      <td>5337.040000</td>\n",
       "      <td>4428.460000</td>\n",
       "      <td>6431.330000</td>\n",
       "      <td>7400.660000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>10389.240000</td>\n",
       "      <td>4729.740000</td>\n",
       "      <td>4557.140000</td>\n",
       "      <td>4961.330000</td>\n",
       "      <td>4429.880000</td>\n",
       "      <td>676.480000</td>\n",
       "      <td>1057.960000</td>\n",
       "      <td>928.490000</td>\n",
       "      <td>927.410000</td>\n",
       "      <td>342.860000</td>\n",
       "      <td>569.710000</td>\n",
       "      <td>351.830000</td>\n",
       "      <td>274.890000</td>\n",
       "      <td>10643.380000</td>\n",
       "      <td>7674.780000</td>\n",
       "      <td>11039.910000</td>\n",
       "      <td>11099.260000</td>\n",
       "      <td>7366.580000</td>\n",
       "      <td>8133.660000</td>\n",
       "      <td>8014.430000</td>\n",
       "      <td>7244.160000</td>\n",
       "      <td>8314.76000</td>\n",
       "      <td>9284.740000</td>\n",
       "      <td>13950.040000</td>\n",
       "      <td>10223.430000</td>\n",
       "      <td>628.560000</td>\n",
       "      <td>544.630000</td>\n",
       "      <td>516.910000</td>\n",
       "      <td>808.490000</td>\n",
       "      <td>8432.990000</td>\n",
       "      <td>10936.730000</td>\n",
       "      <td>13980.060000</td>\n",
       "      <td>10238.380000</td>\n",
       "      <td>5900.660000</td>\n",
       "      <td>5490.280000</td>\n",
       "      <td>5681.540000</td>\n",
       "      <td>4244.530000</td>\n",
       "      <td>1023.210000</td>\n",
       "      <td>1265.790000</td>\n",
       "      <td>1390.880000</td>\n",
       "      <td>1069.090000</td>\n",
       "      <td>100.610000</td>\n",
       "      <td>221.940000</td>\n",
       "      <td>394.930000</td>\n",
       "      <td>787.790000</td>\n",
       "      <td>10674.030000</td>\n",
       "      <td>11365.310000</td>\n",
       "      <td>14043.060000</td>\n",
       "      <td>11140.110000</td>\n",
       "      <td>6351.440000</td>\n",
       "      <td>5709.590000</td>\n",
       "      <td>4003.210000</td>\n",
       "      <td>7565.890000</td>\n",
       "      <td>4693.860000</td>\n",
       "      <td>4171.510000</td>\n",
       "      <td>5738.460000</td>\n",
       "      <td>4534.790000</td>\n",
       "      <td>1678.410000</td>\n",
       "      <td>1983.010000</td>\n",
       "      <td>1588.530000</td>\n",
       "      <td>4318.280000</td>\n",
       "      <td>6496.110000</td>\n",
       "      <td>6466.740000</td>\n",
       "      <td>5748.810000</td>\n",
       "      <td>7785.460000</td>\n",
       "      <td>5459.560000</td>\n",
       "      <td>5800.93000</td>\n",
       "      <td>4309.290000</td>\n",
       "      <td>3819.830000</td>\n",
       "      <td>4630.230000</td>\n",
       "      <td>3100.840000</td>\n",
       "      <td>5645.860000</td>\n",
       "      <td>5689.760000</td>\n",
       "      <td>1351.110000</td>\n",
       "      <td>1136.080000</td>\n",
       "      <td>1394.890000</td>\n",
       "      <td>1431.960000</td>\n",
       "      <td>5459.630000</td>\n",
       "      <td>6745.760000</td>\n",
       "      <td>5957.140000</td>\n",
       "      <td>5956.660000</td>\n",
       "      <td>6798.640000</td>\n",
       "      <td>7279.080000</td>\n",
       "      <td>5990.710000</td>\n",
       "      <td>7785.730000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>21.330000</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>21.560000</td>\n",
       "      <td>3965.690000</td>\n",
       "      <td>4747.910000</td>\n",
       "      <td>4100.380000</td>\n",
       "      <td>5057.740000</td>\n",
       "      <td>1344.140000</td>\n",
       "      <td>1495.940000</td>\n",
       "      <td>1209.860000</td>\n",
       "      <td>919.630000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>35190.000000</td>\n",
       "      <td>40335.000000</td>\n",
       "      <td>45320.000000</td>\n",
       "      <td>37235.000000</td>\n",
       "      <td>3559.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>3399.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>3399.000000</td>\n",
       "      <td>10285.900000</td>\n",
       "      <td>7873.550000</td>\n",
       "      <td>11117.610000</td>\n",
       "      <td>8993.950000</td>\n",
       "      <td>26826.130000</td>\n",
       "      <td>28144.120000</td>\n",
       "      <td>29651.830000</td>\n",
       "      <td>26857.040000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4321.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.210000</td>\n",
       "      <td>2618.570000</td>\n",
       "      <td>37762.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             arpu_6        arpu_7        arpu_8        arpu_9   onnet_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     605.381915    618.668251    580.047979    539.711103    308.772567   \n",
       "std      437.843670    464.965572    502.170458    505.824898    467.783907   \n",
       "min     -810.661000   -622.509000   -345.129000  -1474.195000      0.000000   \n",
       "25%      383.939000    391.220000    334.649000    291.030000     46.445000   \n",
       "50%      512.599000    520.648000    489.762000    455.884000    135.880000   \n",
       "75%      718.534500    728.702500    712.486000    677.751000    373.975000   \n",
       "max    27731.088000  35145.834000  33543.624000  38805.617000   7376.710000   \n",
       "\n",
       "        onnet_mou_7  onnet_mou_8   onnet_mou_9  offnet_mou_6  offnet_mou_7  \\\n",
       "count  25335.000000  25335.00000  25335.000000  25335.000000  25335.000000   \n",
       "mean     323.663869    294.68391    269.313954    434.100403    448.695341   \n",
       "std      494.784885    487.04074    464.580570    470.461181    494.027416   \n",
       "min        0.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%       47.740000     37.66000     29.810000    149.680000    153.120000   \n",
       "50%      139.330000    118.04000    103.310000    299.190000    305.130000   \n",
       "75%      391.550000    339.67500    299.980000    546.900000    568.160000   \n",
       "max     8157.780000  10752.56000  10427.460000   8362.360000   9667.130000   \n",
       "\n",
       "       offnet_mou_8  offnet_mou_9  roam_ic_mou_6  roam_ic_mou_7  \\\n",
       "count  25335.000000   25335.00000   25335.000000   25335.000000   \n",
       "mean     410.454928     375.18889      18.061622      14.346624   \n",
       "std      491.009571     459.10733      79.379923      79.562310   \n",
       "min        0.000000       0.00000       0.000000       0.000000   \n",
       "25%      121.825000      98.31000       0.000000       0.000000   \n",
       "50%      271.480000     241.33000       0.000000       0.000000   \n",
       "75%      522.885000     478.54500       0.000000       0.000000   \n",
       "max    14007.340000   10310.76000    2613.310000    3813.290000   \n",
       "\n",
       "       roam_ic_mou_8  roam_ic_mou_9  roam_og_mou_6  roam_og_mou_7  \\\n",
       "count   25335.000000   25335.000000    25335.00000   25335.000000   \n",
       "mean       14.582006      12.838677       30.56156      23.280403   \n",
       "std        79.311801      73.212563      120.77578     101.356114   \n",
       "min         0.000000       0.000000        0.00000       0.000000   \n",
       "25%         0.000000       0.000000        0.00000       0.000000   \n",
       "50%         0.000000       0.000000        0.00000       0.000000   \n",
       "75%         0.000000       0.000000        0.00000       0.000000   \n",
       "max      4169.810000    3220.660000     3775.11000    2812.040000   \n",
       "\n",
       "       roam_og_mou_8  roam_og_mou_9  loc_og_t2t_mou_6  loc_og_t2t_mou_7  \\\n",
       "count   25335.000000   25335.000000      25335.000000      25335.000000   \n",
       "mean       23.590945      19.478126         99.960790        103.126631   \n",
       "std       112.585652      96.627672        245.564009        262.585641   \n",
       "min         0.000000       0.000000          0.000000          0.000000   \n",
       "25%         0.000000       0.000000          9.730000         10.760000   \n",
       "50%         0.000000       0.000000         35.310000         37.060000   \n",
       "75%         0.000000       0.000000         97.335000         98.285000   \n",
       "max      5337.040000    4428.460000       6431.330000       7400.660000   \n",
       "\n",
       "       loc_og_t2t_mou_8  loc_og_t2t_mou_9  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          95.763798         89.748857        190.822741        193.354505   \n",
       "std          249.911233        242.902259        256.217219        247.363734   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            8.410000          6.790000         34.110000         38.880000   \n",
       "50%           33.890000         30.580000        109.310000        114.260000   \n",
       "75%           94.650000         87.775000        253.535000        257.235000   \n",
       "max        10752.560000      10389.240000       4729.740000       4557.140000   \n",
       "\n",
       "       loc_og_t2m_mou_8  loc_og_t2m_mou_9  loc_og_t2f_mou_6  loc_og_t2f_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         183.183204        174.409525          7.326504          7.524519   \n",
       "std          242.759117        243.334144         22.025513         22.588417   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%           30.635000         26.050000          0.000000          0.000000   \n",
       "50%          104.030000         94.590000          0.480000          0.560000   \n",
       "75%          244.405000        230.130000          5.540000          5.810000   \n",
       "max         4961.330000       4429.880000        676.480000       1057.960000   \n",
       "\n",
       "       loc_og_t2f_mou_8  loc_og_t2f_mou_9  loc_og_t2c_mou_6  loc_og_t2c_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean           7.006037          6.902271          1.608491          1.905115   \n",
       "std           21.293992         21.498673          6.989765          9.246516   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.410000          0.280000          0.000000          0.000000   \n",
       "75%            5.330000          4.980000          0.000000          0.160000   \n",
       "max          928.490000        927.410000        342.860000        569.710000   \n",
       "\n",
       "       loc_og_t2c_mou_8  loc_og_t2c_mou_9  loc_og_mou_6  loc_og_mou_7  \\\n",
       "count      25335.000000      25335.000000  25335.000000  25335.000000   \n",
       "mean           1.811716          1.550170    298.119074    304.014879   \n",
       "std            7.658958          6.572505    390.703307    390.011607   \n",
       "min            0.000000          0.000000      0.000000      0.000000   \n",
       "25%            0.000000          0.000000     57.770000     65.625000   \n",
       "50%            0.000000          0.000000    179.840000    188.190000   \n",
       "75%            0.160000          0.010000    393.350000    404.120000   \n",
       "max          351.830000        274.890000  10643.380000   7674.780000   \n",
       "\n",
       "       loc_og_mou_8  loc_og_mou_9  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "count  25335.000000  25335.000000      25335.000000      25335.000000   \n",
       "mean     285.961925    271.069297        196.812613        211.379736   \n",
       "std      381.771064    379.753460        415.838101        438.203399   \n",
       "min        0.000000      0.000000          0.000000          0.000000   \n",
       "25%       51.520000     44.230000          0.000000          0.000000   \n",
       "50%      170.930000    156.130000         15.390000         17.130000   \n",
       "75%      379.560000    360.370000        191.850000        211.660000   \n",
       "max    11039.910000  11099.260000       7366.580000       8133.660000   \n",
       "\n",
       "       std_og_t2t_mou_8  std_og_t2t_mou_9  std_og_t2m_mou_6  std_og_t2m_mou_7  \\\n",
       "count      25335.000000      25335.000000       25335.00000      25335.000000   \n",
       "mean         189.782722        171.691855         208.44343        224.532096   \n",
       "std          428.727579        404.208737         414.50022        448.737359   \n",
       "min            0.000000          0.000000           0.00000          0.000000   \n",
       "25%            0.000000          0.000000           2.38000          2.245000   \n",
       "50%            9.950000          7.730000          42.41000         43.780000   \n",
       "75%          163.910000        138.875000         220.50000        241.395000   \n",
       "max         8014.430000       7244.160000        8314.76000       9284.740000   \n",
       "\n",
       "       std_og_t2m_mou_8  std_og_t2m_mou_9  std_og_t2f_mou_6  std_og_t2f_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         197.083311        174.495441          2.083931          2.132881   \n",
       "std          436.163646        392.676262         12.723130         13.952247   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.930000          0.250000          0.000000          0.000000   \n",
       "50%           32.010000         25.440000          0.000000          0.000000   \n",
       "75%          193.235000        164.750000          0.000000          0.000000   \n",
       "max        13950.040000      10223.430000        628.560000        544.630000   \n",
       "\n",
       "       std_og_t2f_mou_8  std_og_t2f_mou_9  std_og_mou_6  std_og_mou_7  \\\n",
       "count      25335.000000      25335.000000  25335.000000  25335.000000   \n",
       "mean           1.899306          1.800965    407.344440    438.049207   \n",
       "std           11.992246         12.465551    609.228997    651.051194   \n",
       "min            0.000000          0.000000      0.000000      0.000000   \n",
       "25%            0.000000          0.000000      7.650000      7.790000   \n",
       "50%            0.000000          0.000000    140.740000    155.510000   \n",
       "75%            0.000000          0.000000    599.365000    657.635000   \n",
       "max          516.910000        808.490000   8432.990000  10936.730000   \n",
       "\n",
       "       std_og_mou_8  std_og_mou_9  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     388.769519    347.992249      2.125238      2.191998      2.156291   \n",
       "std      640.513506    593.202566     47.841689     48.191701     48.117680   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        4.535000      2.790000      0.000000      0.000000      0.000000   \n",
       "50%      103.240000     81.940000      0.000000      0.000000      0.000000   \n",
       "75%      547.335000    467.285000      0.000000      0.000000      0.000000   \n",
       "max    13980.060000  10238.380000   5900.660000   5490.280000   5681.540000   \n",
       "\n",
       "       isd_og_mou_9  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  spl_og_mou_9  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       1.945745      6.030383      7.639063      7.345974      6.176769   \n",
       "std       39.440580     18.869381     23.583356     23.659722     19.541272   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.310000      0.900000      0.810000      0.510000   \n",
       "75%        0.000000      5.390000      7.460000      7.110000      5.655000   \n",
       "max     4244.530000   1023.210000   1265.790000   1390.880000   1069.090000   \n",
       "\n",
       "        og_others_6   og_others_7   og_others_8   og_others_9  total_og_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000    25335.000000   \n",
       "mean       0.704512      0.039078      0.049230      0.094892      714.333663   \n",
       "std        2.330394      1.862022      2.733586      5.977913      659.239073   \n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      291.950000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      542.580000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      930.725000   \n",
       "max      100.610000    221.940000    394.930000    787.790000    10674.030000   \n",
       "\n",
       "       total_og_mou_7  total_og_mou_8  total_og_mou_9  loc_ic_t2t_mou_6  \\\n",
       "count    25335.000000    25335.000000    25335.000000      25335.000000   \n",
       "mean       751.943194      684.291694      627.287414         71.333108   \n",
       "std        692.061684      699.416899      669.294780        159.764080   \n",
       "min          0.000000        0.000000        0.000000          0.000000   \n",
       "25%        309.570000      241.720000      199.820000          9.580000   \n",
       "50%        570.810000      495.260000      445.680000         31.380000   \n",
       "75%        980.185000      902.935000      830.910000         77.195000   \n",
       "max      11365.310000    14043.060000    11140.110000       6351.440000   \n",
       "\n",
       "       loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2t_mou_9  loc_ic_t2m_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          73.848361         71.173280         68.356177        166.124937   \n",
       "std          167.999534        162.414297        168.704613        222.977501   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%           11.110000          9.130000          8.290000         37.135000   \n",
       "50%           33.090000         30.390000         28.810000         99.930000   \n",
       "75%           79.450000         76.880000         72.810000        211.750000   \n",
       "max         5709.590000       4003.210000       7565.890000       4693.860000   \n",
       "\n",
       "       loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2m_mou_9  loc_ic_t2f_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         169.562449        166.215392        158.136124         16.339769   \n",
       "std          222.864795        223.408317        212.539206         47.329733   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%           42.635000         37.970000         33.610000          0.000000   \n",
       "50%          103.810000        100.730000         93.780000          2.250000   \n",
       "75%          215.200000        212.100000        201.715000         13.390000   \n",
       "max         4171.510000       5738.460000       4534.790000       1678.410000   \n",
       "\n",
       "       loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_t2f_mou_9  loc_ic_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000  25335.000000   \n",
       "mean          17.317704         15.785543         16.258380    253.807895   \n",
       "std           50.779238         45.608537         56.591804    313.758944   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000     63.315000   \n",
       "50%            2.590000          2.360000          2.240000    160.530000   \n",
       "75%           14.135000         12.910000         12.830000    328.350000   \n",
       "max         1983.010000       1588.530000       4318.280000   6496.110000   \n",
       "\n",
       "       loc_ic_mou_7  loc_ic_mou_8  loc_ic_mou_9  std_ic_t2t_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000      25335.000000   \n",
       "mean     260.738785    253.184272    242.760671         16.844002   \n",
       "std      318.977995    316.417005    315.233280         82.455660   \n",
       "min        0.000000      0.000000      0.000000          0.000000   \n",
       "25%       71.730000     62.880000     57.160000          0.000000   \n",
       "50%      166.990000    159.790000    149.480000          1.280000   \n",
       "75%      335.180000    325.825000    312.830000         10.930000   \n",
       "max     6466.740000   5748.810000   7785.460000       5459.560000   \n",
       "\n",
       "       std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2t_mou_9  std_ic_t2m_mou_6  \\\n",
       "count       25335.00000      25335.000000      25335.000000      25335.000000   \n",
       "mean           17.88079         16.471824         15.634095         32.600116   \n",
       "std            90.11867         77.316442         74.839966         98.893301   \n",
       "min             0.00000          0.000000          0.000000          0.000000   \n",
       "25%             0.00000          0.000000          0.000000          0.660000   \n",
       "50%             1.53000          0.960000          0.700000          7.690000   \n",
       "75%            11.79000         10.130000          9.130000         28.530000   \n",
       "max          5800.93000       4309.290000       3819.830000       4630.230000   \n",
       "\n",
       "       std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2m_mou_9  std_ic_t2f_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          34.782159         32.666067         29.869764          3.025538   \n",
       "std          105.551242        109.024813         97.472437         21.174910   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.750000          0.400000          0.200000          0.000000   \n",
       "50%            8.410000          6.980000          6.140000          0.000000   \n",
       "75%           31.030000         28.170000         25.640000          0.255000   \n",
       "max         3100.840000       5645.860000       5689.760000       1351.110000   \n",
       "\n",
       "       std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_t2f_mou_9  std_ic_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000  25335.000000   \n",
       "mean           3.149795          2.881318          2.962192     52.473777   \n",
       "std           21.633461         21.648678         21.458616    141.642485   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000      3.180000   \n",
       "50%            0.000000          0.000000          0.000000     16.130000   \n",
       "75%            0.350000          0.300000          0.330000     48.985000   \n",
       "max         1136.080000       1394.890000       1431.960000   5459.630000   \n",
       "\n",
       "       std_ic_mou_7  std_ic_mou_8  std_ic_mou_9  total_ic_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000    25335.000000   \n",
       "mean      55.816969     52.023210     48.469934      318.424015   \n",
       "std      153.424340    147.512098    137.805366      361.531618   \n",
       "min        0.000000      0.000000      0.000000        0.000000   \n",
       "25%        3.430000      2.510000      1.910000       97.540000   \n",
       "50%       17.610000     14.680000     13.110000      216.910000   \n",
       "75%       52.840000     47.640000     43.975000      407.050000   \n",
       "max     6745.760000   5957.140000   5956.660000     6798.640000   \n",
       "\n",
       "       total_ic_mou_7  total_ic_mou_8  total_ic_mou_9  spl_ic_mou_6  \\\n",
       "count    25335.000000    25335.000000    25335.000000  25335.000000   \n",
       "mean       330.484101      318.718816      304.456263      0.066769   \n",
       "std        373.960638      370.339577      368.825023      0.157630   \n",
       "min          0.000000        0.000000        0.000000      0.000000   \n",
       "25%        109.360000       96.135000       85.910000      0.000000   \n",
       "50%        225.110000      213.330000      199.480000      0.000000   \n",
       "75%        416.115000      406.200000      390.380000      0.000000   \n",
       "max       7279.080000     5990.710000     7785.730000      6.740000   \n",
       "\n",
       "       spl_ic_mou_7  spl_ic_mou_8  spl_ic_mou_9  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.017484      0.029158      0.143782     10.841112     12.306502   \n",
       "std        0.174782      0.113819      0.481188     66.542701     76.654492   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       21.330000      1.260000     21.560000   3965.690000   4747.910000   \n",
       "\n",
       "       isd_ic_mou_8  isd_ic_mou_9   ic_others_6   ic_others_7   ic_others_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean      12.156147     11.640142      1.225623      1.596091      1.317898   \n",
       "std       77.125182     78.966015     14.871170     16.591331     13.609714   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.080000      0.060000      0.080000   \n",
       "max     4100.380000   5057.740000   1344.140000   1495.940000   1209.860000   \n",
       "\n",
       "        ic_others_9  total_rech_num_6  total_rech_num_7  total_rech_num_8  \\\n",
       "count  25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean       1.433080         12.369213         12.339925         10.954529   \n",
       "std       14.653972          9.478604          9.636941          9.581220   \n",
       "min        0.000000          1.000000          1.000000          1.000000   \n",
       "25%        0.000000          7.000000          6.000000          5.000000   \n",
       "50%        0.000000         10.000000         10.000000          8.000000   \n",
       "75%        0.050000         15.000000         15.000000         14.000000   \n",
       "max      919.630000        307.000000        138.000000        138.000000   \n",
       "\n",
       "       total_rech_num_9  total_rech_amt_6  total_rech_amt_7  total_rech_amt_8  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          10.530255        717.326071        730.384054        669.618315   \n",
       "std            9.177389        535.704258        562.700046        615.007473   \n",
       "min            1.000000          0.000000          0.000000          0.000000   \n",
       "25%            5.000000        453.500000        458.000000        370.000000   \n",
       "50%            8.000000        602.000000        612.000000        566.000000   \n",
       "75%           13.000000        853.000000        865.000000        831.000000   \n",
       "max          131.000000      35190.000000      40335.000000      45320.000000   \n",
       "\n",
       "       total_rech_amt_9  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "count      25335.000000    25335.000000    25335.000000    25335.000000   \n",
       "mean         628.554727      170.440300      176.367397      171.691455   \n",
       "std          594.838126      164.154017      173.003988      169.981003   \n",
       "min            0.000000        0.000000        0.000000        0.000000   \n",
       "25%          322.000000      110.000000      110.000000      100.000000   \n",
       "50%          529.000000      120.000000      128.000000      130.000000   \n",
       "75%          800.000000      200.000000      200.000000      198.000000   \n",
       "max        37235.000000     3559.000000     3299.000000     4449.000000   \n",
       "\n",
       "       max_rech_amt_9  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "count    25335.000000        25335.000000        25335.000000   \n",
       "mean       168.035485          103.618394          106.819814   \n",
       "std        168.862541          131.004585          133.878195   \n",
       "min          0.000000            0.000000            0.000000   \n",
       "25%         77.000000           30.000000           30.000000   \n",
       "50%        130.000000          110.000000          100.000000   \n",
       "75%        200.000000          120.000000          130.000000   \n",
       "max       3399.000000         3299.000000         3100.000000   \n",
       "\n",
       "       last_day_rch_amt_8  last_day_rch_amt_9   vol_2g_mb_6   vol_2g_mb_7  \\\n",
       "count        25335.000000        25335.000000  25335.000000  25335.000000   \n",
       "mean           101.055181           73.296428     80.828362     80.695662   \n",
       "std            143.671631          125.580816    279.498393    284.506065   \n",
       "min              0.000000            0.000000      0.000000      0.000000   \n",
       "25%             20.000000            0.000000      0.000000      0.000000   \n",
       "50%             50.000000           30.000000      0.000000      0.000000   \n",
       "75%            130.000000          130.000000     17.320000     18.505000   \n",
       "max           4449.000000         3399.000000  10285.900000   7873.550000   \n",
       "\n",
       "        vol_2g_mb_8   vol_2g_mb_9   vol_3g_mb_6   vol_3g_mb_7   vol_3g_mb_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean      74.095703     66.970864    259.031232    285.911329    286.022239   \n",
       "std      278.235033    253.897541    810.698076    848.283045    861.636669   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       14.395000     11.200000      0.000000     30.585000     23.915000   \n",
       "max    11117.610000   8993.950000  26826.130000  28144.120000  29651.830000   \n",
       "\n",
       "        vol_3g_mb_9  monthly_2g_6  monthly_2g_7  monthly_2g_8  monthly_2g_9  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     292.322928      0.131202      0.138701      0.122913      0.107953   \n",
       "std      892.571162      0.382467      0.397484      0.369948      0.350807   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       12.620000      0.000000      0.000000      0.000000      0.000000   \n",
       "max    26857.040000      4.000000      5.000000      5.000000      4.000000   \n",
       "\n",
       "        sachet_2g_6   sachet_2g_7   sachet_2g_8   sachet_2g_9  monthly_3g_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.508861      0.606315      0.647642      0.563726      0.176436   \n",
       "std        1.706819      1.910562      1.886947      1.591092      0.579352   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       39.000000     48.000000     44.000000     40.000000     14.000000   \n",
       "\n",
       "       monthly_3g_7  monthly_3g_8  monthly_3g_9   sachet_3g_6   sachet_3g_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.192856      0.185554      0.194237      0.142333      0.157845   \n",
       "std        0.641568      0.605907      0.602066      0.881705      0.984721   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       16.000000     16.000000     11.000000     29.000000     33.000000   \n",
       "\n",
       "        sachet_3g_8   sachet_3g_9           aon    aug_vbc_3g    jul_vbc_3g  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.154411      0.149398   1290.944622    139.401235    142.534482   \n",
       "std        1.033961      0.985798    978.149101    405.205464    421.298082   \n",
       "min        0.000000      0.000000    180.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000    487.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000    950.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000   1980.000000     17.595000      9.295000   \n",
       "max       41.000000     49.000000   4321.000000  12916.220000   9165.600000   \n",
       "\n",
       "         jun_vbc_3g    sep_vbc_3g  average_rech_amt_g  \n",
       "count  25335.000000  25335.000000        25335.000000  \n",
       "mean     126.035382      7.215953          723.855062  \n",
       "std      395.788710     50.055596          500.600700  \n",
       "min        0.000000      0.000000          390.000000  \n",
       "25%        0.000000      0.000000          474.500000  \n",
       "50%        0.000000      0.000000          596.000000  \n",
       "75%        0.000000      0.000000          826.500000  \n",
       "max    11166.210000   2618.570000        37762.500000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Churners\n",
    "\n",
    "**Now tag the churned customers (churn=1, else 0) based on the fourth month as follows:** Those who have not made any calls (either incoming or outgoing) AND have not used mobile internet even once in the churn phase. The attributes we need to use to tag churners are:\n",
    "\n",
    "- total_ic_mou_9\n",
    "\n",
    "- total_og_mou_9\n",
    "\n",
    "- vol_2g_mb_9\n",
    "\n",
    "- vol_3g_mb_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagging Churn\n",
    "fdf['Churn'] = np.where((fdf['total_ic_mou_9']==0) & (fdf['total_og_mou_9']==0) & (fdf['vol_2g_mb_9']==0 ) & (fdf['vol_3g_mb_9']==0),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_ic_mou_9</th>\n",
       "      <th>total_og_mou_9</th>\n",
       "      <th>vol_2g_mb_9</th>\n",
       "      <th>vol_3g_mb_9</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_ic_mou_9  total_og_mou_9  vol_2g_mb_9  vol_3g_mb_9  Churn\n",
       "199             0.0             0.0          0.0          0.0      1\n",
       "590             0.0             0.0          0.0          0.0      1\n",
       "594             0.0             0.0          0.0          0.0      1\n",
       "691             0.0             0.0          0.0          0.0      1\n",
       "763             0.0             0.0          0.0          0.0      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf[(fdf['total_ic_mou_9']==0) & (fdf['total_og_mou_9']==0) & (fdf['vol_2g_mb_9']==0 ) & (fdf['vol_3g_mb_9']==0)][['total_ic_mou_9','total_og_mou_9','vol_2g_mb_9','vol_3g_mb_9','Churn']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have successfully tagged the Churned Customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all the attributes corresponding to Churn Phase\n",
    "col9 = [i for i in fdf.columns if i.endswith('_9')]\n",
    "fdf=fdf.drop(col9,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25335, 133)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now left with 133 columns in fdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Finding the Churn Rate***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vc=fdf['Churn'].value_counts()\n",
    "vc=round(vc/len(fdf)*100,2)\n",
    "colors = [\"green\",\"red\"] \n",
    "labels=[\"0\",\"1\"]\n",
    "plt.pie(vc, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=270,)\n",
    "plt.title('Percentage of Churn in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we observe that only 3.3% of the high value customers churn. We have a churn rate of 3.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exploring the categorical variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last_date_of_month_6',\n",
       " 'last_date_of_month_7',\n",
       " 'last_date_of_month_8',\n",
       " 'date_of_last_rech_6',\n",
       " 'date_of_last_rech_7',\n",
       " 'date_of_last_rech_8']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col=list(fdf.select_dtypes('object').columns)\n",
    "cat_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the Dates to DateTime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_col:\n",
    "    fdf[col]=pd.to_datetime(fdf[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We derive the recency of recharge in each month from the last date of each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf['Recency_6']=fdf['last_date_of_month_6'].dt.day-fdf['date_of_last_rech_6'].dt.day\n",
    "fdf['Recency_7']=fdf['last_date_of_month_7'].dt.day-fdf['date_of_last_rech_7'].dt.day\n",
    "fdf['Recency_8']=fdf['last_date_of_month_8'].dt.day-fdf['date_of_last_rech_8'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency_6</th>\n",
       "      <th>Recency_7</th>\n",
       "      <th>Recency_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99970</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99974</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99986</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99988</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Recency_6  Recency_7  Recency_8\n",
       "8              5          0          1\n",
       "16             0          0         17\n",
       "17             0          1          6\n",
       "21             0          0          0\n",
       "33             0          1          5\n",
       "...          ...        ...        ...\n",
       "99965          0          0          0\n",
       "99970          0          2          8\n",
       "99974          1          4          8\n",
       "99986         10          3         13\n",
       "99988          0          3          2\n",
       "\n",
       "[25335 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf[['Recency_6','Recency_7','Recency_8']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking the Recency for each month with Churn Category***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxenplot(y='Recency_6',x='Churn',data=fdf)\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxenplot(y='Recency_7',x='Churn',data=fdf)\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxenplot(y='Recency_8',x='Churn',data=fdf)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Hence, as we transition from good phase to action phase, the probability of Churn increases as the number of days since the last recharge increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the date columns\n",
    "fdf=fdf.drop(cat_col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf_original=fdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analyzing the numerical variables-Univariate Analysis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col=list(fdf.select_dtypes(include=[np.int64,np.float64]).columns)\n",
    "len(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>average_rech_amt_g</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Recency_6</th>\n",
       "      <th>Recency_7</th>\n",
       "      <th>Recency_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>605.381915</td>\n",
       "      <td>618.668251</td>\n",
       "      <td>580.047979</td>\n",
       "      <td>308.772567</td>\n",
       "      <td>323.663869</td>\n",
       "      <td>294.68391</td>\n",
       "      <td>434.100403</td>\n",
       "      <td>448.695341</td>\n",
       "      <td>410.454928</td>\n",
       "      <td>18.061622</td>\n",
       "      <td>14.346624</td>\n",
       "      <td>14.582006</td>\n",
       "      <td>30.56156</td>\n",
       "      <td>23.280403</td>\n",
       "      <td>23.590945</td>\n",
       "      <td>99.960790</td>\n",
       "      <td>103.126631</td>\n",
       "      <td>95.763798</td>\n",
       "      <td>190.822741</td>\n",
       "      <td>193.354505</td>\n",
       "      <td>183.183204</td>\n",
       "      <td>7.326504</td>\n",
       "      <td>7.524519</td>\n",
       "      <td>7.006037</td>\n",
       "      <td>1.608491</td>\n",
       "      <td>1.905115</td>\n",
       "      <td>1.811716</td>\n",
       "      <td>298.119074</td>\n",
       "      <td>304.014879</td>\n",
       "      <td>285.961925</td>\n",
       "      <td>196.812613</td>\n",
       "      <td>211.379736</td>\n",
       "      <td>189.782722</td>\n",
       "      <td>208.44343</td>\n",
       "      <td>224.532096</td>\n",
       "      <td>197.083311</td>\n",
       "      <td>2.083931</td>\n",
       "      <td>2.132881</td>\n",
       "      <td>1.899306</td>\n",
       "      <td>407.344440</td>\n",
       "      <td>438.049207</td>\n",
       "      <td>388.769519</td>\n",
       "      <td>2.125238</td>\n",
       "      <td>2.191998</td>\n",
       "      <td>2.156291</td>\n",
       "      <td>6.030383</td>\n",
       "      <td>7.639063</td>\n",
       "      <td>7.345974</td>\n",
       "      <td>0.704512</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.049230</td>\n",
       "      <td>714.333663</td>\n",
       "      <td>751.943194</td>\n",
       "      <td>684.291694</td>\n",
       "      <td>71.333108</td>\n",
       "      <td>73.848361</td>\n",
       "      <td>71.173280</td>\n",
       "      <td>166.124937</td>\n",
       "      <td>169.562449</td>\n",
       "      <td>166.215392</td>\n",
       "      <td>16.339769</td>\n",
       "      <td>17.317704</td>\n",
       "      <td>15.785543</td>\n",
       "      <td>253.807895</td>\n",
       "      <td>260.738785</td>\n",
       "      <td>253.184272</td>\n",
       "      <td>16.844002</td>\n",
       "      <td>17.88079</td>\n",
       "      <td>16.471824</td>\n",
       "      <td>32.600116</td>\n",
       "      <td>34.782159</td>\n",
       "      <td>32.666067</td>\n",
       "      <td>3.025538</td>\n",
       "      <td>3.149795</td>\n",
       "      <td>2.881318</td>\n",
       "      <td>52.473777</td>\n",
       "      <td>55.816969</td>\n",
       "      <td>52.023210</td>\n",
       "      <td>318.424015</td>\n",
       "      <td>330.484101</td>\n",
       "      <td>318.718816</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>10.841112</td>\n",
       "      <td>12.306502</td>\n",
       "      <td>12.156147</td>\n",
       "      <td>1.225623</td>\n",
       "      <td>1.596091</td>\n",
       "      <td>1.317898</td>\n",
       "      <td>12.369213</td>\n",
       "      <td>12.339925</td>\n",
       "      <td>10.954529</td>\n",
       "      <td>717.326071</td>\n",
       "      <td>730.384054</td>\n",
       "      <td>669.618315</td>\n",
       "      <td>170.440300</td>\n",
       "      <td>176.367397</td>\n",
       "      <td>171.691455</td>\n",
       "      <td>103.618394</td>\n",
       "      <td>106.819814</td>\n",
       "      <td>101.055181</td>\n",
       "      <td>80.828362</td>\n",
       "      <td>80.695662</td>\n",
       "      <td>74.095703</td>\n",
       "      <td>259.031232</td>\n",
       "      <td>285.911329</td>\n",
       "      <td>286.022239</td>\n",
       "      <td>0.131202</td>\n",
       "      <td>0.138701</td>\n",
       "      <td>0.122913</td>\n",
       "      <td>0.508861</td>\n",
       "      <td>0.606315</td>\n",
       "      <td>0.647642</td>\n",
       "      <td>0.176436</td>\n",
       "      <td>0.192856</td>\n",
       "      <td>0.185554</td>\n",
       "      <td>0.142333</td>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.154411</td>\n",
       "      <td>1290.944622</td>\n",
       "      <td>139.401235</td>\n",
       "      <td>142.534482</td>\n",
       "      <td>126.035382</td>\n",
       "      <td>7.215953</td>\n",
       "      <td>723.855062</td>\n",
       "      <td>0.033274</td>\n",
       "      <td>2.973318</td>\n",
       "      <td>3.163489</td>\n",
       "      <td>3.712532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>437.843670</td>\n",
       "      <td>464.965572</td>\n",
       "      <td>502.170458</td>\n",
       "      <td>467.783907</td>\n",
       "      <td>494.784885</td>\n",
       "      <td>487.04074</td>\n",
       "      <td>470.461181</td>\n",
       "      <td>494.027416</td>\n",
       "      <td>491.009571</td>\n",
       "      <td>79.379923</td>\n",
       "      <td>79.562310</td>\n",
       "      <td>79.311801</td>\n",
       "      <td>120.77578</td>\n",
       "      <td>101.356114</td>\n",
       "      <td>112.585652</td>\n",
       "      <td>245.564009</td>\n",
       "      <td>262.585641</td>\n",
       "      <td>249.911233</td>\n",
       "      <td>256.217219</td>\n",
       "      <td>247.363734</td>\n",
       "      <td>242.759117</td>\n",
       "      <td>22.025513</td>\n",
       "      <td>22.588417</td>\n",
       "      <td>21.293992</td>\n",
       "      <td>6.989765</td>\n",
       "      <td>9.246516</td>\n",
       "      <td>7.658958</td>\n",
       "      <td>390.703307</td>\n",
       "      <td>390.011607</td>\n",
       "      <td>381.771064</td>\n",
       "      <td>415.838101</td>\n",
       "      <td>438.203399</td>\n",
       "      <td>428.727579</td>\n",
       "      <td>414.50022</td>\n",
       "      <td>448.737359</td>\n",
       "      <td>436.163646</td>\n",
       "      <td>12.723130</td>\n",
       "      <td>13.952247</td>\n",
       "      <td>11.992246</td>\n",
       "      <td>609.228997</td>\n",
       "      <td>651.051194</td>\n",
       "      <td>640.513506</td>\n",
       "      <td>47.841689</td>\n",
       "      <td>48.191701</td>\n",
       "      <td>48.117680</td>\n",
       "      <td>18.869381</td>\n",
       "      <td>23.583356</td>\n",
       "      <td>23.659722</td>\n",
       "      <td>2.330394</td>\n",
       "      <td>1.862022</td>\n",
       "      <td>2.733586</td>\n",
       "      <td>659.239073</td>\n",
       "      <td>692.061684</td>\n",
       "      <td>699.416899</td>\n",
       "      <td>159.764080</td>\n",
       "      <td>167.999534</td>\n",
       "      <td>162.414297</td>\n",
       "      <td>222.977501</td>\n",
       "      <td>222.864795</td>\n",
       "      <td>223.408317</td>\n",
       "      <td>47.329733</td>\n",
       "      <td>50.779238</td>\n",
       "      <td>45.608537</td>\n",
       "      <td>313.758944</td>\n",
       "      <td>318.977995</td>\n",
       "      <td>316.417005</td>\n",
       "      <td>82.455660</td>\n",
       "      <td>90.11867</td>\n",
       "      <td>77.316442</td>\n",
       "      <td>98.893301</td>\n",
       "      <td>105.551242</td>\n",
       "      <td>109.024813</td>\n",
       "      <td>21.174910</td>\n",
       "      <td>21.633461</td>\n",
       "      <td>21.648678</td>\n",
       "      <td>141.642485</td>\n",
       "      <td>153.424340</td>\n",
       "      <td>147.512098</td>\n",
       "      <td>361.531618</td>\n",
       "      <td>373.960638</td>\n",
       "      <td>370.339577</td>\n",
       "      <td>0.157630</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.113819</td>\n",
       "      <td>66.542701</td>\n",
       "      <td>76.654492</td>\n",
       "      <td>77.125182</td>\n",
       "      <td>14.871170</td>\n",
       "      <td>16.591331</td>\n",
       "      <td>13.609714</td>\n",
       "      <td>9.478604</td>\n",
       "      <td>9.636941</td>\n",
       "      <td>9.581220</td>\n",
       "      <td>535.704258</td>\n",
       "      <td>562.700046</td>\n",
       "      <td>615.007473</td>\n",
       "      <td>164.154017</td>\n",
       "      <td>173.003988</td>\n",
       "      <td>169.981003</td>\n",
       "      <td>131.004585</td>\n",
       "      <td>133.878195</td>\n",
       "      <td>143.671631</td>\n",
       "      <td>279.498393</td>\n",
       "      <td>284.506065</td>\n",
       "      <td>278.235033</td>\n",
       "      <td>810.698076</td>\n",
       "      <td>848.283045</td>\n",
       "      <td>861.636669</td>\n",
       "      <td>0.382467</td>\n",
       "      <td>0.397484</td>\n",
       "      <td>0.369948</td>\n",
       "      <td>1.706819</td>\n",
       "      <td>1.910562</td>\n",
       "      <td>1.886947</td>\n",
       "      <td>0.579352</td>\n",
       "      <td>0.641568</td>\n",
       "      <td>0.605907</td>\n",
       "      <td>0.881705</td>\n",
       "      <td>0.984721</td>\n",
       "      <td>1.033961</td>\n",
       "      <td>978.149101</td>\n",
       "      <td>405.205464</td>\n",
       "      <td>421.298082</td>\n",
       "      <td>395.788710</td>\n",
       "      <td>50.055596</td>\n",
       "      <td>500.600700</td>\n",
       "      <td>0.179355</td>\n",
       "      <td>3.963857</td>\n",
       "      <td>3.962766</td>\n",
       "      <td>4.682648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-810.661000</td>\n",
       "      <td>-622.509000</td>\n",
       "      <td>-345.129000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>383.939000</td>\n",
       "      <td>391.220000</td>\n",
       "      <td>334.649000</td>\n",
       "      <td>46.445000</td>\n",
       "      <td>47.740000</td>\n",
       "      <td>37.66000</td>\n",
       "      <td>149.680000</td>\n",
       "      <td>153.120000</td>\n",
       "      <td>121.825000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.730000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>34.110000</td>\n",
       "      <td>38.880000</td>\n",
       "      <td>30.635000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.770000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>51.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.38000</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>7.790000</td>\n",
       "      <td>4.535000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>291.950000</td>\n",
       "      <td>309.570000</td>\n",
       "      <td>241.720000</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>9.130000</td>\n",
       "      <td>37.135000</td>\n",
       "      <td>42.635000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.315000</td>\n",
       "      <td>71.730000</td>\n",
       "      <td>62.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>97.540000</td>\n",
       "      <td>109.360000</td>\n",
       "      <td>96.135000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>453.500000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>474.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>512.599000</td>\n",
       "      <td>520.648000</td>\n",
       "      <td>489.762000</td>\n",
       "      <td>135.880000</td>\n",
       "      <td>139.330000</td>\n",
       "      <td>118.04000</td>\n",
       "      <td>299.190000</td>\n",
       "      <td>305.130000</td>\n",
       "      <td>271.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.310000</td>\n",
       "      <td>37.060000</td>\n",
       "      <td>33.890000</td>\n",
       "      <td>109.310000</td>\n",
       "      <td>114.260000</td>\n",
       "      <td>104.030000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.840000</td>\n",
       "      <td>188.190000</td>\n",
       "      <td>170.930000</td>\n",
       "      <td>15.390000</td>\n",
       "      <td>17.130000</td>\n",
       "      <td>9.950000</td>\n",
       "      <td>42.41000</td>\n",
       "      <td>43.780000</td>\n",
       "      <td>32.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.740000</td>\n",
       "      <td>155.510000</td>\n",
       "      <td>103.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>542.580000</td>\n",
       "      <td>570.810000</td>\n",
       "      <td>495.260000</td>\n",
       "      <td>31.380000</td>\n",
       "      <td>33.090000</td>\n",
       "      <td>30.390000</td>\n",
       "      <td>99.930000</td>\n",
       "      <td>103.810000</td>\n",
       "      <td>100.730000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>160.530000</td>\n",
       "      <td>166.990000</td>\n",
       "      <td>159.790000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.53000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.130000</td>\n",
       "      <td>17.610000</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>216.910000</td>\n",
       "      <td>225.110000</td>\n",
       "      <td>213.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>718.534500</td>\n",
       "      <td>728.702500</td>\n",
       "      <td>712.486000</td>\n",
       "      <td>373.975000</td>\n",
       "      <td>391.550000</td>\n",
       "      <td>339.67500</td>\n",
       "      <td>546.900000</td>\n",
       "      <td>568.160000</td>\n",
       "      <td>522.885000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.335000</td>\n",
       "      <td>98.285000</td>\n",
       "      <td>94.650000</td>\n",
       "      <td>253.535000</td>\n",
       "      <td>257.235000</td>\n",
       "      <td>244.405000</td>\n",
       "      <td>5.540000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>393.350000</td>\n",
       "      <td>404.120000</td>\n",
       "      <td>379.560000</td>\n",
       "      <td>191.850000</td>\n",
       "      <td>211.660000</td>\n",
       "      <td>163.910000</td>\n",
       "      <td>220.50000</td>\n",
       "      <td>241.395000</td>\n",
       "      <td>193.235000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>599.365000</td>\n",
       "      <td>657.635000</td>\n",
       "      <td>547.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>7.460000</td>\n",
       "      <td>7.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>930.725000</td>\n",
       "      <td>980.185000</td>\n",
       "      <td>902.935000</td>\n",
       "      <td>77.195000</td>\n",
       "      <td>79.450000</td>\n",
       "      <td>76.880000</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>215.200000</td>\n",
       "      <td>212.100000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>14.135000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>328.350000</td>\n",
       "      <td>335.180000</td>\n",
       "      <td>325.825000</td>\n",
       "      <td>10.930000</td>\n",
       "      <td>11.79000</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>28.530000</td>\n",
       "      <td>31.030000</td>\n",
       "      <td>28.170000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>48.985000</td>\n",
       "      <td>52.840000</td>\n",
       "      <td>47.640000</td>\n",
       "      <td>407.050000</td>\n",
       "      <td>416.115000</td>\n",
       "      <td>406.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>831.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>18.505000</td>\n",
       "      <td>14.395000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.585000</td>\n",
       "      <td>23.915000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>17.595000</td>\n",
       "      <td>9.295000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95%</td>\n",
       "      <td>1252.490200</td>\n",
       "      <td>1295.677500</td>\n",
       "      <td>1309.061800</td>\n",
       "      <td>1173.282000</td>\n",
       "      <td>1258.870000</td>\n",
       "      <td>1183.91000</td>\n",
       "      <td>1288.039000</td>\n",
       "      <td>1322.240000</td>\n",
       "      <td>1247.580000</td>\n",
       "      <td>99.861000</td>\n",
       "      <td>68.189000</td>\n",
       "      <td>70.913000</td>\n",
       "      <td>175.29800</td>\n",
       "      <td>128.696000</td>\n",
       "      <td>129.294000</td>\n",
       "      <td>363.996000</td>\n",
       "      <td>372.755000</td>\n",
       "      <td>349.532000</td>\n",
       "      <td>641.469000</td>\n",
       "      <td>641.116000</td>\n",
       "      <td>619.141000</td>\n",
       "      <td>35.366000</td>\n",
       "      <td>35.996000</td>\n",
       "      <td>33.510000</td>\n",
       "      <td>8.916000</td>\n",
       "      <td>10.230000</td>\n",
       "      <td>9.810000</td>\n",
       "      <td>966.089000</td>\n",
       "      <td>969.509000</td>\n",
       "      <td>936.374000</td>\n",
       "      <td>1002.849000</td>\n",
       "      <td>1066.177000</td>\n",
       "      <td>1008.627000</td>\n",
       "      <td>971.03300</td>\n",
       "      <td>1046.376000</td>\n",
       "      <td>947.686000</td>\n",
       "      <td>8.440000</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.583000</td>\n",
       "      <td>1568.305000</td>\n",
       "      <td>1660.510000</td>\n",
       "      <td>1594.561000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>27.146000</td>\n",
       "      <td>32.896000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>4.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1940.979000</td>\n",
       "      <td>2010.934000</td>\n",
       "      <td>1961.633000</td>\n",
       "      <td>250.398000</td>\n",
       "      <td>246.914000</td>\n",
       "      <td>244.671000</td>\n",
       "      <td>536.543000</td>\n",
       "      <td>538.657000</td>\n",
       "      <td>546.255000</td>\n",
       "      <td>75.902000</td>\n",
       "      <td>79.016000</td>\n",
       "      <td>71.140000</td>\n",
       "      <td>794.994000</td>\n",
       "      <td>807.381000</td>\n",
       "      <td>801.720000</td>\n",
       "      <td>66.883000</td>\n",
       "      <td>70.00200</td>\n",
       "      <td>66.140000</td>\n",
       "      <td>130.110000</td>\n",
       "      <td>134.296000</td>\n",
       "      <td>129.333000</td>\n",
       "      <td>12.603000</td>\n",
       "      <td>12.980000</td>\n",
       "      <td>11.616000</td>\n",
       "      <td>205.667000</td>\n",
       "      <td>211.733000</td>\n",
       "      <td>204.100000</td>\n",
       "      <td>959.248000</td>\n",
       "      <td>969.619000</td>\n",
       "      <td>970.839000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>44.653000</td>\n",
       "      <td>51.834000</td>\n",
       "      <td>48.160000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>5.203000</td>\n",
       "      <td>4.280000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1491.000000</td>\n",
       "      <td>1546.000000</td>\n",
       "      <td>1539.000000</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>495.411000</td>\n",
       "      <td>479.459000</td>\n",
       "      <td>441.644000</td>\n",
       "      <td>1519.505000</td>\n",
       "      <td>1632.148000</td>\n",
       "      <td>1604.678000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3197.000000</td>\n",
       "      <td>870.906000</td>\n",
       "      <td>881.403000</td>\n",
       "      <td>784.329000</td>\n",
       "      <td>23.808000</td>\n",
       "      <td>1444.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99%</td>\n",
       "      <td>1982.920300</td>\n",
       "      <td>2024.926280</td>\n",
       "      <td>2051.568360</td>\n",
       "      <td>2174.954000</td>\n",
       "      <td>2282.491200</td>\n",
       "      <td>2281.69300</td>\n",
       "      <td>2325.534200</td>\n",
       "      <td>2435.052000</td>\n",
       "      <td>2273.954000</td>\n",
       "      <td>352.724000</td>\n",
       "      <td>302.513000</td>\n",
       "      <td>301.132200</td>\n",
       "      <td>559.45900</td>\n",
       "      <td>475.653600</td>\n",
       "      <td>463.054000</td>\n",
       "      <td>1099.601000</td>\n",
       "      <td>1131.579800</td>\n",
       "      <td>1028.457600</td>\n",
       "      <td>1172.027200</td>\n",
       "      <td>1150.859200</td>\n",
       "      <td>1130.570000</td>\n",
       "      <td>94.072000</td>\n",
       "      <td>95.112800</td>\n",
       "      <td>89.223000</td>\n",
       "      <td>25.019200</td>\n",
       "      <td>28.673200</td>\n",
       "      <td>29.586600</td>\n",
       "      <td>1858.009600</td>\n",
       "      <td>1847.549600</td>\n",
       "      <td>1779.577000</td>\n",
       "      <td>1899.697600</td>\n",
       "      <td>1950.481800</td>\n",
       "      <td>2007.485200</td>\n",
       "      <td>1940.66540</td>\n",
       "      <td>2131.282600</td>\n",
       "      <td>1964.802600</td>\n",
       "      <td>46.549800</td>\n",
       "      <td>45.574000</td>\n",
       "      <td>41.822000</td>\n",
       "      <td>2742.151000</td>\n",
       "      <td>2919.936400</td>\n",
       "      <td>2912.019000</td>\n",
       "      <td>37.197800</td>\n",
       "      <td>40.023200</td>\n",
       "      <td>33.863800</td>\n",
       "      <td>71.343000</td>\n",
       "      <td>81.443000</td>\n",
       "      <td>75.929000</td>\n",
       "      <td>9.323200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3200.121200</td>\n",
       "      <td>3379.068200</td>\n",
       "      <td>3350.553200</td>\n",
       "      <td>632.596400</td>\n",
       "      <td>669.849800</td>\n",
       "      <td>655.247800</td>\n",
       "      <td>1038.950800</td>\n",
       "      <td>1039.317600</td>\n",
       "      <td>1016.738000</td>\n",
       "      <td>202.223000</td>\n",
       "      <td>210.553200</td>\n",
       "      <td>193.301600</td>\n",
       "      <td>1494.127200</td>\n",
       "      <td>1546.199400</td>\n",
       "      <td>1502.828000</td>\n",
       "      <td>215.554200</td>\n",
       "      <td>239.59300</td>\n",
       "      <td>232.144000</td>\n",
       "      <td>395.328000</td>\n",
       "      <td>423.183600</td>\n",
       "      <td>391.469400</td>\n",
       "      <td>54.886600</td>\n",
       "      <td>58.309200</td>\n",
       "      <td>51.006000</td>\n",
       "      <td>578.893400</td>\n",
       "      <td>625.896800</td>\n",
       "      <td>598.101000</td>\n",
       "      <td>1752.439800</td>\n",
       "      <td>1840.121000</td>\n",
       "      <td>1814.891000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>229.741800</td>\n",
       "      <td>238.850200</td>\n",
       "      <td>255.405800</td>\n",
       "      <td>20.629800</td>\n",
       "      <td>26.906000</td>\n",
       "      <td>22.193000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.660000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2375.320000</td>\n",
       "      <td>2461.320000</td>\n",
       "      <td>2433.320000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>951.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>1319.751000</td>\n",
       "      <td>1353.505000</td>\n",
       "      <td>1310.414000</td>\n",
       "      <td>3481.759400</td>\n",
       "      <td>3751.657000</td>\n",
       "      <td>3777.915400</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3651.000000</td>\n",
       "      <td>1877.951200</td>\n",
       "      <td>1994.244000</td>\n",
       "      <td>1911.913400</td>\n",
       "      <td>194.335200</td>\n",
       "      <td>2243.990000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>10752.56000</td>\n",
       "      <td>8362.360000</td>\n",
       "      <td>9667.130000</td>\n",
       "      <td>14007.340000</td>\n",
       "      <td>2613.310000</td>\n",
       "      <td>3813.290000</td>\n",
       "      <td>4169.810000</td>\n",
       "      <td>3775.11000</td>\n",
       "      <td>2812.040000</td>\n",
       "      <td>5337.040000</td>\n",
       "      <td>6431.330000</td>\n",
       "      <td>7400.660000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>4729.740000</td>\n",
       "      <td>4557.140000</td>\n",
       "      <td>4961.330000</td>\n",
       "      <td>676.480000</td>\n",
       "      <td>1057.960000</td>\n",
       "      <td>928.490000</td>\n",
       "      <td>342.860000</td>\n",
       "      <td>569.710000</td>\n",
       "      <td>351.830000</td>\n",
       "      <td>10643.380000</td>\n",
       "      <td>7674.780000</td>\n",
       "      <td>11039.910000</td>\n",
       "      <td>7366.580000</td>\n",
       "      <td>8133.660000</td>\n",
       "      <td>8014.430000</td>\n",
       "      <td>8314.76000</td>\n",
       "      <td>9284.740000</td>\n",
       "      <td>13950.040000</td>\n",
       "      <td>628.560000</td>\n",
       "      <td>544.630000</td>\n",
       "      <td>516.910000</td>\n",
       "      <td>8432.990000</td>\n",
       "      <td>10936.730000</td>\n",
       "      <td>13980.060000</td>\n",
       "      <td>5900.660000</td>\n",
       "      <td>5490.280000</td>\n",
       "      <td>5681.540000</td>\n",
       "      <td>1023.210000</td>\n",
       "      <td>1265.790000</td>\n",
       "      <td>1390.880000</td>\n",
       "      <td>100.610000</td>\n",
       "      <td>221.940000</td>\n",
       "      <td>394.930000</td>\n",
       "      <td>10674.030000</td>\n",
       "      <td>11365.310000</td>\n",
       "      <td>14043.060000</td>\n",
       "      <td>6351.440000</td>\n",
       "      <td>5709.590000</td>\n",
       "      <td>4003.210000</td>\n",
       "      <td>4693.860000</td>\n",
       "      <td>4171.510000</td>\n",
       "      <td>5738.460000</td>\n",
       "      <td>1678.410000</td>\n",
       "      <td>1983.010000</td>\n",
       "      <td>1588.530000</td>\n",
       "      <td>6496.110000</td>\n",
       "      <td>6466.740000</td>\n",
       "      <td>5748.810000</td>\n",
       "      <td>5459.560000</td>\n",
       "      <td>5800.93000</td>\n",
       "      <td>4309.290000</td>\n",
       "      <td>4630.230000</td>\n",
       "      <td>3100.840000</td>\n",
       "      <td>5645.860000</td>\n",
       "      <td>1351.110000</td>\n",
       "      <td>1136.080000</td>\n",
       "      <td>1394.890000</td>\n",
       "      <td>5459.630000</td>\n",
       "      <td>6745.760000</td>\n",
       "      <td>5957.140000</td>\n",
       "      <td>6798.640000</td>\n",
       "      <td>7279.080000</td>\n",
       "      <td>5990.710000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>21.330000</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>3965.690000</td>\n",
       "      <td>4747.910000</td>\n",
       "      <td>4100.380000</td>\n",
       "      <td>1344.140000</td>\n",
       "      <td>1495.940000</td>\n",
       "      <td>1209.860000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>35190.000000</td>\n",
       "      <td>40335.000000</td>\n",
       "      <td>45320.000000</td>\n",
       "      <td>3559.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>10285.900000</td>\n",
       "      <td>7873.550000</td>\n",
       "      <td>11117.610000</td>\n",
       "      <td>26826.130000</td>\n",
       "      <td>28144.120000</td>\n",
       "      <td>29651.830000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>4321.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.210000</td>\n",
       "      <td>2618.570000</td>\n",
       "      <td>37762.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             arpu_6        arpu_7        arpu_8   onnet_mou_6   onnet_mou_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     605.381915    618.668251    580.047979    308.772567    323.663869   \n",
       "std      437.843670    464.965572    502.170458    467.783907    494.784885   \n",
       "min     -810.661000   -622.509000   -345.129000      0.000000      0.000000   \n",
       "25%      383.939000    391.220000    334.649000     46.445000     47.740000   \n",
       "50%      512.599000    520.648000    489.762000    135.880000    139.330000   \n",
       "75%      718.534500    728.702500    712.486000    373.975000    391.550000   \n",
       "95%     1252.490200   1295.677500   1309.061800   1173.282000   1258.870000   \n",
       "99%     1982.920300   2024.926280   2051.568360   2174.954000   2282.491200   \n",
       "max    27731.088000  35145.834000  33543.624000   7376.710000   8157.780000   \n",
       "\n",
       "       onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  \\\n",
       "count  25335.00000  25335.000000  25335.000000  25335.000000   25335.000000   \n",
       "mean     294.68391    434.100403    448.695341    410.454928      18.061622   \n",
       "std      487.04074    470.461181    494.027416    491.009571      79.379923   \n",
       "min        0.00000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%       37.66000    149.680000    153.120000    121.825000       0.000000   \n",
       "50%      118.04000    299.190000    305.130000    271.480000       0.000000   \n",
       "75%      339.67500    546.900000    568.160000    522.885000       0.000000   \n",
       "95%     1183.91000   1288.039000   1322.240000   1247.580000      99.861000   \n",
       "99%     2281.69300   2325.534200   2435.052000   2273.954000     352.724000   \n",
       "max    10752.56000   8362.360000   9667.130000  14007.340000    2613.310000   \n",
       "\n",
       "       roam_ic_mou_7  roam_ic_mou_8  roam_og_mou_6  roam_og_mou_7  \\\n",
       "count   25335.000000   25335.000000    25335.00000   25335.000000   \n",
       "mean       14.346624      14.582006       30.56156      23.280403   \n",
       "std        79.562310      79.311801      120.77578     101.356114   \n",
       "min         0.000000       0.000000        0.00000       0.000000   \n",
       "25%         0.000000       0.000000        0.00000       0.000000   \n",
       "50%         0.000000       0.000000        0.00000       0.000000   \n",
       "75%         0.000000       0.000000        0.00000       0.000000   \n",
       "95%        68.189000      70.913000      175.29800     128.696000   \n",
       "99%       302.513000     301.132200      559.45900     475.653600   \n",
       "max      3813.290000    4169.810000     3775.11000    2812.040000   \n",
       "\n",
       "       roam_og_mou_8  loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  \\\n",
       "count   25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean       23.590945         99.960790        103.126631         95.763798   \n",
       "std       112.585652        245.564009        262.585641        249.911233   \n",
       "min         0.000000          0.000000          0.000000          0.000000   \n",
       "25%         0.000000          9.730000         10.760000          8.410000   \n",
       "50%         0.000000         35.310000         37.060000         33.890000   \n",
       "75%         0.000000         97.335000         98.285000         94.650000   \n",
       "95%       129.294000        363.996000        372.755000        349.532000   \n",
       "99%       463.054000       1099.601000       1131.579800       1028.457600   \n",
       "max      5337.040000       6431.330000       7400.660000      10752.560000   \n",
       "\n",
       "       loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2f_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         190.822741        193.354505        183.183204          7.326504   \n",
       "std          256.217219        247.363734        242.759117         22.025513   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%           34.110000         38.880000         30.635000          0.000000   \n",
       "50%          109.310000        114.260000        104.030000          0.480000   \n",
       "75%          253.535000        257.235000        244.405000          5.540000   \n",
       "95%          641.469000        641.116000        619.141000         35.366000   \n",
       "99%         1172.027200       1150.859200       1130.570000         94.072000   \n",
       "max         4729.740000       4557.140000       4961.330000        676.480000   \n",
       "\n",
       "       loc_og_t2f_mou_7  loc_og_t2f_mou_8  loc_og_t2c_mou_6  loc_og_t2c_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean           7.524519          7.006037          1.608491          1.905115   \n",
       "std           22.588417         21.293992          6.989765          9.246516   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.560000          0.410000          0.000000          0.000000   \n",
       "75%            5.810000          5.330000          0.000000          0.160000   \n",
       "95%           35.996000         33.510000          8.916000         10.230000   \n",
       "99%           95.112800         89.223000         25.019200         28.673200   \n",
       "max         1057.960000        928.490000        342.860000        569.710000   \n",
       "\n",
       "       loc_og_t2c_mou_8  loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  \\\n",
       "count      25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean           1.811716    298.119074    304.014879    285.961925   \n",
       "std            7.658958    390.703307    390.011607    381.771064   \n",
       "min            0.000000      0.000000      0.000000      0.000000   \n",
       "25%            0.000000     57.770000     65.625000     51.520000   \n",
       "50%            0.000000    179.840000    188.190000    170.930000   \n",
       "75%            0.160000    393.350000    404.120000    379.560000   \n",
       "95%            9.810000    966.089000    969.509000    936.374000   \n",
       "99%           29.586600   1858.009600   1847.549600   1779.577000   \n",
       "max          351.830000  10643.380000   7674.780000  11039.910000   \n",
       "\n",
       "       std_og_t2t_mou_6  std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2m_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000       25335.00000   \n",
       "mean         196.812613        211.379736        189.782722         208.44343   \n",
       "std          415.838101        438.203399        428.727579         414.50022   \n",
       "min            0.000000          0.000000          0.000000           0.00000   \n",
       "25%            0.000000          0.000000          0.000000           2.38000   \n",
       "50%           15.390000         17.130000          9.950000          42.41000   \n",
       "75%          191.850000        211.660000        163.910000         220.50000   \n",
       "95%         1002.849000       1066.177000       1008.627000         971.03300   \n",
       "99%         1899.697600       1950.481800       2007.485200        1940.66540   \n",
       "max         7366.580000       8133.660000       8014.430000        8314.76000   \n",
       "\n",
       "       std_og_t2m_mou_7  std_og_t2m_mou_8  std_og_t2f_mou_6  std_og_t2f_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         224.532096        197.083311          2.083931          2.132881   \n",
       "std          448.737359        436.163646         12.723130         13.952247   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            2.245000          0.930000          0.000000          0.000000   \n",
       "50%           43.780000         32.010000          0.000000          0.000000   \n",
       "75%          241.395000        193.235000          0.000000          0.000000   \n",
       "95%         1046.376000        947.686000          8.440000          8.130000   \n",
       "99%         2131.282600       1964.802600         46.549800         45.574000   \n",
       "max         9284.740000      13950.040000        628.560000        544.630000   \n",
       "\n",
       "       std_og_t2f_mou_8  std_og_mou_6  std_og_mou_7  std_og_mou_8  \\\n",
       "count      25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean           1.899306    407.344440    438.049207    388.769519   \n",
       "std           11.992246    609.228997    651.051194    640.513506   \n",
       "min            0.000000      0.000000      0.000000      0.000000   \n",
       "25%            0.000000      7.650000      7.790000      4.535000   \n",
       "50%            0.000000    140.740000    155.510000    103.240000   \n",
       "75%            0.000000    599.365000    657.635000    547.335000   \n",
       "95%            7.583000   1568.305000   1660.510000   1594.561000   \n",
       "99%           41.822000   2742.151000   2919.936400   2912.019000   \n",
       "max          516.910000   8432.990000  10936.730000  13980.060000   \n",
       "\n",
       "       isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  spl_og_mou_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       2.125238      2.191998      2.156291      6.030383      7.639063   \n",
       "std       47.841689     48.191701     48.117680     18.869381     23.583356   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.310000      0.900000   \n",
       "75%        0.000000      0.000000      0.000000      5.390000      7.460000   \n",
       "95%        1.010000      1.010000      0.603000     27.146000     32.896000   \n",
       "99%       37.197800     40.023200     33.863800     71.343000     81.443000   \n",
       "max     5900.660000   5490.280000   5681.540000   1023.210000   1265.790000   \n",
       "\n",
       "       spl_og_mou_8   og_others_6   og_others_7   og_others_8  total_og_mou_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000    25335.000000   \n",
       "mean       7.345974      0.704512      0.039078      0.049230      714.333663   \n",
       "std       23.659722      2.330394      1.862022      2.733586      659.239073   \n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      291.950000   \n",
       "50%        0.810000      0.000000      0.000000      0.000000      542.580000   \n",
       "75%        7.110000      0.000000      0.000000      0.000000      930.725000   \n",
       "95%       31.290000      4.180000      0.000000      0.000000     1940.979000   \n",
       "99%       75.929000      9.323200      0.000000      0.000000     3200.121200   \n",
       "max     1390.880000    100.610000    221.940000    394.930000    10674.030000   \n",
       "\n",
       "       total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  \\\n",
       "count    25335.000000    25335.000000      25335.000000      25335.000000   \n",
       "mean       751.943194      684.291694         71.333108         73.848361   \n",
       "std        692.061684      699.416899        159.764080        167.999534   \n",
       "min          0.000000        0.000000          0.000000          0.000000   \n",
       "25%        309.570000      241.720000          9.580000         11.110000   \n",
       "50%        570.810000      495.260000         31.380000         33.090000   \n",
       "75%        980.185000      902.935000         77.195000         79.450000   \n",
       "95%       2010.934000     1961.633000        250.398000        246.914000   \n",
       "99%       3379.068200     3350.553200        632.596400        669.849800   \n",
       "max      11365.310000    14043.060000       6351.440000       5709.590000   \n",
       "\n",
       "       loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          71.173280        166.124937        169.562449        166.215392   \n",
       "std          162.414297        222.977501        222.864795        223.408317   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            9.130000         37.135000         42.635000         37.970000   \n",
       "50%           30.390000         99.930000        103.810000        100.730000   \n",
       "75%           76.880000        211.750000        215.200000        212.100000   \n",
       "95%          244.671000        536.543000        538.657000        546.255000   \n",
       "99%          655.247800       1038.950800       1039.317600       1016.738000   \n",
       "max         4003.210000       4693.860000       4171.510000       5738.460000   \n",
       "\n",
       "       loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000  25335.000000   \n",
       "mean          16.339769         17.317704         15.785543    253.807895   \n",
       "std           47.329733         50.779238         45.608537    313.758944   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000     63.315000   \n",
       "50%            2.250000          2.590000          2.360000    160.530000   \n",
       "75%           13.390000         14.135000         12.910000    328.350000   \n",
       "95%           75.902000         79.016000         71.140000    794.994000   \n",
       "99%          202.223000        210.553200        193.301600   1494.127200   \n",
       "max         1678.410000       1983.010000       1588.530000   6496.110000   \n",
       "\n",
       "       loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  std_ic_t2t_mou_7  \\\n",
       "count  25335.000000  25335.000000      25335.000000       25335.00000   \n",
       "mean     260.738785    253.184272         16.844002          17.88079   \n",
       "std      318.977995    316.417005         82.455660          90.11867   \n",
       "min        0.000000      0.000000          0.000000           0.00000   \n",
       "25%       71.730000     62.880000          0.000000           0.00000   \n",
       "50%      166.990000    159.790000          1.280000           1.53000   \n",
       "75%      335.180000    325.825000         10.930000          11.79000   \n",
       "95%      807.381000    801.720000         66.883000          70.00200   \n",
       "99%     1546.199400   1502.828000        215.554200         239.59300   \n",
       "max     6466.740000   5748.810000       5459.560000        5800.93000   \n",
       "\n",
       "       std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  std_ic_t2m_mou_8  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          16.471824         32.600116         34.782159         32.666067   \n",
       "std           77.316442         98.893301        105.551242        109.024813   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.660000          0.750000          0.400000   \n",
       "50%            0.960000          7.690000          8.410000          6.980000   \n",
       "75%           10.130000         28.530000         31.030000         28.170000   \n",
       "95%           66.140000        130.110000        134.296000        129.333000   \n",
       "99%          232.144000        395.328000        423.183600        391.469400   \n",
       "max         4309.290000       4630.230000       3100.840000       5645.860000   \n",
       "\n",
       "       std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000  25335.000000   \n",
       "mean           3.025538          3.149795          2.881318     52.473777   \n",
       "std           21.174910         21.633461         21.648678    141.642485   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000      3.180000   \n",
       "50%            0.000000          0.000000          0.000000     16.130000   \n",
       "75%            0.255000          0.350000          0.300000     48.985000   \n",
       "95%           12.603000         12.980000         11.616000    205.667000   \n",
       "99%           54.886600         58.309200         51.006000    578.893400   \n",
       "max         1351.110000       1136.080000       1394.890000   5459.630000   \n",
       "\n",
       "       std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  \\\n",
       "count  25335.000000  25335.000000    25335.000000    25335.000000   \n",
       "mean      55.816969     52.023210      318.424015      330.484101   \n",
       "std      153.424340    147.512098      361.531618      373.960638   \n",
       "min        0.000000      0.000000        0.000000        0.000000   \n",
       "25%        3.430000      2.510000       97.540000      109.360000   \n",
       "50%       17.610000     14.680000      216.910000      225.110000   \n",
       "75%       52.840000     47.640000      407.050000      416.115000   \n",
       "95%      211.733000    204.100000      959.248000      969.619000   \n",
       "99%      625.896800    598.101000     1752.439800     1840.121000   \n",
       "max     6745.760000   5957.140000     6798.640000     7279.080000   \n",
       "\n",
       "       total_ic_mou_8  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  \\\n",
       "count    25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       318.718816      0.066769      0.017484      0.029158     10.841112   \n",
       "std        370.339577      0.157630      0.174782      0.113819     66.542701   \n",
       "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         96.135000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        213.330000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        406.200000      0.000000      0.000000      0.000000      0.000000   \n",
       "95%        970.839000      0.430000      0.050000      0.250000     44.653000   \n",
       "99%       1814.891000      0.680000      0.510000      0.630000    229.741800   \n",
       "max       5990.710000      6.740000     21.330000      1.260000   3965.690000   \n",
       "\n",
       "       isd_ic_mou_7  isd_ic_mou_8   ic_others_6   ic_others_7   ic_others_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean      12.306502     12.156147      1.225623      1.596091      1.317898   \n",
       "std       76.654492     77.125182     14.871170     16.591331     13.609714   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.080000      0.060000      0.080000   \n",
       "95%       51.834000     48.160000      3.700000      5.203000      4.280000   \n",
       "99%      238.850200    255.405800     20.629800     26.906000     22.193000   \n",
       "max     4747.910000   4100.380000   1344.140000   1495.940000   1209.860000   \n",
       "\n",
       "       total_rech_num_6  total_rech_num_7  total_rech_num_8  total_rech_amt_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          12.369213         12.339925         10.954529        717.326071   \n",
       "std            9.478604          9.636941          9.581220        535.704258   \n",
       "min            1.000000          1.000000          1.000000          0.000000   \n",
       "25%            7.000000          6.000000          5.000000        453.500000   \n",
       "50%           10.000000         10.000000          8.000000        602.000000   \n",
       "75%           15.000000         15.000000         14.000000        853.000000   \n",
       "95%           30.000000         31.000000         30.000000       1491.000000   \n",
       "99%           47.000000         48.660000         47.000000       2375.320000   \n",
       "max          307.000000        138.000000        138.000000      35190.000000   \n",
       "\n",
       "       total_rech_amt_7  total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  \\\n",
       "count      25335.000000      25335.000000    25335.000000    25335.000000   \n",
       "mean         730.384054        669.618315      170.440300      176.367397   \n",
       "std          562.700046        615.007473      164.154017      173.003988   \n",
       "min            0.000000          0.000000        0.000000        0.000000   \n",
       "25%          458.000000        370.000000      110.000000      110.000000   \n",
       "50%          612.000000        566.000000      120.000000      128.000000   \n",
       "75%          865.000000        831.000000      200.000000      200.000000   \n",
       "95%         1546.000000       1539.000000      459.000000      459.000000   \n",
       "99%         2461.320000       2433.320000     1000.000000     1000.000000   \n",
       "max        40335.000000      45320.000000     3559.000000     3299.000000   \n",
       "\n",
       "       max_rech_amt_8  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "count    25335.000000        25335.000000        25335.000000   \n",
       "mean       171.691455          103.618394          106.819814   \n",
       "std        169.981003          131.004585          133.878195   \n",
       "min          0.000000            0.000000            0.000000   \n",
       "25%        100.000000           30.000000           30.000000   \n",
       "50%        130.000000          110.000000          100.000000   \n",
       "75%        198.000000          120.000000          130.000000   \n",
       "95%        455.000000          252.000000          252.000000   \n",
       "99%        951.000000          550.000000          619.000000   \n",
       "max       4449.000000         3299.000000         3100.000000   \n",
       "\n",
       "       last_day_rch_amt_8   vol_2g_mb_6   vol_2g_mb_7   vol_2g_mb_8  \\\n",
       "count        25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean           101.055181     80.828362     80.695662     74.095703   \n",
       "std            143.671631    279.498393    284.506065    278.235033   \n",
       "min              0.000000      0.000000      0.000000      0.000000   \n",
       "25%             20.000000      0.000000      0.000000      0.000000   \n",
       "50%             50.000000      0.000000      0.000000      0.000000   \n",
       "75%            130.000000     17.320000     18.505000     14.395000   \n",
       "95%            252.000000    495.411000    479.459000    441.644000   \n",
       "99%            565.000000   1319.751000   1353.505000   1310.414000   \n",
       "max           4449.000000  10285.900000   7873.550000  11117.610000   \n",
       "\n",
       "        vol_3g_mb_6   vol_3g_mb_7   vol_3g_mb_8  monthly_2g_6  monthly_2g_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     259.031232    285.911329    286.022239      0.131202      0.138701   \n",
       "std      810.698076    848.283045    861.636669      0.382467      0.397484   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000     30.585000     23.915000      0.000000      0.000000   \n",
       "95%     1519.505000   1632.148000   1604.678000      1.000000      1.000000   \n",
       "99%     3481.759400   3751.657000   3777.915400      2.000000      2.000000   \n",
       "max    26826.130000  28144.120000  29651.830000      4.000000      5.000000   \n",
       "\n",
       "       monthly_2g_8   sachet_2g_6   sachet_2g_7   sachet_2g_8  monthly_3g_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.122913      0.508861      0.606315      0.647642      0.176436   \n",
       "std        0.369948      1.706819      1.910562      1.886947      0.579352   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "95%        1.000000      3.000000      4.000000      4.000000      1.000000   \n",
       "99%        2.000000      9.000000      9.000000      9.000000      3.000000   \n",
       "max        5.000000     39.000000     48.000000     44.000000     14.000000   \n",
       "\n",
       "       monthly_3g_7  monthly_3g_8   sachet_3g_6   sachet_3g_7   sachet_3g_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.192856      0.185554      0.142333      0.157845      0.154411   \n",
       "std        0.641568      0.605907      0.881705      0.984721      1.033961   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "95%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "99%        3.000000      3.000000      3.000000      4.000000      4.000000   \n",
       "max       16.000000     16.000000     29.000000     33.000000     41.000000   \n",
       "\n",
       "                aon    aug_vbc_3g    jul_vbc_3g    jun_vbc_3g    sep_vbc_3g  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean    1290.944622    139.401235    142.534482    126.035382      7.215953   \n",
       "std      978.149101    405.205464    421.298082    395.788710     50.055596   \n",
       "min      180.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      487.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      950.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%     1980.000000     17.595000      9.295000      0.000000      0.000000   \n",
       "95%     3197.000000    870.906000    881.403000    784.329000     23.808000   \n",
       "99%     3651.000000   1877.951200   1994.244000   1911.913400    194.335200   \n",
       "max     4321.000000  12916.220000   9165.600000  11166.210000   2618.570000   \n",
       "\n",
       "       average_rech_amt_g         Churn     Recency_6     Recency_7  \\\n",
       "count        25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean           723.855062      0.033274      2.973318      3.163489   \n",
       "std            500.600700      0.179355      3.963857      3.962766   \n",
       "min            390.000000      0.000000      0.000000      0.000000   \n",
       "25%            474.500000      0.000000      0.000000      0.000000   \n",
       "50%            596.000000      0.000000      2.000000      2.000000   \n",
       "75%            826.500000      0.000000      4.000000      5.000000   \n",
       "95%           1444.000000      0.000000     12.000000     12.000000   \n",
       "99%           2243.990000      1.000000     17.000000     17.000000   \n",
       "max          37762.500000      1.000000     29.000000     30.000000   \n",
       "\n",
       "          Recency_8  \n",
       "count  25335.000000  \n",
       "mean       3.712532  \n",
       "std        4.682648  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        2.000000  \n",
       "75%        5.000000  \n",
       "95%       13.000000  \n",
       "99%       23.000000  \n",
       "max       30.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.describe(percentiles=[0.25,0.5,0.75,0.95,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice significant outliers in most of the numerical variables. Hence we replace them with the value of the 99th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_col:\n",
    "    x99=fdf[col].quantile(0.99)\n",
    "    fdf.loc[fdf[col]>x99,col]=x99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>average_rech_amt_g</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Recency_6</th>\n",
       "      <th>Recency_7</th>\n",
       "      <th>Recency_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.00000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.0</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "      <td>25335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>596.042485</td>\n",
       "      <td>608.734337</td>\n",
       "      <td>569.220534</td>\n",
       "      <td>299.746434</td>\n",
       "      <td>314.274083</td>\n",
       "      <td>285.23841</td>\n",
       "      <td>426.467300</td>\n",
       "      <td>440.010721</td>\n",
       "      <td>400.299730</td>\n",
       "      <td>15.470800</td>\n",
       "      <td>11.363930</td>\n",
       "      <td>11.719989</td>\n",
       "      <td>26.784824</td>\n",
       "      <td>19.868345</td>\n",
       "      <td>19.557186</td>\n",
       "      <td>91.424953</td>\n",
       "      <td>93.417520</td>\n",
       "      <td>86.711115</td>\n",
       "      <td>185.324725</td>\n",
       "      <td>188.685398</td>\n",
       "      <td>178.688372</td>\n",
       "      <td>6.637273</td>\n",
       "      <td>6.832052</td>\n",
       "      <td>6.352746</td>\n",
       "      <td>1.366624</td>\n",
       "      <td>1.584709</td>\n",
       "      <td>1.56513</td>\n",
       "      <td>290.457419</td>\n",
       "      <td>295.988639</td>\n",
       "      <td>278.827496</td>\n",
       "      <td>188.893570</td>\n",
       "      <td>203.084691</td>\n",
       "      <td>181.480989</td>\n",
       "      <td>200.262643</td>\n",
       "      <td>215.749045</td>\n",
       "      <td>186.863905</td>\n",
       "      <td>1.561267</td>\n",
       "      <td>1.514155</td>\n",
       "      <td>1.375912</td>\n",
       "      <td>398.096635</td>\n",
       "      <td>428.084824</td>\n",
       "      <td>378.015193</td>\n",
       "      <td>0.705094</td>\n",
       "      <td>0.775027</td>\n",
       "      <td>0.593821</td>\n",
       "      <td>5.425316</td>\n",
       "      <td>6.818482</td>\n",
       "      <td>6.440810</td>\n",
       "      <td>0.638443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704.683246</td>\n",
       "      <td>741.509082</td>\n",
       "      <td>673.516429</td>\n",
       "      <td>65.440223</td>\n",
       "      <td>67.449198</td>\n",
       "      <td>64.845592</td>\n",
       "      <td>161.005001</td>\n",
       "      <td>164.298192</td>\n",
       "      <td>160.987264</td>\n",
       "      <td>14.835026</td>\n",
       "      <td>15.660360</td>\n",
       "      <td>14.287582</td>\n",
       "      <td>247.522994</td>\n",
       "      <td>254.184674</td>\n",
       "      <td>246.738064</td>\n",
       "      <td>13.377223</td>\n",
       "      <td>14.384658</td>\n",
       "      <td>13.334608</td>\n",
       "      <td>28.980600</td>\n",
       "      <td>30.709588</td>\n",
       "      <td>28.499959</td>\n",
       "      <td>2.184710</td>\n",
       "      <td>2.305970</td>\n",
       "      <td>2.074229</td>\n",
       "      <td>47.458687</td>\n",
       "      <td>50.414308</td>\n",
       "      <td>46.684036</td>\n",
       "      <td>311.890975</td>\n",
       "      <td>323.436649</td>\n",
       "      <td>312.009054</td>\n",
       "      <td>0.065643</td>\n",
       "      <td>0.013892</td>\n",
       "      <td>0.027785</td>\n",
       "      <td>8.003001</td>\n",
       "      <td>9.059714</td>\n",
       "      <td>8.860429</td>\n",
       "      <td>0.721957</td>\n",
       "      <td>0.967892</td>\n",
       "      <td>0.802618</td>\n",
       "      <td>12.217249</td>\n",
       "      <td>12.201052</td>\n",
       "      <td>10.819578</td>\n",
       "      <td>705.679782</td>\n",
       "      <td>718.613115</td>\n",
       "      <td>656.414536</td>\n",
       "      <td>168.357095</td>\n",
       "      <td>173.631340</td>\n",
       "      <td>168.831774</td>\n",
       "      <td>99.539886</td>\n",
       "      <td>103.253799</td>\n",
       "      <td>96.756266</td>\n",
       "      <td>73.553643</td>\n",
       "      <td>72.846348</td>\n",
       "      <td>66.542295</td>\n",
       "      <td>237.141989</td>\n",
       "      <td>263.158051</td>\n",
       "      <td>263.167102</td>\n",
       "      <td>0.129899</td>\n",
       "      <td>0.137201</td>\n",
       "      <td>0.121531</td>\n",
       "      <td>0.470969</td>\n",
       "      <td>0.561239</td>\n",
       "      <td>0.606671</td>\n",
       "      <td>0.167397</td>\n",
       "      <td>0.179278</td>\n",
       "      <td>0.175015</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>0.118769</td>\n",
       "      <td>0.112966</td>\n",
       "      <td>1290.208092</td>\n",
       "      <td>130.264474</td>\n",
       "      <td>133.189805</td>\n",
       "      <td>117.053694</td>\n",
       "      <td>5.201012</td>\n",
       "      <td>712.848449</td>\n",
       "      <td>0.033274</td>\n",
       "      <td>2.936767</td>\n",
       "      <td>3.120347</td>\n",
       "      <td>3.679968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>331.595498</td>\n",
       "      <td>336.525135</td>\n",
       "      <td>368.403123</td>\n",
       "      <td>409.711517</td>\n",
       "      <td>433.395851</td>\n",
       "      <td>420.40088</td>\n",
       "      <td>422.454207</td>\n",
       "      <td>437.701882</td>\n",
       "      <td>418.295718</td>\n",
       "      <td>52.370815</td>\n",
       "      <td>42.709636</td>\n",
       "      <td>43.213058</td>\n",
       "      <td>85.987226</td>\n",
       "      <td>69.742945</td>\n",
       "      <td>68.056774</td>\n",
       "      <td>165.482331</td>\n",
       "      <td>168.409596</td>\n",
       "      <td>155.120578</td>\n",
       "      <td>220.043888</td>\n",
       "      <td>217.409277</td>\n",
       "      <td>214.582751</td>\n",
       "      <td>15.202715</td>\n",
       "      <td>15.446725</td>\n",
       "      <td>14.569787</td>\n",
       "      <td>4.003862</td>\n",
       "      <td>4.554126</td>\n",
       "      <td>4.57898</td>\n",
       "      <td>337.934667</td>\n",
       "      <td>334.718809</td>\n",
       "      <td>327.963699</td>\n",
       "      <td>361.937947</td>\n",
       "      <td>383.350462</td>\n",
       "      <td>370.958285</td>\n",
       "      <td>359.074562</td>\n",
       "      <td>387.255768</td>\n",
       "      <td>353.689882</td>\n",
       "      <td>6.295432</td>\n",
       "      <td>6.150020</td>\n",
       "      <td>5.636165</td>\n",
       "      <td>556.795047</td>\n",
       "      <td>593.063410</td>\n",
       "      <td>571.376292</td>\n",
       "      <td>4.309988</td>\n",
       "      <td>4.718619</td>\n",
       "      <td>3.868400</td>\n",
       "      <td>11.571761</td>\n",
       "      <td>13.553689</td>\n",
       "      <td>12.681168</td>\n",
       "      <td>1.633318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>605.590181</td>\n",
       "      <td>632.866789</td>\n",
       "      <td>631.878515</td>\n",
       "      <td>99.681222</td>\n",
       "      <td>102.531046</td>\n",
       "      <td>100.616229</td>\n",
       "      <td>186.934231</td>\n",
       "      <td>185.843638</td>\n",
       "      <td>185.932215</td>\n",
       "      <td>32.207001</td>\n",
       "      <td>33.794605</td>\n",
       "      <td>30.661986</td>\n",
       "      <td>272.634304</td>\n",
       "      <td>275.168238</td>\n",
       "      <td>274.520495</td>\n",
       "      <td>32.306680</td>\n",
       "      <td>35.036846</td>\n",
       "      <td>33.957429</td>\n",
       "      <td>59.403268</td>\n",
       "      <td>62.987274</td>\n",
       "      <td>59.352268</td>\n",
       "      <td>7.674114</td>\n",
       "      <td>8.090235</td>\n",
       "      <td>7.199801</td>\n",
       "      <td>89.446704</td>\n",
       "      <td>95.433421</td>\n",
       "      <td>90.950715</td>\n",
       "      <td>320.098093</td>\n",
       "      <td>327.477384</td>\n",
       "      <td>327.099411</td>\n",
       "      <td>0.147660</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>0.104797</td>\n",
       "      <td>30.981002</td>\n",
       "      <td>33.305137</td>\n",
       "      <td>34.090107</td>\n",
       "      <td>2.759609</td>\n",
       "      <td>3.642929</td>\n",
       "      <td>3.019891</td>\n",
       "      <td>8.476835</td>\n",
       "      <td>8.879909</td>\n",
       "      <td>8.843089</td>\n",
       "      <td>398.534114</td>\n",
       "      <td>412.931425</td>\n",
       "      <td>446.331950</td>\n",
       "      <td>144.323407</td>\n",
       "      <td>148.361993</td>\n",
       "      <td>141.887905</td>\n",
       "      <td>100.261706</td>\n",
       "      <td>107.314904</td>\n",
       "      <td>107.045625</td>\n",
       "      <td>213.673689</td>\n",
       "      <td>214.145441</td>\n",
       "      <td>202.751197</td>\n",
       "      <td>605.603548</td>\n",
       "      <td>649.731310</td>\n",
       "      <td>654.849284</td>\n",
       "      <td>0.373888</td>\n",
       "      <td>0.387654</td>\n",
       "      <td>0.359864</td>\n",
       "      <td>1.388076</td>\n",
       "      <td>1.560707</td>\n",
       "      <td>1.561500</td>\n",
       "      <td>0.505479</td>\n",
       "      <td>0.530350</td>\n",
       "      <td>0.521655</td>\n",
       "      <td>0.435812</td>\n",
       "      <td>0.526462</td>\n",
       "      <td>0.523419</td>\n",
       "      <td>976.198188</td>\n",
       "      <td>332.718525</td>\n",
       "      <td>348.858850</td>\n",
       "      <td>321.699246</td>\n",
       "      <td>25.237470</td>\n",
       "      <td>350.353374</td>\n",
       "      <td>0.179355</td>\n",
       "      <td>3.801442</td>\n",
       "      <td>3.769039</td>\n",
       "      <td>4.530787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-810.661000</td>\n",
       "      <td>-622.509000</td>\n",
       "      <td>-345.129000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>383.939000</td>\n",
       "      <td>391.220000</td>\n",
       "      <td>334.649000</td>\n",
       "      <td>46.445000</td>\n",
       "      <td>47.740000</td>\n",
       "      <td>37.66000</td>\n",
       "      <td>149.680000</td>\n",
       "      <td>153.120000</td>\n",
       "      <td>121.825000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.730000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>34.110000</td>\n",
       "      <td>38.880000</td>\n",
       "      <td>30.635000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57.770000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>51.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>7.790000</td>\n",
       "      <td>4.535000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.950000</td>\n",
       "      <td>309.570000</td>\n",
       "      <td>241.720000</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>9.130000</td>\n",
       "      <td>37.135000</td>\n",
       "      <td>42.635000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.315000</td>\n",
       "      <td>71.730000</td>\n",
       "      <td>62.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>97.540000</td>\n",
       "      <td>109.360000</td>\n",
       "      <td>96.135000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>453.500000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>474.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>512.599000</td>\n",
       "      <td>520.648000</td>\n",
       "      <td>489.762000</td>\n",
       "      <td>135.880000</td>\n",
       "      <td>139.330000</td>\n",
       "      <td>118.04000</td>\n",
       "      <td>299.190000</td>\n",
       "      <td>305.130000</td>\n",
       "      <td>271.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.310000</td>\n",
       "      <td>37.060000</td>\n",
       "      <td>33.890000</td>\n",
       "      <td>109.310000</td>\n",
       "      <td>114.260000</td>\n",
       "      <td>104.030000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>179.840000</td>\n",
       "      <td>188.190000</td>\n",
       "      <td>170.930000</td>\n",
       "      <td>15.390000</td>\n",
       "      <td>17.130000</td>\n",
       "      <td>9.950000</td>\n",
       "      <td>42.410000</td>\n",
       "      <td>43.780000</td>\n",
       "      <td>32.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.740000</td>\n",
       "      <td>155.510000</td>\n",
       "      <td>103.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>542.580000</td>\n",
       "      <td>570.810000</td>\n",
       "      <td>495.260000</td>\n",
       "      <td>31.380000</td>\n",
       "      <td>33.090000</td>\n",
       "      <td>30.390000</td>\n",
       "      <td>99.930000</td>\n",
       "      <td>103.810000</td>\n",
       "      <td>100.730000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>160.530000</td>\n",
       "      <td>166.990000</td>\n",
       "      <td>159.790000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.130000</td>\n",
       "      <td>17.610000</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>216.910000</td>\n",
       "      <td>225.110000</td>\n",
       "      <td>213.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>718.534500</td>\n",
       "      <td>728.702500</td>\n",
       "      <td>712.486000</td>\n",
       "      <td>373.975000</td>\n",
       "      <td>391.550000</td>\n",
       "      <td>339.67500</td>\n",
       "      <td>546.900000</td>\n",
       "      <td>568.160000</td>\n",
       "      <td>522.885000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.335000</td>\n",
       "      <td>98.285000</td>\n",
       "      <td>94.650000</td>\n",
       "      <td>253.535000</td>\n",
       "      <td>257.235000</td>\n",
       "      <td>244.405000</td>\n",
       "      <td>5.540000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.16000</td>\n",
       "      <td>393.350000</td>\n",
       "      <td>404.120000</td>\n",
       "      <td>379.560000</td>\n",
       "      <td>191.850000</td>\n",
       "      <td>211.660000</td>\n",
       "      <td>163.910000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>241.395000</td>\n",
       "      <td>193.235000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>599.365000</td>\n",
       "      <td>657.635000</td>\n",
       "      <td>547.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>7.460000</td>\n",
       "      <td>7.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.725000</td>\n",
       "      <td>980.185000</td>\n",
       "      <td>902.935000</td>\n",
       "      <td>77.195000</td>\n",
       "      <td>79.450000</td>\n",
       "      <td>76.880000</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>215.200000</td>\n",
       "      <td>212.100000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>14.135000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>328.350000</td>\n",
       "      <td>335.180000</td>\n",
       "      <td>325.825000</td>\n",
       "      <td>10.930000</td>\n",
       "      <td>11.790000</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>28.530000</td>\n",
       "      <td>31.030000</td>\n",
       "      <td>28.170000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>48.985000</td>\n",
       "      <td>52.840000</td>\n",
       "      <td>47.640000</td>\n",
       "      <td>407.050000</td>\n",
       "      <td>416.115000</td>\n",
       "      <td>406.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>831.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>18.505000</td>\n",
       "      <td>14.395000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.585000</td>\n",
       "      <td>23.915000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>17.595000</td>\n",
       "      <td>9.295000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1982.920300</td>\n",
       "      <td>2024.926280</td>\n",
       "      <td>2051.568360</td>\n",
       "      <td>2174.954000</td>\n",
       "      <td>2282.491200</td>\n",
       "      <td>2281.69300</td>\n",
       "      <td>2325.534200</td>\n",
       "      <td>2435.052000</td>\n",
       "      <td>2273.954000</td>\n",
       "      <td>352.724000</td>\n",
       "      <td>302.513000</td>\n",
       "      <td>301.132200</td>\n",
       "      <td>559.459000</td>\n",
       "      <td>475.653600</td>\n",
       "      <td>463.054000</td>\n",
       "      <td>1099.601000</td>\n",
       "      <td>1131.579800</td>\n",
       "      <td>1028.457600</td>\n",
       "      <td>1172.027200</td>\n",
       "      <td>1150.859200</td>\n",
       "      <td>1130.570000</td>\n",
       "      <td>94.072000</td>\n",
       "      <td>95.112800</td>\n",
       "      <td>89.223000</td>\n",
       "      <td>25.019200</td>\n",
       "      <td>28.673200</td>\n",
       "      <td>29.58660</td>\n",
       "      <td>1858.009600</td>\n",
       "      <td>1847.549600</td>\n",
       "      <td>1779.577000</td>\n",
       "      <td>1899.697600</td>\n",
       "      <td>1950.481800</td>\n",
       "      <td>2007.485200</td>\n",
       "      <td>1940.665400</td>\n",
       "      <td>2131.282600</td>\n",
       "      <td>1964.802600</td>\n",
       "      <td>46.549800</td>\n",
       "      <td>45.574000</td>\n",
       "      <td>41.822000</td>\n",
       "      <td>2742.151000</td>\n",
       "      <td>2919.936400</td>\n",
       "      <td>2912.019000</td>\n",
       "      <td>37.197800</td>\n",
       "      <td>40.023200</td>\n",
       "      <td>33.863800</td>\n",
       "      <td>71.343000</td>\n",
       "      <td>81.443000</td>\n",
       "      <td>75.929000</td>\n",
       "      <td>9.323200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.121200</td>\n",
       "      <td>3379.068200</td>\n",
       "      <td>3350.553200</td>\n",
       "      <td>632.596400</td>\n",
       "      <td>669.849800</td>\n",
       "      <td>655.247800</td>\n",
       "      <td>1038.950800</td>\n",
       "      <td>1039.317600</td>\n",
       "      <td>1016.738000</td>\n",
       "      <td>202.223000</td>\n",
       "      <td>210.553200</td>\n",
       "      <td>193.301600</td>\n",
       "      <td>1494.127200</td>\n",
       "      <td>1546.199400</td>\n",
       "      <td>1502.828000</td>\n",
       "      <td>215.554200</td>\n",
       "      <td>239.593000</td>\n",
       "      <td>232.144000</td>\n",
       "      <td>395.328000</td>\n",
       "      <td>423.183600</td>\n",
       "      <td>391.469400</td>\n",
       "      <td>54.886600</td>\n",
       "      <td>58.309200</td>\n",
       "      <td>51.006000</td>\n",
       "      <td>578.893400</td>\n",
       "      <td>625.896800</td>\n",
       "      <td>598.101000</td>\n",
       "      <td>1752.439800</td>\n",
       "      <td>1840.121000</td>\n",
       "      <td>1814.891000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>229.741800</td>\n",
       "      <td>238.850200</td>\n",
       "      <td>255.405800</td>\n",
       "      <td>20.629800</td>\n",
       "      <td>26.906000</td>\n",
       "      <td>22.193000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.660000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2375.320000</td>\n",
       "      <td>2461.320000</td>\n",
       "      <td>2433.320000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>951.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>1319.751000</td>\n",
       "      <td>1353.505000</td>\n",
       "      <td>1310.414000</td>\n",
       "      <td>3481.759400</td>\n",
       "      <td>3751.657000</td>\n",
       "      <td>3777.915400</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3651.000000</td>\n",
       "      <td>1877.951200</td>\n",
       "      <td>1994.244000</td>\n",
       "      <td>1911.913400</td>\n",
       "      <td>194.335200</td>\n",
       "      <td>2243.990000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             arpu_6        arpu_7        arpu_8   onnet_mou_6   onnet_mou_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     596.042485    608.734337    569.220534    299.746434    314.274083   \n",
       "std      331.595498    336.525135    368.403123    409.711517    433.395851   \n",
       "min     -810.661000   -622.509000   -345.129000      0.000000      0.000000   \n",
       "25%      383.939000    391.220000    334.649000     46.445000     47.740000   \n",
       "50%      512.599000    520.648000    489.762000    135.880000    139.330000   \n",
       "75%      718.534500    728.702500    712.486000    373.975000    391.550000   \n",
       "max     1982.920300   2024.926280   2051.568360   2174.954000   2282.491200   \n",
       "\n",
       "       onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  \\\n",
       "count  25335.00000  25335.000000  25335.000000  25335.000000   25335.000000   \n",
       "mean     285.23841    426.467300    440.010721    400.299730      15.470800   \n",
       "std      420.40088    422.454207    437.701882    418.295718      52.370815   \n",
       "min        0.00000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%       37.66000    149.680000    153.120000    121.825000       0.000000   \n",
       "50%      118.04000    299.190000    305.130000    271.480000       0.000000   \n",
       "75%      339.67500    546.900000    568.160000    522.885000       0.000000   \n",
       "max     2281.69300   2325.534200   2435.052000   2273.954000     352.724000   \n",
       "\n",
       "       roam_ic_mou_7  roam_ic_mou_8  roam_og_mou_6  roam_og_mou_7  \\\n",
       "count   25335.000000   25335.000000   25335.000000   25335.000000   \n",
       "mean       11.363930      11.719989      26.784824      19.868345   \n",
       "std        42.709636      43.213058      85.987226      69.742945   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max       302.513000     301.132200     559.459000     475.653600   \n",
       "\n",
       "       roam_og_mou_8  loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  \\\n",
       "count   25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean       19.557186         91.424953         93.417520         86.711115   \n",
       "std        68.056774        165.482331        168.409596        155.120578   \n",
       "min         0.000000          0.000000          0.000000          0.000000   \n",
       "25%         0.000000          9.730000         10.760000          8.410000   \n",
       "50%         0.000000         35.310000         37.060000         33.890000   \n",
       "75%         0.000000         97.335000         98.285000         94.650000   \n",
       "max       463.054000       1099.601000       1131.579800       1028.457600   \n",
       "\n",
       "       loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2f_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         185.324725        188.685398        178.688372          6.637273   \n",
       "std          220.043888        217.409277        214.582751         15.202715   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%           34.110000         38.880000         30.635000          0.000000   \n",
       "50%          109.310000        114.260000        104.030000          0.480000   \n",
       "75%          253.535000        257.235000        244.405000          5.540000   \n",
       "max         1172.027200       1150.859200       1130.570000         94.072000   \n",
       "\n",
       "       loc_og_t2f_mou_7  loc_og_t2f_mou_8  loc_og_t2c_mou_6  loc_og_t2c_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean           6.832052          6.352746          1.366624          1.584709   \n",
       "std           15.446725         14.569787          4.003862          4.554126   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.560000          0.410000          0.000000          0.000000   \n",
       "75%            5.810000          5.330000          0.000000          0.160000   \n",
       "max           95.112800         89.223000         25.019200         28.673200   \n",
       "\n",
       "       loc_og_t2c_mou_8  loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  \\\n",
       "count       25335.00000  25335.000000  25335.000000  25335.000000   \n",
       "mean            1.56513    290.457419    295.988639    278.827496   \n",
       "std             4.57898    337.934667    334.718809    327.963699   \n",
       "min             0.00000      0.000000      0.000000      0.000000   \n",
       "25%             0.00000     57.770000     65.625000     51.520000   \n",
       "50%             0.00000    179.840000    188.190000    170.930000   \n",
       "75%             0.16000    393.350000    404.120000    379.560000   \n",
       "max            29.58660   1858.009600   1847.549600   1779.577000   \n",
       "\n",
       "       std_og_t2t_mou_6  std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2m_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         188.893570        203.084691        181.480989        200.262643   \n",
       "std          361.937947        383.350462        370.958285        359.074562   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          2.380000   \n",
       "50%           15.390000         17.130000          9.950000         42.410000   \n",
       "75%          191.850000        211.660000        163.910000        220.500000   \n",
       "max         1899.697600       1950.481800       2007.485200       1940.665400   \n",
       "\n",
       "       std_og_t2m_mou_7  std_og_t2m_mou_8  std_og_t2f_mou_6  std_og_t2f_mou_7  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean         215.749045        186.863905          1.561267          1.514155   \n",
       "std          387.255768        353.689882          6.295432          6.150020   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            2.245000          0.930000          0.000000          0.000000   \n",
       "50%           43.780000         32.010000          0.000000          0.000000   \n",
       "75%          241.395000        193.235000          0.000000          0.000000   \n",
       "max         2131.282600       1964.802600         46.549800         45.574000   \n",
       "\n",
       "       std_og_t2f_mou_8  std_og_mou_6  std_og_mou_7  std_og_mou_8  \\\n",
       "count      25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean           1.375912    398.096635    428.084824    378.015193   \n",
       "std            5.636165    556.795047    593.063410    571.376292   \n",
       "min            0.000000      0.000000      0.000000      0.000000   \n",
       "25%            0.000000      7.650000      7.790000      4.535000   \n",
       "50%            0.000000    140.740000    155.510000    103.240000   \n",
       "75%            0.000000    599.365000    657.635000    547.335000   \n",
       "max           41.822000   2742.151000   2919.936400   2912.019000   \n",
       "\n",
       "       isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  spl_og_mou_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.705094      0.775027      0.593821      5.425316      6.818482   \n",
       "std        4.309988      4.718619      3.868400     11.571761     13.553689   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.310000      0.900000   \n",
       "75%        0.000000      0.000000      0.000000      5.390000      7.460000   \n",
       "max       37.197800     40.023200     33.863800     71.343000     81.443000   \n",
       "\n",
       "       spl_og_mou_8   og_others_6  og_others_7  og_others_8  total_og_mou_6  \\\n",
       "count  25335.000000  25335.000000      25335.0      25335.0    25335.000000   \n",
       "mean       6.440810      0.638443          0.0          0.0      704.683246   \n",
       "std       12.681168      1.633318          0.0          0.0      605.590181   \n",
       "min        0.000000      0.000000          0.0          0.0        0.000000   \n",
       "25%        0.000000      0.000000          0.0          0.0      291.950000   \n",
       "50%        0.810000      0.000000          0.0          0.0      542.580000   \n",
       "75%        7.110000      0.000000          0.0          0.0      930.725000   \n",
       "max       75.929000      9.323200          0.0          0.0     3200.121200   \n",
       "\n",
       "       total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  \\\n",
       "count    25335.000000    25335.000000      25335.000000      25335.000000   \n",
       "mean       741.509082      673.516429         65.440223         67.449198   \n",
       "std        632.866789      631.878515         99.681222        102.531046   \n",
       "min          0.000000        0.000000          0.000000          0.000000   \n",
       "25%        309.570000      241.720000          9.580000         11.110000   \n",
       "50%        570.810000      495.260000         31.380000         33.090000   \n",
       "75%        980.185000      902.935000         77.195000         79.450000   \n",
       "max       3379.068200     3350.553200        632.596400        669.849800   \n",
       "\n",
       "       loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          64.845592        161.005001        164.298192        160.987264   \n",
       "std          100.616229        186.934231        185.843638        185.932215   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            9.130000         37.135000         42.635000         37.970000   \n",
       "50%           30.390000         99.930000        103.810000        100.730000   \n",
       "75%           76.880000        211.750000        215.200000        212.100000   \n",
       "max          655.247800       1038.950800       1039.317600       1016.738000   \n",
       "\n",
       "       loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000  25335.000000   \n",
       "mean          14.835026         15.660360         14.287582    247.522994   \n",
       "std           32.207001         33.794605         30.661986    272.634304   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000     63.315000   \n",
       "50%            2.250000          2.590000          2.360000    160.530000   \n",
       "75%           13.390000         14.135000         12.910000    328.350000   \n",
       "max          202.223000        210.553200        193.301600   1494.127200   \n",
       "\n",
       "       loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  std_ic_t2t_mou_7  \\\n",
       "count  25335.000000  25335.000000      25335.000000      25335.000000   \n",
       "mean     254.184674    246.738064         13.377223         14.384658   \n",
       "std      275.168238    274.520495         32.306680         35.036846   \n",
       "min        0.000000      0.000000          0.000000          0.000000   \n",
       "25%       71.730000     62.880000          0.000000          0.000000   \n",
       "50%      166.990000    159.790000          1.280000          1.530000   \n",
       "75%      335.180000    325.825000         10.930000         11.790000   \n",
       "max     1546.199400   1502.828000        215.554200        239.593000   \n",
       "\n",
       "       std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  std_ic_t2m_mou_8  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          13.334608         28.980600         30.709588         28.499959   \n",
       "std           33.957429         59.403268         62.987274         59.352268   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.660000          0.750000          0.400000   \n",
       "50%            0.960000          7.690000          8.410000          6.980000   \n",
       "75%           10.130000         28.530000         31.030000         28.170000   \n",
       "max          232.144000        395.328000        423.183600        391.469400   \n",
       "\n",
       "       std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_mou_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000  25335.000000   \n",
       "mean           2.184710          2.305970          2.074229     47.458687   \n",
       "std            7.674114          8.090235          7.199801     89.446704   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000      3.180000   \n",
       "50%            0.000000          0.000000          0.000000     16.130000   \n",
       "75%            0.255000          0.350000          0.300000     48.985000   \n",
       "max           54.886600         58.309200         51.006000    578.893400   \n",
       "\n",
       "       std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  \\\n",
       "count  25335.000000  25335.000000    25335.000000    25335.000000   \n",
       "mean      50.414308     46.684036      311.890975      323.436649   \n",
       "std       95.433421     90.950715      320.098093      327.477384   \n",
       "min        0.000000      0.000000        0.000000        0.000000   \n",
       "25%        3.430000      2.510000       97.540000      109.360000   \n",
       "50%       17.610000     14.680000      216.910000      225.110000   \n",
       "75%       52.840000     47.640000      407.050000      416.115000   \n",
       "max      625.896800    598.101000     1752.439800     1840.121000   \n",
       "\n",
       "       total_ic_mou_8  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  \\\n",
       "count    25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       312.009054      0.065643      0.013892      0.027785      8.003001   \n",
       "std        327.099411      0.147660      0.069501      0.104797     30.981002   \n",
       "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         96.135000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        213.330000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        406.200000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       1814.891000      0.680000      0.510000      0.630000    229.741800   \n",
       "\n",
       "       isd_ic_mou_7  isd_ic_mou_8   ic_others_6   ic_others_7   ic_others_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       9.059714      8.860429      0.721957      0.967892      0.802618   \n",
       "std       33.305137     34.090107      2.759609      3.642929      3.019891   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.080000      0.060000      0.080000   \n",
       "max      238.850200    255.405800     20.629800     26.906000     22.193000   \n",
       "\n",
       "       total_rech_num_6  total_rech_num_7  total_rech_num_8  total_rech_amt_6  \\\n",
       "count      25335.000000      25335.000000      25335.000000      25335.000000   \n",
       "mean          12.217249         12.201052         10.819578        705.679782   \n",
       "std            8.476835          8.879909          8.843089        398.534114   \n",
       "min            1.000000          1.000000          1.000000          0.000000   \n",
       "25%            7.000000          6.000000          5.000000        453.500000   \n",
       "50%           10.000000         10.000000          8.000000        602.000000   \n",
       "75%           15.000000         15.000000         14.000000        853.000000   \n",
       "max           47.000000         48.660000         47.000000       2375.320000   \n",
       "\n",
       "       total_rech_amt_7  total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  \\\n",
       "count      25335.000000      25335.000000    25335.000000    25335.000000   \n",
       "mean         718.613115        656.414536      168.357095      173.631340   \n",
       "std          412.931425        446.331950      144.323407      148.361993   \n",
       "min            0.000000          0.000000        0.000000        0.000000   \n",
       "25%          458.000000        370.000000      110.000000      110.000000   \n",
       "50%          612.000000        566.000000      120.000000      128.000000   \n",
       "75%          865.000000        831.000000      200.000000      200.000000   \n",
       "max         2461.320000       2433.320000     1000.000000     1000.000000   \n",
       "\n",
       "       max_rech_amt_8  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "count    25335.000000        25335.000000        25335.000000   \n",
       "mean       168.831774           99.539886          103.253799   \n",
       "std        141.887905          100.261706          107.314904   \n",
       "min          0.000000            0.000000            0.000000   \n",
       "25%        100.000000           30.000000           30.000000   \n",
       "50%        130.000000          110.000000          100.000000   \n",
       "75%        198.000000          120.000000          130.000000   \n",
       "max        951.000000          550.000000          619.000000   \n",
       "\n",
       "       last_day_rch_amt_8   vol_2g_mb_6   vol_2g_mb_7   vol_2g_mb_8  \\\n",
       "count        25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean            96.756266     73.553643     72.846348     66.542295   \n",
       "std            107.045625    213.673689    214.145441    202.751197   \n",
       "min              0.000000      0.000000      0.000000      0.000000   \n",
       "25%             20.000000      0.000000      0.000000      0.000000   \n",
       "50%             50.000000      0.000000      0.000000      0.000000   \n",
       "75%            130.000000     17.320000     18.505000     14.395000   \n",
       "max            565.000000   1319.751000   1353.505000   1310.414000   \n",
       "\n",
       "        vol_3g_mb_6   vol_3g_mb_7   vol_3g_mb_8  monthly_2g_6  monthly_2g_7  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean     237.141989    263.158051    263.167102      0.129899      0.137201   \n",
       "std      605.603548    649.731310    654.849284      0.373888      0.387654   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000     30.585000     23.915000      0.000000      0.000000   \n",
       "max     3481.759400   3751.657000   3777.915400      2.000000      2.000000   \n",
       "\n",
       "       monthly_2g_8   sachet_2g_6   sachet_2g_7   sachet_2g_8  monthly_3g_6  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.121531      0.470969      0.561239      0.606671      0.167397   \n",
       "std        0.359864      1.388076      1.560707      1.561500      0.505479   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        2.000000      9.000000      9.000000      9.000000      3.000000   \n",
       "\n",
       "       monthly_3g_7  monthly_3g_8   sachet_3g_6   sachet_3g_7   sachet_3g_8  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean       0.179278      0.175015      0.104046      0.118769      0.112966   \n",
       "std        0.530350      0.521655      0.435812      0.526462      0.523419   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        3.000000      3.000000      3.000000      4.000000      4.000000   \n",
       "\n",
       "                aon    aug_vbc_3g    jul_vbc_3g    jun_vbc_3g    sep_vbc_3g  \\\n",
       "count  25335.000000  25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean    1290.208092    130.264474    133.189805    117.053694      5.201012   \n",
       "std      976.198188    332.718525    348.858850    321.699246     25.237470   \n",
       "min      180.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      487.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      950.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%     1980.000000     17.595000      9.295000      0.000000      0.000000   \n",
       "max     3651.000000   1877.951200   1994.244000   1911.913400    194.335200   \n",
       "\n",
       "       average_rech_amt_g         Churn     Recency_6     Recency_7  \\\n",
       "count        25335.000000  25335.000000  25335.000000  25335.000000   \n",
       "mean           712.848449      0.033274      2.936767      3.120347   \n",
       "std            350.353374      0.179355      3.801442      3.769039   \n",
       "min            390.000000      0.000000      0.000000      0.000000   \n",
       "25%            474.500000      0.000000      0.000000      0.000000   \n",
       "50%            596.000000      0.000000      2.000000      2.000000   \n",
       "75%            826.500000      0.000000      4.000000      5.000000   \n",
       "max           2243.990000      1.000000     17.000000     17.000000   \n",
       "\n",
       "          Recency_8  \n",
       "count  25335.000000  \n",
       "mean       3.679968  \n",
       "std        4.530787  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        2.000000  \n",
       "75%        5.000000  \n",
       "max       23.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we observe that all the outliers have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25335, 130)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noticed before, we have a huge class imbalance in our data. We have only 3.3% of customers who actually Churn. Thus, we use SMOTE Analysis while building our models which would help us in oversampling and increase the instances of minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We first build the logistic regression model to identify the important variables.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf=fdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25335 entries, 8 to 99988\n",
      "Columns: 130 entries, arpu_6 to Recency_8\n",
      "dtypes: float64(129), int32(1)\n",
      "memory usage: 25.2 MB\n"
     ]
    }
   ],
   "source": [
    "mdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the columns are numerical columns. Hence, we do not need to create dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=mdf.drop('Churn',axis=1)\n",
    "y=mdf['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.70,stratify=y,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033269425961430024"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03328509406657019"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we retain the Data imbalance present in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1' in training set: 590\n",
      "Before OverSampling, counts of label '0' in training set: 17144 \n",
      "\n",
      "Before OverSampling, the shape of train_X: (17734, 129)\n",
      "Before OverSampling, the shape of train_y: (17734,) \n",
      "\n",
      "After OverSampling, the shape of train_X: (34288, 129)\n",
      "After OverSampling, the shape of train_y: (34288,) \n",
      "\n",
      "After OverSampling, counts of label '1' in training set: 17144\n",
      "After OverSampling, counts of label '0' in training set: 17144\n"
     ]
    }
   ],
   "source": [
    "#training set\n",
    "print(\"Before OverSampling, counts of label '1' in training set: {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling, counts of label '0' in training set: {} \\n\".format(sum(y_train == 0))) \n",
    "\n",
    "print('Before OverSampling, the shape of train_X: {}'.format(X_train.shape)) \n",
    "print('Before OverSampling, the shape of train_y: {} \\n'.format(y_train.shape)) \n",
    "\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
    "  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1' in training set: {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0' in training set: {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "col=list(X_train.columns)\n",
    "X_train_res[col]=scaler.fit_transform(X_train_res[col])\n",
    "X_test[col]=scaler.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 20)             # running RFE with 20 variables as output\n",
    "rfe = rfe.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['onnet_mou_8', 'offnet_mou_8', 'roam_og_mou_8', 'loc_og_t2t_mou_7',\n",
       "       'loc_og_t2m_mou_7', 'loc_og_t2m_mou_8', 'loc_og_t2f_mou_8',\n",
       "       'loc_og_mou_7', 'std_og_t2m_mou_8', 'std_og_mou_6', 'std_og_mou_7',\n",
       "       'std_og_mou_8', 'total_og_mou_6', 'total_og_mou_7', 'total_og_mou_8',\n",
       "       'loc_ic_t2f_mou_8', 'loc_ic_mou_8', 'last_day_rch_amt_8', 'aug_vbc_3g',\n",
       "       'Recency_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = X_train_res.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34267</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11872.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  23744.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:05</td>     <th>  Pearson chi2:      </th> <td>1.63e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7724</td> <td>    0.030</td> <td>  -26.153</td> <td> 0.000</td> <td>   -0.830</td> <td>   -0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.3024</td> <td>    0.075</td> <td>   -4.005</td> <td> 0.000</td> <td>   -0.450</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>   -0.8432</td> <td>    0.087</td> <td>   -9.744</td> <td> 0.000</td> <td>   -1.013</td> <td>   -0.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.2628</td> <td>    0.036</td> <td>   35.482</td> <td> 0.000</td> <td>    1.193</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>   <td>   -0.8546</td> <td>    0.107</td> <td>   -7.982</td> <td> 0.000</td> <td>   -1.064</td> <td>   -0.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -1.4715</td> <td>    0.130</td> <td>  -11.295</td> <td> 0.000</td> <td>   -1.727</td> <td>   -1.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>   <td>    0.5478</td> <td>    0.101</td> <td>    5.413</td> <td> 0.000</td> <td>    0.349</td> <td>    0.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.0288</td> <td>    0.076</td> <td>  -13.609</td> <td> 0.000</td> <td>   -1.177</td> <td>   -0.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>       <td>    1.5927</td> <td>    0.236</td> <td>    6.739</td> <td> 0.000</td> <td>    1.130</td> <td>    2.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>    0.4768</td> <td>    0.100</td> <td>    4.762</td> <td> 0.000</td> <td>    0.281</td> <td>    0.673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>       <td>    0.7678</td> <td>    0.087</td> <td>    8.860</td> <td> 0.000</td> <td>    0.598</td> <td>    0.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>   -0.6107</td> <td>    0.259</td> <td>   -2.354</td> <td> 0.019</td> <td>   -1.119</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>       <td>    1.4781</td> <td>    0.208</td> <td>    7.111</td> <td> 0.000</td> <td>    1.071</td> <td>    1.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>   -0.4091</td> <td>    0.080</td> <td>   -5.105</td> <td> 0.000</td> <td>   -0.566</td> <td>   -0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_7</th>     <td>    1.0138</td> <td>    0.267</td> <td>    3.791</td> <td> 0.000</td> <td>    0.490</td> <td>    1.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>     <td>   -1.8334</td> <td>    0.239</td> <td>   -7.657</td> <td> 0.000</td> <td>   -2.303</td> <td>   -1.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5958</td> <td>    0.059</td> <td>  -10.184</td> <td> 0.000</td> <td>   -0.711</td> <td>   -0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.0597</td> <td>    0.061</td> <td>  -17.306</td> <td> 0.000</td> <td>   -1.180</td> <td>   -0.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5485</td> <td>    0.024</td> <td>  -23.192</td> <td> 0.000</td> <td>   -0.595</td> <td>   -0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -1.0029</td> <td>    0.050</td> <td>  -20.092</td> <td> 0.000</td> <td>   -1.101</td> <td>   -0.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5310</td> <td>    0.019</td> <td>   27.654</td> <td> 0.000</td> <td>    0.493</td> <td>    0.569</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34267\n",
       "Model Family:                Binomial   Df Model:                           20\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -11872.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       23744.\n",
       "Time:                        20:13:05   Pearson chi2:                 1.63e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7724      0.030    -26.153      0.000      -0.830      -0.715\n",
       "onnet_mou_8           -0.3024      0.075     -4.005      0.000      -0.450      -0.154\n",
       "offnet_mou_8          -0.8432      0.087     -9.744      0.000      -1.013      -0.674\n",
       "roam_og_mou_8          1.2628      0.036     35.482      0.000       1.193       1.333\n",
       "loc_og_t2t_mou_7      -0.8546      0.107     -7.982      0.000      -1.064      -0.645\n",
       "loc_og_t2m_mou_7      -1.4715      0.130    -11.295      0.000      -1.727      -1.216\n",
       "loc_og_t2m_mou_8       0.5478      0.101      5.413      0.000       0.349       0.746\n",
       "loc_og_t2f_mou_8      -1.0288      0.076    -13.609      0.000      -1.177      -0.881\n",
       "loc_og_mou_7           1.5927      0.236      6.739      0.000       1.130       2.056\n",
       "std_og_t2m_mou_8       0.4768      0.100      4.762      0.000       0.281       0.673\n",
       "std_og_mou_6           0.7678      0.087      8.860      0.000       0.598       0.938\n",
       "std_og_mou_7          -0.6107      0.259     -2.354      0.019      -1.119      -0.102\n",
       "std_og_mou_8           1.4781      0.208      7.111      0.000       1.071       1.885\n",
       "total_og_mou_6        -0.4091      0.080     -5.105      0.000      -0.566      -0.252\n",
       "total_og_mou_7         1.0138      0.267      3.791      0.000       0.490       1.538\n",
       "total_og_mou_8        -1.8334      0.239     -7.657      0.000      -2.303      -1.364\n",
       "loc_ic_t2f_mou_8      -0.5958      0.059    -10.184      0.000      -0.711      -0.481\n",
       "loc_ic_mou_8          -1.0597      0.061    -17.306      0.000      -1.180      -0.940\n",
       "last_day_rch_amt_8    -0.5485      0.024    -23.192      0.000      -0.595      -0.502\n",
       "aug_vbc_3g            -1.0029      0.050    -20.092      0.000      -1.101      -0.905\n",
       "Recency_8              0.5310      0.019     27.654      0.000       0.493       0.569\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm1 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm1.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate VIF\n",
    "def vif(col):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Features'] = X_train_res[col].columns\n",
    "    vif['VIF'] = [variance_inflation_factor(X_train_res[col].values, i) for i in range(X_train_res[col].shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'], 2)\n",
    "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>total_og_mou_7</td>\n",
       "      <td>123.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>119.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>loc_og_mou_7</td>\n",
       "      <td>82.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>total_og_mou_8</td>\n",
       "      <td>67.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>std_og_mou_8</td>\n",
       "      <td>35.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>loc_og_t2m_mou_7</td>\n",
       "      <td>26.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>offnet_mou_8</td>\n",
       "      <td>24.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>24.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>std_og_mou_6</td>\n",
       "      <td>19.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>onnet_mou_8</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>total_og_mou_6</td>\n",
       "      <td>15.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>loc_og_t2t_mou_7</td>\n",
       "      <td>15.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "      <td>13.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Recency_8</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>aug_vbc_3g</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features     VIF\n",
       "13      total_og_mou_7  123.42\n",
       "10        std_og_mou_7  119.42\n",
       "7         loc_og_mou_7   82.45\n",
       "14      total_og_mou_8   67.25\n",
       "11        std_og_mou_8   35.86\n",
       "4     loc_og_t2m_mou_7   26.59\n",
       "1         offnet_mou_8   24.57\n",
       "8     std_og_t2m_mou_8   24.54\n",
       "9         std_og_mou_6   19.70\n",
       "0          onnet_mou_8   18.58\n",
       "12      total_og_mou_6   15.97\n",
       "3     loc_og_t2t_mou_7   15.21\n",
       "5     loc_og_t2m_mou_8   13.39\n",
       "2        roam_og_mou_8    2.99\n",
       "16        loc_ic_mou_8    2.34\n",
       "15    loc_ic_t2f_mou_8    1.55\n",
       "6     loc_og_t2f_mou_8    1.47\n",
       "17  last_day_rch_amt_8    1.33\n",
       "19           Recency_8    1.15\n",
       "18          aug_vbc_3g    1.10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since total_og_mou_7 has the highest vif value and it is more than 5, we drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('total_og_mou_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34268</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11879.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  23759.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:16</td>     <th>  Pearson chi2:      </th> <td>1.51e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7675</td> <td>    0.029</td> <td>  -26.059</td> <td> 0.000</td> <td>   -0.825</td> <td>   -0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.3520</td> <td>    0.073</td> <td>   -4.806</td> <td> 0.000</td> <td>   -0.496</td> <td>   -0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>   -0.8197</td> <td>    0.086</td> <td>   -9.477</td> <td> 0.000</td> <td>   -0.989</td> <td>   -0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.2638</td> <td>    0.036</td> <td>   35.573</td> <td> 0.000</td> <td>    1.194</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>   <td>   -0.9375</td> <td>    0.108</td> <td>   -8.697</td> <td> 0.000</td> <td>   -1.149</td> <td>   -0.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -1.5745</td> <td>    0.131</td> <td>  -12.012</td> <td> 0.000</td> <td>   -1.831</td> <td>   -1.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>   <td>    0.4576</td> <td>    0.098</td> <td>    4.678</td> <td> 0.000</td> <td>    0.266</td> <td>    0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.0369</td> <td>    0.076</td> <td>  -13.718</td> <td> 0.000</td> <td>   -1.185</td> <td>   -0.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>       <td>    2.1508</td> <td>    0.194</td> <td>   11.071</td> <td> 0.000</td> <td>    1.770</td> <td>    2.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>    0.4121</td> <td>    0.098</td> <td>    4.202</td> <td> 0.000</td> <td>    0.220</td> <td>    0.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>       <td>    0.7290</td> <td>    0.086</td> <td>    8.454</td> <td> 0.000</td> <td>    0.560</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.3653</td> <td>    0.033</td> <td>   11.005</td> <td> 0.000</td> <td>    0.300</td> <td>    0.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>       <td>    1.3405</td> <td>    0.202</td> <td>    6.650</td> <td> 0.000</td> <td>    0.945</td> <td>    1.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>   -0.3695</td> <td>    0.080</td> <td>   -4.638</td> <td> 0.000</td> <td>   -0.526</td> <td>   -0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>     <td>   -1.5975</td> <td>    0.227</td> <td>   -7.033</td> <td> 0.000</td> <td>   -2.043</td> <td>   -1.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5766</td> <td>    0.058</td> <td>   -9.882</td> <td> 0.000</td> <td>   -0.691</td> <td>   -0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.0646</td> <td>    0.061</td> <td>  -17.382</td> <td> 0.000</td> <td>   -1.185</td> <td>   -0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5489</td> <td>    0.024</td> <td>  -23.208</td> <td> 0.000</td> <td>   -0.595</td> <td>   -0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -0.9975</td> <td>    0.050</td> <td>  -20.068</td> <td> 0.000</td> <td>   -1.095</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5319</td> <td>    0.019</td> <td>   27.743</td> <td> 0.000</td> <td>    0.494</td> <td>    0.569</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34268\n",
       "Model Family:                Binomial   Df Model:                           19\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -11879.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       23759.\n",
       "Time:                        20:13:16   Pearson chi2:                 1.51e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7675      0.029    -26.059      0.000      -0.825      -0.710\n",
       "onnet_mou_8           -0.3520      0.073     -4.806      0.000      -0.496      -0.208\n",
       "offnet_mou_8          -0.8197      0.086     -9.477      0.000      -0.989      -0.650\n",
       "roam_og_mou_8          1.2638      0.036     35.573      0.000       1.194       1.333\n",
       "loc_og_t2t_mou_7      -0.9375      0.108     -8.697      0.000      -1.149      -0.726\n",
       "loc_og_t2m_mou_7      -1.5745      0.131    -12.012      0.000      -1.831      -1.318\n",
       "loc_og_t2m_mou_8       0.4576      0.098      4.678      0.000       0.266       0.649\n",
       "loc_og_t2f_mou_8      -1.0369      0.076    -13.718      0.000      -1.185      -0.889\n",
       "loc_og_mou_7           2.1508      0.194     11.071      0.000       1.770       2.532\n",
       "std_og_t2m_mou_8       0.4121      0.098      4.202      0.000       0.220       0.604\n",
       "std_og_mou_6           0.7290      0.086      8.454      0.000       0.560       0.898\n",
       "std_og_mou_7           0.3653      0.033     11.005      0.000       0.300       0.430\n",
       "std_og_mou_8           1.3405      0.202      6.650      0.000       0.945       1.736\n",
       "total_og_mou_6        -0.3695      0.080     -4.638      0.000      -0.526      -0.213\n",
       "total_og_mou_8        -1.5975      0.227     -7.033      0.000      -2.043      -1.152\n",
       "loc_ic_t2f_mou_8      -0.5766      0.058     -9.882      0.000      -0.691      -0.462\n",
       "loc_ic_mou_8          -1.0646      0.061    -17.382      0.000      -1.185      -0.945\n",
       "last_day_rch_amt_8    -0.5489      0.024    -23.208      0.000      -0.595      -0.503\n",
       "aug_vbc_3g            -0.9975      0.050    -20.068      0.000      -1.095      -0.900\n",
       "Recency_8              0.5319      0.019     27.743      0.000       0.494       0.569\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm2 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>total_og_mou_8</td>\n",
       "      <td>57.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>loc_og_mou_7</td>\n",
       "      <td>51.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>std_og_mou_8</td>\n",
       "      <td>33.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>loc_og_t2m_mou_7</td>\n",
       "      <td>25.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>offnet_mou_8</td>\n",
       "      <td>24.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>23.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>std_og_mou_6</td>\n",
       "      <td>19.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>onnet_mou_8</td>\n",
       "      <td>17.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>total_og_mou_6</td>\n",
       "      <td>15.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>loc_og_t2t_mou_7</td>\n",
       "      <td>14.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "      <td>12.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Recency_8</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>aug_vbc_3g</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features    VIF\n",
       "13      total_og_mou_8  57.63\n",
       "7         loc_og_mou_7  51.40\n",
       "11        std_og_mou_8  33.23\n",
       "4     loc_og_t2m_mou_7  25.96\n",
       "1         offnet_mou_8  24.51\n",
       "8     std_og_t2m_mou_8  23.67\n",
       "9         std_og_mou_6  19.14\n",
       "0          onnet_mou_8  17.92\n",
       "12      total_og_mou_6  15.42\n",
       "3     loc_og_t2t_mou_7  14.68\n",
       "5     loc_og_t2m_mou_8  12.17\n",
       "10        std_og_mou_7   3.39\n",
       "2        roam_og_mou_8   2.98\n",
       "15        loc_ic_mou_8   2.34\n",
       "14    loc_ic_t2f_mou_8   1.55\n",
       "6     loc_og_t2f_mou_8   1.45\n",
       "16  last_day_rch_amt_8   1.33\n",
       "18           Recency_8   1.15\n",
       "17          aug_vbc_3g   1.10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 'total_og_mou_8' because of high pvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('total_og_mou_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34269</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    18</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11909.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  23819.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:26</td>     <th>  Pearson chi2:      </th> <td>1.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7416</td> <td>    0.029</td> <td>  -25.423</td> <td> 0.000</td> <td>   -0.799</td> <td>   -0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.5246</td> <td>    0.065</td> <td>   -8.112</td> <td> 0.000</td> <td>   -0.651</td> <td>   -0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>   -0.8859</td> <td>    0.085</td> <td>  -10.372</td> <td> 0.000</td> <td>   -1.053</td> <td>   -0.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.3139</td> <td>    0.035</td> <td>   37.623</td> <td> 0.000</td> <td>    1.245</td> <td>    1.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>   <td>   -0.7993</td> <td>    0.102</td> <td>   -7.840</td> <td> 0.000</td> <td>   -0.999</td> <td>   -0.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -1.1365</td> <td>    0.114</td> <td>   -9.955</td> <td> 0.000</td> <td>   -1.360</td> <td>   -0.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>   <td>   -0.0196</td> <td>    0.070</td> <td>   -0.280</td> <td> 0.779</td> <td>   -0.157</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.0586</td> <td>    0.076</td> <td>  -13.986</td> <td> 0.000</td> <td>   -1.207</td> <td>   -0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>       <td>    1.5413</td> <td>    0.170</td> <td>    9.063</td> <td> 0.000</td> <td>    1.208</td> <td>    1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>    0.3247</td> <td>    0.093</td> <td>    3.481</td> <td> 0.001</td> <td>    0.142</td> <td>    0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>       <td>    0.7776</td> <td>    0.084</td> <td>    9.293</td> <td> 0.000</td> <td>    0.614</td> <td>    0.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.3700</td> <td>    0.033</td> <td>   11.171</td> <td> 0.000</td> <td>    0.305</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>       <td>    0.1459</td> <td>    0.090</td> <td>    1.619</td> <td> 0.105</td> <td>   -0.031</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>   -0.4082</td> <td>    0.077</td> <td>   -5.292</td> <td> 0.000</td> <td>   -0.559</td> <td>   -0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5682</td> <td>    0.058</td> <td>   -9.729</td> <td> 0.000</td> <td>   -0.683</td> <td>   -0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.1074</td> <td>    0.061</td> <td>  -18.196</td> <td> 0.000</td> <td>   -1.227</td> <td>   -0.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5439</td> <td>    0.024</td> <td>  -23.062</td> <td> 0.000</td> <td>   -0.590</td> <td>   -0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -1.0030</td> <td>    0.050</td> <td>  -20.128</td> <td> 0.000</td> <td>   -1.101</td> <td>   -0.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5354</td> <td>    0.019</td> <td>   27.951</td> <td> 0.000</td> <td>    0.498</td> <td>    0.573</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34269\n",
       "Model Family:                Binomial   Df Model:                           18\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -11909.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       23819.\n",
       "Time:                        20:13:26   Pearson chi2:                 1.58e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7416      0.029    -25.423      0.000      -0.799      -0.684\n",
       "onnet_mou_8           -0.5246      0.065     -8.112      0.000      -0.651      -0.398\n",
       "offnet_mou_8          -0.8859      0.085    -10.372      0.000      -1.053      -0.718\n",
       "roam_og_mou_8          1.3139      0.035     37.623      0.000       1.245       1.382\n",
       "loc_og_t2t_mou_7      -0.7993      0.102     -7.840      0.000      -0.999      -0.599\n",
       "loc_og_t2m_mou_7      -1.1365      0.114     -9.955      0.000      -1.360      -0.913\n",
       "loc_og_t2m_mou_8      -0.0196      0.070     -0.280      0.779      -0.157       0.118\n",
       "loc_og_t2f_mou_8      -1.0586      0.076    -13.986      0.000      -1.207      -0.910\n",
       "loc_og_mou_7           1.5413      0.170      9.063      0.000       1.208       1.875\n",
       "std_og_t2m_mou_8       0.3247      0.093      3.481      0.001       0.142       0.507\n",
       "std_og_mou_6           0.7776      0.084      9.293      0.000       0.614       0.942\n",
       "std_og_mou_7           0.3700      0.033     11.171      0.000       0.305       0.435\n",
       "std_og_mou_8           0.1459      0.090      1.619      0.105      -0.031       0.323\n",
       "total_og_mou_6        -0.4082      0.077     -5.292      0.000      -0.559      -0.257\n",
       "loc_ic_t2f_mou_8      -0.5682      0.058     -9.729      0.000      -0.683      -0.454\n",
       "loc_ic_mou_8          -1.1074      0.061    -18.196      0.000      -1.227      -0.988\n",
       "last_day_rch_amt_8    -0.5439      0.024    -23.062      0.000      -0.590      -0.498\n",
       "aug_vbc_3g            -1.0030      0.050    -20.128      0.000      -1.101      -0.905\n",
       "Recency_8              0.5354      0.019     27.951      0.000       0.498       0.573\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm3 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm3.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 'loc_og_t2m_mou_8' feature because of high p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('loc_og_t2m_mou_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34270</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11910.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  23819.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:32</td>     <th>  Pearson chi2:      </th> <td>1.59e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7410</td> <td>    0.029</td> <td>  -25.469</td> <td> 0.000</td> <td>   -0.798</td> <td>   -0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.5253</td> <td>    0.065</td> <td>   -8.122</td> <td> 0.000</td> <td>   -0.652</td> <td>   -0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>   -0.8995</td> <td>    0.070</td> <td>  -12.797</td> <td> 0.000</td> <td>   -1.037</td> <td>   -0.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.3177</td> <td>    0.032</td> <td>   40.935</td> <td> 0.000</td> <td>    1.255</td> <td>    1.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>   <td>   -0.7988</td> <td>    0.102</td> <td>   -7.843</td> <td> 0.000</td> <td>   -0.998</td> <td>   -0.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -1.1415</td> <td>    0.113</td> <td>  -10.129</td> <td> 0.000</td> <td>   -1.362</td> <td>   -0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.0605</td> <td>    0.075</td> <td>  -14.063</td> <td> 0.000</td> <td>   -1.208</td> <td>   -0.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>       <td>    1.5409</td> <td>    0.170</td> <td>    9.068</td> <td> 0.000</td> <td>    1.208</td> <td>    1.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>    0.3355</td> <td>    0.085</td> <td>    3.949</td> <td> 0.000</td> <td>    0.169</td> <td>    0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>       <td>    0.7778</td> <td>    0.084</td> <td>    9.297</td> <td> 0.000</td> <td>    0.614</td> <td>    0.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.3707</td> <td>    0.033</td> <td>   11.221</td> <td> 0.000</td> <td>    0.306</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>       <td>    0.1461</td> <td>    0.090</td> <td>    1.620</td> <td> 0.105</td> <td>   -0.031</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>   -0.4085</td> <td>    0.077</td> <td>   -5.297</td> <td> 0.000</td> <td>   -0.560</td> <td>   -0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5676</td> <td>    0.058</td> <td>   -9.723</td> <td> 0.000</td> <td>   -0.682</td> <td>   -0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.1133</td> <td>    0.057</td> <td>  -19.449</td> <td> 0.000</td> <td>   -1.225</td> <td>   -1.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5440</td> <td>    0.024</td> <td>  -23.080</td> <td> 0.000</td> <td>   -0.590</td> <td>   -0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -1.0027</td> <td>    0.050</td> <td>  -20.128</td> <td> 0.000</td> <td>   -1.100</td> <td>   -0.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5357</td> <td>    0.019</td> <td>   28.013</td> <td> 0.000</td> <td>    0.498</td> <td>    0.573</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34270\n",
       "Model Family:                Binomial   Df Model:                           17\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -11910.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       23819.\n",
       "Time:                        20:13:32   Pearson chi2:                 1.59e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7410      0.029    -25.469      0.000      -0.798      -0.684\n",
       "onnet_mou_8           -0.5253      0.065     -8.122      0.000      -0.652      -0.399\n",
       "offnet_mou_8          -0.8995      0.070    -12.797      0.000      -1.037      -0.762\n",
       "roam_og_mou_8          1.3177      0.032     40.935      0.000       1.255       1.381\n",
       "loc_og_t2t_mou_7      -0.7988      0.102     -7.843      0.000      -0.998      -0.599\n",
       "loc_og_t2m_mou_7      -1.1415      0.113    -10.129      0.000      -1.362      -0.921\n",
       "loc_og_t2f_mou_8      -1.0605      0.075    -14.063      0.000      -1.208      -0.913\n",
       "loc_og_mou_7           1.5409      0.170      9.068      0.000       1.208       1.874\n",
       "std_og_t2m_mou_8       0.3355      0.085      3.949      0.000       0.169       0.502\n",
       "std_og_mou_6           0.7778      0.084      9.297      0.000       0.614       0.942\n",
       "std_og_mou_7           0.3707      0.033     11.221      0.000       0.306       0.435\n",
       "std_og_mou_8           0.1461      0.090      1.620      0.105      -0.031       0.323\n",
       "total_og_mou_6        -0.4085      0.077     -5.297      0.000      -0.560      -0.257\n",
       "loc_ic_t2f_mou_8      -0.5676      0.058     -9.723      0.000      -0.682      -0.453\n",
       "loc_ic_mou_8          -1.1133      0.057    -19.449      0.000      -1.225      -1.001\n",
       "last_day_rch_amt_8    -0.5440      0.024    -23.080      0.000      -0.590      -0.498\n",
       "aug_vbc_3g            -1.0027      0.050    -20.128      0.000      -1.100      -0.905\n",
       "Recency_8              0.5357      0.019     28.013      0.000       0.498       0.573\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm4 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm4.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 'std_og_mou_8' because of high p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('std_og_mou_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34271</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    16</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11911.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  23822.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:36</td>     <th>  Pearson chi2:      </th> <td>1.60e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7382</td> <td>    0.029</td> <td>  -25.441</td> <td> 0.000</td> <td>   -0.795</td> <td>   -0.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.4269</td> <td>    0.022</td> <td>  -19.495</td> <td> 0.000</td> <td>   -0.470</td> <td>   -0.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>   -0.9001</td> <td>    0.070</td> <td>  -12.829</td> <td> 0.000</td> <td>   -1.038</td> <td>   -0.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.3024</td> <td>    0.031</td> <td>   42.434</td> <td> 0.000</td> <td>    1.242</td> <td>    1.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>   <td>   -0.7844</td> <td>    0.101</td> <td>   -7.746</td> <td> 0.000</td> <td>   -0.983</td> <td>   -0.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -1.0895</td> <td>    0.107</td> <td>  -10.136</td> <td> 0.000</td> <td>   -1.300</td> <td>   -0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.0537</td> <td>    0.075</td> <td>  -14.025</td> <td> 0.000</td> <td>   -1.201</td> <td>   -0.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>       <td>    1.4654</td> <td>    0.163</td> <td>    9.006</td> <td> 0.000</td> <td>    1.146</td> <td>    1.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>    0.4251</td> <td>    0.064</td> <td>    6.597</td> <td> 0.000</td> <td>    0.299</td> <td>    0.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>       <td>    0.7749</td> <td>    0.083</td> <td>    9.291</td> <td> 0.000</td> <td>    0.611</td> <td>    0.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.3818</td> <td>    0.032</td> <td>   11.773</td> <td> 0.000</td> <td>    0.318</td> <td>    0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>   -0.4047</td> <td>    0.077</td> <td>   -5.269</td> <td> 0.000</td> <td>   -0.555</td> <td>   -0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5669</td> <td>    0.058</td> <td>   -9.717</td> <td> 0.000</td> <td>   -0.681</td> <td>   -0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.1195</td> <td>    0.057</td> <td>  -19.606</td> <td> 0.000</td> <td>   -1.231</td> <td>   -1.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5455</td> <td>    0.024</td> <td>  -23.161</td> <td> 0.000</td> <td>   -0.592</td> <td>   -0.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -0.9986</td> <td>    0.050</td> <td>  -20.107</td> <td> 0.000</td> <td>   -1.096</td> <td>   -0.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5357</td> <td>    0.019</td> <td>   28.020</td> <td> 0.000</td> <td>    0.498</td> <td>    0.573</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34271\n",
       "Model Family:                Binomial   Df Model:                           16\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -11911.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       23822.\n",
       "Time:                        20:13:36   Pearson chi2:                 1.60e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7382      0.029    -25.441      0.000      -0.795      -0.681\n",
       "onnet_mou_8           -0.4269      0.022    -19.495      0.000      -0.470      -0.384\n",
       "offnet_mou_8          -0.9001      0.070    -12.829      0.000      -1.038      -0.763\n",
       "roam_og_mou_8          1.3024      0.031     42.434      0.000       1.242       1.363\n",
       "loc_og_t2t_mou_7      -0.7844      0.101     -7.746      0.000      -0.983      -0.586\n",
       "loc_og_t2m_mou_7      -1.0895      0.107    -10.136      0.000      -1.300      -0.879\n",
       "loc_og_t2f_mou_8      -1.0537      0.075    -14.025      0.000      -1.201      -0.906\n",
       "loc_og_mou_7           1.4654      0.163      9.006      0.000       1.146       1.784\n",
       "std_og_t2m_mou_8       0.4251      0.064      6.597      0.000       0.299       0.551\n",
       "std_og_mou_6           0.7749      0.083      9.291      0.000       0.611       0.938\n",
       "std_og_mou_7           0.3818      0.032     11.773      0.000       0.318       0.445\n",
       "total_og_mou_6        -0.4047      0.077     -5.269      0.000      -0.555      -0.254\n",
       "loc_ic_t2f_mou_8      -0.5669      0.058     -9.717      0.000      -0.681      -0.453\n",
       "loc_ic_mou_8          -1.1195      0.057    -19.606      0.000      -1.231      -1.008\n",
       "last_day_rch_amt_8    -0.5455      0.024    -23.161      0.000      -0.592      -0.499\n",
       "aug_vbc_3g            -0.9986      0.050    -20.107      0.000      -1.096      -0.901\n",
       "Recency_8              0.5357      0.019     28.020      0.000       0.498       0.573\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm5 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm5.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>loc_og_mou_7</td>\n",
       "      <td>45.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>loc_og_t2m_mou_7</td>\n",
       "      <td>20.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>std_og_mou_6</td>\n",
       "      <td>18.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>total_og_mou_6</td>\n",
       "      <td>14.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>loc_og_t2t_mou_7</td>\n",
       "      <td>14.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>offnet_mou_8</td>\n",
       "      <td>10.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>9.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>onnet_mou_8</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Recency_8</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>aug_vbc_3g</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features    VIF\n",
       "6         loc_og_mou_7  45.60\n",
       "4     loc_og_t2m_mou_7  20.64\n",
       "8         std_og_mou_6  18.63\n",
       "10      total_og_mou_6  14.96\n",
       "3     loc_og_t2t_mou_7  14.27\n",
       "1         offnet_mou_8  10.07\n",
       "7     std_og_t2m_mou_8   9.28\n",
       "9         std_og_mou_7   3.26\n",
       "12        loc_ic_mou_8   2.24\n",
       "0          onnet_mou_8   1.55\n",
       "11    loc_ic_t2f_mou_8   1.55\n",
       "2        roam_og_mou_8   1.52\n",
       "5     loc_og_t2f_mou_8   1.45\n",
       "13  last_day_rch_amt_8   1.33\n",
       "15           Recency_8   1.14\n",
       "14          aug_vbc_3g   1.10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 'loc_og_mou_7' because of high p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('loc_og_mou_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34272</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11947.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  23894.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:44</td>     <th>  Pearson chi2:      </th> <td>1.52e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7403</td> <td>    0.029</td> <td>  -25.531</td> <td> 0.000</td> <td>   -0.797</td> <td>   -0.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.4058</td> <td>    0.022</td> <td>  -18.681</td> <td> 0.000</td> <td>   -0.448</td> <td>   -0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>   -0.8867</td> <td>    0.070</td> <td>  -12.599</td> <td> 0.000</td> <td>   -1.025</td> <td>   -0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.2911</td> <td>    0.031</td> <td>   42.172</td> <td> 0.000</td> <td>    1.231</td> <td>    1.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>   <td>    0.0548</td> <td>    0.032</td> <td>    1.737</td> <td> 0.082</td> <td>   -0.007</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -0.1751</td> <td>    0.036</td> <td>   -4.898</td> <td> 0.000</td> <td>   -0.245</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.0128</td> <td>    0.075</td> <td>  -13.495</td> <td> 0.000</td> <td>   -1.160</td> <td>   -0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>    0.4251</td> <td>    0.065</td> <td>    6.581</td> <td> 0.000</td> <td>    0.299</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>       <td>    0.6552</td> <td>    0.084</td> <td>    7.780</td> <td> 0.000</td> <td>    0.490</td> <td>    0.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.3699</td> <td>    0.032</td> <td>   11.462</td> <td> 0.000</td> <td>    0.307</td> <td>    0.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>   -0.2880</td> <td>    0.078</td> <td>   -3.709</td> <td> 0.000</td> <td>   -0.440</td> <td>   -0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5521</td> <td>    0.058</td> <td>   -9.454</td> <td> 0.000</td> <td>   -0.667</td> <td>   -0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.2046</td> <td>    0.057</td> <td>  -21.196</td> <td> 0.000</td> <td>   -1.316</td> <td>   -1.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5458</td> <td>    0.023</td> <td>  -23.230</td> <td> 0.000</td> <td>   -0.592</td> <td>   -0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -0.9687</td> <td>    0.049</td> <td>  -19.887</td> <td> 0.000</td> <td>   -1.064</td> <td>   -0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5339</td> <td>    0.019</td> <td>   28.010</td> <td> 0.000</td> <td>    0.497</td> <td>    0.571</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34272\n",
       "Model Family:                Binomial   Df Model:                           15\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -11947.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       23894.\n",
       "Time:                        20:13:44   Pearson chi2:                 1.52e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7403      0.029    -25.531      0.000      -0.797      -0.683\n",
       "onnet_mou_8           -0.4058      0.022    -18.681      0.000      -0.448      -0.363\n",
       "offnet_mou_8          -0.8867      0.070    -12.599      0.000      -1.025      -0.749\n",
       "roam_og_mou_8          1.2911      0.031     42.172      0.000       1.231       1.351\n",
       "loc_og_t2t_mou_7       0.0548      0.032      1.737      0.082      -0.007       0.117\n",
       "loc_og_t2m_mou_7      -0.1751      0.036     -4.898      0.000      -0.245      -0.105\n",
       "loc_og_t2f_mou_8      -1.0128      0.075    -13.495      0.000      -1.160      -0.866\n",
       "std_og_t2m_mou_8       0.4251      0.065      6.581      0.000       0.299       0.552\n",
       "std_og_mou_6           0.6552      0.084      7.780      0.000       0.490       0.820\n",
       "std_og_mou_7           0.3699      0.032     11.462      0.000       0.307       0.433\n",
       "total_og_mou_6        -0.2880      0.078     -3.709      0.000      -0.440      -0.136\n",
       "loc_ic_t2f_mou_8      -0.5521      0.058     -9.454      0.000      -0.667      -0.438\n",
       "loc_ic_mou_8          -1.2046      0.057    -21.196      0.000      -1.316      -1.093\n",
       "last_day_rch_amt_8    -0.5458      0.023    -23.230      0.000      -0.592      -0.500\n",
       "aug_vbc_3g            -0.9687      0.049    -19.887      0.000      -1.064      -0.873\n",
       "Recency_8              0.5339      0.019     28.010      0.000       0.497       0.571\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm6 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm6.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 'loc_og_t2t_mou_7' because of high p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('loc_og_t2t_mou_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34273</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11949.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  23897.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:50</td>     <th>  Pearson chi2:      </th> <td>1.48e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7400</td> <td>    0.029</td> <td>  -25.531</td> <td> 0.000</td> <td>   -0.797</td> <td>   -0.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.4008</td> <td>    0.022</td> <td>  -18.615</td> <td> 0.000</td> <td>   -0.443</td> <td>   -0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>   -0.8936</td> <td>    0.070</td> <td>  -12.723</td> <td> 0.000</td> <td>   -1.031</td> <td>   -0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.2941</td> <td>    0.031</td> <td>   42.305</td> <td> 0.000</td> <td>    1.234</td> <td>    1.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -0.1777</td> <td>    0.036</td> <td>   -4.960</td> <td> 0.000</td> <td>   -0.248</td> <td>   -0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.0117</td> <td>    0.075</td> <td>  -13.480</td> <td> 0.000</td> <td>   -1.159</td> <td>   -0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>    0.4324</td> <td>    0.064</td> <td>    6.711</td> <td> 0.000</td> <td>    0.306</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>       <td>    0.5822</td> <td>    0.074</td> <td>    7.910</td> <td> 0.000</td> <td>    0.438</td> <td>    0.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.3717</td> <td>    0.032</td> <td>   11.531</td> <td> 0.000</td> <td>    0.309</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>   -0.2183</td> <td>    0.067</td> <td>   -3.251</td> <td> 0.001</td> <td>   -0.350</td> <td>   -0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5575</td> <td>    0.058</td> <td>   -9.553</td> <td> 0.000</td> <td>   -0.672</td> <td>   -0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.1892</td> <td>    0.056</td> <td>  -21.198</td> <td> 0.000</td> <td>   -1.299</td> <td>   -1.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5481</td> <td>    0.023</td> <td>  -23.347</td> <td> 0.000</td> <td>   -0.594</td> <td>   -0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -0.9670</td> <td>    0.049</td> <td>  -19.872</td> <td> 0.000</td> <td>   -1.062</td> <td>   -0.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5349</td> <td>    0.019</td> <td>   28.075</td> <td> 0.000</td> <td>    0.498</td> <td>    0.572</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34273\n",
       "Model Family:                Binomial   Df Model:                           14\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -11949.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       23897.\n",
       "Time:                        20:13:50   Pearson chi2:                 1.48e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7400      0.029    -25.531      0.000      -0.797      -0.683\n",
       "onnet_mou_8           -0.4008      0.022    -18.615      0.000      -0.443      -0.359\n",
       "offnet_mou_8          -0.8936      0.070    -12.723      0.000      -1.031      -0.756\n",
       "roam_og_mou_8          1.2941      0.031     42.305      0.000       1.234       1.354\n",
       "loc_og_t2m_mou_7      -0.1777      0.036     -4.960      0.000      -0.248      -0.107\n",
       "loc_og_t2f_mou_8      -1.0117      0.075    -13.480      0.000      -1.159      -0.865\n",
       "std_og_t2m_mou_8       0.4324      0.064      6.711      0.000       0.306       0.559\n",
       "std_og_mou_6           0.5822      0.074      7.910      0.000       0.438       0.726\n",
       "std_og_mou_7           0.3717      0.032     11.531      0.000       0.309       0.435\n",
       "total_og_mou_6        -0.2183      0.067     -3.251      0.001      -0.350      -0.087\n",
       "loc_ic_t2f_mou_8      -0.5575      0.058     -9.553      0.000      -0.672      -0.443\n",
       "loc_ic_mou_8          -1.1892      0.056    -21.198      0.000      -1.299      -1.079\n",
       "last_day_rch_amt_8    -0.5481      0.023    -23.347      0.000      -0.594      -0.502\n",
       "aug_vbc_3g            -0.9670      0.049    -19.872      0.000      -1.062      -0.872\n",
       "Recency_8              0.5349      0.019     28.075      0.000       0.498       0.572\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm7 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm7.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>std_og_mou_6</td>\n",
       "      <td>12.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>offnet_mou_8</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>total_og_mou_6</td>\n",
       "      <td>9.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>loc_og_t2m_mou_7</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>onnet_mou_8</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Recency_8</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>aug_vbc_3g</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features    VIF\n",
       "6         std_og_mou_6  12.60\n",
       "1         offnet_mou_8   9.82\n",
       "8       total_og_mou_6   9.42\n",
       "5     std_og_t2m_mou_8   9.07\n",
       "7         std_og_mou_7   3.26\n",
       "3     loc_og_t2m_mou_7   3.09\n",
       "10        loc_ic_mou_8   2.14\n",
       "9     loc_ic_t2f_mou_8   1.54\n",
       "2        roam_og_mou_8   1.51\n",
       "0          onnet_mou_8   1.44\n",
       "4     loc_og_t2f_mou_8   1.40\n",
       "11  last_day_rch_amt_8   1.33\n",
       "13           Recency_8   1.14\n",
       "12          aug_vbc_3g   1.10"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 'std_og_mou_6' because of high VIF value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('std_og_mou_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34274</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11982.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  23963.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:13:57</td>     <th>  Pearson chi2:      </th> <td>1.42e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7432</td> <td>    0.029</td> <td>  -25.616</td> <td> 0.000</td> <td>   -0.800</td> <td>   -0.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.4194</td> <td>    0.021</td> <td>  -19.764</td> <td> 0.000</td> <td>   -0.461</td> <td>   -0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>   -0.9004</td> <td>    0.070</td> <td>  -12.865</td> <td> 0.000</td> <td>   -1.038</td> <td>   -0.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.2871</td> <td>    0.030</td> <td>   42.221</td> <td> 0.000</td> <td>    1.227</td> <td>    1.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -0.3010</td> <td>    0.033</td> <td>   -9.150</td> <td> 0.000</td> <td>   -0.366</td> <td>   -0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.0273</td> <td>    0.075</td> <td>  -13.648</td> <td> 0.000</td> <td>   -1.175</td> <td>   -0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>    0.4264</td> <td>    0.064</td> <td>    6.641</td> <td> 0.000</td> <td>    0.301</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.4706</td> <td>    0.030</td> <td>   15.764</td> <td> 0.000</td> <td>    0.412</td> <td>    0.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>    0.2791</td> <td>    0.022</td> <td>   12.604</td> <td> 0.000</td> <td>    0.236</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5602</td> <td>    0.058</td> <td>   -9.616</td> <td> 0.000</td> <td>   -0.674</td> <td>   -0.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.2415</td> <td>    0.056</td> <td>  -22.235</td> <td> 0.000</td> <td>   -1.351</td> <td>   -1.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5428</td> <td>    0.023</td> <td>  -23.215</td> <td> 0.000</td> <td>   -0.589</td> <td>   -0.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -0.9830</td> <td>    0.049</td> <td>  -20.090</td> <td> 0.000</td> <td>   -1.079</td> <td>   -0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5256</td> <td>    0.019</td> <td>   27.687</td> <td> 0.000</td> <td>    0.488</td> <td>    0.563</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34274\n",
       "Model Family:                Binomial   Df Model:                           13\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -11982.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       23963.\n",
       "Time:                        20:13:57   Pearson chi2:                 1.42e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7432      0.029    -25.616      0.000      -0.800      -0.686\n",
       "onnet_mou_8           -0.4194      0.021    -19.764      0.000      -0.461      -0.378\n",
       "offnet_mou_8          -0.9004      0.070    -12.865      0.000      -1.038      -0.763\n",
       "roam_og_mou_8          1.2871      0.030     42.221      0.000       1.227       1.347\n",
       "loc_og_t2m_mou_7      -0.3010      0.033     -9.150      0.000      -0.366      -0.237\n",
       "loc_og_t2f_mou_8      -1.0273      0.075    -13.648      0.000      -1.175      -0.880\n",
       "std_og_t2m_mou_8       0.4264      0.064      6.641      0.000       0.301       0.552\n",
       "std_og_mou_7           0.4706      0.030     15.764      0.000       0.412       0.529\n",
       "total_og_mou_6         0.2791      0.022     12.604      0.000       0.236       0.322\n",
       "loc_ic_t2f_mou_8      -0.5602      0.058     -9.616      0.000      -0.674      -0.446\n",
       "loc_ic_mou_8          -1.2415      0.056    -22.235      0.000      -1.351      -1.132\n",
       "last_day_rch_amt_8    -0.5428      0.023    -23.215      0.000      -0.589      -0.497\n",
       "aug_vbc_3g            -0.9830      0.049    -20.090      0.000      -1.079      -0.887\n",
       "Recency_8              0.5256      0.019     27.687      0.000       0.488       0.563\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm8 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm8.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>offnet_mou_8</td>\n",
       "      <td>9.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>9.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>loc_og_t2m_mou_7</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>2.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>total_og_mou_6</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>onnet_mou_8</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Recency_8</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>aug_vbc_3g</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features   VIF\n",
       "1         offnet_mou_8  9.78\n",
       "5     std_og_t2m_mou_8  9.06\n",
       "3     loc_og_t2m_mou_7  2.63\n",
       "6         std_og_mou_7  2.61\n",
       "9         loc_ic_mou_8  2.10\n",
       "7       total_og_mou_6  1.65\n",
       "8     loc_ic_t2f_mou_8  1.54\n",
       "2        roam_og_mou_8  1.51\n",
       "4     loc_og_t2f_mou_8  1.40\n",
       "0          onnet_mou_8  1.37\n",
       "10  last_day_rch_amt_8  1.33\n",
       "12           Recency_8  1.14\n",
       "11          aug_vbc_3g  1.10"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 'offnet_mou_8' because of high VIF value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('offnet_mou_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34275</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -12059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  24118.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:14:03</td>     <th>  Pearson chi2:      </th> <td>1.50e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7367</td> <td>    0.029</td> <td>  -25.297</td> <td> 0.000</td> <td>   -0.794</td> <td>   -0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.4311</td> <td>    0.021</td> <td>  -20.309</td> <td> 0.000</td> <td>   -0.473</td> <td>   -0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.0948</td> <td>    0.025</td> <td>   43.583</td> <td> 0.000</td> <td>    1.046</td> <td>    1.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -0.4650</td> <td>    0.030</td> <td>  -15.489</td> <td> 0.000</td> <td>   -0.524</td> <td>   -0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.1501</td> <td>    0.076</td> <td>  -15.109</td> <td> 0.000</td> <td>   -1.299</td> <td>   -1.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>   -0.3543</td> <td>    0.021</td> <td>  -16.979</td> <td> 0.000</td> <td>   -0.395</td> <td>   -0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.5066</td> <td>    0.030</td> <td>   17.010</td> <td> 0.000</td> <td>    0.448</td> <td>    0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>    0.2782</td> <td>    0.022</td> <td>   12.617</td> <td> 0.000</td> <td>    0.235</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5243</td> <td>    0.057</td> <td>   -9.140</td> <td> 0.000</td> <td>   -0.637</td> <td>   -0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.4107</td> <td>    0.055</td> <td>  -25.741</td> <td> 0.000</td> <td>   -1.518</td> <td>   -1.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5817</td> <td>    0.023</td> <td>  -24.805</td> <td> 0.000</td> <td>   -0.628</td> <td>   -0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -0.9824</td> <td>    0.049</td> <td>  -20.101</td> <td> 0.000</td> <td>   -1.078</td> <td>   -0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5437</td> <td>    0.019</td> <td>   28.695</td> <td> 0.000</td> <td>    0.507</td> <td>    0.581</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34275\n",
       "Model Family:                Binomial   Df Model:                           12\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -12059.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       24118.\n",
       "Time:                        20:14:03   Pearson chi2:                 1.50e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7367      0.029    -25.297      0.000      -0.794      -0.680\n",
       "onnet_mou_8           -0.4311      0.021    -20.309      0.000      -0.473      -0.390\n",
       "roam_og_mou_8          1.0948      0.025     43.583      0.000       1.046       1.144\n",
       "loc_og_t2m_mou_7      -0.4650      0.030    -15.489      0.000      -0.524      -0.406\n",
       "loc_og_t2f_mou_8      -1.1501      0.076    -15.109      0.000      -1.299      -1.001\n",
       "std_og_t2m_mou_8      -0.3543      0.021    -16.979      0.000      -0.395      -0.313\n",
       "std_og_mou_7           0.5066      0.030     17.010      0.000       0.448       0.565\n",
       "total_og_mou_6         0.2782      0.022     12.617      0.000       0.235       0.321\n",
       "loc_ic_t2f_mou_8      -0.5243      0.057     -9.140      0.000      -0.637      -0.412\n",
       "loc_ic_mou_8          -1.4107      0.055    -25.741      0.000      -1.518      -1.303\n",
       "last_day_rch_amt_8    -0.5817      0.023    -24.805      0.000      -0.628      -0.536\n",
       "aug_vbc_3g            -0.9824      0.049    -20.101      0.000      -1.078      -0.887\n",
       "Recency_8              0.5437      0.019     28.695      0.000       0.507       0.581\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm9 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm9.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>total_og_mou_6</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>loc_og_t2m_mou_7</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>onnet_mou_8</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Recency_8</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>aug_vbc_3g</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features   VIF\n",
       "5         std_og_mou_7  2.58\n",
       "8         loc_ic_mou_8  2.02\n",
       "6       total_og_mou_6  1.65\n",
       "2     loc_og_t2m_mou_7  1.56\n",
       "7     loc_ic_t2f_mou_8  1.54\n",
       "4     std_og_t2m_mou_8  1.52\n",
       "0          onnet_mou_8  1.37\n",
       "3     loc_og_t2f_mou_8  1.36\n",
       "9   last_day_rch_amt_8  1.30\n",
       "11           Recency_8  1.13\n",
       "1        roam_og_mou_8  1.12\n",
       "10          aug_vbc_3g  1.10"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-values for each variable are less than 0.05 and the VIF values are less than 5. Hence, we are good to go with the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted values on the train set\n",
    "y_train_pred = res.predict(X_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Churn':y_train_res, 'Churn_Prob':y_train_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  predicted\n",
       "0      0    0.349776          0\n",
       "1      0    0.000166          0\n",
       "2      0    0.801592          1\n",
       "3      0    0.000295          0\n",
       "4      0    0.299720          0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Churn, y_train_pred_final.Churn_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_roc(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801592</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299720</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  \\\n",
       "0      0    0.349776          0    1    1    1    1    0    0    0    0    0   \n",
       "1      0    0.000166          0    1    0    0    0    0    0    0    0    0   \n",
       "2      0    0.801592          1    1    1    1    1    1    1    1    1    1   \n",
       "3      0    0.000295          0    1    0    0    0    0    0    0    0    0   \n",
       "4      0    0.299720          0    1    1    1    0    0    0    0    0    0   \n",
       "\n",
       "   0.9  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.axvline(x=0.545,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>final_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801592</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299720</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  \\\n",
       "0      0    0.349776          0    1    1    1    1    0    0    0    0    0   \n",
       "1      0    0.000166          0    1    0    0    0    0    0    0    0    0   \n",
       "2      0    0.801592          1    1    1    1    1    1    1    1    1    1   \n",
       "3      0    0.000295          0    1    0    0    0    0    0    0    0    0   \n",
       "4      0    0.299720          0    1    1    1    0    0    0    0    0    0   \n",
       "\n",
       "   0.9  final_predicted  \n",
       "0    0                0  \n",
       "1    0                0  \n",
       "2    0                1  \n",
       "3    0                0  \n",
       "4    0                0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.545 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649965002333178"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645006999533364"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.axvline(x=0.54,color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our appropriate cutoff should be 0.54 which is similar to the one we chose in the accuracy,sensitivity and specificty cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test[col])\n",
    "y_test_pred = res.predict(X_test_sm)\n",
    "y_test_pred = y_test_pred.values.reshape(-1)\n",
    "\n",
    "#Creating a DataFrame of the original target variable and Purchase Probability \n",
    "y_test_pred_final = pd.DataFrame({'Churn':y_test.values, 'Churn_Prob':y_test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final['final_predicted'] = y_test_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.545 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715958426522826"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8610742940995479"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#roc_auc score\n",
    "metrics.roc_auc_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849802371541502"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the sensitivity.\n",
    "metrics.recall_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18647007805724197"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression without PCA with sampling</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.871596</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.18647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Training Accuracy  \\\n",
       "Logistic Regression without PCA with sampling           0.864997   \n",
       "\n",
       "                                               Test Accuracy  Training Recall  \\\n",
       "Logistic Regression without PCA with sampling       0.871596         0.864501   \n",
       "\n",
       "                                               Test Recall  \\\n",
       "Logistic Regression without PCA with sampling     0.849802   \n",
       "\n",
       "                                               Training Precision  \\\n",
       "Logistic Regression without PCA with sampling            0.865359   \n",
       "\n",
       "                                               Test Precision  \n",
       "Logistic Regression without PCA with sampling         0.18647  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics.loc['Logistic Regression without PCA with sampling','Training Accuracy']=metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression without PCA with sampling','Test Accuracy']=metrics.accuracy_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression without PCA with sampling','Training Recall']=metrics.recall_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression without PCA with sampling','Test Recall']=metrics.recall_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression without PCA with sampling','Training Precision']=metrics.precision_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression without PCA with sampling','Test Precision']=metrics.precision_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the metrics in the training set and the test set are almost same with a difference of maximum 2%. Hence, there is less chance of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** Even though the precision score is low, but the cost of False Positive is quite low. The most we will do is work on non-churn customers and provide them better schemes. We are treating our high value customers well in that case.\n",
    "<br>\n",
    "<br>\n",
    "Moreover, as informed in the problem statement, ***retaining high profitable customers is the number one business goal***. Thus, it is more important to identify churners more than non churners accurately. Thus, the recall score or sensitivity should be high.\n",
    "<br>\n",
    "<br>\n",
    "Because of the above mentioned reasons, we compensate on precision score to make a model which has a higher recall (sensitivity) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 34288</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 34275</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -12059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  24118.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:21:06</td>     <th>  Pearson chi2:      </th> <td>1.50e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -0.7367</td> <td>    0.029</td> <td>  -25.297</td> <td> 0.000</td> <td>   -0.794</td> <td>   -0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>        <td>   -0.4311</td> <td>    0.021</td> <td>  -20.309</td> <td> 0.000</td> <td>   -0.473</td> <td>   -0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    1.0948</td> <td>    0.025</td> <td>   43.583</td> <td> 0.000</td> <td>    1.046</td> <td>    1.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -0.4650</td> <td>    0.030</td> <td>  -15.489</td> <td> 0.000</td> <td>   -0.524</td> <td>   -0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -1.1501</td> <td>    0.076</td> <td>  -15.109</td> <td> 0.000</td> <td>   -1.299</td> <td>   -1.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>   -0.3543</td> <td>    0.021</td> <td>  -16.979</td> <td> 0.000</td> <td>   -0.395</td> <td>   -0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>    0.5066</td> <td>    0.030</td> <td>   17.010</td> <td> 0.000</td> <td>    0.448</td> <td>    0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>    0.2782</td> <td>    0.022</td> <td>   12.617</td> <td> 0.000</td> <td>    0.235</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.5243</td> <td>    0.057</td> <td>   -9.140</td> <td> 0.000</td> <td>   -0.637</td> <td>   -0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>   -1.4107</td> <td>    0.055</td> <td>  -25.741</td> <td> 0.000</td> <td>   -1.518</td> <td>   -1.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.5817</td> <td>    0.023</td> <td>  -24.805</td> <td> 0.000</td> <td>   -0.628</td> <td>   -0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -0.9824</td> <td>    0.049</td> <td>  -20.101</td> <td> 0.000</td> <td>   -1.078</td> <td>   -0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Recency_8</th>          <td>    0.5437</td> <td>    0.019</td> <td>   28.695</td> <td> 0.000</td> <td>    0.507</td> <td>    0.581</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                34288\n",
       "Model:                            GLM   Df Residuals:                    34275\n",
       "Model Family:                Binomial   Df Model:                           12\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -12059.\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       24118.\n",
       "Time:                        20:21:06   Pearson chi2:                 1.50e+05\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -0.7367      0.029    -25.297      0.000      -0.794      -0.680\n",
       "onnet_mou_8           -0.4311      0.021    -20.309      0.000      -0.473      -0.390\n",
       "roam_og_mou_8          1.0948      0.025     43.583      0.000       1.046       1.144\n",
       "loc_og_t2m_mou_7      -0.4650      0.030    -15.489      0.000      -0.524      -0.406\n",
       "loc_og_t2f_mou_8      -1.1501      0.076    -15.109      0.000      -1.299      -1.001\n",
       "std_og_t2m_mou_8      -0.3543      0.021    -16.979      0.000      -0.395      -0.313\n",
       "std_og_mou_7           0.5066      0.030     17.010      0.000       0.448       0.565\n",
       "total_og_mou_6         0.2782      0.022     12.617      0.000       0.235       0.321\n",
       "loc_ic_t2f_mou_8      -0.5243      0.057     -9.140      0.000      -0.637      -0.412\n",
       "loc_ic_mou_8          -1.4107      0.055    -25.741      0.000      -1.518      -1.303\n",
       "last_day_rch_amt_8    -0.5817      0.023    -24.805      0.000      -0.628      -0.536\n",
       "aug_vbc_3g            -0.9824      0.049    -20.101      0.000      -1.078      -0.887\n",
       "Recency_8              0.5437      0.019     28.695      0.000       0.507       0.581\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 7 important variables affecting the churn are as follows:\n",
    "- loc_ic_mou_8 (negatively related)\n",
    "- loc_og_t2f_mou_8 (negatively related)\n",
    "- roam_og_mou_8 (positively related)\n",
    "- aug_vbc_3g (negatively related)\n",
    "- last_day_rch_amt_8 (negatively related)\n",
    "- Recency_8 (positively related)\n",
    "- std_og_mou_7 (positively related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp_col=['loc_ic_mou_8','loc_og_t2f_mou_8','roam_og_mou_8','aug_vbc_3g','last_day_rch_amt_8','Recency_8','std_og_mou_7']\n",
    "i=1\n",
    "plt.figure(figsize=(15,15))\n",
    "for col in imp_col:\n",
    "    plt.subplot(4,2,i)\n",
    "    sns.boxenplot(y=fdf[col],x=fdf['Churn'])\n",
    "    i+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First four variables which are negatively correlated show higher probability of Churn for lower values.\n",
    "- Last two variables which are positively correlated show higher probability of Churn for higher values.\n",
    "\n",
    "Thus, we are able to visually verify the importance of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the top 7 important variables affecting the churn are as follows:\n",
    "\n",
    "- loc_ic_mou_8 (negatively related)\n",
    "- loc_og_t2f_mou_8 (negatively related)\n",
    "- roam_og_mou_8 (positively related)\n",
    "- aug_vbc_3g (negatively related)\n",
    "- last_day_rch_amt_8 (negatively related)\n",
    "- Recency_8 (positively related)\n",
    "- std_og_mou_7 (positively related)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**If the telecom company wants to retain high value customers, the company should provide special schemes or plans for customers in following call situations:**\n",
    "\n",
    "- **Local Outgoing calls from Operator T to fixed lines of T (since loc_og_t2f_mou_8 is negatively related to churn, so as the minutes of usage in this case increase, the probability of retaining these customers increases)**\n",
    "- **We also notice that as mintues of usage of roaming outgoing calls increase in August, the probability of Churn also increases and the customer is also not using special data plans in August since aug_vbc_3g also increases. This happened because possibly the customer has changed his location and needs a new sim card because of the location change. Thus, the company should have provisions to provide a new area connection on the same number or some special plans if a customer changes his/her location.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We now begin the model building with an aim to predict as better as possible. Note we want to maximize the recall (sensitivity) metric since we want to predict correctly the people who actually churn and the cost of false negatives is really high. If we predict a churning customer as not churn, then we have more chances to lose a high revenue customer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest without PCA using class_weight='balanced' argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required classes or libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:   21.5s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:   24.9s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   27.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   27.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 20, 2)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=True, scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(2, 20, 2)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(class_weight='balanced',random_state=100) #we put class_weight='balanced' to deal with Data Imbalance present in the dataset\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axhline(y=0.84,color='r')\n",
    "plt.axvline(x=2,color='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal max_depth=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:    9.6s remaining:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:   19.0s remaining:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  20 | elapsed:   24.9s remaining:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:   32.1s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   37.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   37.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(100, 1500, 400)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(100, 1500, 400)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=2,class_weight='balanced',random_state=100) #we put class_weight='balanced' to deal with Data Imbalance present in the dataset\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEJCAYAAACDscAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXwV1fn48c+Tm9yEbCwJKhIwaFHZtxCkiqAoIlqXKiqiiFJxqbb6tSpWReuv7ddaq9WvC6IsQlEUlUorCi6gtSKQyK6igAgBlySsSSAbz++PmcRLuCH3Qi5zkzzv12temTlzZu5zuJCHOTNzjqgqxhhjTKhivA7AGGNMw2KJwxhjTFgscRhjjAmLJQ5jjDFhscRhjDEmLJY4jDHGhCWiiUNEhorIWhFZJyLjguxvLyILRGSZiKwUkWEB+7qLyCIRWSMiq0QkwS1f6J5zubscFck2GGOM2Z9E6j0OEfEBXwFnA3nAUmCEqn4eUGcisExVnxWRzsBcVc0UkVjgM+BqVV0hImnADlWtFJGFwO9UNSfUWNLT0zUzMzPsNqwtXAvASWknhX2sMcY0dLm5uQWq2rpmeWwEPzMbWKeqGwBEZCZwIfB5QB0FUt315sBWd30IsFJVVwCoauHhBJKZmUlOTsh5ptqgqYMAWDh64eF8vDHGNEgi8m2w8kh2VbUFNgds57llgR4ErhKRPGAucKtbfiKgIjJPRD4TkbtqHDfF7aa6X0QkArEbY4ypRSQTR7Bf6DX7xUYAU1U1AxgGTBeRGJwrodOAke7Pi0VksHvMSFXtBgxwl6uDfrjIWBHJEZGc/Pz8w2+NMcYYILKJIw9oF7CdwU9dUVXGAK8CqOoiIAFId4/9UFULVLUE52qkt1tvi/tzN/ASTpfYAVR1oqpmqWpW69YHdNEZY4w5RJG8x7EU6CgiHYAtwBXAlTXqbAIGA1NFpBNO4sgH5gF3iUgiUAYMBB53b5q3UNUCEYkDzgfei2AbjDGHqby8nLy8PPbu3et1KKYWCQkJZGRkEBcXF1L9iCUOVa0QkVtwkoAPmKyqa0TkISBHVecAdwDPi8jtON1Yo9V5zGu7iDyGk3wU52mrt0QkCZjnJg0fTtJ4PlJtMMYcvry8PFJSUsjMzMRuSUYfVaWwsJC8vDw6dOgQ0jGRvOJAVefidDMFlo0PWP8cOLWWY/8B/KNGWTHQp/4jNcZEyt69ey1pRDERIS0tjXDuBdub48aYiLOkEd3C/X4scRzEtuIyikorvA7DGHMYduzYwTPPPHNIxw4bNowdO3YctM748eN5773ovtWanJwMwMaNG+natethn88SRy3KKvaxeVsJX36/m3U/7vY6HGPMITpY4qisrDzosXPnzqVFixYHrfPQQw9x1llnHXJ8takrNi9Z4qiFPzaGk45JQYBRk5awdccer0MyxhyCcePGsX79enr27Mmdd97JwoULOeOMM7jyyivp1q0bABdddBF9+vShS5cuTJw4sfrYzMxMCgoK2LhxI506deL666+nS5cuDBkyhD17nN8Jo0eP5rXXXquu/8ADD9C7d2+6devGl19+CUB+fj5nn302vXv35oYbbuC4446joKDggFiTk5MZP348/fr1Y9GiReTm5jJw4ED69OnDOeecw3fffQfAunXrOOuss+jRowe9e/dm/fr1FBUVMXjw4OrPfvPNNyP3h6qqjX7p06ePHoqBUwZq1oRTtcv4d/Ssvy3U7cWlh3QeY5qyzz//3NPP/+abb7RLly7V2wsWLNDExETdsGFDdVlhYaGqqpaUlGiXLl20oKBAVVWPO+44zc/P12+++UZ9Pp8uW7ZMVVWHDx+u06dPV1XVa665RmfNmlVd/8knn1RV1aefflrHjBmjqqq//vWv9c9//rOqqr799tsKaH5+/gGxAvrKK6+oqmpZWZn2799ff/zxR1VVnTlzpl577bWqqpqdna1vvPGGqqru2bNHi4uLtby8XHfu3Kmqqvn5+XrCCSfovn37VFU1KSkp6J9FoGDfE84TsAf8To3oU1WNQVJ8LE+M6sPoyUu5bupSZvzqFJr5fV6HZUyD9Id/reHzrbvq9Zydj03lgV90CeuY7Ozs/R49ffLJJ5k9ezYAmzdv5uuvvyYtLW2/Yzp06EDPnj0B6NOnDxs3bgx67l/+8pfVdd544w0APv744+rzDx06lJYtWwY91ufzcckllwCwdu1aVq9ezdlnnw04XVdt2rRh9+7dbNmyhYsvvhhw3sEA532Z3//+93z00UfExMSwZcsWfvjhB4455piw/mxCYYkjBD8/IZ0nrujJzS99xs0zcpk4Kos4n/XyGdNQJSUlVa8vXLiQ9957j0WLFpGYmMigQYOCvqwYHx9fve7z+aq7qmqr5/P5qKhwHq7REEchT0hIwOfzVR/TpUsXFi1atF+dXbuCJ94ZM2aQn59Pbm4ucXFxZGZmRuylS0scITq3Wxv+eFFX7p29mrtfX8mjl/YgJsYeMTQmHOFeGdSHlJQUdu+u/QGXnTt30rJlSxITE/nyyy/59NNP6z2G0047jVdffZW7776b+fPns3379jqPOemkk8jPz2fRokX079+f8vJyvvrqK7p06UJGRgb//Oc/ueiiiygtLaWyspKdO3dy1FFHERcXx4IFC/j226AD29YL+29zGEb2O47bzzqRNz7bwsPvfOl1OMaYEKSlpXHqqafStWtX7rzzzgP2Dx06lIqKCrp3787999/PKaecUu8xPPDAA8yfP5/evXvz9ttv06ZNG1JSUg56jN/v57XXXuPuu++mR48e9OzZk08++QSA6dOn8+STT9K9e3d+/vOf8/333zNy5EhycnLIyspixowZnHzyyfXejioRm8gpmmRlZWl9zcehqjwwZw3TFn3L74edzNjTT6inKI1pnL744gs6derkdRieKi0txefzERsby6JFi7jppptYvny512HtJ9j3JCK5qppVs651VYVJRHjgF10oLCrjz3O/JC0pnkv6ZHgdljEmim3atInLLruMffv24ff7ef75hj3EniWOQ+CLER67vAc79pRx1+sraZkUx5knH+11WMaYKNWxY0eWLVvmdRj1xu5xHKL4WB/PXZ1FpzYp3DzjM3K/3eZ1SMYYc0RY4jgMyfGxTL02m2NSE7huag5f/WBDkxhjGj9LHIcpPTme6WP64Y+NYdSkJWyxoUmMMY2cJY560K5VItOuy6a4rIJRkxazrbjM65CMMSZiIpo4RGSoiKwVkXUiMi7I/vYiskBElonIShEZFrCvu4gsEpE1IrJKRBLc8j7u9joReVKiZKD/Tm1SeWFUFpu37+G6qUspKbPh2I2JBoczrDrA3//+d0pKSuoxorpVDa4IPw2JHk0iljhExAc8DZwLdAZGiEjnGtXuA15V1V44c5I/4x4bizP7342q2gUYBJS7xzwLjAU6usvQSLUhXP2OT+OpEb1YmbeDm/7xGeWV+7wOyZgm70gljmgeBr2+RfKKIxtYp6obVLUMmAlcWKOOAqnuenNgq7s+BFipqisAVLVQVStFpA2QqqqL3JEbpwEXRbANYRvS5Rj+fHE3PvwqnztnrWDfvsb/gqUx0azmsOoAf/3rX+nbty/du3fngQceAKC4uJjzzjuPHj160LVrV1555RWefPJJtm7dyhlnnMEZZ5xxwLkzMzN56KGHOO2005g1axbr169n6NCh9OnThwEDBlQPq/7DDz9w8cUX06NHD3r06FH9Bnhtw7lHu0i+x9EW2BywnQf0q1HnQWC+iNwKJAFVs6GcCKiIzANaAzNV9RH3nHk1ztm2/kM/PFdkt6ewuIy/zltLWnI8953XyabONMYjDz/8MKtXr65+U3v+/Pl8/fXXLFmyBFXlggsu4KOPPiI/P59jjz2Wt956C3DGsGrevDmPPfYYCxYsID09Pej5ExIS+PjjjwEYPHgwEyZMoGPHjixevJibb76ZDz74gN/85jcMHDiQ2bNnU1lZSVFREQCTJ0+mVatW7Nmzh759+3LJJZccMCpvNIpk4gj2m7Lmf79HAFNV9W8i0h+YLiJd3bhOA/oCJcD7IpILBBsWMuh/6UVkLE6XFu3btz+0FhyGmwedQP7uUiZ9/A3pyfHcNMiGJjGGt8fB96vq95zHdINzHw65+vz585k/fz69evUCoKioiK+//poBAwbwu9/9jrvvvpvzzz+fAQMGhHS+yy+/vPo8n3zyCcOHD6/eV1paCsAHH3zAtGnTAGfU3ObNmwOhDecejSKZOPKAdgHbGfzUFVVlDO49ClVd5N4AT3eP/VBVCwBEZC7QG+e+R+D4HsHOiXu+icBEcMaqOtzGhEtEGH9+Z7YVl/GXd74kLdnPZVnt6j7QGBNRqso999zDDTfccMC+3Nxc5s6dyz333MOQIUMYP358neerGqJ93759tGjRIuQxqEIdzj0aRTJxLAU6ikgHYAvOze8ra9TZBAwGpopIJyAByAfmAXeJSCJQBgwEHlfV70Rkt4icAiwGRgH/F8E2HJaYGOHR4T3YXlLGPW+solWin7M629AkpgkL48qgvtQcVv2cc87h/vvvZ+TIkSQnJ7Nlyxbi4uKoqKigVatWXHXVVSQnJzN16tT9jq+tq6pKamoqHTp0YNasWQwfPhxVZeXKlfTo0YPBgwfz7LPPctttt1FZWUlxcfERGc49UiJ2c1xVK4BbcJLAFzhPT60RkYdE5AK32h3A9SKyAngZGO3OWLgdeAwn+SwHPlPVt9xjbgJeANYB64G3I9WG+uCPjWHCVX3oemwqv37pM5ZutKFJjDmSag6rPmTIEK688kr69+9Pt27duPTSS9m9ezerVq0iOzubnj178qc//Yn77rsPgLFjx3LuuecGvTle04wZM5g0aRI9evSgS5cu1fN+P/HEEyxYsIBu3brRp08f1qxZc0SGc48UG1b9IIINq36oCotKGT5hEflFpcy6sT8nH5Na90HGNAI2rHrDEM6w6vbm+BGSlhzPtDHZJPp9jJq0hM3bjuwLRcYYU18scRxBGS0TmXZdP/aWV3LN5CUUFpV6HZIxxoTNEscRdtIxKUwa3ZctO/Zw7dSlFJXa0CTGmIbFEocH+ma24ukre7Nm6y5unJ5LWYUNTWIat6ZwL7UhC/f7scThkbM6H83//rIbH68r4A4bmsQ0YgkJCRQWFlryiFKqSmFhIQkJCSEfY1PHeuiyrHYUFrkvCCb5eeAXnW1oEtPoZGRkkJeXR35+vtehmFokJCSQkZFRd0WXJQ6P3TjweAqKqoYm8XPLmR29DsmYehUXF0eHDh28DsPUI0scHhMR7h3WiW3FZTw6/yvSkuMZkX3kx9YyxphQWeKIAjExwiOXdmdbcRn3zl5Fy0Q/Q7se43VYxhgTlN0cjxJxvhievao33TNa8JuZy/h0Q6HXIRljTFCWOKJIoj+WKaP70q5lM65/MYfPtwYbRd4YY7xliSPKtEzyM21MP5ITYrlmyhI2FdrQJMaY6GKJIwq1bdGMaddlU1axj1GTF1NgQ5MYY6KIJY4o1fHoFCaP7sv3u/YyesoSdu8t9zokY4wBLHFEtT7HteSZkb354rvd3DA9l9KKSq9DMsYYSxzR7syTj+aRS7rzyfpC/ueVFVTa0CTGGI9FNHGIyFARWSsi60RkXJD97UVkgYgsE5GVIjLMLc8UkT0istxdJgQcs9A9Z9W+oyLZhmhwSZ8Mfj/sZN5a9R0PzlljY/4YYzwVsRcARcQHPA2cDeQBS0Vkjqp+HlDtPpwpZZ8Vkc7AXCDT3bdeVXvWcvqRqhr+lH4N2NjTT6CgqIyJH20gPTme355lQ5MYY7wRyTfHs4F1qroBQERmAhcCgYlDgao5VJsDWyMYT4M3bujJFBSV8vh7X5GW7OeqU47zOiRjTBMUya6qtsDmgO08tyzQg8BVIpKHc7Vxa8C+Dm4X1ociMqDGcVPcbqr7pQkNJxsTI/zlku6cefJR3P/mat5e9Z3XIRljmqBIJo5gv9Brds6PAKaqagYwDJguIjHAd0B7Ve0F/A/wkohUXZmMVNVuwAB3uTroh4uMFZEcEclpTMM5x/liePrK3vRq14LfzlzOJ+sLvA7JGNPERDJx5AHtArYzOLAragzwKoCqLgISgHRVLVXVQrc8F1gPnOhub3F/7gZewukSO4CqTlTVLFXNat26db01Kho08/uYPLovx6UlMnZaLqu37PQ6JGNMExLJxLEU6CgiHUTED1wBzKlRZxMwGEBEOuEkjnwRae3eXEdEjgc6AhtEJFZE0t3yOOB8YHUE2xC1WiT6mTYmm9SEWEZPWcq3hcVeh2SMaSIiljhUtQK4BZgHfIHz9NQaEXlIRC5wq90BXC8iK4CXgdHqPGt6OrDSLX8NuFFVtwHxwDwRWQksB7YAz0eqDdGuTfNmTBuTTcW+fVw9aQk/7t7rdUjGmCZAmsI7AVlZWZqTE/7Tu4OmDgJg4eiF9RtQPVu2aTtXPr+YDulJzLzhFFIT4rwOyRjTCIhIrqpm1Sy3N8cbgV7tWzLh6j589cNuxk7LYW+5DU1ijIkcSxyNxMATW/Po8B58umEbt81cbkOTGGMixhJHI3JRr7bcf35n3lnzPfe/udqGJjHGRITNOd7IjDmtAwVFpTy7cD3pyfH8z9kneh2SMaaRscTRCN11zkkUFpXy5Ptf0zrZz9X9M70OyRjTiFjiaIREhD9f3I1txeWMn7OGlkl+zu9+rNdhGWMaCbvH0UjF+mJ46speZB3XkttfWc5/19nQJMaY+mGJoxFLiPPxwqi+HJ+ezNhpOazKs6FJjDGHzxJHI9c8MY5pY7Jpkehn9JQlfFNgQ5MYYw6PJY4m4OjUBKaPyUaBqyct5sddNjSJMebQWeJoIo5vncyU0X3ZVlzGqMlL2Lmn3OuQjDENlCWOJqRHuxY8d3Uf1ucXcf2LNjSJMebQWOJoYgZ0bM3fLuvJ0m+3cevLy6io3Od1SMaYBsYSRxN0QY9jeeD8zrz7+Q/cO9uGJjHGhMdeAGyiRp/agYKiMp5asI70FD93nnOy1yEZYxoISxxN2B1DTqSwuJSnFzjjWl17agevQzLGNAAR7aoSkaEislZE1onIuCD724vIAhFZJiIrRWSYW54pIntEZLm7TAg4po+IrHLP+aSISCTb0JiJCP/vwq4M6Xw0f/jX57y5fIvXIRljGoCIJQ53zvCngXOBzsAIEelco9p9OFPK9sKZk/yZgH3rVbWnu9wYUP4sMBZnHvKOwNBItaEpiPXF8OSIXmR3aMXvZq3go6/yvQ7JGBPlInnFkQ2sU9UNqloGzAQurFFHgVR3vTmw9WAnFJE2QKqqLnLnJp8GXFS/YTc9CXE+nh+VxQmtk7nxH7ks37zD65CMMVEskomjLbA5YDvPLQv0IHCViOQBc4FbA/Z1cLuwPhSRAQHnzKvjnOYQNG8Wx7TrsklL9nPtlCWszy/yOiRjTJSKZOIIdu+h5nOfI4CpqpoBDAOmi0gM8B3Q3u3C+h/gJRFJDfGczoeLjBWRHBHJyc+37pdQHJWawLTr+hEjwqhJS/h+pw1NYow5UCQTRx7QLmA7gwO7osYArwKo6iIgAUhX1VJVLXTLc4H1wInuOTPqOCfucRNVNUtVs1q3bl0PzWkaOqQnMfXabHaUlHHN5CXsLLGhSYwx+4tk4lgKdBSRDiLix7n5PadGnU3AYAAR6YSTOPJFpLV7cx0ROR7nJvgGVf0O2C0ip7hPU40C3oxgG5qkbhnNmTgqi28Kihnz4lL2lNnQJMaYn0QscahqBXALMA/4AufpqTUi8pCIXOBWuwO4XkRWAC8Do92b3qcDK93y14AbVXWbe8xNwAvAOpwrkbcj1Yam7NSfpfP45T3J3bSdW176zIYmMcZUi+gLgKo6F+emd2DZ+ID1z4FTgxz3OvB6LefMAbrWb6QmmPO6t2FbcRfuf3MN97yxikcu7Y69NmOMsTfHzUFd3T+T/KIynnz/a9KS4xl3rg1NYkxTZ4nD1On2szpSUFTKhA/Xk57s51cDjvc6JGOMhyxxmDpVDU2yvbiMP771BWnJfi7ulVH3gcaYRsmGVTch8cUIj1/ek1OOb8Wds1ayYO2PXodkjPGIJQ4TsqqhSU48OoWb//EZyzZt9zokY4wHLHGYsKQkxDH1ur60Tonn2qlLWffjbq9DMsYcYZY4TNiOSklg+phsYmNiGDVpCVt37PE6JGPMEWSJwxyS49KSmHptX3btreCayUvYUVLmdUjGmCPEEoc5ZF3bNmfiqD58W1jCdVNtaBJjmgpLHOaw/PyEdJ64oifLNu/g5hm5lNvQJMY0epY4zGE7t1sb/nhRVxaszefu11eyb1/Qke6NMY2EvQBo6sXIfsdRWFTGY+9+RXpyPL8f1snrkIwxEWKJw9SbW8/8GQVFpUz8aAPpyX7Gnn6C1yEZYyLAEoepNyLCA7/oQmFxGX+e+yVpSfFc0seGJjGmsbHEYeqVL0Z47LIe7Cgp467XV9IyKY4zTz7a67CMMfXooDfHReRfIjKntqWuk4vIUBFZKyLrRGRckP3tRWSBiCwTkZUiMizI/iIR+V1A2UYRWSUiy0UkJ5zGmiMjPtbHc1dn0blNKjfP+Izcb7fVfZAxpsGo64rj0UM9sTv169PA2ThzhS8VkTnu5E1V7sOZGfBZEemMM+lTZsD+xwk+w98ZqlpwqLGZyEuOj2XKtX0ZPmER103NYdaN/Tnx6BSvwzLG1IODXnGo6ocHW+o4dzawTlU3qGoZMBO4sOZHAKnuenNga9UOEbkI2ACsCadBJnqkJ8cz7bps/LHO0CRbbGgSYxqFurqqVrldSEGXOs7dFtgcsJ3nlgV6ELhKRPJwrjZudT83Cbgb+EOQ8yowX0RyRWRsHTEYj7Vrlci067IpLqtg1KTFbCu2oUmMaejq6qo6/zDOHWxy6ppvho0Apqrq30SkPzBdRLriJIzHVbUoyBzXp6rqVhE5CnhXRL5U1Y8O+HAnqYwFaN++/WE0wxyuTm1SeWFUFldPXsJ1U5fy0vX9SPTbcxnGNFR1dVV9e7CljnPnAe0CtjMI6IpyjQFedT9rEZAApAP9gEdEZCNwG/B7EbnFrbfV/fkjMBunSyxY7BNVNUtVs1q3bl1HqCbS+h2fxlMjerEybwc3/eMzG5rEmAYspCFHROQUEVnqPuFUJiKVIrKrjsOWAh1FpIOI+IErgJpPYm0CBruf0QknceSr6gBVzVTVTODvwJ9V9SkRSRKRFLd+EjAEWB1iW43HhnQ5hj9f3I0Pv8rnzlkrbGgSYxqoUPsLnsL5xT8LyAJGAT872AGqWuFeJcwDfMBkVV0jIg8BOao6B7gDeF5Ebsfpxhqtqgf7bXI0MNvtvooFXlLVd0Jsg4kCV2S3p7C4jL/OW0urpHjuP78TQbojjTFRLOSOZlVdJyI+Va0EpojIJyEcMxfnpndg2fiA9c+BU+s4x4MB6xuAHqHGbKLTzYNOIH93KZP/+w3pKX5uHnTQ/4MYY6JMqImjxO1uWi4ijwDfAUmRC8s0ZiLC+PM7s624jEfeWUt6UjyX9W1X94HGmKgQ6rDqV7t1bwGKcW56XxKpoEzjFxMjPDq8BwM6pjPujZW8+/kPXodkjAlRqImjAChT1V2q+gfgTg58QsqYsPhjY5hwVR+6tW3OLS99xpJvbGgSYxqCUBPH+0BiwHYz4L36D8c0NUnxsUwe3Ze2LZox5sWlfPl9XQ/rGWO8FmriSFDVoqoNdz3xIPWNCVlacjzTxmST6PcxatISNm8r8TokY8xBhJo4ikWkd9WGiPQBbOAhU28yWiYy7bp+7C2v5JrJSygsKvU6JGNMLUJNHLcBs0TkPyLyH+AVnBvlxtSbk45JYdLovmzZsYdrpy6lqLTC65CMMUGE9Diuqi4VkZOBk3DGoPpSVcsjGll9WrsWBg0K/7juuRATc2jHmkPSF/i0pIy1PxSx+f9iOemYVGLs/UBjokqoQ44k4oxW+1tVXQVkisjhDIAY/VShvARKd8Oe7V5H06S0TPRzfHoSO/eUsz6/6ICRMY0x3gr1BcApQC7Q393Owxl+5N+RCKrenXQSLFwY/nHP94P8L+DojXDaxXDGfeCzUV2PhKOA1xeu5y/vfMnon2fywC8629AkxhxptfybC/W34AmqermIjABQ1T3SFP4VxzWDNj0hrSd8/Dh8uwgunQTNM7yOrEm4ceDxFBSVMunjb0hP9nPLmR29DskYQ+g3x8tEpBnufBoicgLQNB57kRi44En45Qvww2qYcBp8Nc/rqJoEEeHeYZ24uFdbHp3/FS8v2eR1SMYYQkgc7pXFBOAdoJ2IzMB5IfCuCMcWXboPh7EfQmoGvHQZzL8PKhvO8wENVUyM8Mil3Rl4Ymvunb2Kd1Z/73VIxjR5dSYOd5jz3wK/BEYDLwNZqrowopFFo/Sfwa/eg6wx8Mn/wZRzYYf9LzjS4nwxPHtVb7pntOA3M5fx6YZCr0MypkkL9R7Hp8DxqvpWJINpEOIS4PzHIPM0mPMbmDAALnoGTj7P68gatUR/LFNG9+XSCZ9w1QuLSU+OJ7VZLKkJcaQ2iyM1IZaUhLgaZTW3nTr+2FB7aI0xwYSaOM4AbhCRb3FGxxWci5HuEYss2nX9JRzbE2aNhplXwik3w1l/gFi/15E1Wi2T/Mz41Sm8uGgj24rK2LW3nF17y8nfXcr6/CJ27Sln194KKuuYWbBZnI+UhNjqZBI8yey/nZIQW10WH+s7Mg02JkqFmjjOPZSTi8hQ4AmcGQBfUNWHa+xvD7wItHDrjHMnfwrc/znwoKo+Gso5j6hWx8OYd2H+/fDpM7DpUxg+BVpmehZSY3dM8wTuHnpyrftVlZKySiep7Klgt5tcdu2pcH86ycX56ZRvKy5jY0FxdXlFHYknPjYmSNLZf/tgiSkhzhKPadhCfXP823BPLCI+4GngbJz3PpaKyBx31r8q9wGvquqzItIZZ7bAzID9jwNvh3nOIys2HoY94nRdvXkLTDgdLnwKOl/gWUhNmYiQFB9LUnwsbZqHf7yqsrd8X0CSOXjS2bW3nB17ytm8rYRde8vZuaec8sqDJx5/bMxBr2iCJaLmAeXxsTH2TovxVCTfZgx/ffoAABsdSURBVMsG1rnTvSIiM4ELca4gqiiQ6q43J2CODxG5CNiA0zUWzjm90fkCaNMdZl0Lr14N2WNhyB+dxGIaDBGhmd9HM7+Po1MTwj5eVSmt2FedXHYGSTq79x5Ylre9xElEe8opq9x30M/w+2JC6Grbvzwl4af1ZnE+SzzmsEQycbQFNgds5wH9atR5EJgvIrfiTEV7FoCIJOEMcXI28Lswz+mdlplw3Tx47wGn62rzYrh0CqSd4HVk5ggRERLifCTE+TjqEBIPwN7yygOudH5KNsGvfrbu2FO9XVpx8MQTGyMHTTop8W55Lfd8Ev2WeJq6SCaOYH+zal7DjwCmqurfRKQ/MF1EugJ/AB5X1aIaf0FDOadTUWQsMBagffv24cZ+6GL9MPR/na6rf94Ezw10XiDs+ssjF4Np0KoTT8qhHV9aUekkmlq61oJtf79rr3M/aE8Fe8orD3p+X4wceD8nIY6WSXG0SvKTlhRPWrKfVknOkp4cT8tEvz3N1ohEMnHk4cxNXiWDA6ebHQMMBVDVRSKSAKTjXEVcKiKP4Nw43ycie3HGy6rrnLjnmwhMBMjKyjry4+SdfB7c+DG8dh28di1s/A+c87/O47zGRFB8rI/4ZB/pyYfWTVpWsc99qODgSSewzvr8IrZ/W8624lJqe7YgJSGWNDeZpCXHV69XJZdW1fucn/b0WvSKZOJYCnQUkQ7AFuAK4MoadTYBg4GpItIJSADyVXVAVQUReRAoUtWnRCQ2hHNGjxbt4dq34f0/OC8Mbl4Kw6c6LxIaE6X8sTHOL/ZDSDz79ik795RTWFzGtuIythWXUlBUtV5GYXEZhUWlbN5WwvLNO9heXFbrU2wp8bG0cpNImnsl0yrZX2vCsafVjpyIJQ5VrRCRW4B5OI/OTlbVNSLyEJCjqnOAO4DnReR2nC6n0e6b6mGdM1JtqBe+OOcmeeYAmH0DTBwI5//dGcLEmEYmJkZomeSnZVJo7zOpKrv2VFBQXOokFjfJFBaVBiSfMrbs2MvKvJ1sO0iiSfL7SHMTSXVySfaTnhRfvZ4WcLVjiebQyUF+TzcaWVlZmpOTE/Zxg6YOAmDh6IX1E8jOPHhtDGz+FHqPgnMfcUbgNcaERFXZtbciaHIpKCr96cqmKgEVl9b6eHSi3/fT1UyNhFOzKy0t2U+iv+lNqSAiuaqaVbO86f1JeKl5Box+Cxb8CT5+DPJyYPiL0PpEryMzpkEQEZo3i6N5szg6pCfVWV9V2V1awbain7rJqrrMAhPOD7v28sV3uygsLqOslqfSmsX59rsHU/MhgLQaCacxP31mieNI88XCWQ9A5qnwxlin6+q8x6DnCK8jM6bRERHnUeKEODJDTDRFpRU/JRf3yqWguLR6vdBNNl99v5vC4rJaH3+Oj43Z/6Z/sKuZqq60ZD9JDSjRWOLwys/Ocp66ev1X8M8bYePHzhvo/rr/chtjIkNESEmIIyUhjuPSQks0JWWV+3WVFRYHv0+z7sciCotL2VsePNH4Y2MO8tSZn1ZJAd1pyX5S4mM9SzSWOLyUeiyMmgMfPgwfPQpbcpynro7q5HVkxpgQBA5x065VYkjHlJRV7HcPpjDIU2fbisvYkF/EtuIySsqCv1fj98Xsdw/GSTQ136Hx0yOjBbG++n2HxhKH13yxcOZ9cNyp8Mb1MPEMOO9R6Dmy1vl+jTENV6I/lsRWoSeaPWWVFBaXBiQW5zHn/bvSythYWMy2ojKKaySaL//fUOr7lRhLHNHihDN+6rp689fwzUfOvY/4ZK8jM8Z4qJnfR4Y/kYyWoSWaveWVPyWVkrKIPHZsiSOapBwDo96Ej/4KCx+GLZ85XVfHdPU6MmNMA5EQ56Nti2a0bRG5R/1t8JhoE+ODQePgmjlQugteGAw5U6AJvG9jjGkYLHFEqw6nO11X7fvDv2+D18fA3l1eR2WMMZY4olryUXDVG87N8zWznXc+vlvhdVTGmCbOEke0i4mB0++Ea/4N5XvghbNh6QvWdWWM8YwljoYi81Sn66rDAHjrDpg1Gvbu9DoqY0wTZImjIUlKhytnwVkPwhf/gudOh63LvI7KGNPEWOJoaGJi4LTb4dq5UFkOk4bA4ues68oYc8RY4mio2p/idF2dcCa8fRe8ejXs2eF1VMaYJsASR0OW2ApGzHQmilr7Njw3APJyvY7KGNPIRTRxiMhQEVkrIutEZFyQ/e1FZIGILBORlSIyzC3PFpHl7rJCRC4OOGajiKxy94U/O1NjIwI/vxWufceZQ3HyObDoaeu6MsZETMQSh4j4gKeBc4HOwAgR6Vyj2n3Aq6raC2f+8Gfc8tVAlqr2BIYCz7nzjVc5Q1V7BpuZqslq1xdu/Ag6DoF5v4eZV0LJNq+jMsY0QpG84sgG1qnqBlUtA2YCF9aoo0Cqu94c2AqgqiWqWuGWJ7j1TF2atYQrZsDQh+Hrd2HCANi8xOuojDGNTCQTR1tgc8B2nlsW6EHgKhHJA+YCt1btEJF+IrIGWAXcGJBIFJgvIrkiMjZSwTdYInDKTTBmnjPu1ZRz4b9PwL7gk8cYY0y4Ipk4gk0mUfPKYQQwVVUzgGHAdBGJAVDVxaraBegL3CMiCe4xp6pqb5wusF+LyOlBP1xkrIjkiEhOfn5+fbSnYWnbB274CE4aBu+Oh5cvh+JCr6MyxjQCkUwceUC7gO0M3K6oAGOAVwFUdRFOt1R6YAVV/QIoBrq621XdWT8Cs3G6xA6gqhNVNUtVs1q3bn3YjWmQmrWAy6bBsEdhw0KYcBp8u8jrqIwxDVwkE8dSoKOIdBARP87N7zk16mwCBgOISCecxJHvHhPrlh8HnARsFJEkEUlxy5OAITg30k1tRCD7ehjzLsTGw9Tz4D9/s64rY8whi1jicO9J3ALMA77AeXpqjYg8JCIXuNXuAK4XkRXAy8BoVVXgNGCFiCzHuaq4WVULgKOBj936S4C3VPWdSLWhUTm2p9N11flCeP8hmHEpFDXBLjxjzGETbQLP+2dlZWlOTvivfAyaOgiAhaMX1m9AXlKF3Cnw9jjnKaxLJ0HmaV5HZYyJQiKSG+y1B3tzvKkRgazr4Pr3nfnMX/wFfPgI7Kus+1hjjMESR9N1TDcYuxC6XgoL/gTTL4aiH72OyhjTAFjiaMriU+CXE+GC/4PNi+HZU2HDh15HZYyJcpY4mjoR6D0Krl/gPL477UJY8GfrujLG1MoSh3Ec3dnpuuoxAj78i5NAdn3ndVTGmChkicP8xJ8EFz8LFz4DW3KdFwbXve91VMaYKGOJwxyo10in6yqpNfzjEue9j8qKuo8zxjQJljhMcEedDNd/4CSR//zNeWx35xavozLGRAFLHKZ2/kS48Gm4eCJ8t8Lpuvr6Xa+jMsZ4zBKHqVuPy+GGDyH1WGeoknfHQ2W511EZYzxiicOEJr0j/Oo96HOtM7/H1PNgx+a6jzPGNDqWOEzo4prBL/4Ol0yCHz6H5wbA2re9jsoYc4RZ4jDh63ap03XVvB28fAXMuxcqyryOyhhzhFjiMIcm7QRnjo++18Oip5wpard/63VUxpgjwBKHOXRxCXDeozD8RSj4yum6+uLfXkdljIkwSxzm8HW5yOm6atkBXhnpzPVhXVfGNFoRTRwiMlRE1orIOhEZF2R/exFZICLLRGSliAxzy7NFZLm7rBCRi0M9p/FIq+NhzHzodyMsfhYmD4Ft33gdlTEmAiKWOETEBzwNnAt0BkaISOca1e7DmVK2F86c5M+45auBLFXtCQwFnhOR2BDPabwSGw/n/gUu/wds2wDPnQ5r/ul1VMaYehbJK45sYJ2qblDVMmAmcGGNOgqkuuvNga0AqlrizlkOkODWC/WcxmudfgE3/Md592PWNfDWHVC+1+uojDH1JJKJoy0Q+IZYnlsW6EHgKhHJA+YCt1btEJF+IrIGWAXc6CaSUM5pokHL4+Dad6D/LbD0BZh0NhSu9zoqY0w9iGTikCBlWmN7BDBVVTOAYcB0EYkBUNXFqtoF6AvcIyIJIZ7T+XCRsSKSIyI5+fn5h9wIcxhi/XDOn2DETNi5GZ4bCKte8zoqY8xhimTiyAPaBWxn4HZFBRgDvAqgqotwuqXSAyuo6hdAMdA1xHNWHTdRVbNUNat169aH0Qxz2E461+m6OrozvD4G/nUblO/xOipjzCGKZOJYCnQUkQ4i4se5+T2nRp1NwGAAEemEkzjy3WNi3fLjgJOAjSGe00SjFu1g9Ftw6m8hdwq8cBYUfO11VMaYQxCxxOHek7gFmAd8gfP01BoReUhELnCr3QFcLyIrgJeB0aqqwGnAChFZDswGblbVgtrOGak2mHrmi4OzH4IrZ8GurU7X1cpXvY7KGBMmcX5PN25ZWVmak5MT9nGDpg4CYOHohfUbkHEmhXp9DGxaBL2uhnMfceb/MMZEDRHJVdWsmuX25rjxRvO2cM2/YcAdsOwf8MJgyF/rdVTGmBBY4jDe8cXC4PFw1etQ9CNMHATLX/I6KmNMHSxxGO/9bDDc+DG07QP/vAlm3wRlxV5HZYyphSUOEx1S28CoN2Hg3bDiZZh4hjNZlDEm6ljiMNEjxgdn/B5G/RP2bIfnz4TPpkETeIDDmIbEEoeJPscPcrqu2mXDnFvhjbFQutvrqIwxLkscJjqlHA1Xz4Yz7oXVrzk3zr9f5XVUxhgscZhoFuODgXfBNf+C0iJ4fjDkTLauK2M8Fut1AMbUKfM0p+tq9lj49+3w1XzIyIKkdEhqDYnpznpiGiQ0Bwk2FqYxpr5Y4jANQ3JrGPk6/Pdx+PgJ+Ort4PVi4twkkg5JaQGJJe2nBBNYltDCEo0xYbLEYRqOmBjnTfMBdzij65YUQnE+FBdCSQEUFzjbJQU/lW3/1ikvq+Xmekzs/lcs1UmndZBk4yaaGOvhNU2bJQ7TMMU1g+YZzhKK8r1OoikpqCXZFDrrW5c5+0p3Bj+P+H5KMNVJJuDnfuutLdGYRskSh2ka4hKc8bGahzhhZEXpT8mkOsEEWf9uhfNz78ESTavgiSXR7UoLLGvW0nkowJgoZonDmGBi4yH1WGcJRUVZwBVNQUA3Wo1k8/0q5+feHcHPIzHQrFUt92mCJJvEVpZozBFnicOY+hDrd4ZNSW0TWv3K8gOvaA5INoXOsCslBc6b9EGJc5VSnUzSDnwAILDrrFkrZ3BJYw6D/Q0yxgu+OEg5xllCUVkBe7YdmFiq79m4iSd/LWz82E00tbzv0qxl8AcAautO88XVW7NN4xDRxCEiQ4EnAB/wgqo+XGN/e+BFoIVbZ5yqzhWRs4GHAT9QBtypqh+4xywE2gBVk1YPUdUfI9kOYzzni4Xko5wlFPsqoWRb8AcAAh8QKPgaihc5+2pLNAktDpJYapQlpjlXX6ZRi1jiEBEf8DRwNpAHLBWROaoaOOTpfTjTvz4rIp2BuUAmUAD8QlW3ikhXnKliA+9qjlTV8Kf0M6apiPE5774ktw6t/r5K5yplv3syNZNNARSuh82LnXLdF/xcCc1rJJY67tNYomlwInnFkQ2sU9UNACIyE7gQCEwcCqS6682BrQCquiygzhogQUTiVbU0gvEa03TF+H66cgjFvn1Ooqm+PxPkybOSAtj+DeQtdRNNZfBzxafWSCYHuU+TmO48IWc8FcnE0RbYHLCdB/SrUedBYL6I3AokAWcFOc8lwLIaSWOKiFQCrwN/1KYwcbox0SQmxr2SSIPWJ9Vdf98+50mymomluDDgpc0C2LEJtuQ6iWZfRfBz+VMCkkmw+zQ1yuKa1W/bTUQTR7BxHGr+gh8BTFXVv4lIf2C6iHRVda6BRaQL8BdgSMAxI1V1i4ik4CSOq4FpB3y4yFhgLED79u0PuzHGmMMQE+O+z9IKOLHu+qpuoqn5AECNZLMzD75b7uzbVx78XP7kGqMC1HGfxp9Yr01vjCKZOPKAdgHbGbhdUQHGAEMBVHWRiCQA6cCPIpIBzAZGqer6qgNUdYv7c7eIvITTJXZA4lDVicBEgKysLLsiMaYhEfcx42YtgZ/VXV/VeQnzgAcACvYv273VeZempAAqy4KfKy4xSIKpeZ8moMyfVK9NbwgimTiWAh1FpAOwBbgCuLJGnU3AYGCqiHQCEoB8EWkBvAXco6r/raosIrFAC1UtEJE44HzgvQi2wRjTEIhAsxbOknZC3fVVncnBgj0AELhe9AP8sMZZr6zlFmtssyA3/Wvepwko8yc3+IE1I5Y4VLVCRG7BeSLKB0xW1TUi8hCQo6pzgDuA50XkdpxurNGqqu5xPwPuF5H73VMOAYqBeW7S8OEkjecj1QZjTCMlAgmpzhJqoikrOvioAFVXOflfOj8r9gY/V2xCjZv+NZJNzfs08SlRl2gi+h6Hqs7FecQ2sGx8wPrnwKlBjvsj8MdaTtunPmM0xpg6iTi/wONToFWHuuurQllxLS9q1igr+NpZLy8Jfi6f/6fRmUO5TxOfGvFEY2+OG2NMfROB+GRnaZkZ2jFlxUESS5D3aQrXOfvLi4Ofx+d3kkxVMrliRr3fh7HEYYwx0cCf5CwtjwutfvmeukdvLil07sHUM0scxhjTEMU1gxbtnOUIsxlmjDHGhMUShzHGmLBY4jDGGBMWSxzGGGPCYonDGGNMWCxxGGOMCYslDmOMMWGxxGGMMSYs0hTmQBKRfOBbr+M4iHSc6XIbA2tL9Gks7QBry5F2nKoeMP9wk0gc0U5EclQ1y+s46oO1Jfo0lnaAtSVaWFeVMcaYsFjiMMYYExZLHNFhotcB1CNrS/RpLO0Aa0tUsHscxhhjwmJXHMYYY8JiieMIEJF2IrJARL4QkTUi8lu3vJWIvCsiX7s/W7rlIiJPisg6EVkpIr29bcH+RMQnIstE5N/udgcRWey24xUR8bvl8e72Ond/ppdx1yQiLUTkNRH50v1u+jfg7+R29+/WahF5WUQSGsr3IiKTReRHEVkdUBb29yAi17j1vxaRa6KkHX91/36tFJHZItIiYN89bjvWisg5AeVD3bJ1IjLuSLcjJKpqS4QXoA3Q211PAb4COgOPAOPc8nHAX9z1YcDbgACnAIu9bkON9vwP8BLwb3f7VeAKd30CcJO7fjMwwV2/AnjF69hrtONF4Ffuuh9o0RC/E6At8A3QLOD7GN1QvhfgdKA3sDqgLKzvAWgFbHB/tnTXW0ZBO4YAse76XwLa0RlYAcQDHYD1gM9d1gPHu38nVwCdvf47dkBbvQ6gKS7Am8DZwFqgjVvWBljrrj8HjAioX13P6wXIAN4HzgT+7f4DLgj4x9EfmOeuzwP6u+uxbj3xug1uPKnuL1upUd4Qv5O2wGb3l2as+72c05C+FyCzxi/csL4HYATwXED5fvW8akeNfRcDM9z1e4B7AvbNc7+j6u8pWL1oWayr6ghzuwV6AYuBo1X1OwD351FutapfBFXy3LJo8HfgLmCfu50G7FDVCnc7MNbqdrj7d7r1o8HxQD4wxe12e0FEkmiA34mqbgEeBTYB3+H8OefSML+XKuF+D1H7/QS4DudqCRp2OyxxHEkikgy8DtymqrsOVjVImeePv4nI+cCPqpobWBykqoawz2uxON0Kz6pqL6AYp0ukNlHbFrf//0KcLo9jgSTg3CBVG8L3UpfaYo/qNonIvUAFMKOqKEi1qG9HFUscR4iIxOEkjRmq+oZb/IOItHH3twF+dMvzgMAZ6DOArUcq1oM4FbhARDYCM3G6q/4OtBCRWLdOYKzV7XD3Nwe2HcmADyIPyFPVxe72aziJpKF9JwBnAd+oar6qlgNvAD+nYX4vVcL9HqL2+3Fv1J8PjFS3/4kG2I5AljiOABERYBLwhao+FrBrDlD19Mc1OPc+qspHuU+QnALsrLps95Kq3qOqGaqaiXNT9QNVHQksAC51q9VsR1X7LnXrR8X/nlT1e2CziJzkFg0GPqeBfSeuTcApIpLo/l2rakuD+14ChPs9zAOGiEhL9wpsiFvmKREZCtwNXKCqJQG75gBXuE+4dQA6AkuApUBH94k4P86/szlHOu46eX2TpSkswGk4l5srgeXuMgynX/l94Gv3Zyu3vgBP4zxdsQrI8roNQdo0iJ+eqjoe5y/9OmAWEO+WJ7jb69z9x3sdd4029ARy3O/lnzhP4zTI7wT4A/AlsBqYjvO0ToP4XoCXce7NlOP8j3vMoXwPOPcQ1rnLtVHSjnU49yyq/t1PCKh/r9uOtcC5AeXDcJ68XA/c6/XfrWCLvTlujDEmLNZVZYwxJiyWOIwxxoTFEocxxpiwWOIwxhgTFkscxhhjwmKJwxhjTFgscRgTISLSU0SGBWxfUF/DZIvIbSKSWB/nMiZc9h6HMREiIqNxXlC7JQLn3uieuyCMY3yqWlnfsZimx644TJMnIpnuRE7Pu5MhzReRZrXUPUFE3hGRXBH5j4ic7JYPdydRWiEiH7nDRTwEXC4iy0XkchEZLSJPufWnisiz4kzwtUFEBroTAX0hIlMDPu9ZEclx4/qDW/YbnMEMF4jIArdshIiscmP4S8DxRSLykIgsBvqLyMMi8rk7sdCjkfkTNY2e16+u22KL1wvOHAoVQE93+1Xgqlrqvg90dNf74YzzBM7wF23d9Rbuz9HAUwHHVm8DU3EGihSckW13Ad1w/jOXGxBL1VAbPmAh0N3d3giku+vH4oxX1Rpn1N8PgIvcfQpcVnUunOEtJDBOW2wJd7ErDmMc36jqcnc9FyeZ7McdFv/nwCwRWY4zWVAbd/d/gakicj3OL/lQ/EtVFSfp/KCqq1R1H7Am4PMvE5HPgGVAF5yZ42rqCyxUZ3TcqqG7T3f3VeKMygxOctoLvCAivwRKDjiTMSGIrbuKMU1CacB6JRCsqyoGZ3KknjV3qOqNItIPOA9YLiIH1DnIZ+6r8fn7gFh31NTfAX1VdbvbhZUQ5DzB5nCoslfd+xqqWiEi2Tij514B3IIzNL4xYbErDmNCpM7kW9+IyHBwhssXkR7u+gmqulhVx+NMxdoO2I0zx/yhSsWZYGqniBzN/pMzBZ57MTBQRNJFxIczjeqHNU/mXjE1V9W5wG04owMbEza74jAmPCOBZ0XkPiAO5z7FCuCvItIR53//77tlm4BxbrfW/4b7Qaq6QkSW4XRdbcDpDqsyEXhbRL5T1TNE5B6c+TcEmKuqbx54RlKAN0Ukwa13e7gxGQP2OK4xxpgwWVeVMcaYsFhXlTFBiMjTOHOsB3pCVad4EY8x0cS6qowxxoTFuqqMMcaExRKHMcaYsFjiMMYYExZLHMYYY8JiicMYY0xY/j/ZSTkHVHO1FQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axhline(y=0.8425,color='r')\n",
    "plt.axvline(x=100,color='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal n_estimators=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  60 | elapsed:   14.4s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   17.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_features': range(2, 26, 2)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': range(2, 26, 2)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=2,class_weight='balanced',random_state=100) #we put class_weight='balanced' to deal with Data Imbalance present in the dataset\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features=22,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with max_features\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axhline(y=0.926,color='r')\n",
    "plt.axvline(x=22,color='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal max_features=22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    7.5s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    9.4s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_split': range(100, 500, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(100,500,50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=2,class_weight='balanced',random_state=100) #we put class_weight='balanced' to deal with Data Imbalance present in the dataset\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=100,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with min_samples_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axhline(y=0.8425,color='r')\n",
    "plt.axvline(x=100,color='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal min_samples_split=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    7.7s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    9.1s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': range(100, 500, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100,500,50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=2,class_weight='balanced',random_state=100) #we put class_weight='balanced' to deal with Data Imbalance present in the dataset\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=450, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axhline(y=0.873,color='r')\n",
    "plt.axvline(x=450,color='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal min_samples_leaf=450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'min_samples_leaf': [100,200,300,450],\n",
    "    'min_samples_split': [100,200,300],\n",
    "    'n_estimators': [100,200], \n",
    "    'max_features': [5,10,15,20,22]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\",random_state=100)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,scoring='recall',\n",
    "                          cv = 3, n_jobs = -1,verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'max_features': [5, 10, 15, 20, 22],\n",
       "                         'min_samples_leaf': [100, 200, 300, 450],\n",
       "                         'min_samples_split': [100, 200, 300],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get best recall of 0.928769985151421 using {'max_depth': 4, 'max_features': 22, 'min_samples_leaf': 300, 'min_samples_split': 100, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal recall score and hyperparameters\n",
    "print('We can get best recall of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=4, max_features=22,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=300, min_samples_split=100,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_nopca=RandomForestClassifier(max_depth=4,max_features=22,n_estimators=200,min_samples_split=100,min_samples_leaf=300,random_state=100,class_weight='balanced')\n",
    "rf_nopca.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train 0.8949475583624675\n",
      "Recall of Train 0.9542372881355933\n",
      "Accuracy of Test 0.11248519931587948\n",
      "Recall of Test 0.9881422924901185\n"
     ]
    }
   ],
   "source": [
    "#Training Set\n",
    "print(\"Accuracy of Train \"+str(metrics.accuracy_score(y_train,rf_nopca.predict(X_train))))\n",
    "print(\"Recall of Train \"+str(metrics.recall_score(y_train,rf_nopca.predict(X_train))))\n",
    "\n",
    "#Test Set\n",
    "print(\"Accuracy of Test \"+str(metrics.accuracy_score(y_test,rf_nopca.predict(X_test))))\n",
    "print(\"Recall of Test \"+str(metrics.recall_score(y_test,rf_nopca.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression without PCA with sampling</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.871596</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.18647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest without PCA without sampling</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.954237</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.234681</td>\n",
       "      <td>0.03575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Training Accuracy  \\\n",
       "Logistic Regression without PCA with sampling           0.864997   \n",
       "Random Forest without PCA without sampling              0.894948   \n",
       "\n",
       "                                               Test Accuracy  Training Recall  \\\n",
       "Logistic Regression without PCA with sampling       0.871596         0.864501   \n",
       "Random Forest without PCA without sampling          0.112485         0.954237   \n",
       "\n",
       "                                               Test Recall  \\\n",
       "Logistic Regression without PCA with sampling     0.849802   \n",
       "Random Forest without PCA without sampling        0.988142   \n",
       "\n",
       "                                               Training Precision  \\\n",
       "Logistic Regression without PCA with sampling            0.865359   \n",
       "Random Forest without PCA without sampling               0.234681   \n",
       "\n",
       "                                               Test Precision  \n",
       "Logistic Regression without PCA with sampling         0.18647  \n",
       "Random Forest without PCA without sampling            0.03575  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics.loc['Random Forest without PCA without sampling','Training Accuracy']=metrics.accuracy_score(y_train,rf_nopca.predict(X_train))\n",
    "model_metrics.loc['Random Forest without PCA without sampling','Test Accuracy']=metrics.accuracy_score(y_test,rf_nopca.predict(X_test))\n",
    "model_metrics.loc['Random Forest without PCA without sampling','Training Recall']=metrics.recall_score(y_train,rf_nopca.predict(X_train))\n",
    "model_metrics.loc['Random Forest without PCA without sampling','Test Recall']=metrics.recall_score(y_test,rf_nopca.predict(X_test))\n",
    "model_metrics.loc['Random Forest without PCA without sampling','Training Precision']=metrics.precision_score(y_train,rf_nopca.predict(X_train))\n",
    "model_metrics.loc['Random Forest without PCA without sampling','Test Precision']=metrics.precision_score(y_test,rf_nopca.predict(X_test))\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the Test Accuracy decreases here. Thus, we cannot use this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8        0\n",
       "16       0\n",
       "17       0\n",
       "21       0\n",
       "33       0\n",
       "        ..\n",
       "99965    0\n",
       "99970    0\n",
       "99974    0\n",
       "99986    0\n",
       "99988    0\n",
       "Name: Churn, Length: 25335, dtype: int32"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a copy of the original dataframe\n",
    "pcdf=fdf.copy()\n",
    "pcdf.pop('Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25335, 129)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25335 entries, 8 to 99988\n",
      "Data columns (total 129 columns):\n",
      "arpu_6                float64\n",
      "arpu_7                float64\n",
      "arpu_8                float64\n",
      "onnet_mou_6           float64\n",
      "onnet_mou_7           float64\n",
      "onnet_mou_8           float64\n",
      "offnet_mou_6          float64\n",
      "offnet_mou_7          float64\n",
      "offnet_mou_8          float64\n",
      "roam_ic_mou_6         float64\n",
      "roam_ic_mou_7         float64\n",
      "roam_ic_mou_8         float64\n",
      "roam_og_mou_6         float64\n",
      "roam_og_mou_7         float64\n",
      "roam_og_mou_8         float64\n",
      "loc_og_t2t_mou_6      float64\n",
      "loc_og_t2t_mou_7      float64\n",
      "loc_og_t2t_mou_8      float64\n",
      "loc_og_t2m_mou_6      float64\n",
      "loc_og_t2m_mou_7      float64\n",
      "loc_og_t2m_mou_8      float64\n",
      "loc_og_t2f_mou_6      float64\n",
      "loc_og_t2f_mou_7      float64\n",
      "loc_og_t2f_mou_8      float64\n",
      "loc_og_t2c_mou_6      float64\n",
      "loc_og_t2c_mou_7      float64\n",
      "loc_og_t2c_mou_8      float64\n",
      "loc_og_mou_6          float64\n",
      "loc_og_mou_7          float64\n",
      "loc_og_mou_8          float64\n",
      "std_og_t2t_mou_6      float64\n",
      "std_og_t2t_mou_7      float64\n",
      "std_og_t2t_mou_8      float64\n",
      "std_og_t2m_mou_6      float64\n",
      "std_og_t2m_mou_7      float64\n",
      "std_og_t2m_mou_8      float64\n",
      "std_og_t2f_mou_6      float64\n",
      "std_og_t2f_mou_7      float64\n",
      "std_og_t2f_mou_8      float64\n",
      "std_og_mou_6          float64\n",
      "std_og_mou_7          float64\n",
      "std_og_mou_8          float64\n",
      "isd_og_mou_6          float64\n",
      "isd_og_mou_7          float64\n",
      "isd_og_mou_8          float64\n",
      "spl_og_mou_6          float64\n",
      "spl_og_mou_7          float64\n",
      "spl_og_mou_8          float64\n",
      "og_others_6           float64\n",
      "og_others_7           float64\n",
      "og_others_8           float64\n",
      "total_og_mou_6        float64\n",
      "total_og_mou_7        float64\n",
      "total_og_mou_8        float64\n",
      "loc_ic_t2t_mou_6      float64\n",
      "loc_ic_t2t_mou_7      float64\n",
      "loc_ic_t2t_mou_8      float64\n",
      "loc_ic_t2m_mou_6      float64\n",
      "loc_ic_t2m_mou_7      float64\n",
      "loc_ic_t2m_mou_8      float64\n",
      "loc_ic_t2f_mou_6      float64\n",
      "loc_ic_t2f_mou_7      float64\n",
      "loc_ic_t2f_mou_8      float64\n",
      "loc_ic_mou_6          float64\n",
      "loc_ic_mou_7          float64\n",
      "loc_ic_mou_8          float64\n",
      "std_ic_t2t_mou_6      float64\n",
      "std_ic_t2t_mou_7      float64\n",
      "std_ic_t2t_mou_8      float64\n",
      "std_ic_t2m_mou_6      float64\n",
      "std_ic_t2m_mou_7      float64\n",
      "std_ic_t2m_mou_8      float64\n",
      "std_ic_t2f_mou_6      float64\n",
      "std_ic_t2f_mou_7      float64\n",
      "std_ic_t2f_mou_8      float64\n",
      "std_ic_mou_6          float64\n",
      "std_ic_mou_7          float64\n",
      "std_ic_mou_8          float64\n",
      "total_ic_mou_6        float64\n",
      "total_ic_mou_7        float64\n",
      "total_ic_mou_8        float64\n",
      "spl_ic_mou_6          float64\n",
      "spl_ic_mou_7          float64\n",
      "spl_ic_mou_8          float64\n",
      "isd_ic_mou_6          float64\n",
      "isd_ic_mou_7          float64\n",
      "isd_ic_mou_8          float64\n",
      "ic_others_6           float64\n",
      "ic_others_7           float64\n",
      "ic_others_8           float64\n",
      "total_rech_num_6      float64\n",
      "total_rech_num_7      float64\n",
      "total_rech_num_8      float64\n",
      "total_rech_amt_6      float64\n",
      "total_rech_amt_7      float64\n",
      "total_rech_amt_8      float64\n",
      "max_rech_amt_6        float64\n",
      "max_rech_amt_7        float64\n",
      "max_rech_amt_8        float64\n",
      "last_day_rch_amt_6    float64\n",
      "last_day_rch_amt_7    float64\n",
      "last_day_rch_amt_8    float64\n",
      "vol_2g_mb_6           float64\n",
      "vol_2g_mb_7           float64\n",
      "vol_2g_mb_8           float64\n",
      "vol_3g_mb_6           float64\n",
      "vol_3g_mb_7           float64\n",
      "vol_3g_mb_8           float64\n",
      "monthly_2g_6          float64\n",
      "monthly_2g_7          float64\n",
      "monthly_2g_8          float64\n",
      "sachet_2g_6           float64\n",
      "sachet_2g_7           float64\n",
      "sachet_2g_8           float64\n",
      "monthly_3g_6          float64\n",
      "monthly_3g_7          float64\n",
      "monthly_3g_8          float64\n",
      "sachet_3g_6           float64\n",
      "sachet_3g_7           float64\n",
      "sachet_3g_8           float64\n",
      "aon                   float64\n",
      "aug_vbc_3g            float64\n",
      "jul_vbc_3g            float64\n",
      "jun_vbc_3g            float64\n",
      "sep_vbc_3g            float64\n",
      "average_rech_amt_g    float64\n",
      "Recency_6             float64\n",
      "Recency_7             float64\n",
      "Recency_8             float64\n",
      "dtypes: float64(129)\n",
      "memory usage: 25.1 MB\n"
     ]
    }
   ],
   "source": [
    "pcdf.info(verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we observe that all the columns are numerical and we do not need to create dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x=scaler.fit_transform(pcdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying PCA on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing PCA function\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=50,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting on pca\n",
    "pca.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumsum=np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x26f33cd8d08>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,len(var_cumsum)+1), var_cumsum)\n",
    "plt.axhline(y=0.95,color='r')\n",
    "plt.axvline(x=70,color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we are able to explain 95% variance with 70 columns. Thus, we reduced the dimensionality by 59 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the new data after PCA with 70 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2=PCA(n_components=70,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=pca2.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25335, 70)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=[(\"PC\"+\"_\"+str(i)) for i in range(1,71)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>PC_7</th>\n",
       "      <th>PC_8</th>\n",
       "      <th>PC_9</th>\n",
       "      <th>PC_10</th>\n",
       "      <th>PC_11</th>\n",
       "      <th>PC_12</th>\n",
       "      <th>PC_13</th>\n",
       "      <th>PC_14</th>\n",
       "      <th>PC_15</th>\n",
       "      <th>PC_16</th>\n",
       "      <th>PC_17</th>\n",
       "      <th>PC_18</th>\n",
       "      <th>PC_19</th>\n",
       "      <th>PC_20</th>\n",
       "      <th>PC_21</th>\n",
       "      <th>PC_22</th>\n",
       "      <th>PC_23</th>\n",
       "      <th>PC_24</th>\n",
       "      <th>PC_25</th>\n",
       "      <th>PC_26</th>\n",
       "      <th>PC_27</th>\n",
       "      <th>PC_28</th>\n",
       "      <th>PC_29</th>\n",
       "      <th>PC_30</th>\n",
       "      <th>PC_31</th>\n",
       "      <th>PC_32</th>\n",
       "      <th>PC_33</th>\n",
       "      <th>PC_34</th>\n",
       "      <th>PC_35</th>\n",
       "      <th>PC_36</th>\n",
       "      <th>PC_37</th>\n",
       "      <th>PC_38</th>\n",
       "      <th>PC_39</th>\n",
       "      <th>PC_40</th>\n",
       "      <th>PC_41</th>\n",
       "      <th>PC_42</th>\n",
       "      <th>PC_43</th>\n",
       "      <th>PC_44</th>\n",
       "      <th>PC_45</th>\n",
       "      <th>PC_46</th>\n",
       "      <th>PC_47</th>\n",
       "      <th>PC_48</th>\n",
       "      <th>PC_49</th>\n",
       "      <th>PC_50</th>\n",
       "      <th>PC_51</th>\n",
       "      <th>PC_52</th>\n",
       "      <th>PC_53</th>\n",
       "      <th>PC_54</th>\n",
       "      <th>PC_55</th>\n",
       "      <th>PC_56</th>\n",
       "      <th>PC_57</th>\n",
       "      <th>PC_58</th>\n",
       "      <th>PC_59</th>\n",
       "      <th>PC_60</th>\n",
       "      <th>PC_61</th>\n",
       "      <th>PC_62</th>\n",
       "      <th>PC_63</th>\n",
       "      <th>PC_64</th>\n",
       "      <th>PC_65</th>\n",
       "      <th>PC_66</th>\n",
       "      <th>PC_67</th>\n",
       "      <th>PC_68</th>\n",
       "      <th>PC_69</th>\n",
       "      <th>PC_70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-3.302524</td>\n",
       "      <td>-2.047346</td>\n",
       "      <td>-0.792873</td>\n",
       "      <td>-1.463941</td>\n",
       "      <td>1.437729</td>\n",
       "      <td>0.429305</td>\n",
       "      <td>0.291593</td>\n",
       "      <td>0.039070</td>\n",
       "      <td>-0.344564</td>\n",
       "      <td>-0.477755</td>\n",
       "      <td>1.497306</td>\n",
       "      <td>0.583250</td>\n",
       "      <td>-0.501002</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>-0.227516</td>\n",
       "      <td>-0.116628</td>\n",
       "      <td>1.361494</td>\n",
       "      <td>-0.067306</td>\n",
       "      <td>-0.714113</td>\n",
       "      <td>0.660802</td>\n",
       "      <td>-0.568835</td>\n",
       "      <td>-0.221683</td>\n",
       "      <td>0.723890</td>\n",
       "      <td>-0.365080</td>\n",
       "      <td>0.367657</td>\n",
       "      <td>-0.120647</td>\n",
       "      <td>0.326636</td>\n",
       "      <td>1.212525</td>\n",
       "      <td>0.096936</td>\n",
       "      <td>-0.626133</td>\n",
       "      <td>-0.267525</td>\n",
       "      <td>-0.758820</td>\n",
       "      <td>1.055533</td>\n",
       "      <td>-0.541310</td>\n",
       "      <td>0.597650</td>\n",
       "      <td>-0.294169</td>\n",
       "      <td>-0.324569</td>\n",
       "      <td>0.734055</td>\n",
       "      <td>0.102867</td>\n",
       "      <td>-0.387977</td>\n",
       "      <td>-0.517437</td>\n",
       "      <td>-0.289151</td>\n",
       "      <td>1.406778</td>\n",
       "      <td>-0.597128</td>\n",
       "      <td>-0.258430</td>\n",
       "      <td>0.203102</td>\n",
       "      <td>-0.614115</td>\n",
       "      <td>0.582464</td>\n",
       "      <td>0.250351</td>\n",
       "      <td>-0.151800</td>\n",
       "      <td>0.344645</td>\n",
       "      <td>0.355169</td>\n",
       "      <td>-0.289252</td>\n",
       "      <td>2.612237</td>\n",
       "      <td>-0.133919</td>\n",
       "      <td>-0.084890</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>-0.662775</td>\n",
       "      <td>0.383637</td>\n",
       "      <td>0.045519</td>\n",
       "      <td>0.781561</td>\n",
       "      <td>-0.191357</td>\n",
       "      <td>-0.570332</td>\n",
       "      <td>0.185316</td>\n",
       "      <td>-0.254488</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.364053</td>\n",
       "      <td>-0.082144</td>\n",
       "      <td>-0.146273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.782748</td>\n",
       "      <td>-2.534450</td>\n",
       "      <td>-0.861802</td>\n",
       "      <td>2.736280</td>\n",
       "      <td>-0.260174</td>\n",
       "      <td>0.423037</td>\n",
       "      <td>0.420540</td>\n",
       "      <td>-1.091213</td>\n",
       "      <td>1.057371</td>\n",
       "      <td>-0.078111</td>\n",
       "      <td>0.491298</td>\n",
       "      <td>-0.382676</td>\n",
       "      <td>-0.624343</td>\n",
       "      <td>-1.333879</td>\n",
       "      <td>0.591627</td>\n",
       "      <td>-0.161664</td>\n",
       "      <td>0.139258</td>\n",
       "      <td>0.330781</td>\n",
       "      <td>-0.886692</td>\n",
       "      <td>0.292967</td>\n",
       "      <td>-0.172457</td>\n",
       "      <td>0.947384</td>\n",
       "      <td>-0.280141</td>\n",
       "      <td>-0.212093</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>-0.145981</td>\n",
       "      <td>0.209523</td>\n",
       "      <td>-0.004105</td>\n",
       "      <td>0.099894</td>\n",
       "      <td>0.614578</td>\n",
       "      <td>-0.518381</td>\n",
       "      <td>0.354663</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>-0.608414</td>\n",
       "      <td>0.095193</td>\n",
       "      <td>-1.715515</td>\n",
       "      <td>0.241093</td>\n",
       "      <td>-1.310035</td>\n",
       "      <td>-0.143083</td>\n",
       "      <td>0.490977</td>\n",
       "      <td>0.714952</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.539872</td>\n",
       "      <td>-0.415701</td>\n",
       "      <td>0.183875</td>\n",
       "      <td>0.286894</td>\n",
       "      <td>0.217710</td>\n",
       "      <td>-0.537288</td>\n",
       "      <td>0.836479</td>\n",
       "      <td>0.490919</td>\n",
       "      <td>-0.427198</td>\n",
       "      <td>-0.264927</td>\n",
       "      <td>-0.357435</td>\n",
       "      <td>-0.211409</td>\n",
       "      <td>-0.254766</td>\n",
       "      <td>-0.311702</td>\n",
       "      <td>0.765596</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>-0.081272</td>\n",
       "      <td>0.692344</td>\n",
       "      <td>0.446406</td>\n",
       "      <td>-0.051950</td>\n",
       "      <td>0.351461</td>\n",
       "      <td>0.134506</td>\n",
       "      <td>0.132254</td>\n",
       "      <td>0.163996</td>\n",
       "      <td>0.753221</td>\n",
       "      <td>0.826014</td>\n",
       "      <td>0.613957</td>\n",
       "      <td>-0.908908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-5.052647</td>\n",
       "      <td>-1.940768</td>\n",
       "      <td>-1.578072</td>\n",
       "      <td>0.061570</td>\n",
       "      <td>-0.584338</td>\n",
       "      <td>1.460674</td>\n",
       "      <td>0.147229</td>\n",
       "      <td>-0.153382</td>\n",
       "      <td>2.752557</td>\n",
       "      <td>-2.179398</td>\n",
       "      <td>-0.140038</td>\n",
       "      <td>0.156622</td>\n",
       "      <td>-1.074593</td>\n",
       "      <td>0.223191</td>\n",
       "      <td>-0.344492</td>\n",
       "      <td>-0.088704</td>\n",
       "      <td>0.491057</td>\n",
       "      <td>0.097275</td>\n",
       "      <td>1.325039</td>\n",
       "      <td>-0.100042</td>\n",
       "      <td>-0.341067</td>\n",
       "      <td>-0.063430</td>\n",
       "      <td>-0.532083</td>\n",
       "      <td>-0.054955</td>\n",
       "      <td>-0.133498</td>\n",
       "      <td>-0.437718</td>\n",
       "      <td>-0.390968</td>\n",
       "      <td>0.489184</td>\n",
       "      <td>0.256840</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.131282</td>\n",
       "      <td>0.424301</td>\n",
       "      <td>-0.045085</td>\n",
       "      <td>0.369237</td>\n",
       "      <td>-0.670030</td>\n",
       "      <td>-0.440074</td>\n",
       "      <td>-0.943911</td>\n",
       "      <td>-0.259794</td>\n",
       "      <td>1.103741</td>\n",
       "      <td>0.141470</td>\n",
       "      <td>0.145396</td>\n",
       "      <td>0.830468</td>\n",
       "      <td>0.694980</td>\n",
       "      <td>-0.067395</td>\n",
       "      <td>0.598033</td>\n",
       "      <td>1.162282</td>\n",
       "      <td>-1.073347</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.865121</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>0.018040</td>\n",
       "      <td>-0.359873</td>\n",
       "      <td>-0.167055</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.195374</td>\n",
       "      <td>0.492098</td>\n",
       "      <td>0.111935</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>-0.353744</td>\n",
       "      <td>-0.276584</td>\n",
       "      <td>-0.324027</td>\n",
       "      <td>0.123418</td>\n",
       "      <td>0.151478</td>\n",
       "      <td>0.256939</td>\n",
       "      <td>0.264427</td>\n",
       "      <td>-0.098836</td>\n",
       "      <td>-0.061520</td>\n",
       "      <td>-0.424417</td>\n",
       "      <td>0.020047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-2.784637</td>\n",
       "      <td>2.900961</td>\n",
       "      <td>-0.823700</td>\n",
       "      <td>1.101149</td>\n",
       "      <td>0.701504</td>\n",
       "      <td>-3.230526</td>\n",
       "      <td>-0.275074</td>\n",
       "      <td>-1.170111</td>\n",
       "      <td>0.216613</td>\n",
       "      <td>1.202857</td>\n",
       "      <td>0.302535</td>\n",
       "      <td>-0.476057</td>\n",
       "      <td>-1.066236</td>\n",
       "      <td>0.943876</td>\n",
       "      <td>0.349864</td>\n",
       "      <td>-0.501896</td>\n",
       "      <td>1.481387</td>\n",
       "      <td>0.146149</td>\n",
       "      <td>0.485364</td>\n",
       "      <td>-0.059674</td>\n",
       "      <td>-0.352642</td>\n",
       "      <td>-0.357602</td>\n",
       "      <td>-0.345634</td>\n",
       "      <td>0.580044</td>\n",
       "      <td>0.356632</td>\n",
       "      <td>-0.168434</td>\n",
       "      <td>0.271265</td>\n",
       "      <td>-0.214971</td>\n",
       "      <td>-0.198324</td>\n",
       "      <td>0.318257</td>\n",
       "      <td>-0.111851</td>\n",
       "      <td>-0.644729</td>\n",
       "      <td>0.215988</td>\n",
       "      <td>0.200107</td>\n",
       "      <td>0.319363</td>\n",
       "      <td>-0.704563</td>\n",
       "      <td>-0.017269</td>\n",
       "      <td>0.259530</td>\n",
       "      <td>0.374380</td>\n",
       "      <td>-0.143889</td>\n",
       "      <td>-0.276478</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.229743</td>\n",
       "      <td>0.105728</td>\n",
       "      <td>-0.046585</td>\n",
       "      <td>0.275464</td>\n",
       "      <td>-0.071035</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>0.414334</td>\n",
       "      <td>-0.146727</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>0.464096</td>\n",
       "      <td>0.146666</td>\n",
       "      <td>0.164728</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>-0.597471</td>\n",
       "      <td>-0.216833</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.082375</td>\n",
       "      <td>-0.066439</td>\n",
       "      <td>0.378327</td>\n",
       "      <td>-0.208878</td>\n",
       "      <td>-0.188453</td>\n",
       "      <td>0.075635</td>\n",
       "      <td>-0.044944</td>\n",
       "      <td>0.248019</td>\n",
       "      <td>0.208884</td>\n",
       "      <td>0.088565</td>\n",
       "      <td>-0.017294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.477498</td>\n",
       "      <td>-3.014318</td>\n",
       "      <td>12.834200</td>\n",
       "      <td>-7.785206</td>\n",
       "      <td>2.082295</td>\n",
       "      <td>0.680095</td>\n",
       "      <td>-1.048387</td>\n",
       "      <td>-2.383967</td>\n",
       "      <td>3.081192</td>\n",
       "      <td>0.781266</td>\n",
       "      <td>0.638335</td>\n",
       "      <td>-3.023950</td>\n",
       "      <td>-0.489423</td>\n",
       "      <td>1.031153</td>\n",
       "      <td>0.385071</td>\n",
       "      <td>0.186131</td>\n",
       "      <td>-1.020070</td>\n",
       "      <td>1.261522</td>\n",
       "      <td>-3.554594</td>\n",
       "      <td>0.150767</td>\n",
       "      <td>0.782603</td>\n",
       "      <td>-0.396112</td>\n",
       "      <td>-1.485565</td>\n",
       "      <td>-0.156879</td>\n",
       "      <td>0.655269</td>\n",
       "      <td>-0.202192</td>\n",
       "      <td>0.598208</td>\n",
       "      <td>-0.487277</td>\n",
       "      <td>-0.961132</td>\n",
       "      <td>-2.008463</td>\n",
       "      <td>-0.370932</td>\n",
       "      <td>-0.107970</td>\n",
       "      <td>0.871146</td>\n",
       "      <td>-0.064890</td>\n",
       "      <td>1.200858</td>\n",
       "      <td>-1.314702</td>\n",
       "      <td>0.189318</td>\n",
       "      <td>-2.082040</td>\n",
       "      <td>1.342594</td>\n",
       "      <td>1.336253</td>\n",
       "      <td>-0.582851</td>\n",
       "      <td>0.187623</td>\n",
       "      <td>-0.130036</td>\n",
       "      <td>-0.087401</td>\n",
       "      <td>-0.436013</td>\n",
       "      <td>-1.846490</td>\n",
       "      <td>-1.068223</td>\n",
       "      <td>1.712436</td>\n",
       "      <td>-1.313066</td>\n",
       "      <td>0.087369</td>\n",
       "      <td>0.923352</td>\n",
       "      <td>0.931984</td>\n",
       "      <td>-0.619932</td>\n",
       "      <td>1.574414</td>\n",
       "      <td>3.452214</td>\n",
       "      <td>0.260408</td>\n",
       "      <td>0.224318</td>\n",
       "      <td>-0.785947</td>\n",
       "      <td>-1.156028</td>\n",
       "      <td>-0.342211</td>\n",
       "      <td>0.272678</td>\n",
       "      <td>-0.494230</td>\n",
       "      <td>-0.921919</td>\n",
       "      <td>-1.177072</td>\n",
       "      <td>-0.593474</td>\n",
       "      <td>-1.816937</td>\n",
       "      <td>3.080137</td>\n",
       "      <td>-1.575720</td>\n",
       "      <td>0.745876</td>\n",
       "      <td>-0.067303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PC_1      PC_2       PC_3      PC_4      PC_5      PC_6      PC_7  \\\n",
       "0 -3.302524 -2.047346  -0.792873 -1.463941  1.437729  0.429305  0.291593   \n",
       "1 -0.782748 -2.534450  -0.861802  2.736280 -0.260174  0.423037  0.420540   \n",
       "2 -5.052647 -1.940768  -1.578072  0.061570 -0.584338  1.460674  0.147229   \n",
       "3 -2.784637  2.900961  -0.823700  1.101149  0.701504 -3.230526 -0.275074   \n",
       "4  1.477498 -3.014318  12.834200 -7.785206  2.082295  0.680095 -1.048387   \n",
       "\n",
       "       PC_8      PC_9     PC_10     PC_11     PC_12     PC_13     PC_14  \\\n",
       "0  0.039070 -0.344564 -0.477755  1.497306  0.583250 -0.501002  0.022636   \n",
       "1 -1.091213  1.057371 -0.078111  0.491298 -0.382676 -0.624343 -1.333879   \n",
       "2 -0.153382  2.752557 -2.179398 -0.140038  0.156622 -1.074593  0.223191   \n",
       "3 -1.170111  0.216613  1.202857  0.302535 -0.476057 -1.066236  0.943876   \n",
       "4 -2.383967  3.081192  0.781266  0.638335 -3.023950 -0.489423  1.031153   \n",
       "\n",
       "      PC_15     PC_16     PC_17     PC_18     PC_19     PC_20     PC_21  \\\n",
       "0 -0.227516 -0.116628  1.361494 -0.067306 -0.714113  0.660802 -0.568835   \n",
       "1  0.591627 -0.161664  0.139258  0.330781 -0.886692  0.292967 -0.172457   \n",
       "2 -0.344492 -0.088704  0.491057  0.097275  1.325039 -0.100042 -0.341067   \n",
       "3  0.349864 -0.501896  1.481387  0.146149  0.485364 -0.059674 -0.352642   \n",
       "4  0.385071  0.186131 -1.020070  1.261522 -3.554594  0.150767  0.782603   \n",
       "\n",
       "      PC_22     PC_23     PC_24     PC_25     PC_26     PC_27     PC_28  \\\n",
       "0 -0.221683  0.723890 -0.365080  0.367657 -0.120647  0.326636  1.212525   \n",
       "1  0.947384 -0.280141 -0.212093  0.045714 -0.145981  0.209523 -0.004105   \n",
       "2 -0.063430 -0.532083 -0.054955 -0.133498 -0.437718 -0.390968  0.489184   \n",
       "3 -0.357602 -0.345634  0.580044  0.356632 -0.168434  0.271265 -0.214971   \n",
       "4 -0.396112 -1.485565 -0.156879  0.655269 -0.202192  0.598208 -0.487277   \n",
       "\n",
       "      PC_29     PC_30     PC_31     PC_32     PC_33     PC_34     PC_35  \\\n",
       "0  0.096936 -0.626133 -0.267525 -0.758820  1.055533 -0.541310  0.597650   \n",
       "1  0.099894  0.614578 -0.518381  0.354663  0.255811 -0.608414  0.095193   \n",
       "2  0.256840  0.108471  0.131282  0.424301 -0.045085  0.369237 -0.670030   \n",
       "3 -0.198324  0.318257 -0.111851 -0.644729  0.215988  0.200107  0.319363   \n",
       "4 -0.961132 -2.008463 -0.370932 -0.107970  0.871146 -0.064890  1.200858   \n",
       "\n",
       "      PC_36     PC_37     PC_38     PC_39     PC_40     PC_41     PC_42  \\\n",
       "0 -0.294169 -0.324569  0.734055  0.102867 -0.387977 -0.517437 -0.289151   \n",
       "1 -1.715515  0.241093 -1.310035 -0.143083  0.490977  0.714952  0.968182   \n",
       "2 -0.440074 -0.943911 -0.259794  1.103741  0.141470  0.145396  0.830468   \n",
       "3 -0.704563 -0.017269  0.259530  0.374380 -0.143889 -0.276478  0.010400   \n",
       "4 -1.314702  0.189318 -2.082040  1.342594  1.336253 -0.582851  0.187623   \n",
       "\n",
       "      PC_43     PC_44     PC_45     PC_46     PC_47     PC_48     PC_49  \\\n",
       "0  1.406778 -0.597128 -0.258430  0.203102 -0.614115  0.582464  0.250351   \n",
       "1  0.539872 -0.415701  0.183875  0.286894  0.217710 -0.537288  0.836479   \n",
       "2  0.694980 -0.067395  0.598033  1.162282 -1.073347  0.818620  0.865121   \n",
       "3  0.229743  0.105728 -0.046585  0.275464 -0.071035  0.076804  0.414334   \n",
       "4 -0.130036 -0.087401 -0.436013 -1.846490 -1.068223  1.712436 -1.313066   \n",
       "\n",
       "      PC_50     PC_51     PC_52     PC_53     PC_54     PC_55     PC_56  \\\n",
       "0 -0.151800  0.344645  0.355169 -0.289252  2.612237 -0.133919 -0.084890   \n",
       "1  0.490919 -0.427198 -0.264927 -0.357435 -0.211409 -0.254766 -0.311702   \n",
       "2  0.133283  0.018040 -0.359873 -0.167055  0.001217  0.026600  0.195374   \n",
       "3 -0.146727  0.009272  0.095331  0.464096  0.146666  0.164728  0.078629   \n",
       "4  0.087369  0.923352  0.931984 -0.619932  1.574414  3.452214  0.260408   \n",
       "\n",
       "      PC_57     PC_58     PC_59     PC_60     PC_61     PC_62     PC_63  \\\n",
       "0  0.016425 -0.662775  0.383637  0.045519  0.781561 -0.191357 -0.570332   \n",
       "1  0.765596  0.008569 -0.081272  0.692344  0.446406 -0.051950  0.351461   \n",
       "2  0.492098  0.111935  0.011866 -0.353744 -0.276584 -0.324027  0.123418   \n",
       "3 -0.597471 -0.216833  0.005742  0.082375 -0.066439  0.378327 -0.208878   \n",
       "4  0.224318 -0.785947 -1.156028 -0.342211  0.272678 -0.494230 -0.921919   \n",
       "\n",
       "      PC_64     PC_65     PC_66     PC_67     PC_68     PC_69     PC_70  \n",
       "0  0.185316 -0.254488 -0.184632 -0.277023 -0.364053 -0.082144 -0.146273  \n",
       "1  0.134506  0.132254  0.163996  0.753221  0.826014  0.613957 -0.908908  \n",
       "2  0.151478  0.256939  0.264427 -0.098836 -0.061520 -0.424417  0.020047  \n",
       "3 -0.188453  0.075635 -0.044944  0.248019  0.208884  0.088565 -0.017294  \n",
       "4 -1.177072 -0.593474 -1.816937  3.080137 -1.575720  0.745876 -0.067303  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a dataframe for convenience \n",
    "md=pd.DataFrame(md,columns=col_names)\n",
    "md.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>PC_7</th>\n",
       "      <th>PC_8</th>\n",
       "      <th>PC_9</th>\n",
       "      <th>PC_10</th>\n",
       "      <th>PC_11</th>\n",
       "      <th>PC_12</th>\n",
       "      <th>PC_13</th>\n",
       "      <th>PC_14</th>\n",
       "      <th>PC_15</th>\n",
       "      <th>PC_16</th>\n",
       "      <th>PC_17</th>\n",
       "      <th>PC_18</th>\n",
       "      <th>PC_19</th>\n",
       "      <th>PC_20</th>\n",
       "      <th>PC_21</th>\n",
       "      <th>PC_22</th>\n",
       "      <th>PC_23</th>\n",
       "      <th>PC_24</th>\n",
       "      <th>PC_25</th>\n",
       "      <th>PC_26</th>\n",
       "      <th>PC_27</th>\n",
       "      <th>PC_28</th>\n",
       "      <th>PC_29</th>\n",
       "      <th>PC_30</th>\n",
       "      <th>PC_31</th>\n",
       "      <th>PC_32</th>\n",
       "      <th>PC_33</th>\n",
       "      <th>PC_34</th>\n",
       "      <th>PC_35</th>\n",
       "      <th>PC_36</th>\n",
       "      <th>PC_37</th>\n",
       "      <th>PC_38</th>\n",
       "      <th>PC_39</th>\n",
       "      <th>PC_40</th>\n",
       "      <th>PC_41</th>\n",
       "      <th>PC_42</th>\n",
       "      <th>PC_43</th>\n",
       "      <th>PC_44</th>\n",
       "      <th>PC_45</th>\n",
       "      <th>PC_46</th>\n",
       "      <th>PC_47</th>\n",
       "      <th>PC_48</th>\n",
       "      <th>PC_49</th>\n",
       "      <th>PC_50</th>\n",
       "      <th>PC_51</th>\n",
       "      <th>PC_52</th>\n",
       "      <th>PC_53</th>\n",
       "      <th>PC_54</th>\n",
       "      <th>PC_55</th>\n",
       "      <th>PC_56</th>\n",
       "      <th>PC_57</th>\n",
       "      <th>PC_58</th>\n",
       "      <th>PC_59</th>\n",
       "      <th>PC_60</th>\n",
       "      <th>PC_61</th>\n",
       "      <th>PC_62</th>\n",
       "      <th>PC_63</th>\n",
       "      <th>PC_64</th>\n",
       "      <th>PC_65</th>\n",
       "      <th>PC_66</th>\n",
       "      <th>PC_67</th>\n",
       "      <th>PC_68</th>\n",
       "      <th>PC_69</th>\n",
       "      <th>PC_70</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-3.302524</td>\n",
       "      <td>-2.047346</td>\n",
       "      <td>-0.792873</td>\n",
       "      <td>-1.463941</td>\n",
       "      <td>1.437729</td>\n",
       "      <td>0.429305</td>\n",
       "      <td>0.291593</td>\n",
       "      <td>0.039070</td>\n",
       "      <td>-0.344564</td>\n",
       "      <td>-0.477755</td>\n",
       "      <td>1.497306</td>\n",
       "      <td>0.583250</td>\n",
       "      <td>-0.501002</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>-0.227516</td>\n",
       "      <td>-0.116628</td>\n",
       "      <td>1.361494</td>\n",
       "      <td>-0.067306</td>\n",
       "      <td>-0.714113</td>\n",
       "      <td>0.660802</td>\n",
       "      <td>-0.568835</td>\n",
       "      <td>-0.221683</td>\n",
       "      <td>0.723890</td>\n",
       "      <td>-0.365080</td>\n",
       "      <td>0.367657</td>\n",
       "      <td>-0.120647</td>\n",
       "      <td>0.326636</td>\n",
       "      <td>1.212525</td>\n",
       "      <td>0.096936</td>\n",
       "      <td>-0.626133</td>\n",
       "      <td>-0.267525</td>\n",
       "      <td>-0.758820</td>\n",
       "      <td>1.055533</td>\n",
       "      <td>-0.541310</td>\n",
       "      <td>0.597650</td>\n",
       "      <td>-0.294169</td>\n",
       "      <td>-0.324569</td>\n",
       "      <td>0.734055</td>\n",
       "      <td>0.102867</td>\n",
       "      <td>-0.387977</td>\n",
       "      <td>-0.517437</td>\n",
       "      <td>-0.289151</td>\n",
       "      <td>1.406778</td>\n",
       "      <td>-0.597128</td>\n",
       "      <td>-0.258430</td>\n",
       "      <td>0.203102</td>\n",
       "      <td>-0.614115</td>\n",
       "      <td>0.582464</td>\n",
       "      <td>0.250351</td>\n",
       "      <td>-0.151800</td>\n",
       "      <td>0.344645</td>\n",
       "      <td>0.355169</td>\n",
       "      <td>-0.289252</td>\n",
       "      <td>2.612237</td>\n",
       "      <td>-0.133919</td>\n",
       "      <td>-0.084890</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>-0.662775</td>\n",
       "      <td>0.383637</td>\n",
       "      <td>0.045519</td>\n",
       "      <td>0.781561</td>\n",
       "      <td>-0.191357</td>\n",
       "      <td>-0.570332</td>\n",
       "      <td>0.185316</td>\n",
       "      <td>-0.254488</td>\n",
       "      <td>-0.184632</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.364053</td>\n",
       "      <td>-0.082144</td>\n",
       "      <td>-0.146273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.782748</td>\n",
       "      <td>-2.534450</td>\n",
       "      <td>-0.861802</td>\n",
       "      <td>2.736280</td>\n",
       "      <td>-0.260174</td>\n",
       "      <td>0.423037</td>\n",
       "      <td>0.420540</td>\n",
       "      <td>-1.091213</td>\n",
       "      <td>1.057371</td>\n",
       "      <td>-0.078111</td>\n",
       "      <td>0.491298</td>\n",
       "      <td>-0.382676</td>\n",
       "      <td>-0.624343</td>\n",
       "      <td>-1.333879</td>\n",
       "      <td>0.591627</td>\n",
       "      <td>-0.161664</td>\n",
       "      <td>0.139258</td>\n",
       "      <td>0.330781</td>\n",
       "      <td>-0.886692</td>\n",
       "      <td>0.292967</td>\n",
       "      <td>-0.172457</td>\n",
       "      <td>0.947384</td>\n",
       "      <td>-0.280141</td>\n",
       "      <td>-0.212093</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>-0.145981</td>\n",
       "      <td>0.209523</td>\n",
       "      <td>-0.004105</td>\n",
       "      <td>0.099894</td>\n",
       "      <td>0.614578</td>\n",
       "      <td>-0.518381</td>\n",
       "      <td>0.354663</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>-0.608414</td>\n",
       "      <td>0.095193</td>\n",
       "      <td>-1.715515</td>\n",
       "      <td>0.241093</td>\n",
       "      <td>-1.310035</td>\n",
       "      <td>-0.143083</td>\n",
       "      <td>0.490977</td>\n",
       "      <td>0.714952</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.539872</td>\n",
       "      <td>-0.415701</td>\n",
       "      <td>0.183875</td>\n",
       "      <td>0.286894</td>\n",
       "      <td>0.217710</td>\n",
       "      <td>-0.537288</td>\n",
       "      <td>0.836479</td>\n",
       "      <td>0.490919</td>\n",
       "      <td>-0.427198</td>\n",
       "      <td>-0.264927</td>\n",
       "      <td>-0.357435</td>\n",
       "      <td>-0.211409</td>\n",
       "      <td>-0.254766</td>\n",
       "      <td>-0.311702</td>\n",
       "      <td>0.765596</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>-0.081272</td>\n",
       "      <td>0.692344</td>\n",
       "      <td>0.446406</td>\n",
       "      <td>-0.051950</td>\n",
       "      <td>0.351461</td>\n",
       "      <td>0.134506</td>\n",
       "      <td>0.132254</td>\n",
       "      <td>0.163996</td>\n",
       "      <td>0.753221</td>\n",
       "      <td>0.826014</td>\n",
       "      <td>0.613957</td>\n",
       "      <td>-0.908908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-5.052647</td>\n",
       "      <td>-1.940768</td>\n",
       "      <td>-1.578072</td>\n",
       "      <td>0.061570</td>\n",
       "      <td>-0.584338</td>\n",
       "      <td>1.460674</td>\n",
       "      <td>0.147229</td>\n",
       "      <td>-0.153382</td>\n",
       "      <td>2.752557</td>\n",
       "      <td>-2.179398</td>\n",
       "      <td>-0.140038</td>\n",
       "      <td>0.156622</td>\n",
       "      <td>-1.074593</td>\n",
       "      <td>0.223191</td>\n",
       "      <td>-0.344492</td>\n",
       "      <td>-0.088704</td>\n",
       "      <td>0.491057</td>\n",
       "      <td>0.097275</td>\n",
       "      <td>1.325039</td>\n",
       "      <td>-0.100042</td>\n",
       "      <td>-0.341067</td>\n",
       "      <td>-0.063430</td>\n",
       "      <td>-0.532083</td>\n",
       "      <td>-0.054955</td>\n",
       "      <td>-0.133498</td>\n",
       "      <td>-0.437718</td>\n",
       "      <td>-0.390968</td>\n",
       "      <td>0.489184</td>\n",
       "      <td>0.256840</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.131282</td>\n",
       "      <td>0.424301</td>\n",
       "      <td>-0.045085</td>\n",
       "      <td>0.369237</td>\n",
       "      <td>-0.670030</td>\n",
       "      <td>-0.440074</td>\n",
       "      <td>-0.943911</td>\n",
       "      <td>-0.259794</td>\n",
       "      <td>1.103741</td>\n",
       "      <td>0.141470</td>\n",
       "      <td>0.145396</td>\n",
       "      <td>0.830468</td>\n",
       "      <td>0.694980</td>\n",
       "      <td>-0.067395</td>\n",
       "      <td>0.598033</td>\n",
       "      <td>1.162282</td>\n",
       "      <td>-1.073347</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.865121</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>0.018040</td>\n",
       "      <td>-0.359873</td>\n",
       "      <td>-0.167055</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.195374</td>\n",
       "      <td>0.492098</td>\n",
       "      <td>0.111935</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>-0.353744</td>\n",
       "      <td>-0.276584</td>\n",
       "      <td>-0.324027</td>\n",
       "      <td>0.123418</td>\n",
       "      <td>0.151478</td>\n",
       "      <td>0.256939</td>\n",
       "      <td>0.264427</td>\n",
       "      <td>-0.098836</td>\n",
       "      <td>-0.061520</td>\n",
       "      <td>-0.424417</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-2.784637</td>\n",
       "      <td>2.900961</td>\n",
       "      <td>-0.823700</td>\n",
       "      <td>1.101149</td>\n",
       "      <td>0.701504</td>\n",
       "      <td>-3.230526</td>\n",
       "      <td>-0.275074</td>\n",
       "      <td>-1.170111</td>\n",
       "      <td>0.216613</td>\n",
       "      <td>1.202857</td>\n",
       "      <td>0.302535</td>\n",
       "      <td>-0.476057</td>\n",
       "      <td>-1.066236</td>\n",
       "      <td>0.943876</td>\n",
       "      <td>0.349864</td>\n",
       "      <td>-0.501896</td>\n",
       "      <td>1.481387</td>\n",
       "      <td>0.146149</td>\n",
       "      <td>0.485364</td>\n",
       "      <td>-0.059674</td>\n",
       "      <td>-0.352642</td>\n",
       "      <td>-0.357602</td>\n",
       "      <td>-0.345634</td>\n",
       "      <td>0.580044</td>\n",
       "      <td>0.356632</td>\n",
       "      <td>-0.168434</td>\n",
       "      <td>0.271265</td>\n",
       "      <td>-0.214971</td>\n",
       "      <td>-0.198324</td>\n",
       "      <td>0.318257</td>\n",
       "      <td>-0.111851</td>\n",
       "      <td>-0.644729</td>\n",
       "      <td>0.215988</td>\n",
       "      <td>0.200107</td>\n",
       "      <td>0.319363</td>\n",
       "      <td>-0.704563</td>\n",
       "      <td>-0.017269</td>\n",
       "      <td>0.259530</td>\n",
       "      <td>0.374380</td>\n",
       "      <td>-0.143889</td>\n",
       "      <td>-0.276478</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.229743</td>\n",
       "      <td>0.105728</td>\n",
       "      <td>-0.046585</td>\n",
       "      <td>0.275464</td>\n",
       "      <td>-0.071035</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>0.414334</td>\n",
       "      <td>-0.146727</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>0.464096</td>\n",
       "      <td>0.146666</td>\n",
       "      <td>0.164728</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>-0.597471</td>\n",
       "      <td>-0.216833</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.082375</td>\n",
       "      <td>-0.066439</td>\n",
       "      <td>0.378327</td>\n",
       "      <td>-0.208878</td>\n",
       "      <td>-0.188453</td>\n",
       "      <td>0.075635</td>\n",
       "      <td>-0.044944</td>\n",
       "      <td>0.248019</td>\n",
       "      <td>0.208884</td>\n",
       "      <td>0.088565</td>\n",
       "      <td>-0.017294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.477498</td>\n",
       "      <td>-3.014318</td>\n",
       "      <td>12.834200</td>\n",
       "      <td>-7.785206</td>\n",
       "      <td>2.082295</td>\n",
       "      <td>0.680095</td>\n",
       "      <td>-1.048387</td>\n",
       "      <td>-2.383967</td>\n",
       "      <td>3.081192</td>\n",
       "      <td>0.781266</td>\n",
       "      <td>0.638335</td>\n",
       "      <td>-3.023950</td>\n",
       "      <td>-0.489423</td>\n",
       "      <td>1.031153</td>\n",
       "      <td>0.385071</td>\n",
       "      <td>0.186131</td>\n",
       "      <td>-1.020070</td>\n",
       "      <td>1.261522</td>\n",
       "      <td>-3.554594</td>\n",
       "      <td>0.150767</td>\n",
       "      <td>0.782603</td>\n",
       "      <td>-0.396112</td>\n",
       "      <td>-1.485565</td>\n",
       "      <td>-0.156879</td>\n",
       "      <td>0.655269</td>\n",
       "      <td>-0.202192</td>\n",
       "      <td>0.598208</td>\n",
       "      <td>-0.487277</td>\n",
       "      <td>-0.961132</td>\n",
       "      <td>-2.008463</td>\n",
       "      <td>-0.370932</td>\n",
       "      <td>-0.107970</td>\n",
       "      <td>0.871146</td>\n",
       "      <td>-0.064890</td>\n",
       "      <td>1.200858</td>\n",
       "      <td>-1.314702</td>\n",
       "      <td>0.189318</td>\n",
       "      <td>-2.082040</td>\n",
       "      <td>1.342594</td>\n",
       "      <td>1.336253</td>\n",
       "      <td>-0.582851</td>\n",
       "      <td>0.187623</td>\n",
       "      <td>-0.130036</td>\n",
       "      <td>-0.087401</td>\n",
       "      <td>-0.436013</td>\n",
       "      <td>-1.846490</td>\n",
       "      <td>-1.068223</td>\n",
       "      <td>1.712436</td>\n",
       "      <td>-1.313066</td>\n",
       "      <td>0.087369</td>\n",
       "      <td>0.923352</td>\n",
       "      <td>0.931984</td>\n",
       "      <td>-0.619932</td>\n",
       "      <td>1.574414</td>\n",
       "      <td>3.452214</td>\n",
       "      <td>0.260408</td>\n",
       "      <td>0.224318</td>\n",
       "      <td>-0.785947</td>\n",
       "      <td>-1.156028</td>\n",
       "      <td>-0.342211</td>\n",
       "      <td>0.272678</td>\n",
       "      <td>-0.494230</td>\n",
       "      <td>-0.921919</td>\n",
       "      <td>-1.177072</td>\n",
       "      <td>-0.593474</td>\n",
       "      <td>-1.816937</td>\n",
       "      <td>3.080137</td>\n",
       "      <td>-1.575720</td>\n",
       "      <td>0.745876</td>\n",
       "      <td>-0.067303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PC_1      PC_2       PC_3      PC_4      PC_5      PC_6      PC_7  \\\n",
       "0 -3.302524 -2.047346  -0.792873 -1.463941  1.437729  0.429305  0.291593   \n",
       "1 -0.782748 -2.534450  -0.861802  2.736280 -0.260174  0.423037  0.420540   \n",
       "2 -5.052647 -1.940768  -1.578072  0.061570 -0.584338  1.460674  0.147229   \n",
       "3 -2.784637  2.900961  -0.823700  1.101149  0.701504 -3.230526 -0.275074   \n",
       "4  1.477498 -3.014318  12.834200 -7.785206  2.082295  0.680095 -1.048387   \n",
       "\n",
       "       PC_8      PC_9     PC_10     PC_11     PC_12     PC_13     PC_14  \\\n",
       "0  0.039070 -0.344564 -0.477755  1.497306  0.583250 -0.501002  0.022636   \n",
       "1 -1.091213  1.057371 -0.078111  0.491298 -0.382676 -0.624343 -1.333879   \n",
       "2 -0.153382  2.752557 -2.179398 -0.140038  0.156622 -1.074593  0.223191   \n",
       "3 -1.170111  0.216613  1.202857  0.302535 -0.476057 -1.066236  0.943876   \n",
       "4 -2.383967  3.081192  0.781266  0.638335 -3.023950 -0.489423  1.031153   \n",
       "\n",
       "      PC_15     PC_16     PC_17     PC_18     PC_19     PC_20     PC_21  \\\n",
       "0 -0.227516 -0.116628  1.361494 -0.067306 -0.714113  0.660802 -0.568835   \n",
       "1  0.591627 -0.161664  0.139258  0.330781 -0.886692  0.292967 -0.172457   \n",
       "2 -0.344492 -0.088704  0.491057  0.097275  1.325039 -0.100042 -0.341067   \n",
       "3  0.349864 -0.501896  1.481387  0.146149  0.485364 -0.059674 -0.352642   \n",
       "4  0.385071  0.186131 -1.020070  1.261522 -3.554594  0.150767  0.782603   \n",
       "\n",
       "      PC_22     PC_23     PC_24     PC_25     PC_26     PC_27     PC_28  \\\n",
       "0 -0.221683  0.723890 -0.365080  0.367657 -0.120647  0.326636  1.212525   \n",
       "1  0.947384 -0.280141 -0.212093  0.045714 -0.145981  0.209523 -0.004105   \n",
       "2 -0.063430 -0.532083 -0.054955 -0.133498 -0.437718 -0.390968  0.489184   \n",
       "3 -0.357602 -0.345634  0.580044  0.356632 -0.168434  0.271265 -0.214971   \n",
       "4 -0.396112 -1.485565 -0.156879  0.655269 -0.202192  0.598208 -0.487277   \n",
       "\n",
       "      PC_29     PC_30     PC_31     PC_32     PC_33     PC_34     PC_35  \\\n",
       "0  0.096936 -0.626133 -0.267525 -0.758820  1.055533 -0.541310  0.597650   \n",
       "1  0.099894  0.614578 -0.518381  0.354663  0.255811 -0.608414  0.095193   \n",
       "2  0.256840  0.108471  0.131282  0.424301 -0.045085  0.369237 -0.670030   \n",
       "3 -0.198324  0.318257 -0.111851 -0.644729  0.215988  0.200107  0.319363   \n",
       "4 -0.961132 -2.008463 -0.370932 -0.107970  0.871146 -0.064890  1.200858   \n",
       "\n",
       "      PC_36     PC_37     PC_38     PC_39     PC_40     PC_41     PC_42  \\\n",
       "0 -0.294169 -0.324569  0.734055  0.102867 -0.387977 -0.517437 -0.289151   \n",
       "1 -1.715515  0.241093 -1.310035 -0.143083  0.490977  0.714952  0.968182   \n",
       "2 -0.440074 -0.943911 -0.259794  1.103741  0.141470  0.145396  0.830468   \n",
       "3 -0.704563 -0.017269  0.259530  0.374380 -0.143889 -0.276478  0.010400   \n",
       "4 -1.314702  0.189318 -2.082040  1.342594  1.336253 -0.582851  0.187623   \n",
       "\n",
       "      PC_43     PC_44     PC_45     PC_46     PC_47     PC_48     PC_49  \\\n",
       "0  1.406778 -0.597128 -0.258430  0.203102 -0.614115  0.582464  0.250351   \n",
       "1  0.539872 -0.415701  0.183875  0.286894  0.217710 -0.537288  0.836479   \n",
       "2  0.694980 -0.067395  0.598033  1.162282 -1.073347  0.818620  0.865121   \n",
       "3  0.229743  0.105728 -0.046585  0.275464 -0.071035  0.076804  0.414334   \n",
       "4 -0.130036 -0.087401 -0.436013 -1.846490 -1.068223  1.712436 -1.313066   \n",
       "\n",
       "      PC_50     PC_51     PC_52     PC_53     PC_54     PC_55     PC_56  \\\n",
       "0 -0.151800  0.344645  0.355169 -0.289252  2.612237 -0.133919 -0.084890   \n",
       "1  0.490919 -0.427198 -0.264927 -0.357435 -0.211409 -0.254766 -0.311702   \n",
       "2  0.133283  0.018040 -0.359873 -0.167055  0.001217  0.026600  0.195374   \n",
       "3 -0.146727  0.009272  0.095331  0.464096  0.146666  0.164728  0.078629   \n",
       "4  0.087369  0.923352  0.931984 -0.619932  1.574414  3.452214  0.260408   \n",
       "\n",
       "      PC_57     PC_58     PC_59     PC_60     PC_61     PC_62     PC_63  \\\n",
       "0  0.016425 -0.662775  0.383637  0.045519  0.781561 -0.191357 -0.570332   \n",
       "1  0.765596  0.008569 -0.081272  0.692344  0.446406 -0.051950  0.351461   \n",
       "2  0.492098  0.111935  0.011866 -0.353744 -0.276584 -0.324027  0.123418   \n",
       "3 -0.597471 -0.216833  0.005742  0.082375 -0.066439  0.378327 -0.208878   \n",
       "4  0.224318 -0.785947 -1.156028 -0.342211  0.272678 -0.494230 -0.921919   \n",
       "\n",
       "      PC_64     PC_65     PC_66     PC_67     PC_68     PC_69     PC_70  Churn  \n",
       "0  0.185316 -0.254488 -0.184632 -0.277023 -0.364053 -0.082144 -0.146273      0  \n",
       "1  0.134506  0.132254  0.163996  0.753221  0.826014  0.613957 -0.908908      0  \n",
       "2  0.151478  0.256939  0.264427 -0.098836 -0.061520 -0.424417  0.020047      0  \n",
       "3 -0.188453  0.075635 -0.044944  0.248019  0.208884  0.088565 -0.017294      0  \n",
       "4 -1.177072 -0.593474 -1.816937  3.080137 -1.575720  0.745876 -0.067303      0  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md['Churn']=fdf['Churn'].values\n",
    "md.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a copy of the original dataframe\n",
    "forest = md.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25335, 71)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Model Building (to be used for rest of the models as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = forest.drop('Churn',axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = forest['Churn']\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y,random_state=101)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTEENN Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 17144, 1: 590})\n",
      "Counter({0: 14322, 1: 8562})\n"
     ]
    }
   ],
   "source": [
    "# summarize class distribution\n",
    "print(Counter(y_train))\n",
    "\n",
    "# define sampling strategy\n",
    "sample = SMOTEENN(sampling_strategy=0.5,random_state=100)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_train_res, y_train_res = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y_train_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - Model Building without using any sampling technique but using class_weight='balanced' argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:   31.8s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:   36.7s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   40.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   40.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 20, 2)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=True, scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(2, 20, 2)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(class_weight='balanced',random_state=100) #we put class_weight='balanced' to deal with Data Imbalance present in the dataset\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXwV9dX48c/JTUIIBMIS1iQkYtghEcKigICgoiiouC996KNiXapdtNXWotKnv/rY1qotahHX6uOGC6CouAEqKHvYKYsIISwBZF+ynd8f35sQQoAEMpmb3PN+Oa87d+Y7c48kmXNn+Z6vqCrGGGPCV4TfARhjjPGXJQJjjAlzlgiMMSbMWSIwxpgwZ4nAGGPCXKTfAVRW06ZNNSUlpdLbrdqxCoD2TdpXcUTGGBP65s+fv11VE8pbV+MSQUpKCvPmzav0dgNfGgjA9FHTqzYgY4ypAUTkh+Ots0tDxhgT5iwRGGNMmLNEYIwxYc4SgTHGhDlLBMYYE+Y8SwQi8oKIbBORpcdZLyLylIisEZHFItLdq1iMMcYcn5dnBC8BQ0+w/iIgLTiNBp7xMBZjjDHH4Vk/AlWdKSIpJ2gyAnhFXR3sb0UkXkRaqupmr2IyxvhHVSkoUgqDU0GRUlSkFKlSqIoqbr7o6Pmi4HyRKkVFpeaVYNuj5wu11DZFx867zwp+bnB/WmYeABH3EpwVpHjRUcs4apmUrKOc7SjTRoIbi1Bqu7LLiltBh5ZxJDaKrfKfjZ8dyloDG0u9zw4uOyYRiMho3FkDycnJ1RKcMaFOVTmYX8i+wwUcOBx8zStk/+EC9ucVuNfDhRzIKyg5AJe8FiqFRUXHLi9yywvLba8UBNeV3e5I+1LrC0u3K6LIhj45bf9zWRdu7NOmyvfrZyKQcpaV+6uiquOB8QCZmZn262RqpPzCInfAzivgwOGCkgO3ey1g3+FCDhwOHsBLDujB1+DB/agDfl4BlRlXKhAhBCKEyKNeIwhEQGRExFHrAhFCZMCtj4wQAuKW1YmKLLOPI9tFlLNvt49S+xUhEAi2lyPbibh1EQIR4paVnQ+Iaxch7v8lQtw37aPmS9of2T4Q4dYVz0cIpT5PiIgIfk5wXkodmhQl+F/Jv7XizljcMrewZJ0GtymZd22Kf0yu3ZHtS2+jeuxnHLVvlFbxdSv+A68EPxNBNpBU6n0ikONTLMacsoN5hXy+citf/Wc7uw/mH/VtvGQ+r5C8gqIK7U8E6kVHEhsdoH6dSGLrBKgXHUmzuBjqNY2kXnSAenVKvdaJpF6wTcn7kjaR1I0OEBVwB1FjyuNnIpgM3CUibwC9gd12f8DUFIcLCpmxKpcpizfz+YqtHMgrJD42imZxdUoOwAlxdUoOzrF1AtSPjiS2TiT16xw5SNerc/QBv36dSGIiA0RE2EHbVB/PEoGIvA4MBJqKSDbwEBAFoKrPAlOBi4E1wAHgp17FYkxVyC8s4ps125mStZlpy7ew91ABjWKjuOys1lzarRW9UhsTsAO4qYG8fGroupOsV+BOrz7fmKpQWKR89/0OpmRt5uOlm/nxQD5xMZFc2LkFl6a34py2TYgKWL9MU7PVuDLUxnitqEhZuPFHpmRt5sMlm8nde5jY6ABDOjbn0vRWnNuuKXUiA36HaUyVsURgDO7JjqWb9jBlcQ4fZOWQs/sQ0ZERnNe+GZemt+K8Ds2oG20Hf1M7WSIwYW3Vlr1MycphyuIcfthxgKiA0D8tgfuGtmdIx+bExUT5HaIxnrNEYMLOutx9fLB4M1Oycli9bR8RAue0bcodA9tyYecWxMdG+x2iMdXKEoEJCxt3HuDDJe7gvyxnDyLQM6UxfxzRmaFdWpIQV8fvEI3xjSUCU2tt3XOIDxdvZsriHBZu2AVARlI8Dw7ryLBuLWnZ0JtemsbUNJYITK2yY99hPlq6hSlZOcxZvxNV6NSyAb8Z2p5LurYiuUnVF+wypqazRGBqvN0H8vlk2RamLM5h1todFBYpbRPqcc/gNC7p1oozm9X3O0RjQpolAlMj7TtcwOcrtjIlK4cZ/8klv1BJbhzLbeeewaXprejQIs5q6xhTQZYITI2hqsz5ficvz17P5yu2cbigiJYNYxh1TgqXdGtFt8SGdvA35hRYIjAhr6hI+WzFVp6ZsZaFG3bRuF401/ZM4pL0VvRIbmQF2ow5TZYITMjKKyhi0qJN/GvmOtZs20dS47r88bIuXNUjkZgo6+VrTFWxRGBCzv7DBbwxdyMTvlrH5t2H6NAijievzWBY15ZEWoE3Y6qcJQITMnbuz+OlWet5edZ6dh/Mp3dqY/58RVcGtEuwa//GeMgSgfFd9o8HmPDV97wxdwOH8ou4oFNzfjawLd2TG/kdmjFhwRKB8c2qLXv514y1TMrKQYDLzmrNzwacwZnN4vwOzZiwYonAVLt563fyzPS1fL5yG7HRAUadk8LN/VI9G5jbGHNilghMtVBVvly1jWemr2Xu+h9pFBvFr85vx0/ObmPVPo3xmSUC46n8wiI+WJzDs9PXsWrrXlrH1+XhSztxdc8kYqPt18+YUODpX6KIDAWeBALABFV9tMz6NsALQAKwE7hRVbO9jMlUj4N5hbw5dwPPffU9m3YdpF3z+jx+dTqXpreyMX6NCTGeJQIRCQDjgPOBbGCuiExW1eWlmv0VeEVVXxaR84A/Azd5FZPx3q4Debwy+wdemrWenfvzyGzTiLEjOjOofTPrAWxMiPLyjKAXsEZV1wGIyBvACKB0IugE/DI4/yXwvofxGA9t3n2QCV99z+tzNnAgr5DBHZrxs4Ft6ZnS2O/QjDEn4WUiaA1sLPU+G+hdpk0WMBJ3+ehyIE5EmqjqjtKNRGQ0MBogOTnZs4BN5a3ZtpdnZ6xj0qJNFCmMSG/FbQPa0r6FPQJqTE3hZSIo7zqAlnl/L/BPERkFzAQ2AQXHbKQ6HhgPkJmZWXYfxgcLNvzIs9PXMm35VmKiIrihdxtu7pdKUmMb+MWYmsbLRJANJJV6nwjklG6gqjnAFQAiUh8Yqaq7PYzJnAZVZcZ/cnlm+lq++34nDetGcffgNP7r7DY0qW9j/hpTU3mZCOYCaSKSivumfy1wfekGItIU2KmqRcADuCeITIgpKCziwyWbeXbGOlZs3kPLhjE8OKwj1/VKpl4dewTUmJrOs79iVS0QkbuAT3CPj76gqstEZCwwT1UnAwOBP4uI4i4N3elVPKbyDuUX8vb8bMbPXMvGnQdpm1CPv1zZjREZrYmOtEdAjaktPP06p6pTgalllo0pNT8RmOhlDKZyVJVlOXuYtGgT7y3cxPZ9eWQkxfPgsE6c37G5PQJqTC1k5/UGgO+372fyohwmZW1iXe5+ogLCgHbNuKV/Kr1TG1sZaGNqMUsEYWzbnkNMWbyZyYs2kZW9GxHondqYW/ufwUVdWlgNIGPChCWCMLP7YD6fLN3CpKxNzF67gyKFLq0b8PuLO3JJektaNrQKoMaEG0sEYeBQfiFfrNzGpEWb+HJlLnmFRaQ0ieWu89IYnt6KM5vV9ztEY4yPLBHUUgWFRcxau4NJi3L4ZNkW9h0uICGuDjf2acOIjFZ0S2xo1/2NMYAlglpFVVm4cReTF+XwweIctu/LIy4mkou7tmBERmv6nNGEgD31Y4wpwxJBLbB6614mBZ/42bjzINGREQzp2Izh6a0Z2D6BmKiA3yEaY0KYJYIaatOug0zJymHSohxWbN5DhEDfM5tyz+B2XNi5OXExUX6HaIypISwR1CA79+cxdclmJi/KYc76nQCclRzPw5d2Yli3ViTEWb0fY0zlWSIIcfsPF/DZiq1MWpTDzP/kUlCkpDWrz30XtufSbq1IbmLVPo0xp8cSQQjKKyjiq9W5TFqUw6fLt3Iwv5BWDWO4pf8ZjMhoRYcWcfbEjzGmylgiCBFFRcrc9TuZlJXD1CWb2XUgn0axUYzs0ZoRGa3pkdzI6vwYYzxhicBHuw/ksyh7F9+s2c6UrBw27z5EbHSACzo1Z0RGa/qlNbWB3o0xnrNEUE3yCopYsXkPizbuKpm+374fgMgIYWD7BB64uCNDOjYjNtp+LMaY6mNHHA+oKj/sOEBW9i4WbnAH/eU5e8grLAIgIa4OGUnxXNkjkbOS4uma2NAe9zTG+MYSQRX4cX8ei7J3kRX8pp+1cRc/HsgHoG5UgK6tGzKqbwoZSfFkJMXTsmGM3ew1xoQMSwSVdLigkOU5e0oO+Is27mL9jgMAiEBas/qc36k5GUmNyEiKp13z+kTadX5jTAizRHACqsr6HQdYtPFHFm3YxaLs3awodYmnWfASz9U9k8hIiqdbYjz1bQxfY0wN4+lRS0SGAk/ixiyeoKqPllmfDLwMxAfb3B8c3tIXO/fnkbVxFwuD3/azsnexq/QlnsSG/LT4Ek9yvNXuN8bUCp4lAhEJAOOA84FsYK6ITFbV5aWaPQi8parPiEgn3PjGKV7FVNqh/EKWb97jvukHD/o/BC/xRAi0ax7HhZ1akJHsruunNbNLPMaY2snLM4JewBpVXQcgIm8AI4DSiUCBBsH5hkCOV8HkFRSx51A+YyYtZdHGXazYvIf8QgWgRYMYMpLiubZnMhnBp3jsEo8xJlx4ebRrDWws9T4b6F2mzcPANBH5OVAPGFLejkRkNDAaIDk5+ZSC2b7vMBt2HmDitmy6JTbk5n5nkJHUkIykRrRoGHNK+zTGmNrAy0RQ3vORWub9dcBLqvo3ETkb+LeIdFHVoqM2Uh0PjAfIzMwsu48KaVq/DvGx0cy+5UIbnMUYY0rxMhFkA0ml3idy7KWfm4GhAKo6W0RigKbAtqoOJjoygmiwJGCMMWV4efdzLpAmIqkiEg1cC0wu02YDMBhARDoCMUCuhzEZY4wpw7NEoKoFwF3AJ8AK3NNBy0RkrIgMDzb7NXCriGQBrwOjVPWULv0YY4w5NZ4+GhPsEzC1zLIxpeaXA329jMEYY8yJ2YPxxhgT5iwRGGNMmLNEYIwxYc4SgTHGhDlLBMYYE+YsERhjTJizRGCMMWGu5pXYXLUKBg6s/HYZi9zrqWxrjDG1WPicERQVQP5B2LvFvRpjjAFq4hlB+/YwfXrlt/tHB/hxPVy6GdgMdRtDch9I6g3JZ0OrDIisU8XBGmNMiJDjF9yseYngVMW1cNMlz8GGb9208VtYFayAEagDrbsfSQxJvSC2sb8xG2NMNQifRFCsaZqbut/k3u/LhY3fwYbZ7nX2OPjmCbcuocORxJDcGxqlnjCrGmNMTRR+iaCs+gnQ8RI3gbt/sGnBkcSw7H1Y8HKwbfNgYujjphbdIBDlX+zGGFMFLBGUFVUXUvq6CaCoCHJXHkkMG76FFcFhFaJioXWPI4khsSfENPQvdmOMOQWWCE4mIgKad3JTz5vdsj2b3f2F4nsNXz0OWggINO/iLiMln+3OHuKTTrh7Y4zxmyWCU9GgJXS+3E0Ah/fBpnlHEkPWGzB3QrBt4tGJoXlniAj4F7sxxpRhiaAq1KkPZwx0E0BhAWxbBhuCN6F/mA1L33HrouMgqSckFV9OyoToev7EbYwxWCLwRiASWqa7qfdoUIXdG48kho3fwfQ/AwoScI+qXvAnSOzhd+TGmDDkaSIQkaHAk0AAmKCqj5ZZ/3dgUPBtLNBMVeO9jMkXIhCf7KZuV7llB3dB9jyXGLJeh+eHQJ87YNDv7AzBGFOtPCsxISIBYBxwEdAJuE5EOpVuo6q/VNUMVc0A/gG861U8IaduPKQNgcF/gDu+hR4/hdn/hGfOgXUz/I7OGBNGvKw11AtYo6rrVDUPeAMYcYL21wGvexhP6IppAJc8DqOmuktFrwyHyT93Zw3GGOMxLxNBa2BjqffZwWXHEJE2QCrwhYfxhL6UvnD7N9Dvl7DwNRjXG1Z84HdUxphazst7BOXVYtDjtL0WmKiqheXuSGQ0MBogOTm5aqILVVF1YcjD0OkymHwXvHmDm7/4L1C/md/RmTCXn59PdnY2hw4d8jsUcxwxMTEkJiYSFVXxqgdeJoJsoHRvqkQg5zhtrwXuPN6OVHU8MB4gMzPzeMmkdmmVAbd+CbOegun/C+umw9BHIf1aq3dkfJOdnU1cXBwpKSmI/R6GHFVlx44dZGdnk5qaWuHtvLw0NBdIE5FUEYnGHewnl20kIu2BRsBsD2OpmQJR0P/X8LOvXQG8938Gr14BP/7gd2QmTB06dIgmTZpYEghRIkKTJk0qfcbmWSJQ1QLgLuATYAXwlqouE5GxIjK8VNPrgDdUNTy+6Z+KhHbw04/g4r/Cxjnw9Nnw3b9cHSRjqpklgdB2Kj8fT0coU9WpqtpOVduq6p+Cy8ao6uRSbR5W1fu9jKNWiIiAXre6R03bnA0f/QZeHAq5q/yOzJhqs2vXLp5++ulT2vbiiy9m164TP4k3ZswYPvvss1Paf3WpX78+AOvXr6dLly5Vss/wGaqytohPghsmwuXjYft/4Nl+MPMvUJjvd2TGeO5EiaCwsNxnTUpMnTqV+PgT91cdO3YsQ4YMOeX4judksfnthIlARKaIyOTjTdUVpClDBNKvgTvnQodL4Iv/gfEDIWeh35EZ46n777+ftWvXkpGRwX333cf06dMZNGgQ119/PV27dgXgsssuo0ePHnTu3Jnx48eXbJuSksL27dtZv349HTt25NZbb6Vz585ccMEFHDzoxjEfNWoUEydOLGn/0EMP0b17d7p27crKlSsByM3N5fzzz6d79+7cdttttGnThu3btx8Ta/369RkzZgy9e/dm9uzZzJ8/nwEDBtCjRw8uvPBCNm/eDMCaNWsYMmQI6enpdO/enbVr17Jv3z4GDx5c8tmTJk3y9N/1ZE8N/dXTTzenp34CXPUidL0SPvw1PHcenPNzGPiAewzVGA89MmUZy3P2VOk+O7VqwEOXdj7u+kcffZSlS5eyaNEiAKZPn86cOXNYunRpyVMyL7zwAo0bN+bgwYP07NmTkSNH0qRJk6P2s3r1al5//XWee+45rr76at555x1uvPHGYz6vadOmLFiwgKeffpq//vWvTJgwgUceeYTzzjuPBx54gI8//vioZFPa/v376dKlC2PHjiU/P58BAwYwadIkEhISePPNN/n973/PCy+8wA033MD999/P5ZdfzqFDhygqKiI6Opr33nuPBg0asH37dvr06cPw4cM9uz9zwkSgqlbroCboMAza9IVPx8A3T8KKKTD8H5DSz+/IjPFcr169jnpU8qmnnuK9994DYOPGjaxevfqYRJCamkpGRgYAPXr0YP369eXu+4orrihp8+67rgLO119/XbL/oUOH0qhRo3K3DQQCjBw5EoBVq1axdOlSzj//fMBdKmrZsiV79+5l06ZNXH65K2kfExMDuP4av/vd75g5cyYRERFs2rSJrVu30qJFi8r941TQCROBiCzh+J3AUNVuVR6ROTV142H4U9BlJEy5G14a5uoXnf+IjZpmPHGib+7VqV69I0Uap0+fzmeffcbs2bOJjY1l4MCB5T5KWadOnZL5QCBQcmnoeO0CgQAFBQWAe1a/ImJiYggEAiXbdO7cmdmzj35Kfs+e8s+oXnvtNXJzc5k/fz5RUVGkpKR42onvZDeLLwEuPcFkQs0ZA+D22XD2XW6s5XF9YNXHfkdlTJWIi4tj7969x12/e/duGjVqRGxsLCtXruTbb7+t8hj69evHW2+9BcC0adP48ccfT7pN+/btyc3NLUkE+fn5LFu2jAYNGpCYmMj7778PwOHDhzlw4AC7d++mWbNmREVF8eWXX/LDD972HTphIlDVH040eRqZOXXRsXDhn+CWz6BuI3j9Gph4M+w/9oaWMTVJkyZN6Nu3L126dOG+++47Zv3QoUMpKCigW7du/OEPf6BPnz5VHsNDDz3EtGnT6N69Ox999BEtW7YkLi7uhNtER0czceJEfvvb35Kenk5GRgazZs0C4N///jdPPfUU3bp145xzzmHLli3ccMMNzJs3j8zMTF577TU6dOhQ5f8fpUlFTnNEpA+uTHRHIBo3vsB+VW3gaXTlyMzM1Hnz5lV6u4EvDQRg+qjpVRtQqCvIg2+egBmPQZ04uOgxd3PZOgWZU7BixQo6duzodxi+Onz4MIFAgMjISGbPns3tt99ecvM6VJT3cxKR+aqaWV77itYa+ieuRMTbQCbwE+DM04jTVJfIaBjwG+h4qStt/e4tsORtV/a6YaLf0RlT42zYsIGrr7665Ome5557zu+QTluFi86p6hoRCQQrhL4oIrM8jMtUtWYd4b8/gTnj4fOx7t7B+Q9Dj/92vZaNMRWSlpbGwoW1q89ORY8AB4KF4xaJyGMi8kvAxlOsaSIC0Od2uGO2Gx/5w1+7p4u2r/E7MmOMjyqaCG4Ktr0L2I8rLz3Sq6CMxxqlwE3vw4hxsG2ZGx7z679DYYHfkRljfFDRRLAdyFPVPar6CHAfxx9bwNQEInDWjXDnHGh3AXz2MEw4DzYv9jsyY0w1q2gi+ByILfW+LhDaJfpMxcS1gGtehatfgT2bXc2iz8dCvo1AZUy4qGgiiFHVfcVvgvOxJ2hvappOI+DO7yD9Ovjqb66q6Q82VpAJLadThhrgiSee4MCBA1UY0ckVF7uDIyWkQ01FE8F+Eele/EZEegDl98k2NVdsY7hsHNz4LhQeduMdTPkFHDx5z0ljqkN1JYJQLxtd1SqaCH4BvC0iX4nIV8CbuBvHpjY6c/DRZSr+2ROWTAQbRM74rGwZaoC//OUv9OzZk27duvHQQw8BrvLnsGHDSE9Pp0uXLrz55ps89dRT5OTkMGjQIAYNGnTMvlNSUhg7diz9+vXj7bffZu3atQwdOpQePXrQv3//kjLUW7du5fLLLyc9PZ309PSSHsLHK39dE1SoH4GqzhWRDkB7QICVqmojodRmdeq7MhXdrnZnBe/cDIteg2F/g8Zn+B2dCQUf3Q9bllTtPlt0hYsePe7qsmWop02bxurVq5kzZw6qyvDhw5k5cya5ubm0atWKDz/8EHA1iBo2bMjjjz/Ol19+SdOmTcvdf0xMDF9//TUAgwcP5tlnnyUtLY3vvvuOO+64gy+++IK7776bAQMG8N5771FYWMi+fe6qeUXKX4eqCiUCEYkFfgW0UdVbRSRNRNqr6gfehmd81zLd1Sya+7y7ifz02XDufXDO3a7XsjE+mjZtGtOmTeOss84CYN++faxevZr+/ftz77338tvf/pZLLrmE/v37V2h/11xzTcl+Zs2axVVXXVWy7vDhwwB88cUXvPLKK4CrStqwoavuW5Hy16Gqoj2LXwTmA2cH32fjyk2cMBGIyFDgSVxtogmqekyqF5GrgYdx5a6zVPX6CsZkqktEAHqPho6XwMf3wxd/DJap+Du0Ocfv6IxfTvDNvbqoKg888AC33XbbMevmz5/P1KlTeeCBB7jgggsYM2bMSfdXXNK6qKiI+Pj4CtcQqmj561BV0XsEbVX1MSAfQFUP4i4RHZeIBIBxwEVAJ+A6EelUpk0a8ADQV1U74+5FmFDVoJV7zPT6tyDvALx4katfdGCn35GZMFG2DPWFF17ICy+8UHJ5ZtOmTWzbto2cnBxiY2O58cYbuffee1mwYEG52x9PgwYNSE1N5e233wZcwsnKygLcJaNnnnkGcDeV9+zZUy3lr71U0USQJyJ1CQ5SIyJtgcMn2aYXsEZV16lqHvAGMKJMm1uBcar6I4Cqbqtw5MY/7S6EO791l4cWvuZuJme9aTeTjefKlqG+4IILuP766zn77LPp2rUrV155JXv37mXJkiX06tWLjIwM/vSnP/Hggw8CMHr0aC666KJybxaX9dprr/H888+Tnp5O586dS8YNfvLJJ/nyyy/p2rUrPXr0YNmyZdVS/tpLJy1DLW6QzJuAm3Hf7KcBfYFRqjr9BNtdCQxV1VuC728CeqvqXaXavA/8J7i/APCwqh4zioqIjAZGAyQnJ/c4lUEawrYMtde2LHE3kzfNg9QBMOxxaGqFaWsrK0NdM1S2DPVJzwjUZYp7gCuAUcDrQOaJkkDx55a3uzLvI4E0YCBwHTBBROLLiWG8qmaqamZCQsLJQjbVqUVXuPlTlwByFrm6RTMeg4KTnTAaY0JFRS8NfQucoaofquoHqlqRoa6yccXpiiVybH2ibGCSquar6vfAKlxiMDVJRAT0vBnumgMdhsGXf4Jn+sL6r/2OzBhTARVNBIOA2SKyVkQWi8gSETlZdbK5QJqIpAZLWF8LTC7T5v3gvhGRpkA7YF3FwzchJa4FXPUi3PAOFOa5Etfv3wH7d/gdmTHmBCr6+OhFld2xqhaIyF3AJ7jr/y+o6jIRGQvMU9XJwXUXiMhyoBC4T1XtqFHTpQ2BO76FmX+BWU/Bqo9c57T062yIzFpAVRH7OYasigw/XFZFexaf0kD1qjoVmFpm2ZhS84rrqParU9m/CWHRsTDkIeh6FXzwC3j/dlj0f+5eQkI7v6MzpygmJoYdO3bQpEkTSwYhSFXZsWMHMTExldquwkNVGnNKmneCn34MC1+BT8fAs32h3y+h368gqnK/rMZ/iYmJZGdnk5ub63co5jhiYmJITKzceOSWCIz3IiKgxyhofzF88nuY8b+uiN0lf4czBvgdnamEqKgoUlNT/Q7DVDEbtdxUn/rNYORzcNN7oEXwynB49zbYX5GH0IwxXrFEYKpf2/PgjtmueN3Sd+AfPWDBK1BU5HdkxoQlSwTGH1F14bwH4fZvoFknV7PopWGwbaXfkRkTdiwRGH8ltIdRH8Lwf0LuCjdE5ud/hHwbAM+Y6mKJwPgvIgK63wR3zYOuV8JXf3XjHqz9wu/IjAkLlghM6KjXFC5/Fn4yGSQC/n05vHML7LOitMZ4yRKBCT1nDIDbZ8GA+2H5JPhnJsx70W4mG+MRSwQmNEXFwKAHXEJo0c31Tn5xKGxd7ndkxtQ6lghMaGuaBv81BS57Fravhn/1h08fgkO7/Y7MmFrDEoEJfSKQcZ27mdztWvjmCXiiG3z1OBze53d0xtR4lghMzVGvCVw2DkbPgKTe8Pkj8GQ6zB5nj5sacxosEZiap1UG3PCWGxmtRRf45Hfw1Fkw5zkbGc2YU2CJwNRcSb3gJ5Nch7RGqUWqat8AABLaSURBVDD13iPlKgrz/Y7OmBrDEoGp+VL6wU+nwo3vusJ2k38O/+wJWW9AUaHf0RkT8iwRmNpBBM4cDLd8Dte9AXXqw3u3uR7KS9+1PgjGnIAlAlO7iED7i2D0TLj6Ffd+4k/dY6crP4RTGMbPmNrO00QgIkNFZJWIrBGR+8tZP0pEckVkUXC6xct4TBiJiIBOI1yHtCsmQP4BeON6eG4QrP7MEoIxpXiWCEQkAIzDDXzfCbhORDqV0/RNVc0IThO8iseEqYgAdLsK7pwLI8bB/h3w2kh44UL4fqbf0RkTErw8I+gFrFHVdaqaB7wBjPDw84w5vkAknHUj/Hw+DHscdm2Ely+Fly6BDd/6HZ0xvvIyEbQGNpZ6nx1cVtZIEVksIhNFJMnDeIyByGjoeTPcvRCGPgq5q9zZwasjYdMCv6MzxhdeJgIpZ1nZC7NTgBRV7QZ8Brxc7o5ERovIPBGZl5ubW8VhmrAUFQN9bod7FsGQR1wSeG4QvH49bFnqd3TGVCsvE0E2UPobfiKQU7qBqu5Q1eKuoM8BPcrbkaqOV9VMVc1MSEjwJFgTpqLrQb9fwD1ZMOj3sP5reLYvvD3KnS0YEwa8TARzgTQRSRWRaOBaYHLpBiLSstTb4cAKD+Mx5vhiGsCA38AvsqD/vbD6U3i6D7x7G+xc53d0xnjKs0SgqgXAXcAnuAP8W6q6TETGisjwYLO7RWSZiGQBdwOjvIrHmAqp2wgG/wHuWQxn3+UGxvlHpuutvGuD39EZ4wnRGvY8dWZmps6bN6/S2w18aSAA00dNr9qATO22d4srdz3/Rdf3oMco6P9raNDypJsaE0pEZL6qZpa3znoWG3MicS3g4sfcU0Zn3egSwlMZ8MnvYZ89uGBqB0sExlREw0S49Ak3OE6XkfDt024shM8egQM7/Y7OmNNiicCYymicCpc9DXfOcTWNvv67Swhf/tmGzzQ1liUCY05F0zS48nlXy+iMATDjUTd85uynoSDP7+iMqRRLBMacjuad4JpX3fCZrbvDJw/A071hxQdW2M7UGJYIjKkKrTLgpvfghncgEA1v3uDqGOUs8jsyY07KEoExVSltCPzsG1fYLncljB8I790Oe3JOuqkxfrFEYExVC0QGC9stgL73wNKJ8FR3d0M5b7/f0RlzDEsExnglpiGc/wjcNdc9YTTjUZcQFr5qYymbkGKJwBivNUqBq16E/57m+iNMuhPGD7CBcUzIsERgTHVJ7g23fAYjn4eDu9zAOK9fB9vX+B2ZCXOWCIypTiLQ9Up3uWjwQ/D9V+5x049+az2UjW8sERjjh6i60P9X7obyWTfBnPHw1FnWIc34whKBMX6q38zVMPrZN2U6pE2xDmmm2lgiMCYUNO9UpkPajfDSMMhZ6HdkJgxYIjAmlBzVIW1VsEPaz2D3Jr8jM7WYJQJjQs1RHdJ+AUvfgX/0gC//Hxze53d0phayRGBMqDqmQ9r/uoRgHdJMFbNEYEyoK+6QdvOnR3dIWzfD78hMLeFpIhCRoSKySkTWiMj9J2h3pYioiJQ7nqYxBkjqdXSHtFeGBzukrfY7MlPDeZYIRCQAjAMuAjoB14lIp3LaxQF3A995FYsxtUa5HdL6WIc0c1q8PCPoBaxR1XWqmge8AYwop90fgceAQx7GYkztUm6HtAyYPc46pJlK8zIRtAY2lnqfHVxWQkTOApJU9YMT7UhERovIPBGZl5ubW/WRGlNTHdUhrQd88jsY1wuWT7YOaabCvEwEUs6ykt9MEYkA/g78+mQ7UtXxqpqpqpkJCQlVGKIxtUTpDmmRdeCtm6xDmqkwLxNBNpBU6n0iUHqYpjigCzBdRNYDfYDJdsPYmNNQXoe0d2+DjXPtDMEcV6SH+54LpIlIKrAJuBa4vnilqu4Gmha/F5HpwL2qOs/DmIyp/Yo7pHW9Er56HL59Bha/AfHJ0PkK6HIFtOjmbjwbg4dnBKpaANwFfAKsAN5S1WUiMlZEhnv1ucaYoOIOafethsuegabtYfY/4V/nwj8zXU/lbSv9jtKEANEadrqYmZmp8+ZV/qRh4EsDAZg+anrVBmRMTbJ/B6yYDMvedY+eotCsM3S53J0tNGnrd4TGIyIyX1XLvfTu5aUhY0yoqdcEMn/qpr1bYPkkWPoufPE/bmp1lksInS+H+KST78/UCpYIjAlXcS2g921u2rURlr3nzhQ+/YObkvq4+wmdLoO45n5HazxkicAY4779973bTTvWuoSw9D346Dfw8f3Qpi90GQkdh7uzClOrWNE5Y8zRmrSFc++DO2bBHd+5+b2b4YNfwN/awasjYdH/waHdfkdqqoidERhjjq9ZB2j2Oxj4AGxZ7O4nLH0X3r/djaR25vnu8lH7iyC6nt/RmlNkicAYc3Ii0DLdTUMehk3z3YA5y96DVR9CVCy0u9BdPjrzfIiK8TtiUwmWCIwxlSMCiZluuuBPsGG2SwrL33eJIToOOgxzSeGMgRAZ7XfE5iQsERhjTl1EBKT0ddNFj8H6mS4prJjiejPHxEOn4S4ptOnnej2bkGM/FWNM1QhEQtvz3DTs77D2C5cUlr4LC16BegnuUdQuV7hHUyPsWZVQYYnAGFP1IqOh/VA35R+E1dNcQlj4b5j7HMS1cp3W0oa4pBAd63fEYc0SgTHGW1F1odMINx3eC6s+dv0U5oyHb8dBRBQk9oTUc92UmOlKaZtqY4nAGFN96sRBt6vcdHgfbPwWvp/pppmPwYxHIbIuJPd2SSHlXFf2wu4teMr+dY0x/qhTH84c4iaAg7vgh1lHEsPnY93y6Dhoc07wjKE/NO9q9xeqmCUCY0xoqBsPHS52E8D+7bD+qyOJYfUnwXaNIKUfpA6AlP6Q0N7GVjhNlgiMMaGpXlN3Q7nz5e79nhxXOrs4MayYEmzX7MjZQuq50CjVEkMlWSIwxtQMDVpB+jVuAvhxfTApBJPD0oluecOk4P2FYGJo2Nq3kGsKSwTGmJqpUYqbuv/Ejce8fTV8P8NdTlr1ESx6zbVr3PbIGUPKuVA/wc+oQ5IlAmNMzScCCe3c1OtWKCqCbcuOnDEsfQfmv+jaNut05Iwhpa+75xDmPE0EIjIUeBIIABNU9dEy638G3AkUAvuA0aq63MuYjDFhICICWnR109l3QmEBbM46csYw/2X47lkgWEwvtb+7+Zzcxz3iGmY8SwQiEgDGAecD2cBcEZlc5kD/f6r6bLD9cOBxYKhXMRljwlQgEhJ7uKn/r6DgsKugWnx/4bt/wax/QEQktOru+i606ALNu0Czjq5TXC3m5RlBL2CNqq4DEJE3gBFASSJQ1T2l2tcD1MN4jDHGiazj+ia0OQcG/hbyDsDG79zZwvqvYeGrkL/ftZUIaJJ2JDG06Ope41rUmqeTvEwErYGNpd5nA73LNhKRO4FfAdHAeeXtSERGA6MBkpOTqzxQY0yYi46FtoPcBO4ew4/fw9alsGWpe904191rKBbbxCWE5l2OJImEDjWy7LaXiaC8VHnMN35VHQeME5HrgQeB/yqnzXhgPEBmZqadNRhjvBUR4YbsbNLW1UgqdnAXbF0WTBBL3Ou856HgUHC7SGjavtTZQxfXEzrEn1TyMhFkA0ml3icCOSdo/wbwjIfxGGPM6akbf2T8hWKFBbBz7ZHEsGWpu++w+M0jbeo3PzoxtOjiLjeFSA0lL6OYC6SJSCqwCbgWuL50AxFJU9XVwbfDgNUYY0xNEoh0ZS4S2kPXK48s378Dti5xZxBblrr52U9DUX5wuzpuTOiyl5diG1f7/4JniUBVC0TkLuAT3OOjL6jqMhEZC8xT1cnAXSIyBMgHfqScy0LGGFMj1Wvihuo8Y+CRZYX5sP0/RxLDlqVurIbizm8ADVofnRhadIXGZ0BEwLNQPT0vUdWpwNQyy8aUmr/Hy883xpiQEoiC5p3dxDVHlu/deiQxFF9eWvMZaKFbHxXrHmPt/2s3HnQVC40LVMYYE87imrupuCQ3QP4hyF3pEsPWZe4eRIQ3h2xLBMYYE4qiYqBVhps8ZqM7GGNMmLNEYIwxYc4SgTHGhDlLBMYYE+YsERhjTJizRGCMMWHOEoExxoQ5SwTGGBPmRLVmVXUWkVzgh1PcvCmwvQrDqSoWV+VYXJUXqrFZXJVzOnG1UdVy62HXuERwOkRknqpm+h1HWRZX5VhclReqsVlcleNVXHZpyBhjwpwlAmOMCXPhlgjG+x3AcVhclWNxVV6oxmZxVY4ncYXVPQJjjDHHCrczAmOMMWVYIjDGmDAXFolARJJE5EsRWSEiy0QkpIbIFJGAiCwUkQ/8jqWYiMSLyEQRWRn8dzvb75gAROSXwZ/hUhF5XURifIrjBRHZJiJLSy1rLCKfisjq4GujEInrL8Gf42IReU9E4kMhrlLr7hURFZGmoRKXiPxcRFYFf9ceC4W4RCRDRL4VkUUiMk9EelXV54VFIgAKgF+rakegD3CniHTyOabS7gFW+B1EGU8CH6tqByCdEIhPRFoDdwOZqtoFCADX+hTOS8DQMsvuBz5X1TTg8+D76vYSx8b1KdBFVbsB/wEeqO6gKD8uRCQJOB/YUN0BBb1EmbhEZBAwAuimqp2Bv4ZCXMBjwCOqmgGMCb6vEmGRCFR1s6ouCM7vxR3UWvsblSMiicAwYILfsRQTkQbAucDzAKqap6q7/I2qRCRQV0QigVggx48gVHUmsLPM4hHAy8H5l4HLqjUoyo9LVaepakHw7bdAYijEFfR34DeAL0+tHCeu24FHVfVwsM22EIlLgQbB+YZU4e9+WCSC0kQkBTgL+M7fSEo8gftDKPI7kFLOAHKBF4OXrCaISD2/g1LVTbhvZxuAzcBuVZ3mb1RHaa6qm8F9+QCa+RxPef4b+MjvIABEZDiwSVWz/I6ljHZAfxH5TkRmiEhPvwMK+gXwFxHZiPs7qLIzu7BKBCJSH3gH+IWq7gmBeC4BtqnqfL9jKSMS6A48o6pnAfvx5zLHUYLX3EcAqUAroJ6I3OhvVDWHiPwed5n0tRCIJRb4Pe4SR6iJBBrhLiPfB7wlIuJvSIA7U/mlqiYBvyR4xl4VwiYRiEgULgm8pqrv+h1PUF9guIisB94AzhORV/0NCYBsIFtVi8+aJuISg9+GAN+raq6q5gPvAuf4HFNpW0WkJUDwtdovKRyPiPwXcAlwg4ZG56G2uISeFfz9TwQWiEgLX6NysoF31ZmDO1uv9hvZ5fgv3O88wNuA3SyujGA2fx5YoaqP+x1PMVV9QFUTVTUFd9PzC1X1/Ruuqm4BNopI++CiwcByH0MqtgHoIyKxwZ/pYELgJnYpk3F/rARfJ/kYSwkRGQr8Fhiuqgf8jgdAVZeoajNVTQn+/mcD3YO/e357HzgPQETaAdGERiXSHGBAcP48YHWV7VlVa/0E9MPdaFkMLApOF/sdV5kYBwIf+B1HqXgygHnBf7P3gUZ+xxSM6xFgJbAU+DdQx6c4Xsfdp8jHHcRuBprgnhZaHXxtHCJxrQE2lvrdfzYU4iqzfj3QNBTiwh34Xw3+ji0AzguRuPoB84Es3D3OHlX1eVZiwhhjwlxYXBoyxhhzfJYIjDEmzFkiMMaYMGeJwBhjwpwlAmOMCXOWCIwxJsxZIjDGIyKy/lRLK4vIKBFpVRX7MuZkLBEYE5pG4eopGeM5SwSm1hORlODALBOCA9q8JiJDROSb4CAyvYLTrGC11VnF5TVE5Fci8kJwvmtw+9jjfE4TEZkW3Me/ACm17kYRmRMcVORfIhIILt8nIn8TkQUi8rmIJIjIlUAm8Fqwfd3gbn4ebLdERDp4+W9mwoslAhMuzsQNttMN6ABcj+uyfy/wO1zZinPVVVsdA/y/4HZPAGeKyOXAi8Btevx6PQ8BXwf3MRlIBhCRjsA1QF91g4oUAjcEt6kHLFDV7sAM4CFVnYgr73GDqmao6sFg2+3Bds8E4zamSkT6HYAx1eR7VV0CICLLcCOJqYgsAVJwA328LCJpuLpUUQCqWiQio3A1l/6lqt+c4DPOBa4IbvehiPwYXD4Y6AHMDVYzrsuRyqRFwJvB+Vc5Ul2yPMXr5hd/jjFVwRKBCReHS80XlXpfhPs7+CPwpapeHhy8aHqp9mnAPip2zb684l0CvKyqFRlI5ETFv4pjLsT+dk0VsktDxjgNgU3B+VHFC0WkIe6S0rlAk+D1++OZSfCSj4hchBvcBFwl0itFpFlwXWMRaRNcFwEU7/N64Ovg/F4g7jT+f4ypMEsExjiPAX8WkW+AQKnlfweeVtX/4EoBP1p8QC/HI8C5IrIAuIDggOyquhx4EJgmIotxg8m3DG6zH+gsIvNxNebHBpe/BDxb5maxMZ6wMtTG+EhE9qlqfb/jMOHNzgiMMSbM2RmBMZUkIj8F7imz+BtVvdOPeIw5XZYIjDEmzNmlIWOMCXOWCIwxJsxZIjDGmDBnicAYY8Lc/wcrzXgBwvXmjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axhline(y=0.75,color='r')\n",
    "plt.axvline(x=2,color='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we observe that the optimal max_depth parameter should be 2 since after 2, we start observing some overfitting and the recall score is around 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:   19.5s remaining:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:   31.1s remaining:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  20 | elapsed:   41.1s remaining:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:   50.0s remaining:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   55.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   55.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(100, 1500, 400)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(100, 1500, 400)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf = RandomForestClassifier(max_depth=2,class_weight='balanced',random_state=100) \n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with n_estimators\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axvline(x=500,color='r')\n",
    "plt.le\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we observe that the highest test score is when n_estimators=500 with lesser overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features\n",
    "\n",
    "Let's see how the model performance varies with ```max_features```, which is the maximum numbre of features considered for splitting at a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    5.7s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    8.1s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:   11.0s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:   12.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   14.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   14.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_features': [4, 8, 14, 20, 24]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': [4, 8, 14, 20, 24]}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=2,class_weight='balanced',random_state=100)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",n_jobs=-1,\n",
    "                 return_train_score=True,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features=24,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with max_features\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axvline(x=24,color='r')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we observe the highest test score with minimal overfitting when max_features=24."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   10.5s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   12.2s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': range(100, 500, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100, 500, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=2,class_weight='balanced',random_state=100)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",n_jobs=-1,\n",
    "                 return_train_score=True,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=100, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axvline(x=100,color='r')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, test score is maximum and less overfitting when min_samples_leaf=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   10.5s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   12.2s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_split': range(100, 500, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(100, 500, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=2,class_weight='balanced',random_state=100)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",n_jobs=-1,\n",
    "                 return_train_score=True,verbose=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=100,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with min_samples_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axvline(x=100,color='r')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal value of min_samples_split is 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'min_samples_leaf': [100,200,300],\n",
    "    'min_samples_split': [100, 200, 300],\n",
    "    'n_estimators': [100,300,500], \n",
    "    'max_features': [5,10,15,24]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\",random_state=100)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,scoring='recall',\n",
    "                          cv = 3, n_jobs = -1,verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   57.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed: 28.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'max_features': [5, 10, 15, 24],\n",
       "                         'min_samples_leaf': [100, 200, 300],\n",
       "                         'min_samples_split': [100, 200, 300],\n",
       "                         'n_estimators': [100, 300, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get best recall of 0.7661694119272076 using {'max_depth': 2, 'max_features': 24, 'min_samples_leaf': 100, 'min_samples_split': 100, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal recall score and hyperparameters\n",
    "print('We can get best recall of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=2, max_features=24,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=100, min_samples_split=100,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final=RandomForestClassifier(max_depth=2,max_features=24, min_samples_split=100,min_samples_leaf=100,n_estimators=100,class_weight=\"balanced\")\n",
    "rf_final.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics.loc['Random Forest with PCA without Sampling','Training Accuracy']=metrics.accuracy_score(y_train,rf_final.predict(X_train))\n",
    "model_metrics.loc['Random Forest with PCA without Sampling','Test Accuracy']=metrics.accuracy_score(y_test,rf_final.predict(X_test))\n",
    "model_metrics.loc['Random Forest with PCA without Sampling','Training Recall']=metrics.recall_score(y_train,rf_final.predict(X_train))\n",
    "model_metrics.loc['Random Forest with PCA without Sampling','Test Recall']=metrics.recall_score(y_test,rf_final.predict(X_test))\n",
    "model_metrics.loc['Random Forest with PCA without Sampling','Training Precision']=metrics.precision_score(y_train,rf_final.predict(X_train))\n",
    "model_metrics.loc['Random Forest with PCA without Sampling','Test Precision']=metrics.precision_score(y_test,rf_final.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression without PCA with sampling</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.871596</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.186470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest without PCA without sampling</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.954237</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.234681</td>\n",
       "      <td>0.035750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA without Sampling</td>\n",
       "      <td>0.770948</td>\n",
       "      <td>0.774503</td>\n",
       "      <td>0.798305</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.106706</td>\n",
       "      <td>0.107047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Training Accuracy  \\\n",
       "Logistic Regression without PCA with sampling           0.864997   \n",
       "Random Forest without PCA without sampling              0.894948   \n",
       "Random Forest with PCA without Sampling                 0.770948   \n",
       "\n",
       "                                               Test Accuracy  Training Recall  \\\n",
       "Logistic Regression without PCA with sampling       0.871596         0.864501   \n",
       "Random Forest without PCA without sampling          0.112485         0.954237   \n",
       "Random Forest with PCA without Sampling             0.774503         0.798305   \n",
       "\n",
       "                                               Test Recall  \\\n",
       "Logistic Regression without PCA with sampling     0.849802   \n",
       "Random Forest without PCA without sampling        0.988142   \n",
       "Random Forest with PCA without Sampling           0.786561   \n",
       "\n",
       "                                               Training Precision  \\\n",
       "Logistic Regression without PCA with sampling            0.865359   \n",
       "Random Forest without PCA without sampling               0.234681   \n",
       "Random Forest with PCA without Sampling                  0.106706   \n",
       "\n",
       "                                               Test Precision  \n",
       "Logistic Regression without PCA with sampling        0.186470  \n",
       "Random Forest without PCA without sampling           0.035750  \n",
       "Random Forest with PCA without Sampling              0.107047  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - Model Building using SMOTEENN (Combined) Sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:   50.7s remaining:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:   59.9s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 20, 2)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=True, scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(2, 20, 2)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(random_state=100)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axhline(y=0.75,color='r')\n",
    "plt.axvline(x=4,color='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal max_depth=4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:   29.7s remaining:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:  1.0min remaining:   49.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  20 | elapsed:  1.4min remaining:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:  1.8min remaining:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=4,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(100, 1500, 400)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(100, 1500, 400)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf = RandomForestClassifier(max_depth=4,random_state=100) \n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with n_estimators\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axvline(x=100,color='r')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal n_estimators=100 to compensate with the computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:   50.7s remaining:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:  1.0min remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=4,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_features': range(2, 24, 2)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': range(2,24,2)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf = RandomForestClassifier(max_depth=4,random_state=100) \n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\",\n",
    "                 return_train_score=True,n_jobs=-1,verbose=10)\n",
    "rf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features=22,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEHCAYAAAC9TnFRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV1bnw8d+TeZ4hMyRgmEGQMDtWRagDWlvrdKv13kutter1bd9qW2219nNtbXvb3qu2anntbbW2tlVRKaBValUIEGQIMyQBkkAIOSETmc96/9g7ySHkhBPMPifD8/18zufss/fa+zzZOTlP1lp7ryXGGJRSSqmzCQp0AEoppYYGTRhKKaV8oglDKaWUTzRhKKWU8okmDKWUUj4JCXQAAyUlJcXk5OQEOgyllPKvvXut54kTz2n3wsLCE8aYUb6UHTYJIycnh82bNwc6DKWU8q9LL7We1607p91F5JCvZbVJSimllE80YSillPKJJgyllFI+GTZ9GL1pa2ujrKyM5ubmQIeivIiIiCArK4vQ0NBAh6KUOgtHE4aILAF+AQQDLxhjnuyxfQzwWyDBLvOQMWaVve1h4F+BDuA+Y8ya/r5/WVkZsbGx5OTkICKf7odRA84YQ3V1NWVlZeTm5gY6HKXUWTjWJCUiwcDTwFJgCnCLiEzpUey7wJ+MMbOAm4Fn7H2n2K+nAkuAZ+zj9UtzczPJycmaLAYpESE5OVlrgEoNEU72YcwFDhhjio0xrcArwLIeZQwQZy/HAxX28jLgFWNMizGmBDhgH6/fNFkMbvr7UWrocLJJKhM44vG6DJjXo8z3gbUi8nUgGrjCY98NPfbN7PkGIrIcWA4wZsyYAQlaKaUGu/rmNirrWqisa2ZCQwtBIiT74X2dTBi9/evYc/KNW4AXjTE/FZEFwO9EZJqP+2KMeQ54DiA/P3/QTexx8uRJXn75Ze65555+7/vZz36Wl19+mYSEBK9lHn30US6++GKuuOIKr2UCLSYmhoaGBkpLS7nmmmsoKioKdEhKDVqt7W6O1zdTWddMZV0Lx2qbqaxvprK2uStBVNY109ja0bXPK8cbiA4PGfIJowzI9nidRXeTU6d/xeqjwBizXkQigBQf9x30Tp48yTPPPNNrwujo6CA42Hu3zKpVq856/Mcff/xTxefN2WJTSvWP221wnWrlWG0zx+ubOVbb/eVfWdfMsboWjtc1U93Yesa+YcFBjI4LJzUugsnpcVwycRRpcRGk2o/z/5lAWLB/7pBwMmFsAvJEJBcox+rEvrVHmcPA5cCLIjIZiACqgJXAyyLyMyADyAM2OhirIx566CEOHjzIzJkzufLKK7n66qt57LHHSE9PZ+vWrezatYvrr7+eI0eO0NzczP3338/y5cuB7qFOGhoaWLp0KRdeeCEff/wxmZmZvPHGG0RGRnLnnXdyzTXX8PnPf56cnBzuuOMO3nzzTdra2nj11VeZNGkSVVVV3HrrrVRXVzNnzhxWr15NYWEhKSkpp8UaExPDgw8+yJo1a/jpT39KZGQkDz74IA0NDaSkpPDiiy+Snp7OgQMHuPvuu6mqqiI4OJhXX32V1NRUli1bRk1NDW1tbTzxxBMsW9azu0qp4autw80nh09SVnPqtJrAsbpmjte1cLy+mbaO0xtBRCA5Opy0+HAy4iOYNSaB1NgI0uLDGR0XYS9HkBgV2ndfX6j//rlzLGEYY9pF5F5gDdYlsyuMMTtF5HFgszFmJfB/gOdF5D+wmpzuNNacsTtF5E/ALqAd+JoxpqP3d/LNY2/uZFdF3ac5xBmmZMTxvWunet3+5JNPUlRUxNatWwFYt24dGzdupKioqOsy0hUrVpCUlERTUxNz5szhxhtvJDn59Mrl/v37+cMf/sDzzz/PTTfdxF/+8hduv/32M94vJSWFLVu28Mwzz/CTn/yEF154gccee4zPfOYzPPzww6xevZrnnnuu11gbGxuZNm0ajz/+OG1tbVxyySW88cYbjBo1ij/+8Y985zvfYcWKFdx222089NBD3HDDDTQ3N+N2uwkLC+O1114jLi6OEydOMH/+fK677jrt0FbDWlNrBx/sr2JN0THe3V1JXXN717bY8BBS4yNIjQtn3rgkUuMi7FpBeFfNYFRsOKF+qhkMFEfvw7DvqVjVY92jHsu7gEVe9v0h8EMn4wuEuXPnnnbPwS9/+Utee+01AI4cOcL+/fvPSBi5ubnMnDkTgNmzZ1NaWtrrsT/3uc91lfnrX/8KwIcffth1/CVLlpCYmNjrvsHBwdx4440A7N27l6KiIq688krAaqJKT0+nvr6e8vJybrjhBsC66Q6sGyS//e1v88EHHxAUFER5eTmVlZWkpaX17+QoNcjVNbfx/p7jrC46xrq9VTS1dRAfGcqVU9JYPDWVvNExpMZFEB0+PO+JHp4/VS/6qgn4U3R0dNfyunXrePfdd1m/fj1RUVFceumlvd6TEB4e3rUcHBxMU1NTr8fuLBccHEx7u/XfjlVhO7uIiIiufgtjDFOnTmX9+vWnlamr672G9tJLL1FVVUVhYSGhoaHk5OTovRVq2KhuaOGdXZWs3nmMjw6coK3DMCo2nBtnZ7JkajrzxiUNuZrCuRoxCSMQYmNjqa+v97q9traWxMREoqKi2LNnDxs2bPBa9lxdeOGF/OlPf+Jb3/oWa9eupaam5qz7TJw4kaqqKtavX8+CBQtoa2tj3759TJ06laysLF5//XWuv/56Wlpa6OjooLa2ltGjRxMaGsr777/PoUM+j5as1KBUcbKJNTuPsbroGJtKXbgNZCdF8uVFuVw1NY1Z2QkEBTnQ5NrWDE011qP5ZPdy00nv6w/vgbDosx97AGjCcFBycjKLFi1i2rRpLF26lKuvvvq07UuWLOFXv/oVM2bMYOLEicyfP3/AY/je977HLbfcwh//+EcuueQS0tPTiY2N7XOfsLAw/vznP3PfffdRW1tLe3s7DzzwAFOnTuV3v/sdX/nKV3j00UcJDQ3l1Vdf5bbbbuPaa68lPz+fmTNnMmnSpAH/OdTQYIzhiKuJbWUniYsM5bzRMWTERwyJ/qziqgZW7zzGmqJjbCurBWBiaiz3fiaPJVPTmJwe69vP4XZDS20fX/QnvSeA9j5q5hIEkYkQkWA9R6VA8nkQUw2hUQN0FvomvjZZDHb5+fmm5wRKu3fvZvLkyQGKaHBoaWkhODiYkJAQ1q9fz1e/+tWuTvjBQn9PQ1dru5udFbUUHqqh8FANmw/VUFXfclqZqLBgxo+K4bzR1qNzeWxyVECbcowx7Dpax5qiY6zeeYx9lQ0AnJ+dwJKpaVw1NZVxo2L6PkhbM5R+CPvXQPE/oKESmmvp5baxbqHREGl/6UcmQkR89/Jp6xNOXx8WC0G9nK9PP4FSoTEm35eyWsMY5g4fPsxNN93UdTXT888/H+iQ1BB28lQrWw7XsLnUSg7bjpykpd0NQFZiJIvGJzM7J4lZ2Qk0tLRz4HgDB443cLCqgQ3F1bz2SXnXsUKDhbHJ0ZznkUzOGx3DuFHRRIU589Xkdhs+OVLDajtJHHE1ESQwNzeJ7187hcVT08hIiOz7IHUVsH8t7FsDxeug7RSERELuRTDukt6/7D2TQEiYIz+bP2jCGOby8vL45JNPAh2GGoKMMZRWn2JzqaurBrH/uPVfeEiQMDUjjtvmjWX22ETycxJJjYs44xjzx51+xV9DSzsH7SRyoMp63ne8nnd2V9Lh7v6vPDMh8rQkct7oGM4bFUNidP+/bNs63BQUu1i98yhrdlZSVd9CWHAQi85L5t7LzuOKyakkx4R7P4DbDRVbYN9qK0kc226tjx8DM2+FCUsg50IIPUuiGQY0YSilAGhp76CovJbNpVZy2HK4hhMN1p3HcREhzB6byLKZGcwem8TM7AQiw/p/w1hMeAjnZydwfvbpQ960trs5VN3YVSPpTCYFJdU0t7m7yiVHhzHeI4F0JpP0Hv0kzW0d/HP/CVbb90jUNrURFRbMZRNHs3hqKpdNGk1cRB9zsDTXwsH3YN9aqzZx6oTVh5A9D674PuRdBaMnW3ffjSCaMJQaoaobWthy+CSbD7koLK1he3ktrXbz0tjkKC6eMIr8sUnk5yRy3qgYZ64KsoWFBJGXGkte6ukXZLjdhvKTTRyoauiumRxvYNWOo5w81dZVzrOfpKW9g3V7qzjVat0jccXkVJZMS+OivBQi+ror+sQBuxaxGg6vB3e71YSUd6WVIM67HKKSnDoFQ4ImDKVGAGMMB6saKTzk6qpBFJ9oBKy+hGmZ8dyxYCyzxyYxe2wio2L7aKLxo6AgITspiuykKC6bOLprvTGG6sbW7hqJRz+JMfC5C3y4R6K9FQ59ZPdHrAZXsbV+9BRYcK/V1JQ1B4L1a7KTngmlhiFjDHsr63l/TxWFh6w+iBr7P/LEqFBmj03kC/nZzB6byIys+L7/8/ZFWxMcK4KjW6HiE6gsguBwiBkNsWkQkwaxqac/R6dA0Lm9r4iQEhNOSkz4Gf0kfWo43p0gDq6D1norztyLYf49kLcYEseeU0wjgSYMB32a4c0Bfv7zn7N8+XKiovxzjTV0D3qYkpLSNTS5Gho6k8Sq7Ud5e8dRDlZZNYhxo6K5YnIq+TmJzB6bxPhR0Z/uvoi2ZishVHwCFVutJHF8N3QO9xaVDGkzwLih+oB12WnzyTOPI0EQPdpOIPYjNs3jOa17W8g51njcbji2zeqs3rfG6rwGiM2A6TdatYjci/1249tQpwnDQX0Nb+6Ln//859x+++1nTRg6HPnI1VuSCBKYl5vMlxflsnhqKqNjz7x6yWdtzVC5E45+YieIbVC122rfB4hMgoxZMOEq6zl9JsRnndkZ3NZs3aPQUAn1x05/7lw+ug0aq6xE01Nkopek0iO5hMdCS711ueu+NVZtoqESEMjKh8981+qPSJs+4jqsB4ImDAf1HN78qaee4qmnnuJPf/oTLS0t3HDDDTz22GM0NjZy0003UVZWRkdHB4888giVlZVUVFRw2WWXkZKSwvvvv3/asXNycrjrrrtYu3Yt9957L3PmzOFrX/saVVVVREVF8fzzzzNp0iQqKyu5++67KS622mefffZZFi5c6HVYdTX4nS1JXDU17dz6INpb7JrD1u6mpeOeySHRSgp5V0LGTGs5Ptu3L97QCKup52zNPR3t1hVJ3pJKQyUcWg8Nx6DjzLkjCI221rvbIDzO6qjOu8qKOTrlzPKqX0ZOwvjbQ3Bsx8AeM206LH3S6+aew5uvXbuW/fv3s3HjRowxXHfddXzwwQdUVVWRkZHB22+/DVhjTMXHx/Ozn/2M999//4y5KzpFRETw4YcfAnD55Zfzq1/9iry8PAoKCrjnnnt47733uO+++7jkkkt47bXX6Ojo6Gpi8mVYdTV4DHiSaG+B47u6m5W6koN95VFEgpUQFn7dqjVkzIKEMc7/Vx4cYtUYYs8y0rEx1lAaZySVSusY510JY+ZDcB+Xzqp+GzkJYxBYu3Yta9euZdasWQA0NDSwf/9+LrroIr7xjW/wrW99i2uuuYaLLrrIp+N98Ytf7DrOxx9/zBe+8IWubS0t1vAM7733Hv/7v/8LWKPYxsfHA74Nq64CyxjDvsoG3t5ecUaSuHNRLkt8TRLtrd3JoatTepdHcoi3EsKCr3XXHBLGDu4mGxHrEteoJOt+COUXIydh9FET8BdjDA8//DBf+cpXzthWWFjIqlWrePjhh1m8eDGPPvpoL0c4XedQ6W63m4SEBJ/HiPJ1WHXlfwOSJIyxEsPuN62bzyp3djffhMdbSWHBPd01h8ScwZ0c1KAxchJGAPQc3vyqq67ikUce4bbbbiMmJoby8nJCQ0Npb28nKSmJ22+/nZiYGF588cXT9vfWJNUpLi6O3NxcXn31Vb7whS9gjGH79u2cf/75XH755Tz77LM88MADdHR00NjY6Jdh1ZXvBiRJuDvgSIGVJHa/CbVHQIKtZpl5d3fXHBJzNTmoc6YJw0E9hzd/6qmn2L17NwsWLACsebR///vfc+DAAb75zW8SFBREaGgozz77LADLly9n6dKlpKenn9Hp3dNLL73EV7/6VZ544gna2tq4+eabOf/88/nFL37B8uXL+c1vfkNwcDDPPvusX4ZVV33rShI7jvL29opzSxLtrVDyAex5E/a8bV1hFBwO4z8Dlz4ME5eO+DuT1cDS4c1VwI2U35O3JDE3N4mrZ2T4liRaG+HA361axL411rwLYTHWDWeTr7WuBgrve74TNczo8OZKDX0dbsOJhhbKapr4x76qM5KEzzWJppNWcti90koW7U3WJa6Tr7Ue4y61LltVymGaMJQ6B63tbo7XN3OstpmjtR7PdU1dr4/Xt3QN2d2VJBbmcNW0tLPfTNdw3Gpm2v0mlPzDuhciNh1m3W4libGLdIwj5XfD/hNnjBkS00OOVIOxSbS5raPXBOD5XN3YQs/Qo8KCSY+PID0+kkXnpZAeH0FafARpcRFMz4o/e5KoOQR73oLdb1mjpWKsTur598Dk6yBzdu8zrinlJ8M6YURERFBdXU1ycrImjUHIGEN1dTUREf5rTmloaedYrZUETk8ETRyra+FYbVPXIH2e4iNDSY+PIDUugqkZcaTFR9gJIbIrMcSGh/T/c1a112pq2v2mNTQGQOo0uORbVk0idape1aQGjWGdMLKysigrK6OqqirQoSgvIiIiyMrKGvDjut2G0upGdpTXsr2slh1ltew+Vkd9c/sZZZOjw0iLjyAzIYLZYxNIj48kLS6iu4YQHzFwU4Z63iOx+004sc9anzUHrnwcJl0DyeMH5r2UGmDDOmGEhoaSm5sb6DCUw4wxHHE1sb38JDvKrARRVF5LfYuVHMJDgpiaEcf1MzPJSozsaiZKj49kdFz4px/a+2y83SORswjmLodJV0NchrMxKDUAhnXCUMOPMYaK2mZ2lJ20ag52DaK2yWpGCgsOYnJ6LMtmZTAjM4HpWfHkjY4hxNskOgOprQmqD0L1fjjR+dhnDfHd2gDBYfY9Eg/BhKUQrUOxqKFFE4Ya1Crrmu0mpZNsL7ealqobrWEuQoKEiWmxfHZ6GtMzE5iRFc+E1FjCQhxMDsZYg92d2Hd6YqjeDyePAB494XFZkJIHM2+15oLOWwwRcc7FppTDNGGoQeNEQ0tXk9KOcqsGcbzeGkQxSGBCaiyfmTSaGVnxTM9KYFJarHPNSZ21hc4aQs/aQqfQKEg+D7LmwszbrOWUCVY/hE7Ko4YZTRgqIGoaW9lR3tmkZPU9VNRaAyCKwPhRMVx4XgrTs+KZkRXP5PS4get47tSf2kJ8tpUMZt5qJ4TzrNpDbIZe6qpGDE0Yym/qmtv4+Tv7eWf3MY64mrrW5yRHMTsniS9nxjM9K56pGXHERgzgPAbGQE2pdXVSb30LnUKjrZpBZ20hJQ+S87S2oJRNE4ZynDGGt7Yf5fG3dlHd0MIVk1O5de5YZmTFMy0jnvioAZ7kprkWyrdA2WYo32w9nzrRvb2rttCZFOxmpLgMvedBqT5owlCOOlx9ikfeKOIf+6qYlhnHb+7IZ0ZWwsC9QUe7Ncd02SYoK7QSRNVeupqTUiZY801nzobMC6zXWltQ6pw4mjBEZAnwCyAYeMEY82SP7f8FXGa/jAJGG2MS7G0dQOecqoeNMdc5GasaWK3tbp7/ZzG//Pt+QoKER6+ZwpcWjP30l7fWHbVrDXaCqNgCbaesbZFJ1g1w0260E8RsiBzA5KTUCOdYwhCRYOBp4EqgDNgkIiuNMbs6yxhj/sOj/NeBWR6HaDLGzHQqPuWcTaUuvvPaDvZVNrBkahrfu24K6fGR/T9Q6ylruIyyTXaSKIS6MmtbUCikz4BZ/wJZ+dZDJwdSylFO1jDmAgeMMcUAIvIKsAzY5aX8LcD3HIxHOezkqVae/NseXtl0hMyESF74Uj5XTEn1bWe3G1wH7ZqD3fdwrAhMh7U9YQyMmQeZX7NqEWnTdUhvpfzMyYSRCRzxeF0GzOutoIiMBXKB9zxWR4jIZqAdeNIY83ov+y0HlgOMGTNmgMJW/WWM4fWt5Tzx1m5ONrWx/OJx3H95HtHhfXy8TrmgvPD0BNFca20Li7X6Gy58wEoOmbMhZrR/fhillFdOJoze2ga8jWV9M/BnYzr/nQRgjDGmQkTGAe+JyA5jzMHTDmbMc8BzYM24NxBBq/4prmrgkTeK+OhANTOzE/jdDdOZkuHlbubWU/DBj2HXSqs2ASBBMHoKTLneblqaY3VMBzk8vpNSqt+cTBhlQLbH6yygwkvZm4Gvea4wxlTYz8Uisg6rf+PgmbuqQGhp7+DZdQd55v2DhIcG8YPrp3Hr3DEEB3npQyj9EN64F2pKIO8qayKgrDmQMQvCY/wbvFLqnDiZMDYBeSKSC5RjJYVbexYSkYlAIrDeY10icMoY0yIiKcAi4McOxqr64eODJ/ju60UUVzVy7fkZPHLNZO+TA7U0wLvfh03PQ2IO3PEW5F7kz3CVUgPEsYRhjGkXkXuBNViX1a4wxuwUkceBzcaYlXbRW4BXzOlTr00Gfi0ibiAIqw/DW2e58pPqhhZ+uGo3f91SzpikKH5711wumTDK+w4H34c377OG2Zh/D3zmu3oPhFJDmKP3YRhjVgGreqx7tMfr7/ey38fAdCdjU75zuw2vFh7hP/+2h4bmdr522Xi+/pk87wP/NdfC2kdgy2+tu6jvWg1j5vs3aKXUgNM7vVWf9lfW853XithY6mJOTiI/vGE6E1Jj+9jhHXjzfqg/Covuh0sfhtBzuAdDKTXoaMJQvWpu6+C/39vPcx8UExUWwo9unM4XZmcT5K1Tu6kGVn8btr0MoybBTb+DrNn+DVop5ShNGOoMH+yr4ruvF3HYdYrPzcrk21dPJiUm3PsOe1bBW/8BjVVw8TetR0gf5ZVSQ5ImDNXleH0zP3hrN29uq2BcSjQv/9s8Fp6X4n2Hxmr42/+Foj9D6nS47U+Qfr7/AlZK+ZUmDIXbbXh542F+tHoPLW1uHrgij7svGd/3bHY7X4dV34Cmk3DZd2DRAxAS5r+glVJ+pwljhNt9tI5vv7aDTw6fZMG4ZJ64YRrjR/VxI13DcStR7HoD0mfCl96A1Kn+C1gpFTCaMEaoU63t/OLd/bzwYQnxkaH87KbzuWFWJuJttFdjYMefrSao1ga4/Huw8D4I1o+QUiOF/rWPILWn2thQUs36g9Ws2XmMo7XN3Dwnm4eWTiIhqo/mpLqj8PaDsHeVNZzHsqdh1ET/Ba6UGhQ0YQxj9c1tbCp1sf5gNR8frGbX0TqMgYjQIObkJPGLm2cxNzfJ+wGMga0vw5qHob0FFv8Q5n9VBwZUaoTShDGMnGptZ3NpDeuLrQRRVF5Lh9sQFhzErDEJPHD5BBaMT+b87HjCQ87ypV9bZt2Ad+BdGLMQlv0PJI/3zw+ilBqUNGEMYc1tHWw5XMOGg9WsL65m65GTtHUYQoKE87MTuOfS8SwYl8wFYxP7vuLJkzFQ+KI1tIdxw9KnYM6/QdCnnFpVKTXkacIYQlrb3WwrO8n6g1Y/ROHhGlrb3QQJTM+M564Lc1k4PoX8sYl9T17kTU0prLwPSv4BuRfDdf9tjTCrlFJowhjU2jvcFFXU8fHBE6w/WM3m0hqa2joQgclpcfzL/LEsHJ/MnNwk4iJCz/2N3G7Y9II1DLkEwTU/h9l36vzYSqnTaMIYRNxuw66jdWyw+yA2lrhoaGkHYEJqDDflZ7FgfArzxyX1fVVTf1QfhJVfh0MfwfjL4dpfQEL22fdTSo04mjACyBjDvsoG1h88wfriajYUu6htagNgXEo0183MYOH4ZOaPS+57LKdz4e6ADc/Ce09AcBgsewZm3qq1CqWUV5owAuina/fxP+8fACA7KZKrpqaycHwK88clkxbvZQa7T6OlHiq2Qnmhdad2xRaYsBSu+S+ISx/491NKDSuaMALojW3lzMtN4idfOJ/spKiBPXh7KxzfaSWH8k+s56o9gD2xYdI4+NwLMP3zWqtQSvlEE0aAVJxs4oiriTsX5n76ZOF2g6vYSgoVW6zno9uho8XaHpUCmbNh6g2QeQFkXADRyZ/+h1BKjSiaMAJkY4kLgHl93WntTf0xu+awpTtJNNda20KjIGMWzP13K0lkzoaEMVqLUEp9apowAqSgpJrYiBAmp8f1XbC5Dio+6a45lG+BunJrmwRD6hS75mAnh5SJOiCgUsoR+s0SIAXFLubkJBHsOeVpewtUFtk1BztBnNhHV79DYi6MWdCdHNKmQ9gA930opZQXmjAC4Hh9M8UnGvnSzDjY9opdcyiEYzugo9UqFD3KSgrTP9/d7xB1Ds1XSik1QDRhBEBn/8Wy8p/Bh29CaLTV7zDv7u7aQ3yW9jsopQYVTRgBUFDsIiosiITjBTDlevj8Ch0yXCk16OkQpAGwscTF0owmpPE4jLtEk4VSakjQhOFnrsZW9lbW89n4UmvFmAUBjUcppXylCcPPOvsvZrh3Q0SCdRmsUkoNAZow/GxjiYvwkCCSXZ9YtQudmEgpNUTot5WfFZRUc2mmEFS9H8bMD3Q4SinlM00YflTb1Mauo3VcnXjIWqH9F0qpIUQThh8VHnJhDOTLXggOh4yZgQ5JKaV8pgnDjwqKXYQGC2m1n1g354UM8KRISinlIEcThogsEZG9InJARB7qZft/ichW+7FPRE56bLtDRPbbjzucjNNfNpS4mJsZQdCx7dp/oZQachy701tEgoGngSuBMmCTiKw0xuzqLGOM+Q+P8l8HZtnLScD3gHyskfcK7X1rnIrXaY0t7RSV1/LDmS443g5jFwY6JKWU6hcnaxhzgQPGmGJjTCvwCrCsj/K3AH+wl68C3jHGuOwk8Q6wxMFYHVd4qIYOt2F+8D5AIGtOoENSSql+cTJhZAJHPF6X2evOICJjgVzgvf7sKyLLRWSziGyuqqoakKCdUlBSTXCQkF2/DVKnQmRCoENSSql+cTJh9DbUqvFS9mbgz8aYjv7sa4x5zhiTb4zJHzVq1DmG6R8FxS5mZMQQXLFZ+y+UUkOSkwmjDMj2eJ0FVHgpezPdzVH93XfQa27rYFvZSa5NrYbWBsxs6dUAABd6SURBVL3/Qik1JDmZMDYBeSKSKyJhWElhZc9CIjIRSATWe6xeAywWkUQRSQQW2+uGpC2Ha2jrMFwYfsBaoTUMpdQQ5NhVUsaYdhG5F+uLPhhYYYzZKSKPA5uNMZ3J4xbgFWOM8djXJSI/wEo6AI8bY1xOxeq0gmIXIpDTuAPix1iTIyml1BDj6ARKxphVwKoe6x7t8fr7XvZdAaxwLDg/2ljiYkpaLGHlBZB7caDDUUqpc6J3ejuspb2DLYdrWJLZDA3HtDlKKTVk6RStDtteVktLu5tLIkqtFdrhrZQaovpMGCLyJt4vhcUYc92ARzTMdE6YNKG1CCLiYdSkAEeklFLn5mw1jJ/4JYphbENxNRNTY4mo2AjZ83XCJKXUkNVnwjDG/MNfgQxHbR1uCg/V8C8zoqFoH8y8NdAhKaXUOTtbk9QO+m6SmjHgEQ0jOyvqONXawRUxpdYK7b9QSg1hZ2uSusYvUQxTBcXVAExt22lPmDQrwBEppdS5O1uT1CF/BTIcFZS4GJcSTdSxTZB5gU6YpJQa0nzqgRWR+SKySUQaRKRVRDpEpM7p4IayDrdhU6mLC3Oi4OhWvf9CKTXk+XrJzv9gDeGxH4gE/g34b6eCGg52H62jvrmdxfHl4G7X/gul1JDn8417xpgDIhJsD0H+/0TkYwfjGvIK7PsvZrh3AwLZcwMbkFJKfUq+JoxT9oizW0Xkx8BRINq5sIa+guJqspMiiTu+GUZPgcjEQIeklFKfiq9NUv9il70XaMSaq+JGp4Ia6tx2/8X8nAQ4slH7L5RSw4KvNYwTQKsxphl4TESCAb3kx4v9xxuoOdXG4uQTsKte+y+UUsOCrzWMvwNRHq8jgXcHPpzhoaDEuv9ituy1VmgNQyk1DPiaMCKMMQ2dL+zlqD7Kj2gFJS7S4yNIrC6EuCxIyD77TkopNcj5mjAaReSCzhciMhtociakoc0YQ0Gxi3k5icjhDVq7UEoNG772YTwAvCoiFfbrdOCLzoQ0tBWfaOREQwuXpTXD3qMwVvsvlFLDg08JwxizSUQmARMBAfYYY9ocjWyI6pz/Yn5IZ/+FJgyl1PDg69AgUcC3gPuNMTuAHBHRgQl7UVBcTUpMOKNrPoHweBg1OdAhKaXUgPC1D+P/Aa1A57/LZcATjkQ0hBljKChxMS83ye6/mKcTJimlhg1fv83GG2N+DLQBGGOasJqmlIeymiaO1jZzcZbAib3a4a2UGlZ8TRitIhKJPZmSiIwHWhyLaojaYM9/sSi82Fqh/RdKqWHkrJ3eIiLAr4DVQLaIvAQsAu50NrShp6DERWJUKJm1GyA4DDIuOPtOSik1RJw1YRhjjIjcDywG5mM1Rd1vjDnhdHBDzcYSF3NykpAjG6xkERoR6JCUUmrA+NoktQEYZ4x52xjzliaLMx2tbeKw6xQLx0ZDxSfaf6GUGnZ8vXHvMuArInIIa7Rawap8zHAssiGmoNi6/+Li6MPgbtP+C6XUsONrwljqaBTDQEGJi9iIEHIat1srdMIkpdQw4+ud3oecDmSoKyipZk5OEkFHNlg360UlBTokpZQaUHpX2QA4Xt9McVUj83PirQmTdPwopdQwpAljAHSOH3VxfBW01Gn/hVJqWNKEMQA2lriICgsmr2WHtUKvkFJKDUOOJgwRWSIie0XkgIg85KXMTSKyS0R2isjLHus7RGSr/VjpZJyfVkGxi9ljEwk+UgBxmRCvEyYppYYfX6+S6jd73u+ngSuxBivcJCIrjTG7PMrkAQ8Di4wxNSIy2uMQTcaYmU7FN1Bcja3srazn2hlpsHU9jF0IosNsKaWGHydrGHOBA8aYYmNMK/AKsKxHmX8HnjbG1AAYY447GI8jNpVa/RcXjW6G+qPaf6GUGracTBiZwBGP12X2Ok8TgAki8pGIbBCRJR7bIkRks73++t7eQESW22U2V1VVDWz0PioodhEeEsSU9p3WCk0YSqlhyrEmKXof/tz08v55wKVAFvBPEZlmjDkJjDHGVIjIOOA9EdlhjDl42sGMeQ54DiA/P7/nsf2ioKSaWWMSCC1bY02YNFonTFJKDU9O1jDKAM/e3yygopcybxhj2owxJcBerASCMabCfi4G1gGzHIz1nNQ1t7HraB3zcpPh8Hrr7u6g4ECHpZRSjnAyYWwC8kQkV0TCgJuBnlc7vY41ThUikoLVRFUsIokiEu6xfhGwi0Fmc6kLY2BRpkDVHr2cVik1rDnWJGWMaReRe4E1QDCwwhizU0QeBzYbY1ba2xaLyC6gA/imMaZaRBYCvxYRN1ZSe9Lz6qrBoqDYRWiwMNPss1Zo/4VSahhzsg8DY8wqYFWPdY96LBvgQfvhWeZjYLqTsQ2EghIX52clEFaxGoJCIVMnTFJKDV96p/c5amxpZ0d5LfPGJcHhDZAxC0IjAx2WUko5RhPGOSo8VEOH27AgOxrKt+iAg0qpYU8TxjnaWOIiOEi4ILREJ0xSSo0ImjDOUUFJNdMy44k6utFakT0vsAEppZTDNGGcg+a2DrYdqWV+rt1/MWqSTpiklBr2NGGcgy2Ha2jtcDN3rD1hkt5/oZQaATRhnIONJS5EYG7McWip1f4LpdSIoAnjHBQUu5iSHkds5SZrhSYMpdQIoAmjn1raO9hyuIa5nf0XsRmQMCbQYSmllOM0YfTTjrJaWtrdzMtJsgYcHDNfJ0xSSo0ImjD6qaDEmjBpfvIpqCvX5iil1IihCaOfNhRXMzE1loQThdYKvUJKKTVCaMLoh/YON4WHOvsv1kN4HKRODXRYSinlF5ow+qGooo5TrR3dAw7qhElKqRFEE0Y/FBRXAzAvPQiO79LmKKXUiKIJox82lrgYlxLNKNdWa4V2eCulRhBNGD7qcBs2lrrs5qj11oRJGTphklJq5NCE4aPdR+uob25nXm6yPWHSTAiLCnRYSinlN5owfLTRvv9ibnYUVGzR/gul1IijCcNHBSXVZCdFktG4BzpaYczCQIeklFJ+pQnDB263YWOJy26OWm+t1AmTlFIjjCYMH+w/3kDNqbbuG/ZSJkJ0cqDDUkopv9KE4YONJdb9F/NzEuFwgfZfKKVGJE0YPthQ4iI9PoLs9lKdMEkpNWJpwjgLYwwFxS7m5iYhRzZYK7WGoZQagTRhnEXJiUZONLR0338Rmw6JOYEOSyml/E4Txll0zn/RNeCgTpiklBqhNGGcRUFxNSkx4YwLdUHtEe2/UEqNWJow+mCMoaDExbzcJORwgbVS+y+UUiOUJow+lNU0cbS2uXvAwbBYGK0TJimlRiZNGH3Y0Dn/RWeHd/YcCA4JcFRKKRUYmjD6sLHERUJUKHmx7faESdp/oZQauRxNGCKyRET2isgBEXnIS5mbRGSXiOwUkZc91t8hIvvtxx1OxulNQYmLuTlJBJVvAowmDKXUiOZY+4qIBANPA1cCZcAmEVlpjNnlUSYPeBhYZIypEZHR9vok4HtAPmCAQnvfGqfi7elobROHXae4Y2EOHH4bgkIgc7a/3l4ppQYdJ2sYc4EDxphiY0wr8AqwrEeZfwee7kwExpjj9vqrgHeMMS572zvAEgdjPUPn/BfzOgccTNcJk5RSI5uTCSMTOOLxusxe52kCMEFEPhKRDSKypB/7IiLLRWSziGyuqqoawNBhQ7GL2IgQJo8Kg/JCvZxWKTXiOZkwersd2vR4HQLkAZcCtwAviEiCj/tijHnOGJNvjMkfNWrUpwz3dAUl1czJSSL42DZ7wiTtv1BKjWxOJowyINvjdRZQ0UuZN4wxbcaYEmAvVgLxZV/HVNW3UFzV2D3/BWgNQyk14jmZMDYBeSKSKyJhwM3Ayh5lXgcuAxCRFKwmqmJgDbBYRBJFJBFYbK/zi9P7LzZAygSITvHX2yul1KDk2FVSxph2EbkX64s+GFhhjNkpIo8Dm40xK+lODLuADuCbxphqABH5AVbSAXjcGONyKtaeCkqqiQoLZlpGrJUwplznr7dWSqlBy9Hblo0xq4BVPdY96rFsgAftR899VwArnIzPm4JiF7PHJhJavQ+aT2r/hVJKoXd6n6GmsZW9lfXdl9OC9l8opRSaMM6wsbRz/gt7/KiYVEjMDXBUSikVeJoweigodhEeEsSMrHidMEkppTxowuhhY2k1s8YkEN54FGoPw5iFgQ5JKaUGBU0YHuqa29hVUdc9nDlo/4VSStk0YXjYXOrCbfCYMCkGUqcFOiyllBoUNGF4KChxERoszMpOtGoYWTphklJKddKE4aGg2MX5WQlEdtRD5U69/0IppTxowrA1trSzo7zWao4q65wwSfsvlFKqkyYM25bDNXS4DXNzk63+i6AQyMoPdFhKKTVoaMKwFRS7CA4SZo+1+y/Sz4ew6ECHpZRSg4YmDFtBSTXTMuOJCe6wJ0zS/gullPKkCQNobutg25Faa/yoiq3Q3qz9F0op1YMmDOCTwydp7XCfPuBgtiYMpZTypAkDqzlKBPJz7AmTks+DmIGd8lUppYY6TRhYHd5T0uOIDw+GIxu0OUoppXox4hNGa7ubLYdrrPm7T+yDphodcFAppXox4hNGzalW5uYmcVFeik6YpJRSfRjxAyWlxkXwu3+dZ73463qIHg1J4wIblFJKDUIjvoZxmsPrdcIkpZTyQhNGp9pyOHlYb9hTSikvNGF0OqITJimlVF80YXQ6vAFCoyFtRqAjUUqpQUkTRqfD6yFbJ0xSSilvNGEANNfCsSLtv1BKqT5owgA4ohMmKaXU2WjCAKs5SoIhUydMUkopbzRhgD1h0gwIjwl0JEopNWhpwmhvhfLNOn6UUkqdhSaMUycgey7kXhzoSJRSalDTa0jjMuCONwMdhVJKDXpaw1BKKeUTRxOGiCwRkb0ickBEHupl+50iUiUiW+3Hv3ls6/BYv9LJOJVSSp2dY01SIhIMPA1cCZQBm0RkpTFmV4+ifzTG3NvLIZqMMTOdik8ppVT/OFnDmAscMMYUG2NagVeAZQ6+n1JKKQc5mTAygSMer8vsdT3dKCLbReTPIpLtsT5CRDaLyAYRub63NxCR5XaZzVVVVQMYulJKqZ6cTBi9zUJkerx+E8gxxswA3gV+67FtjDEmH7gV+LmIjD/jYMY8Z4zJN8bkjxo1aqDiVkop1QsnE0YZ4FljyAIqPAsYY6qNMS32y+eB2R7bKuznYmAdMMvBWJVSSp2FkwljE5AnIrkiEgbcDJx2tZOIpHu8vA7Yba9PFJFwezkFWAT07CxXSinlR45dJWWMaReRe4E1QDCwwhizU0QeBzYbY1YC94nIdUA74ALutHefDPxaRNxYSe3JXq6uOk1hYeEJETnk0I+TApxw6NifhsbVPxpX/w3W2DSunqS3XoAufcU11ue3MKZnt4LqSUQ22/0pg4rG1T8aV/8N1tg0rv4ZqLj0Tm+llFI+0YShlFLKJ5owfPNcoAPwQuPqH42r/wZrbBpX/wxIXNqHoZRSyidaw1BKKeUTTRhKKaV8ognDJiLZIvK+iOwWkZ0icn8vZS4VkVqPYdcf9VNspSKyw37Pzb1sFxH5pT2M/HYRucAPMU30OA9bRaRORB7oUcYv50tEVojIcREp8liXJCLviMh++znRy7532GX2i8gdfojrKRHZY/+eXhORBC/79vk7dyi274tIucfv67Ne9u1z2oIBjumPHvGUishWL/s6dr68fTcE+jPWR1zOfcaMMfqw+nHSgQvs5VhgHzClR5lLgbcCEFspkNLH9s8Cf8Mav2s+UODn+IKBY8DYQJwv4GLgAqDIY92PgYfs5YeAH/WyXxJQbD8n2suJDse1GAixl3/UW1y+/M4diu37wDd8+F0fBMYBYcC2nn8nAxlTj+0/BR719/ny9t0Q6M9YH3E59hnTGobNGHPUGLPFXq7HGqakt9F1B6NlwP8aywYgocewK067HDhojHHqTvs+GWM+wBopwNMyugez/C3Q24jHVwHvGGNcxpga4B1giZNxGWPWGmPa7ZcbsMZY8zsv58wXjk1b0FdMIiLATcAfBuK9+qOP74aAfsa8xeXkZ0wTRi9EJAdrsMOCXjYvEJFtIvI3EZnqp5AMsFZECkVkeS/bfR1K3ik34/0PORDnCyDVGHMUrD8sYHQvZQJ93u7Cqhn25my/c6fcazdlrPDSxBKoc3YRUGmM2e9lu1/OV4/vhkHzGevjO2tAP2OOjSU1VIlIDPAX4AFjTF2PzVuwml0a7Pbd14E8P4S1yBhTISKjgXdEZI/931hX2L3s45frpcUaWPI64OFeNgfqfPkqkOftO1hjqL3kpcjZfudOeBb4AdY5+AFWE9BdPcoE6pzdQt+1C8fPV8/vBul77Kau3XpZN6Dny9t3lhOfMa1heBCRUKwT/5Ix5q89txtj6owxDfbyKiBUrNF0HWW6h3o/DryG1Szg6axDyTtoKbDFGFPZc0OgzpetsrNZzn4+3kuZgJw3u+PzGuA2Yzcm9+TD73zAGWMqjTEdxhg31nQDvb2n38+ZiIQAnwP+6K2M0+fLy3dDwD9j3r6znPqMacKw2W2kvwF2G2N+5qVMml0OEZmLdf6qHY4rWkRiO5exOrSKehRbCXxJLPOB2s6qsh94/c8vEOfLw0qg84qUO4A3eimzBlgs1nD6iVjndo2TQYnIEuBbwHXGmFNeyvjyO3ciNs9+rxu8vOdZpy1wwBXAHmNMWW8bnT5ffXw3BPQz5i0uRz9jA9FbPxwewIVYVcXtwFb78VngbuBuu8y9wE6sK0M2AAv9ENc4+/222e/9HXu9Z1wCPI119coOIN9P5ywKKwHEe6zz+/nCSlhHgTas/+j+FUgG/g7st5+T7LL5wAse+94FHLAfX/ZDXAew2rQ7P2O/sstmAKv6+p37Ibbf2Z+f7Vhfhuk9Y7NffxbripyDAxlbbzHZ61/s/Ex5lPXb+erjuyGgn7E+4nLsM6ZDgyillPKJNkkppZTyiSYMpZRSPtGEoZRSyieaMJRSSvlEE4ZSSimfaMJQSinlE00YSg0QEQkXkXft4aK/eA77Xy8iU5yITamBoGNJKTVwZgGhxpiZ57j/9cBbwC5fdxCRENM9MqlSjtIahhr2RCTHnlDmBREpEpGXROQKEfnIntRmrv34WEQ+sZ8n2vs+KCIr7OXp9v5RvbzHaOD3wEy7hjFeRGaLyD/s0UDXeIw79O8isskexfcvIhIlIguxBnF8ymP/dSKSb++TIiKl9vKdIvKqiLwJrLXXfdM+5nYRecxeFy0ib9vvU3QutR6lTjPQQw7oQx+D7QHkYI3aOR3rn6RCYAXWkCrLsEbRjaN70pkrgL/Yy0HAB1hjK23GGuHT2/tcij1hFBAKfAyMsl9/EVhhLyd77PME8HV7+UXg8x7b1mEP8wKkAKX28p1YQ2d0DkWxGHjO/nmCsGopFwM3As97HC++P+dNH/ro+dAmKTVSlBhjdgCIyE7g78YYIyI7sBJKPPBbEcnDGp8nFMAY4xaRO7HG6/m1MeYjH99vIjANa9hosGaq6xwQcpqIPAEkADGc22B07xhjOicbWmw/PrFfx2ANI/9P4Cci8iOsRPbPc3gfpbpowlAjRYvHstvjtRvr7+AHwPvGmBvEmoxmnUf5PKABa/A2Xwmw0xizoJdtLwLXG2O22cnoUi/HaKe72Tiix7bGHu/1n8aYX58RhMhsrAHp/lNE1hpjHvf5J1CqB+3DUMoSD5Tby3d2rhSReOAXWE08ySLyeR+PtxcYJSIL7OOESveMg7HAUXsug9s89qm3t3UqBWbby3297xrgLrEm0kFEMkVktIhkAKeMMb8HfoI1X7ZS50wThlKWH2P9F/4RVvNRp/8CnjHG7MMaAvxJu4O7T8aa7/rzwI9EZBvWMNML7c2PYE2l+Q6wx2O3V4Bv2h3v47G+5L8qIh9j9WF4e6+1wMvAeruJ7c9YiWc6sFFEtgLfweovUeqc6fDmSimlfKI1DKWUUj7RTm+l+klEvgzc32P1R8aYrwUiHqX8RZuklFJK+USbpJRSSvlEE4ZSSimfaMJQSinlE00YSimlfPL/Ae7SAPoRxvlrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with max_features\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.axvline(x=22,color='r')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal max_features=22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch to find optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'min_samples_leaf': [100,200,300],\n",
    "    'min_samples_split': [100, 200,300],\n",
    "    'n_estimators': [100,200], \n",
    "    'max_features': [5,10,15,22]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier(random_state=100)\n",
    "# Instantiate the grid search model\n",
    "grid_search_sam = GridSearchCV(estimator = rf, param_grid = param_grid,scoring='recall',\n",
    "                          cv = 3, n_jobs = -1,verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed: 11.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=100,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'max_features': [5, 10, 15, 22],\n",
       "                         'min_samples_leaf': [100, 200, 300],\n",
       "                         'min_samples_split': [100, 200, 300],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_sam.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get best recall of 0.7862648913805185 using {'max_depth': 4, 'max_features': 22, 'min_samples_leaf': 100, 'min_samples_split': 100, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal recall score and hyperparameters\n",
    "print('We can get best recall of',grid_search_sam.best_score_,'using',grid_search_sam.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features=22,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=100, min_samples_split=100,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_sam_final=RandomForestClassifier(max_depth=4,max_features=22,min_samples_leaf=100,min_samples_split=100,n_estimators=100,random_state=100)\n",
    "rf_sam_final.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics.loc['Random Forest with PCA with Sampling','Training Accuracy']=metrics.accuracy_score(y_train_res,rf_sam_final.predict(X_train_res))\n",
    "model_metrics.loc['Random Forest with PCA with Sampling','Test Accuracy']=metrics.accuracy_score(y_test,rf_sam_final.predict(X_test))\n",
    "model_metrics.loc['Random Forest with PCA with Sampling','Training Recall']=metrics.recall_score(y_train_res,rf_sam_final.predict(X_train_res))\n",
    "model_metrics.loc['Random Forest with PCA with Sampling','Test Recall']=metrics.recall_score(y_test,rf_sam_final.predict(X_test))\n",
    "model_metrics.loc['Random Forest with PCA with Sampling','Training Precision']=metrics.precision_score(y_train_res,rf_sam_final.predict(X_train_res))\n",
    "model_metrics.loc['Random Forest with PCA with Sampling','Test Precision']=metrics.precision_score(y_test,rf_sam_final.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression without PCA with sampling</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.871596</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.186470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest without PCA without sampling</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.954237</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.234681</td>\n",
       "      <td>0.035750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA without Sampling</td>\n",
       "      <td>0.770948</td>\n",
       "      <td>0.774503</td>\n",
       "      <td>0.798305</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.106706</td>\n",
       "      <td>0.107047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA without sampling</td>\n",
       "      <td>0.983591</td>\n",
       "      <td>0.945665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438735</td>\n",
       "      <td>0.669694</td>\n",
       "      <td>0.290576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA with sampling</td>\n",
       "      <td>0.968366</td>\n",
       "      <td>0.938034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513834</td>\n",
       "      <td>0.512598</td>\n",
       "      <td>0.271967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA with Sampling</td>\n",
       "      <td>0.899624</td>\n",
       "      <td>0.897908</td>\n",
       "      <td>0.796076</td>\n",
       "      <td>0.715415</td>\n",
       "      <td>0.925207</td>\n",
       "      <td>0.204520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Training Accuracy  \\\n",
       "Logistic Regression without PCA with sampling           0.864997   \n",
       "Random Forest without PCA without sampling              0.894948   \n",
       "Random Forest with PCA without Sampling                 0.770948   \n",
       "AdaBoost with PCA without sampling                      0.983591   \n",
       "AdaBoost with PCA with sampling                         0.968366   \n",
       "Random Forest with PCA with Sampling                    0.899624   \n",
       "\n",
       "                                               Test Accuracy  Training Recall  \\\n",
       "Logistic Regression without PCA with sampling       0.871596         0.864501   \n",
       "Random Forest without PCA without sampling          0.112485         0.954237   \n",
       "Random Forest with PCA without Sampling             0.774503         0.798305   \n",
       "AdaBoost with PCA without sampling                  0.945665         1.000000   \n",
       "AdaBoost with PCA with sampling                     0.938034         1.000000   \n",
       "Random Forest with PCA with Sampling                0.897908         0.796076   \n",
       "\n",
       "                                               Test Recall  \\\n",
       "Logistic Regression without PCA with sampling     0.849802   \n",
       "Random Forest without PCA without sampling        0.988142   \n",
       "Random Forest with PCA without Sampling           0.786561   \n",
       "AdaBoost with PCA without sampling                0.438735   \n",
       "AdaBoost with PCA with sampling                   0.513834   \n",
       "Random Forest with PCA with Sampling              0.715415   \n",
       "\n",
       "                                               Training Precision  \\\n",
       "Logistic Regression without PCA with sampling            0.865359   \n",
       "Random Forest without PCA without sampling               0.234681   \n",
       "Random Forest with PCA without Sampling                  0.106706   \n",
       "AdaBoost with PCA without sampling                       0.669694   \n",
       "AdaBoost with PCA with sampling                          0.512598   \n",
       "Random Forest with PCA with Sampling                     0.925207   \n",
       "\n",
       "                                               Test Precision  \n",
       "Logistic Regression without PCA with sampling        0.186470  \n",
       "Random Forest without PCA without sampling           0.035750  \n",
       "Random Forest with PCA without Sampling              0.107047  \n",
       "AdaBoost with PCA without sampling                   0.290576  \n",
       "AdaBoost with PCA with sampling                      0.271967  \n",
       "Random Forest with PCA with Sampling                 0.204520  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Boosting (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter tuning without using any Sampling Technique but using class_weight='balanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split and max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  27 | elapsed:  3.5min remaining:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  27 | elapsed:  5.5min remaining:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  27 | elapsed:  6.7min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:  6.8min remaining:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  8.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                                                class_weight='balanced',\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                presort='deprecated',\n",
       "                                                                                random_state=100,\n",
       "                                                                                splitter='best'),\n",
       "                                          learning_rate=0.6, n_estimators=300,\n",
       "                                          random_state=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'base_estimator__max_depth': [2, 3, 5],\n",
       "                         'base_estimator__min_samples_split': [100, 200, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter grid\n",
    "param_grid = {\"base_estimator__min_samples_split\" : [100,200,300],\n",
    "              \"base_estimator__max_depth\":[2,3,5]\n",
    "             }\n",
    "\n",
    "\n",
    "# base estimator\n",
    "tree = DecisionTreeClassifier(class_weight='balanced',random_state=100)\n",
    "\n",
    "# adaboost with the tree as base estimator\n",
    "# learning rate is arbitrarily set to 0.6\n",
    "ABC = AdaBoostClassifier(\n",
    "    base_estimator=tree,\n",
    "    learning_rate=0.6,\n",
    "    n_estimators=300)\n",
    "\n",
    "# run grid search\n",
    "folds = 3\n",
    "grid_search_ABC = GridSearchCV(ABC, \n",
    "                               cv = folds,\n",
    "                               param_grid=param_grid, \n",
    "                               scoring = 'recall', \n",
    "                               return_train_score=True,                         \n",
    "                               verbose = 10,n_jobs=-1)\n",
    "\n",
    "# fit \n",
    "grid_search_ABC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search_ABC.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with hyperparameter combinations\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "for n, depth in enumerate(param_grid['base_estimator__max_depth']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(2,2, n+1)\n",
    "    depth_df = cv_results[cv_results['param_base_estimator__max_depth']==depth]\n",
    "\n",
    "    plt.plot(depth_df[\"param_base_estimator__min_samples_split\"], depth_df[\"mean_test_score\"])\n",
    "    plt.plot(depth_df[\"param_base_estimator__min_samples_split\"], depth_df[\"mean_train_score\"])\n",
    "    plt.xlabel('min_samples_split')\n",
    "    plt.ylabel('recall')\n",
    "    plt.title(\"max_depth={0}\".format(depth))\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get recall of 0.36438585586518873 using {'base_estimator__max_depth': 2, 'base_estimator__min_samples_split': 200}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get recall of',grid_search_ABC.best_score_,'using',grid_search_ABC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight='balanced',\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=2,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=200,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=100,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.6, n_estimators=300, random_state=100)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiating the decision tree\n",
    "f_tree=DecisionTreeClassifier(max_depth=2,min_samples_split=200,class_weight='balanced',random_state=100)\n",
    "\n",
    "abc_final=AdaBoostClassifier(base_estimator=f_tree,learning_rate=0.6,\n",
    "                            n_estimators=300,random_state=100)\n",
    "abc_final.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics.loc['AdaBoost with PCA without sampling','Training Accuracy']=metrics.accuracy_score(y_train,abc_final.predict(X_train))\n",
    "model_metrics.loc['AdaBoost with PCA without sampling','Test Accuracy']=metrics.accuracy_score(y_test,abc_final.predict(X_test))\n",
    "model_metrics.loc['AdaBoost with PCA without sampling','Training Recall']=metrics.recall_score(y_train,abc_final.predict(X_train))\n",
    "model_metrics.loc['AdaBoost with PCA without sampling','Test Recall']=metrics.recall_score(y_test,abc_final.predict(X_test))\n",
    "model_metrics.loc['AdaBoost with PCA without sampling','Training Precision']=metrics.precision_score(y_train,abc_final.predict(X_train))\n",
    "model_metrics.loc['AdaBoost with PCA without sampling','Test Precision']=metrics.precision_score(y_test,abc_final.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression without PCA with sampling</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.871596</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.186470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest without PCA without sampling</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.954237</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.234681</td>\n",
       "      <td>0.035750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA without Sampling</td>\n",
       "      <td>0.770948</td>\n",
       "      <td>0.774503</td>\n",
       "      <td>0.798305</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.106706</td>\n",
       "      <td>0.107047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA without sampling</td>\n",
       "      <td>0.983591</td>\n",
       "      <td>0.945665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438735</td>\n",
       "      <td>0.669694</td>\n",
       "      <td>0.290576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Training Accuracy  \\\n",
       "Logistic Regression without PCA with sampling           0.864997   \n",
       "Random Forest without PCA without sampling              0.894948   \n",
       "Random Forest with PCA without Sampling                 0.770948   \n",
       "AdaBoost with PCA without sampling                      0.983591   \n",
       "\n",
       "                                               Test Accuracy  Training Recall  \\\n",
       "Logistic Regression without PCA with sampling       0.871596         0.864501   \n",
       "Random Forest without PCA without sampling          0.112485         0.954237   \n",
       "Random Forest with PCA without Sampling             0.774503         0.798305   \n",
       "AdaBoost with PCA without sampling                  0.945665         1.000000   \n",
       "\n",
       "                                               Test Recall  \\\n",
       "Logistic Regression without PCA with sampling     0.849802   \n",
       "Random Forest without PCA without sampling        0.988142   \n",
       "Random Forest with PCA without Sampling           0.786561   \n",
       "AdaBoost with PCA without sampling                0.438735   \n",
       "\n",
       "                                               Training Precision  \\\n",
       "Logistic Regression without PCA with sampling            0.865359   \n",
       "Random Forest without PCA without sampling               0.234681   \n",
       "Random Forest with PCA without Sampling                  0.106706   \n",
       "AdaBoost with PCA without sampling                       0.669694   \n",
       "\n",
       "                                               Test Precision  \n",
       "Logistic Regression without PCA with sampling        0.186470  \n",
       "Random Forest without PCA without sampling           0.035750  \n",
       "Random Forest with PCA without Sampling              0.107047  \n",
       "AdaBoost with PCA without sampling                   0.290576  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter tuning using SMOTEENN (Combined) Sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  27 | elapsed:  3.1min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  27 | elapsed:  4.8min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  27 | elapsed:  5.9min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:  5.9min remaining:   44.4s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  7.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                                                class_weight=None,\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                presort='deprecated',\n",
       "                                                                                random_state=100,\n",
       "                                                                                splitter='best'),\n",
       "                                          learning_rate=0.6, n_estimators=200,\n",
       "                                          random_state=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'base_estimator__max_depth': [2, 3, 5],\n",
       "                         'base_estimator__min_samples_split': [100, 200, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter grid\n",
    "param_grid = {\"base_estimator__min_samples_split\" : [100,200,300],\n",
    "              \"base_estimator__max_depth\":[2,3,5]\n",
    "             }\n",
    "\n",
    "\n",
    "# base estimator\n",
    "tree = DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "# adaboost with the tree as base estimator\n",
    "# learning rate is arbitrarily set to 0.6\n",
    "ABC = AdaBoostClassifier(\n",
    "    base_estimator=tree,\n",
    "    learning_rate=0.6,\n",
    "    n_estimators=200)\n",
    "\n",
    "# run grid search\n",
    "folds = 3\n",
    "grid_search_ABC = GridSearchCV(ABC, \n",
    "                               cv = folds,\n",
    "                               param_grid=param_grid, \n",
    "                               scoring = 'recall', \n",
    "                               return_train_score=True,                         \n",
    "                               verbose = 10,n_jobs=-1)\n",
    "\n",
    "# fit \n",
    "grid_search_ABC.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search_ABC.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting recall with hyperparameter combinations\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "for n, depth in enumerate(param_grid['base_estimator__max_depth']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(2,2, n+1)\n",
    "    depth_df = cv_results[cv_results['param_base_estimator__max_depth']==depth]\n",
    "\n",
    "    plt.plot(depth_df[\"param_base_estimator__min_samples_split\"], depth_df[\"mean_test_score\"])\n",
    "    plt.plot(depth_df[\"param_base_estimator__min_samples_split\"], depth_df[\"mean_train_score\"])\n",
    "    plt.xlabel('min_samples_split')\n",
    "    plt.ylabel('recall')\n",
    "    plt.title(\"max_depth={0}\".format(depth))\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get recall of 0.9926419060967064 using {'base_estimator__max_depth': 5, 'base_estimator__min_samples_split': 100}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get recall of',grid_search_ABC.best_score_,'using',grid_search_ABC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight='balanced',\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=2,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=200,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=100,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.6, n_estimators=200, random_state=100)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiating the decision tree\n",
    "f_sam_tree=DecisionTreeClassifier(max_depth=5,min_samples_split=100,random_state=100)\n",
    "\n",
    "abc_sam_final=AdaBoostClassifier(base_estimator=f_tree,learning_rate=0.6,\n",
    "                            n_estimators=200,random_state=100)\n",
    "abc_sam_final.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics.loc['AdaBoost with PCA with sampling','Training Accuracy']=metrics.accuracy_score(y_train,abc_sam_final.predict(X_train))\n",
    "model_metrics.loc['AdaBoost with PCA with sampling','Test Accuracy']=metrics.accuracy_score(y_test,abc_sam_final.predict(X_test))\n",
    "model_metrics.loc['AdaBoost with PCA with sampling','Training Recall']=metrics.recall_score(y_train,abc_sam_final.predict(X_train))\n",
    "model_metrics.loc['AdaBoost with PCA with sampling','Test Recall']=metrics.recall_score(y_test,abc_sam_final.predict(X_test))\n",
    "model_metrics.loc['AdaBoost with PCA with sampling','Training Precision']=metrics.precision_score(y_train,abc_sam_final.predict(X_train))\n",
    "model_metrics.loc['AdaBoost with PCA with sampling','Test Precision']=metrics.precision_score(y_test,abc_sam_final.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression without PCA with sampling</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.871596</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.186470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest without PCA without sampling</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.954237</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.234681</td>\n",
       "      <td>0.035750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA without Sampling</td>\n",
       "      <td>0.770948</td>\n",
       "      <td>0.774503</td>\n",
       "      <td>0.798305</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.106706</td>\n",
       "      <td>0.107047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA without sampling</td>\n",
       "      <td>0.983591</td>\n",
       "      <td>0.945665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438735</td>\n",
       "      <td>0.669694</td>\n",
       "      <td>0.290576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA with sampling</td>\n",
       "      <td>0.968366</td>\n",
       "      <td>0.938034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513834</td>\n",
       "      <td>0.512598</td>\n",
       "      <td>0.271967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Training Accuracy  \\\n",
       "Logistic Regression without PCA with sampling           0.864997   \n",
       "Random Forest without PCA without sampling              0.894948   \n",
       "Random Forest with PCA without Sampling                 0.770948   \n",
       "AdaBoost with PCA without sampling                      0.983591   \n",
       "AdaBoost with PCA with sampling                         0.968366   \n",
       "\n",
       "                                               Test Accuracy  Training Recall  \\\n",
       "Logistic Regression without PCA with sampling       0.871596         0.864501   \n",
       "Random Forest without PCA without sampling          0.112485         0.954237   \n",
       "Random Forest with PCA without Sampling             0.774503         0.798305   \n",
       "AdaBoost with PCA without sampling                  0.945665         1.000000   \n",
       "AdaBoost with PCA with sampling                     0.938034         1.000000   \n",
       "\n",
       "                                               Test Recall  \\\n",
       "Logistic Regression without PCA with sampling     0.849802   \n",
       "Random Forest without PCA without sampling        0.988142   \n",
       "Random Forest with PCA without Sampling           0.786561   \n",
       "AdaBoost with PCA without sampling                0.438735   \n",
       "AdaBoost with PCA with sampling                   0.513834   \n",
       "\n",
       "                                               Training Precision  \\\n",
       "Logistic Regression without PCA with sampling            0.865359   \n",
       "Random Forest without PCA without sampling               0.234681   \n",
       "Random Forest with PCA without Sampling                  0.106706   \n",
       "AdaBoost with PCA without sampling                       0.669694   \n",
       "AdaBoost with PCA with sampling                          0.512598   \n",
       "\n",
       "                                               Test Precision  \n",
       "Logistic Regression without PCA with sampling        0.186470  \n",
       "Random Forest without PCA without sampling           0.035750  \n",
       "Random Forest with PCA without Sampling              0.107047  \n",
       "AdaBoost with PCA without sampling                   0.290576  \n",
       "AdaBoost with PCA with sampling                      0.271967  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a general overfitting in with sampling cases after PCA. Thus, we use only class_weight='balanced' argument for XGBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import gc # for deleting unused variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  91 out of  96 | elapsed:  5.0min remaining:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     class_weight='balanced',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=100, reg_alpha=0,\n",
       "                                     reg_lambda=1, scale_pos_weight=1,\n",
       "                                     seed=None, silent=None, subsample=1,\n",
       "                                     verbosity=1),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.2, 0.6], 'max_depth': [2, 3, 4, 5],\n",
       "                         'n_estimators': [200, 300], 'subsample': [0.6, 0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning with XGBoost\n",
    "\n",
    "# creating a KFold object \n",
    "folds = 3\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.6, 0.9],\n",
    "             'max_depth':[2,3,4,5],\n",
    "             'n_estimators':[200,300]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(class_weight='balanced',random_state=100)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'recall', \n",
    "                        cv = folds, \n",
    "                        verbose = 10,n_jobs=-1,\n",
    "                        return_train_score=True) \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get recall of 0.21346558928139783 using {'learning_rate': 0.6, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get recall of',model_cv.best_score_,'using',model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              gamma=0, learning_rate=0.6, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=0.6, verbosity=1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbf=XGBClassifier(learning_rate=0.6,max_depth=2,n_estimators=200,subsample=0.6,class_weight='balanced',random_state=100)\n",
    "xgbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics.loc['XGBoost with PCA','Training Accuracy']=metrics.accuracy_score(y_train,xgbf.predict(X_train))\n",
    "model_metrics.loc['XGBoost with PCA','Test Accuracy']=metrics.accuracy_score(y_test,xgbf.predict(X_test))\n",
    "model_metrics.loc['XGBoost with PCA','Training Recall']=metrics.recall_score(y_train,xgbf.predict(X_train))\n",
    "model_metrics.loc['XGBoost with PCA','Test Recall']=metrics.recall_score(y_test,xgbf.predict(X_test))\n",
    "model_metrics.loc['XGBoost with PCA','Training Precision']=metrics.precision_score(y_train,xgbf.predict(X_train))\n",
    "model_metrics.loc['XGBoost with PCA','Test Precision']=metrics.precision_score(y_test,xgbf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression without PCA with sampling</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.871596</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.186470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest without PCA without sampling</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.954237</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.234681</td>\n",
       "      <td>0.035750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA without Sampling</td>\n",
       "      <td>0.770948</td>\n",
       "      <td>0.774503</td>\n",
       "      <td>0.798305</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.106706</td>\n",
       "      <td>0.107047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA without sampling</td>\n",
       "      <td>0.983591</td>\n",
       "      <td>0.945665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438735</td>\n",
       "      <td>0.669694</td>\n",
       "      <td>0.290576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA with sampling</td>\n",
       "      <td>0.968366</td>\n",
       "      <td>0.938034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513834</td>\n",
       "      <td>0.512598</td>\n",
       "      <td>0.271967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA with Sampling</td>\n",
       "      <td>0.899624</td>\n",
       "      <td>0.897908</td>\n",
       "      <td>0.796076</td>\n",
       "      <td>0.715415</td>\n",
       "      <td>0.925207</td>\n",
       "      <td>0.204520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost with PCA</td>\n",
       "      <td>0.991485</td>\n",
       "      <td>0.962110</td>\n",
       "      <td>0.783051</td>\n",
       "      <td>0.292490</td>\n",
       "      <td>0.952577</td>\n",
       "      <td>0.404372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Training Accuracy  \\\n",
       "Logistic Regression without PCA with sampling           0.864997   \n",
       "Random Forest without PCA without sampling              0.894948   \n",
       "Random Forest with PCA without Sampling                 0.770948   \n",
       "AdaBoost with PCA without sampling                      0.983591   \n",
       "AdaBoost with PCA with sampling                         0.968366   \n",
       "Random Forest with PCA with Sampling                    0.899624   \n",
       "XGBoost with PCA                                        0.991485   \n",
       "\n",
       "                                               Test Accuracy  Training Recall  \\\n",
       "Logistic Regression without PCA with sampling       0.871596         0.864501   \n",
       "Random Forest without PCA without sampling          0.112485         0.954237   \n",
       "Random Forest with PCA without Sampling             0.774503         0.798305   \n",
       "AdaBoost with PCA without sampling                  0.945665         1.000000   \n",
       "AdaBoost with PCA with sampling                     0.938034         1.000000   \n",
       "Random Forest with PCA with Sampling                0.897908         0.796076   \n",
       "XGBoost with PCA                                    0.962110         0.783051   \n",
       "\n",
       "                                               Test Recall  \\\n",
       "Logistic Regression without PCA with sampling     0.849802   \n",
       "Random Forest without PCA without sampling        0.988142   \n",
       "Random Forest with PCA without Sampling           0.786561   \n",
       "AdaBoost with PCA without sampling                0.438735   \n",
       "AdaBoost with PCA with sampling                   0.513834   \n",
       "Random Forest with PCA with Sampling              0.715415   \n",
       "XGBoost with PCA                                  0.292490   \n",
       "\n",
       "                                               Training Precision  \\\n",
       "Logistic Regression without PCA with sampling            0.865359   \n",
       "Random Forest without PCA without sampling               0.234681   \n",
       "Random Forest with PCA without Sampling                  0.106706   \n",
       "AdaBoost with PCA without sampling                       0.669694   \n",
       "AdaBoost with PCA with sampling                          0.512598   \n",
       "Random Forest with PCA with Sampling                     0.925207   \n",
       "XGBoost with PCA                                         0.952577   \n",
       "\n",
       "                                               Test Precision  \n",
       "Logistic Regression without PCA with sampling        0.186470  \n",
       "Random Forest without PCA without sampling           0.035750  \n",
       "Random Forest with PCA without Sampling              0.107047  \n",
       "AdaBoost with PCA without sampling                   0.290576  \n",
       "AdaBoost with PCA with sampling                      0.271967  \n",
       "Random Forest with PCA with Sampling                 0.204520  \n",
       "XGBoost with PCA                                     0.404372  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA+SMOTEENN+LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PC_7</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>PC_9</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>PC_10</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PC_1</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>PC_19</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>PC_6</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>PC_46</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>PC_39</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>PC_47</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PC_11</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>PC_24</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>PC_23</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PC_5</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>PC_49</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>PC_42</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>PC_60</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>PC_8</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>PC_66</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>PC_48</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>PC_45</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>PC_33</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>PC_61</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>PC_37</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>PC_68</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PC_2</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>PC_36</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PC_14</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>PC_20</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PC_12</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>PC_22</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PC_3</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>PC_4</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>PC_64</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PC_13</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>PC_57</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>PC_53</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>PC_44</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>PC_70</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>PC_35</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>PC_38</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>PC_21</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>PC_69</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>PC_29</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>PC_67</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>PC_30</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>PC_65</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>PC_31</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>PC_62</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>PC_26</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>PC_34</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>PC_40</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>PC_55</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>PC_52</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>PC_51</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>PC_41</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>PC_50</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>PC_43</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>PC_25</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>PC_28</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>PC_18</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>PC_16</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>PC_17</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PC_15</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>PC_63</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>PC_54</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>PC_32</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>PC_59</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>PC_58</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>PC_56</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>PC_27</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features   VIF\n",
       "6      PC_7  1.18\n",
       "8      PC_9  1.18\n",
       "9     PC_10  1.15\n",
       "0      PC_1  1.12\n",
       "18    PC_19  1.11\n",
       "5      PC_6  1.09\n",
       "45    PC_46  1.09\n",
       "38    PC_39  1.08\n",
       "46    PC_47  1.07\n",
       "10    PC_11  1.07\n",
       "23    PC_24  1.06\n",
       "22    PC_23  1.06\n",
       "4      PC_5  1.06\n",
       "48    PC_49  1.06\n",
       "41    PC_42  1.05\n",
       "59    PC_60  1.05\n",
       "7      PC_8  1.05\n",
       "65    PC_66  1.05\n",
       "47    PC_48  1.04\n",
       "44    PC_45  1.04\n",
       "32    PC_33  1.04\n",
       "60    PC_61  1.04\n",
       "36    PC_37  1.04\n",
       "67    PC_68  1.04\n",
       "1      PC_2  1.04\n",
       "35    PC_36  1.04\n",
       "13    PC_14  1.04\n",
       "19    PC_20  1.04\n",
       "11    PC_12  1.04\n",
       "21    PC_22  1.04\n",
       "2      PC_3  1.03\n",
       "3      PC_4  1.03\n",
       "63    PC_64  1.03\n",
       "12    PC_13  1.03\n",
       "56    PC_57  1.03\n",
       "52    PC_53  1.03\n",
       "43    PC_44  1.03\n",
       "69    PC_70  1.03\n",
       "34    PC_35  1.03\n",
       "37    PC_38  1.03\n",
       "20    PC_21  1.02\n",
       "68    PC_69  1.02\n",
       "28    PC_29  1.02\n",
       "66    PC_67  1.02\n",
       "29    PC_30  1.02\n",
       "64    PC_65  1.02\n",
       "30    PC_31  1.02\n",
       "61    PC_62  1.02\n",
       "25    PC_26  1.02\n",
       "33    PC_34  1.02\n",
       "39    PC_40  1.02\n",
       "54    PC_55  1.02\n",
       "51    PC_52  1.02\n",
       "50    PC_51  1.02\n",
       "40    PC_41  1.02\n",
       "49    PC_50  1.02\n",
       "42    PC_43  1.02\n",
       "24    PC_25  1.02\n",
       "27    PC_28  1.02\n",
       "17    PC_18  1.02\n",
       "15    PC_16  1.01\n",
       "16    PC_17  1.01\n",
       "14    PC_15  1.01\n",
       "62    PC_63  1.01\n",
       "53    PC_54  1.01\n",
       "31    PC_32  1.01\n",
       "58    PC_59  1.01\n",
       "57    PC_58  1.01\n",
       "55    PC_56  1.01\n",
       "26    PC_27  1.01"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif(list(X_train_res.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that VIF value of all the Principal components is below 5. Hence, we do not need to check VIF values while model building because PCA reduces the Multicollinearity while decreasing the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Logistic Regression\n",
    "logreg2 = LogisticRegression()\n",
    "\n",
    "rfe = RFE(logreg2, 50)             # running RFE with 20 variables as output\n",
    "rfe = rfe.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PC_1', 'PC_2', 'PC_4', 'PC_5', 'PC_7', 'PC_8', 'PC_9', 'PC_10',\n",
       "       'PC_14', 'PC_16', 'PC_17', 'PC_18', 'PC_19', 'PC_20', 'PC_21', 'PC_22',\n",
       "       'PC_23', 'PC_24', 'PC_25', 'PC_26', 'PC_28', 'PC_29', 'PC_31', 'PC_32',\n",
       "       'PC_33', 'PC_34', 'PC_35', 'PC_38', 'PC_39', 'PC_40', 'PC_41', 'PC_42',\n",
       "       'PC_44', 'PC_45', 'PC_46', 'PC_48', 'PC_50', 'PC_51', 'PC_52', 'PC_53',\n",
       "       'PC_54', 'PC_56', 'PC_58', 'PC_60', 'PC_61', 'PC_63', 'PC_64', 'PC_66',\n",
       "       'PC_69', 'PC_70'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = X_train_res.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Churn</td>      <th>  No. Observations:  </th>  <td> 22884</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22833</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    50</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -5029.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  10058.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:07:53</td>     <th>  Pearson chi2:      </th> <td>1.19e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.9321</td> <td>    0.072</td> <td>  -54.555</td> <td> 0.000</td> <td>   -4.073</td> <td>   -3.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_1</th>  <td>   -0.9014</td> <td>    0.019</td> <td>  -48.243</td> <td> 0.000</td> <td>   -0.938</td> <td>   -0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_2</th>  <td>    0.1384</td> <td>    0.009</td> <td>   15.882</td> <td> 0.000</td> <td>    0.121</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_4</th>  <td>    0.1629</td> <td>    0.017</td> <td>    9.622</td> <td> 0.000</td> <td>    0.130</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_5</th>  <td>   -0.2089</td> <td>    0.018</td> <td>  -11.388</td> <td> 0.000</td> <td>   -0.245</td> <td>   -0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_7</th>  <td>    0.6714</td> <td>    0.021</td> <td>   32.233</td> <td> 0.000</td> <td>    0.631</td> <td>    0.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_8</th>  <td>   -0.0870</td> <td>    0.024</td> <td>   -3.642</td> <td> 0.000</td> <td>   -0.134</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_9</th>  <td>    0.6192</td> <td>    0.024</td> <td>   25.474</td> <td> 0.000</td> <td>    0.572</td> <td>    0.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_10</th> <td>   -0.3744</td> <td>    0.023</td> <td>  -16.306</td> <td> 0.000</td> <td>   -0.419</td> <td>   -0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_14</th> <td>    0.1797</td> <td>    0.026</td> <td>    6.876</td> <td> 0.000</td> <td>    0.128</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_16</th> <td>   -0.1587</td> <td>    0.034</td> <td>   -4.727</td> <td> 0.000</td> <td>   -0.225</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_17</th> <td>   -0.1520</td> <td>    0.031</td> <td>   -4.956</td> <td> 0.000</td> <td>   -0.212</td> <td>   -0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_18</th> <td>    0.3320</td> <td>    0.026</td> <td>   12.706</td> <td> 0.000</td> <td>    0.281</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_19</th> <td>   -0.7782</td> <td>    0.026</td> <td>  -30.481</td> <td> 0.000</td> <td>   -0.828</td> <td>   -0.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_20</th> <td>    0.4287</td> <td>    0.037</td> <td>   11.446</td> <td> 0.000</td> <td>    0.355</td> <td>    0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_21</th> <td>   -0.1020</td> <td>    0.038</td> <td>   -2.702</td> <td> 0.007</td> <td>   -0.176</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_22</th> <td>   -0.1283</td> <td>    0.026</td> <td>   -4.885</td> <td> 0.000</td> <td>   -0.180</td> <td>   -0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_23</th> <td>    0.3115</td> <td>    0.036</td> <td>    8.596</td> <td> 0.000</td> <td>    0.240</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_24</th> <td>    0.2492</td> <td>    0.033</td> <td>    7.598</td> <td> 0.000</td> <td>    0.185</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_25</th> <td>   -0.1985</td> <td>    0.037</td> <td>   -5.405</td> <td> 0.000</td> <td>   -0.271</td> <td>   -0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_26</th> <td>   -0.1858</td> <td>    0.040</td> <td>   -4.608</td> <td> 0.000</td> <td>   -0.265</td> <td>   -0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_28</th> <td>   -0.0995</td> <td>    0.031</td> <td>   -3.244</td> <td> 0.001</td> <td>   -0.160</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_29</th> <td>   -0.4275</td> <td>    0.044</td> <td>   -9.716</td> <td> 0.000</td> <td>   -0.514</td> <td>   -0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_31</th> <td>   -0.4871</td> <td>    0.041</td> <td>  -11.836</td> <td> 0.000</td> <td>   -0.568</td> <td>   -0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_32</th> <td>   -0.1170</td> <td>    0.050</td> <td>   -2.350</td> <td> 0.019</td> <td>   -0.215</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_33</th> <td>    0.1368</td> <td>    0.034</td> <td>    4.014</td> <td> 0.000</td> <td>    0.070</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_34</th> <td>   -0.3561</td> <td>    0.037</td> <td>   -9.667</td> <td> 0.000</td> <td>   -0.428</td> <td>   -0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_35</th> <td>    0.1508</td> <td>    0.041</td> <td>    3.682</td> <td> 0.000</td> <td>    0.071</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_38</th> <td>   -0.1288</td> <td>    0.036</td> <td>   -3.614</td> <td> 0.000</td> <td>   -0.199</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_39</th> <td>    0.1072</td> <td>    0.042</td> <td>    2.534</td> <td> 0.011</td> <td>    0.024</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_40</th> <td>   -0.3564</td> <td>    0.036</td> <td>   -9.937</td> <td> 0.000</td> <td>   -0.427</td> <td>   -0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_41</th> <td>   -0.1896</td> <td>    0.044</td> <td>   -4.301</td> <td> 0.000</td> <td>   -0.276</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_42</th> <td>   -0.1012</td> <td>    0.041</td> <td>   -2.462</td> <td> 0.014</td> <td>   -0.182</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_44</th> <td>    0.2331</td> <td>    0.053</td> <td>    4.422</td> <td> 0.000</td> <td>    0.130</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_45</th> <td>    0.1069</td> <td>    0.042</td> <td>    2.567</td> <td> 0.010</td> <td>    0.025</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_46</th> <td>    0.1372</td> <td>    0.043</td> <td>    3.202</td> <td> 0.001</td> <td>    0.053</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_48</th> <td>    0.3009</td> <td>    0.043</td> <td>    7.012</td> <td> 0.000</td> <td>    0.217</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_50</th> <td>    0.3695</td> <td>    0.046</td> <td>    8.056</td> <td> 0.000</td> <td>    0.280</td> <td>    0.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_51</th> <td>    0.1080</td> <td>    0.054</td> <td>    1.995</td> <td> 0.046</td> <td>    0.002</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_52</th> <td>   -0.4484</td> <td>    0.048</td> <td>   -9.333</td> <td> 0.000</td> <td>   -0.543</td> <td>   -0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_53</th> <td>   -0.5172</td> <td>    0.050</td> <td>  -10.428</td> <td> 0.000</td> <td>   -0.614</td> <td>   -0.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_54</th> <td>    0.1012</td> <td>    0.054</td> <td>    1.871</td> <td> 0.061</td> <td>   -0.005</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_56</th> <td>    0.1356</td> <td>    0.067</td> <td>    2.020</td> <td> 0.043</td> <td>    0.004</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_58</th> <td>    0.4427</td> <td>    0.056</td> <td>    7.949</td> <td> 0.000</td> <td>    0.334</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_60</th> <td>    0.2196</td> <td>    0.062</td> <td>    3.534</td> <td> 0.000</td> <td>    0.098</td> <td>    0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_61</th> <td>   -0.3563</td> <td>    0.070</td> <td>   -5.104</td> <td> 0.000</td> <td>   -0.493</td> <td>   -0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_63</th> <td>   -0.0889</td> <td>    0.068</td> <td>   -1.298</td> <td> 0.194</td> <td>   -0.223</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_64</th> <td>   -0.2489</td> <td>    0.073</td> <td>   -3.420</td> <td> 0.001</td> <td>   -0.392</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_66</th> <td>    0.2392</td> <td>    0.055</td> <td>    4.313</td> <td> 0.000</td> <td>    0.131</td> <td>    0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_69</th> <td>    0.1741</td> <td>    0.057</td> <td>    3.078</td> <td> 0.002</td> <td>    0.063</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_70</th> <td>    0.1152</td> <td>    0.075</td> <td>    1.539</td> <td> 0.124</td> <td>   -0.032</td> <td>    0.262</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Churn   No. Observations:                22884\n",
       "Model:                            GLM   Df Residuals:                    22833\n",
       "Model Family:                Binomial   Df Model:                           50\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -5029.2\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       10058.\n",
       "Time:                        21:07:53   Pearson chi2:                 1.19e+06\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.9321      0.072    -54.555      0.000      -4.073      -3.791\n",
       "PC_1          -0.9014      0.019    -48.243      0.000      -0.938      -0.865\n",
       "PC_2           0.1384      0.009     15.882      0.000       0.121       0.156\n",
       "PC_4           0.1629      0.017      9.622      0.000       0.130       0.196\n",
       "PC_5          -0.2089      0.018    -11.388      0.000      -0.245      -0.173\n",
       "PC_7           0.6714      0.021     32.233      0.000       0.631       0.712\n",
       "PC_8          -0.0870      0.024     -3.642      0.000      -0.134      -0.040\n",
       "PC_9           0.6192      0.024     25.474      0.000       0.572       0.667\n",
       "PC_10         -0.3744      0.023    -16.306      0.000      -0.419      -0.329\n",
       "PC_14          0.1797      0.026      6.876      0.000       0.128       0.231\n",
       "PC_16         -0.1587      0.034     -4.727      0.000      -0.225      -0.093\n",
       "PC_17         -0.1520      0.031     -4.956      0.000      -0.212      -0.092\n",
       "PC_18          0.3320      0.026     12.706      0.000       0.281       0.383\n",
       "PC_19         -0.7782      0.026    -30.481      0.000      -0.828      -0.728\n",
       "PC_20          0.4287      0.037     11.446      0.000       0.355       0.502\n",
       "PC_21         -0.1020      0.038     -2.702      0.007      -0.176      -0.028\n",
       "PC_22         -0.1283      0.026     -4.885      0.000      -0.180      -0.077\n",
       "PC_23          0.3115      0.036      8.596      0.000       0.240       0.383\n",
       "PC_24          0.2492      0.033      7.598      0.000       0.185       0.314\n",
       "PC_25         -0.1985      0.037     -5.405      0.000      -0.271      -0.127\n",
       "PC_26         -0.1858      0.040     -4.608      0.000      -0.265      -0.107\n",
       "PC_28         -0.0995      0.031     -3.244      0.001      -0.160      -0.039\n",
       "PC_29         -0.4275      0.044     -9.716      0.000      -0.514      -0.341\n",
       "PC_31         -0.4871      0.041    -11.836      0.000      -0.568      -0.406\n",
       "PC_32         -0.1170      0.050     -2.350      0.019      -0.215      -0.019\n",
       "PC_33          0.1368      0.034      4.014      0.000       0.070       0.204\n",
       "PC_34         -0.3561      0.037     -9.667      0.000      -0.428      -0.284\n",
       "PC_35          0.1508      0.041      3.682      0.000       0.071       0.231\n",
       "PC_38         -0.1288      0.036     -3.614      0.000      -0.199      -0.059\n",
       "PC_39          0.1072      0.042      2.534      0.011       0.024       0.190\n",
       "PC_40         -0.3564      0.036     -9.937      0.000      -0.427      -0.286\n",
       "PC_41         -0.1896      0.044     -4.301      0.000      -0.276      -0.103\n",
       "PC_42         -0.1012      0.041     -2.462      0.014      -0.182      -0.021\n",
       "PC_44          0.2331      0.053      4.422      0.000       0.130       0.336\n",
       "PC_45          0.1069      0.042      2.567      0.010       0.025       0.189\n",
       "PC_46          0.1372      0.043      3.202      0.001       0.053       0.221\n",
       "PC_48          0.3009      0.043      7.012      0.000       0.217       0.385\n",
       "PC_50          0.3695      0.046      8.056      0.000       0.280       0.459\n",
       "PC_51          0.1080      0.054      1.995      0.046       0.002       0.214\n",
       "PC_52         -0.4484      0.048     -9.333      0.000      -0.543      -0.354\n",
       "PC_53         -0.5172      0.050    -10.428      0.000      -0.614      -0.420\n",
       "PC_54          0.1012      0.054      1.871      0.061      -0.005       0.207\n",
       "PC_56          0.1356      0.067      2.020      0.043       0.004       0.267\n",
       "PC_58          0.4427      0.056      7.949      0.000       0.334       0.552\n",
       "PC_60          0.2196      0.062      3.534      0.000       0.098       0.341\n",
       "PC_61         -0.3563      0.070     -5.104      0.000      -0.493      -0.219\n",
       "PC_63         -0.0889      0.068     -1.298      0.194      -0.223       0.045\n",
       "PC_64         -0.2489      0.073     -3.420      0.001      -0.392      -0.106\n",
       "PC_66          0.2392      0.055      4.313      0.000       0.131       0.348\n",
       "PC_69          0.1741      0.057      3.078      0.002       0.063       0.285\n",
       "PC_70          0.1152      0.075      1.539      0.124      -0.032       0.262\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm1 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm1.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping PC_63 due to high p value equal to 0.194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('PC_63')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Churn</td>      <th>  No. Observations:  </th>  <td> 22884</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22834</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    49</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -5030.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  10060.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:08:34</td>     <th>  Pearson chi2:      </th> <td>1.34e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.9269</td> <td>    0.072</td> <td>  -54.634</td> <td> 0.000</td> <td>   -4.068</td> <td>   -3.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_1</th>  <td>   -0.8996</td> <td>    0.019</td> <td>  -48.328</td> <td> 0.000</td> <td>   -0.936</td> <td>   -0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_2</th>  <td>    0.1381</td> <td>    0.009</td> <td>   15.852</td> <td> 0.000</td> <td>    0.121</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_4</th>  <td>    0.1656</td> <td>    0.017</td> <td>    9.873</td> <td> 0.000</td> <td>    0.133</td> <td>    0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_5</th>  <td>   -0.2104</td> <td>    0.018</td> <td>  -11.497</td> <td> 0.000</td> <td>   -0.246</td> <td>   -0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_7</th>  <td>    0.6686</td> <td>    0.021</td> <td>   32.352</td> <td> 0.000</td> <td>    0.628</td> <td>    0.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_8</th>  <td>   -0.0832</td> <td>    0.024</td> <td>   -3.522</td> <td> 0.000</td> <td>   -0.129</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_9</th>  <td>    0.6160</td> <td>    0.024</td> <td>   25.595</td> <td> 0.000</td> <td>    0.569</td> <td>    0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_10</th> <td>   -0.3768</td> <td>    0.023</td> <td>  -16.548</td> <td> 0.000</td> <td>   -0.421</td> <td>   -0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_14</th> <td>    0.1832</td> <td>    0.026</td> <td>    7.068</td> <td> 0.000</td> <td>    0.132</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_16</th> <td>   -0.1592</td> <td>    0.034</td> <td>   -4.750</td> <td> 0.000</td> <td>   -0.225</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_17</th> <td>   -0.1527</td> <td>    0.031</td> <td>   -4.982</td> <td> 0.000</td> <td>   -0.213</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_18</th> <td>    0.3307</td> <td>    0.026</td> <td>   12.680</td> <td> 0.000</td> <td>    0.280</td> <td>    0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_19</th> <td>   -0.7781</td> <td>    0.026</td> <td>  -30.506</td> <td> 0.000</td> <td>   -0.828</td> <td>   -0.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_20</th> <td>    0.4304</td> <td>    0.037</td> <td>   11.524</td> <td> 0.000</td> <td>    0.357</td> <td>    0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_21</th> <td>   -0.1003</td> <td>    0.038</td> <td>   -2.666</td> <td> 0.008</td> <td>   -0.174</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_22</th> <td>   -0.1271</td> <td>    0.026</td> <td>   -4.838</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_23</th> <td>    0.3045</td> <td>    0.036</td> <td>    8.508</td> <td> 0.000</td> <td>    0.234</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_24</th> <td>    0.2531</td> <td>    0.033</td> <td>    7.758</td> <td> 0.000</td> <td>    0.189</td> <td>    0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_25</th> <td>   -0.1999</td> <td>    0.037</td> <td>   -5.451</td> <td> 0.000</td> <td>   -0.272</td> <td>   -0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_26</th> <td>   -0.1843</td> <td>    0.040</td> <td>   -4.579</td> <td> 0.000</td> <td>   -0.263</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_28</th> <td>   -0.0996</td> <td>    0.031</td> <td>   -3.247</td> <td> 0.001</td> <td>   -0.160</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_29</th> <td>   -0.4236</td> <td>    0.044</td> <td>   -9.654</td> <td> 0.000</td> <td>   -0.510</td> <td>   -0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_31</th> <td>   -0.4872</td> <td>    0.041</td> <td>  -11.842</td> <td> 0.000</td> <td>   -0.568</td> <td>   -0.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_32</th> <td>   -0.1176</td> <td>    0.050</td> <td>   -2.362</td> <td> 0.018</td> <td>   -0.215</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_33</th> <td>    0.1382</td> <td>    0.034</td> <td>    4.060</td> <td> 0.000</td> <td>    0.071</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_34</th> <td>   -0.3552</td> <td>    0.037</td> <td>   -9.650</td> <td> 0.000</td> <td>   -0.427</td> <td>   -0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_35</th> <td>    0.1527</td> <td>    0.041</td> <td>    3.733</td> <td> 0.000</td> <td>    0.073</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_38</th> <td>   -0.1275</td> <td>    0.036</td> <td>   -3.578</td> <td> 0.000</td> <td>   -0.197</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_39</th> <td>    0.1091</td> <td>    0.042</td> <td>    2.581</td> <td> 0.010</td> <td>    0.026</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_40</th> <td>   -0.3564</td> <td>    0.036</td> <td>   -9.936</td> <td> 0.000</td> <td>   -0.427</td> <td>   -0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_41</th> <td>   -0.1882</td> <td>    0.044</td> <td>   -4.271</td> <td> 0.000</td> <td>   -0.275</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_42</th> <td>   -0.1001</td> <td>    0.041</td> <td>   -2.437</td> <td> 0.015</td> <td>   -0.181</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_44</th> <td>    0.2357</td> <td>    0.053</td> <td>    4.472</td> <td> 0.000</td> <td>    0.132</td> <td>    0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_45</th> <td>    0.1079</td> <td>    0.042</td> <td>    2.591</td> <td> 0.010</td> <td>    0.026</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_46</th> <td>    0.1348</td> <td>    0.043</td> <td>    3.151</td> <td> 0.002</td> <td>    0.051</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_48</th> <td>    0.3029</td> <td>    0.043</td> <td>    7.072</td> <td> 0.000</td> <td>    0.219</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_50</th> <td>    0.3724</td> <td>    0.046</td> <td>    8.142</td> <td> 0.000</td> <td>    0.283</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_51</th> <td>    0.1048</td> <td>    0.054</td> <td>    1.944</td> <td> 0.052</td> <td>   -0.001</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_52</th> <td>   -0.4454</td> <td>    0.048</td> <td>   -9.287</td> <td> 0.000</td> <td>   -0.539</td> <td>   -0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_53</th> <td>   -0.5164</td> <td>    0.050</td> <td>  -10.420</td> <td> 0.000</td> <td>   -0.614</td> <td>   -0.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_54</th> <td>    0.1029</td> <td>    0.054</td> <td>    1.904</td> <td> 0.057</td> <td>   -0.003</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_56</th> <td>    0.1306</td> <td>    0.067</td> <td>    1.958</td> <td> 0.050</td> <td>   -0.000</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_58</th> <td>    0.4276</td> <td>    0.054</td> <td>    7.857</td> <td> 0.000</td> <td>    0.321</td> <td>    0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_60</th> <td>    0.2126</td> <td>    0.062</td> <td>    3.433</td> <td> 0.001</td> <td>    0.091</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_61</th> <td>   -0.3500</td> <td>    0.069</td> <td>   -5.042</td> <td> 0.000</td> <td>   -0.486</td> <td>   -0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_64</th> <td>   -0.2558</td> <td>    0.072</td> <td>   -3.530</td> <td> 0.000</td> <td>   -0.398</td> <td>   -0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_66</th> <td>    0.2424</td> <td>    0.055</td> <td>    4.379</td> <td> 0.000</td> <td>    0.134</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_69</th> <td>    0.1729</td> <td>    0.057</td> <td>    3.060</td> <td> 0.002</td> <td>    0.062</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_70</th> <td>    0.1140</td> <td>    0.075</td> <td>    1.526</td> <td> 0.127</td> <td>   -0.032</td> <td>    0.261</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Churn   No. Observations:                22884\n",
       "Model:                            GLM   Df Residuals:                    22834\n",
       "Model Family:                Binomial   Df Model:                           49\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -5030.0\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       10060.\n",
       "Time:                        21:08:34   Pearson chi2:                 1.34e+06\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.9269      0.072    -54.634      0.000      -4.068      -3.786\n",
       "PC_1          -0.8996      0.019    -48.328      0.000      -0.936      -0.863\n",
       "PC_2           0.1381      0.009     15.852      0.000       0.121       0.155\n",
       "PC_4           0.1656      0.017      9.873      0.000       0.133       0.198\n",
       "PC_5          -0.2104      0.018    -11.497      0.000      -0.246      -0.175\n",
       "PC_7           0.6686      0.021     32.352      0.000       0.628       0.709\n",
       "PC_8          -0.0832      0.024     -3.522      0.000      -0.129      -0.037\n",
       "PC_9           0.6160      0.024     25.595      0.000       0.569       0.663\n",
       "PC_10         -0.3768      0.023    -16.548      0.000      -0.421      -0.332\n",
       "PC_14          0.1832      0.026      7.068      0.000       0.132       0.234\n",
       "PC_16         -0.1592      0.034     -4.750      0.000      -0.225      -0.093\n",
       "PC_17         -0.1527      0.031     -4.982      0.000      -0.213      -0.093\n",
       "PC_18          0.3307      0.026     12.680      0.000       0.280       0.382\n",
       "PC_19         -0.7781      0.026    -30.506      0.000      -0.828      -0.728\n",
       "PC_20          0.4304      0.037     11.524      0.000       0.357       0.504\n",
       "PC_21         -0.1003      0.038     -2.666      0.008      -0.174      -0.027\n",
       "PC_22         -0.1271      0.026     -4.838      0.000      -0.179      -0.076\n",
       "PC_23          0.3045      0.036      8.508      0.000       0.234       0.375\n",
       "PC_24          0.2531      0.033      7.758      0.000       0.189       0.317\n",
       "PC_25         -0.1999      0.037     -5.451      0.000      -0.272      -0.128\n",
       "PC_26         -0.1843      0.040     -4.579      0.000      -0.263      -0.105\n",
       "PC_28         -0.0996      0.031     -3.247      0.001      -0.160      -0.039\n",
       "PC_29         -0.4236      0.044     -9.654      0.000      -0.510      -0.338\n",
       "PC_31         -0.4872      0.041    -11.842      0.000      -0.568      -0.407\n",
       "PC_32         -0.1176      0.050     -2.362      0.018      -0.215      -0.020\n",
       "PC_33          0.1382      0.034      4.060      0.000       0.071       0.205\n",
       "PC_34         -0.3552      0.037     -9.650      0.000      -0.427      -0.283\n",
       "PC_35          0.1527      0.041      3.733      0.000       0.073       0.233\n",
       "PC_38         -0.1275      0.036     -3.578      0.000      -0.197      -0.058\n",
       "PC_39          0.1091      0.042      2.581      0.010       0.026       0.192\n",
       "PC_40         -0.3564      0.036     -9.936      0.000      -0.427      -0.286\n",
       "PC_41         -0.1882      0.044     -4.271      0.000      -0.275      -0.102\n",
       "PC_42         -0.1001      0.041     -2.437      0.015      -0.181      -0.020\n",
       "PC_44          0.2357      0.053      4.472      0.000       0.132       0.339\n",
       "PC_45          0.1079      0.042      2.591      0.010       0.026       0.189\n",
       "PC_46          0.1348      0.043      3.151      0.002       0.051       0.219\n",
       "PC_48          0.3029      0.043      7.072      0.000       0.219       0.387\n",
       "PC_50          0.3724      0.046      8.142      0.000       0.283       0.462\n",
       "PC_51          0.1048      0.054      1.944      0.052      -0.001       0.210\n",
       "PC_52         -0.4454      0.048     -9.287      0.000      -0.539      -0.351\n",
       "PC_53         -0.5164      0.050    -10.420      0.000      -0.614      -0.419\n",
       "PC_54          0.1029      0.054      1.904      0.057      -0.003       0.209\n",
       "PC_56          0.1306      0.067      1.958      0.050      -0.000       0.261\n",
       "PC_58          0.4276      0.054      7.857      0.000       0.321       0.534\n",
       "PC_60          0.2126      0.062      3.433      0.001       0.091       0.334\n",
       "PC_61         -0.3500      0.069     -5.042      0.000      -0.486      -0.214\n",
       "PC_64         -0.2558      0.072     -3.530      0.000      -0.398      -0.114\n",
       "PC_66          0.2424      0.055      4.379      0.000       0.134       0.351\n",
       "PC_69          0.1729      0.057      3.060      0.002       0.062       0.284\n",
       "PC_70          0.1140      0.075      1.526      0.127      -0.032       0.261\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm2 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping PC_70 due to high p value equal to 0.127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('PC_70')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Churn</td>      <th>  No. Observations:  </th>  <td> 22884</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22835</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -5031.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  10062.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:09:11</td>     <th>  Pearson chi2:      </th> <td>1.25e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.9180</td> <td>    0.071</td> <td>  -54.825</td> <td> 0.000</td> <td>   -4.058</td> <td>   -3.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_1</th>  <td>   -0.8977</td> <td>    0.019</td> <td>  -48.418</td> <td> 0.000</td> <td>   -0.934</td> <td>   -0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_2</th>  <td>    0.1376</td> <td>    0.009</td> <td>   15.820</td> <td> 0.000</td> <td>    0.121</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_4</th>  <td>    0.1648</td> <td>    0.017</td> <td>    9.824</td> <td> 0.000</td> <td>    0.132</td> <td>    0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_5</th>  <td>   -0.2127</td> <td>    0.018</td> <td>  -11.642</td> <td> 0.000</td> <td>   -0.248</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_7</th>  <td>    0.6665</td> <td>    0.021</td> <td>   32.295</td> <td> 0.000</td> <td>    0.626</td> <td>    0.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_8</th>  <td>   -0.0822</td> <td>    0.024</td> <td>   -3.477</td> <td> 0.001</td> <td>   -0.128</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_9</th>  <td>    0.6114</td> <td>    0.024</td> <td>   25.590</td> <td> 0.000</td> <td>    0.565</td> <td>    0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_10</th> <td>   -0.3775</td> <td>    0.023</td> <td>  -16.524</td> <td> 0.000</td> <td>   -0.422</td> <td>   -0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_14</th> <td>    0.1808</td> <td>    0.026</td> <td>    6.983</td> <td> 0.000</td> <td>    0.130</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_16</th> <td>   -0.1540</td> <td>    0.033</td> <td>   -4.616</td> <td> 0.000</td> <td>   -0.219</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_17</th> <td>   -0.1491</td> <td>    0.031</td> <td>   -4.876</td> <td> 0.000</td> <td>   -0.209</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_18</th> <td>    0.3301</td> <td>    0.026</td> <td>   12.659</td> <td> 0.000</td> <td>    0.279</td> <td>    0.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_19</th> <td>   -0.7771</td> <td>    0.026</td> <td>  -30.452</td> <td> 0.000</td> <td>   -0.827</td> <td>   -0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_20</th> <td>    0.4345</td> <td>    0.037</td> <td>   11.649</td> <td> 0.000</td> <td>    0.361</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_21</th> <td>   -0.0967</td> <td>    0.038</td> <td>   -2.576</td> <td> 0.010</td> <td>   -0.170</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_22</th> <td>   -0.1276</td> <td>    0.026</td> <td>   -4.857</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_23</th> <td>    0.3035</td> <td>    0.036</td> <td>    8.480</td> <td> 0.000</td> <td>    0.233</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_24</th> <td>    0.2537</td> <td>    0.033</td> <td>    7.779</td> <td> 0.000</td> <td>    0.190</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_25</th> <td>   -0.1983</td> <td>    0.037</td> <td>   -5.409</td> <td> 0.000</td> <td>   -0.270</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_26</th> <td>   -0.1863</td> <td>    0.040</td> <td>   -4.630</td> <td> 0.000</td> <td>   -0.265</td> <td>   -0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_28</th> <td>   -0.1006</td> <td>    0.031</td> <td>   -3.275</td> <td> 0.001</td> <td>   -0.161</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_29</th> <td>   -0.4217</td> <td>    0.044</td> <td>   -9.611</td> <td> 0.000</td> <td>   -0.508</td> <td>   -0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_31</th> <td>   -0.4882</td> <td>    0.041</td> <td>  -11.865</td> <td> 0.000</td> <td>   -0.569</td> <td>   -0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_32</th> <td>   -0.1153</td> <td>    0.050</td> <td>   -2.320</td> <td> 0.020</td> <td>   -0.213</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_33</th> <td>    0.1382</td> <td>    0.034</td> <td>    4.057</td> <td> 0.000</td> <td>    0.071</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_34</th> <td>   -0.3538</td> <td>    0.037</td> <td>   -9.615</td> <td> 0.000</td> <td>   -0.426</td> <td>   -0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_35</th> <td>    0.1487</td> <td>    0.041</td> <td>    3.647</td> <td> 0.000</td> <td>    0.069</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_38</th> <td>   -0.1269</td> <td>    0.036</td> <td>   -3.564</td> <td> 0.000</td> <td>   -0.197</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_39</th> <td>    0.1129</td> <td>    0.042</td> <td>    2.677</td> <td> 0.007</td> <td>    0.030</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_40</th> <td>   -0.3542</td> <td>    0.036</td> <td>   -9.885</td> <td> 0.000</td> <td>   -0.424</td> <td>   -0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_41</th> <td>   -0.1910</td> <td>    0.044</td> <td>   -4.339</td> <td> 0.000</td> <td>   -0.277</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_42</th> <td>   -0.0960</td> <td>    0.041</td> <td>   -2.337</td> <td> 0.019</td> <td>   -0.176</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_44</th> <td>    0.2322</td> <td>    0.053</td> <td>    4.418</td> <td> 0.000</td> <td>    0.129</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_45</th> <td>    0.1089</td> <td>    0.042</td> <td>    2.614</td> <td> 0.009</td> <td>    0.027</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_46</th> <td>    0.1354</td> <td>    0.043</td> <td>    3.166</td> <td> 0.002</td> <td>    0.052</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_48</th> <td>    0.3041</td> <td>    0.043</td> <td>    7.100</td> <td> 0.000</td> <td>    0.220</td> <td>    0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_50</th> <td>    0.3684</td> <td>    0.046</td> <td>    8.071</td> <td> 0.000</td> <td>    0.279</td> <td>    0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_51</th> <td>    0.1053</td> <td>    0.054</td> <td>    1.956</td> <td> 0.051</td> <td>   -0.000</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_52</th> <td>   -0.4399</td> <td>    0.048</td> <td>   -9.192</td> <td> 0.000</td> <td>   -0.534</td> <td>   -0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_53</th> <td>   -0.5140</td> <td>    0.050</td> <td>  -10.367</td> <td> 0.000</td> <td>   -0.611</td> <td>   -0.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_54</th> <td>    0.1050</td> <td>    0.054</td> <td>    1.943</td> <td> 0.052</td> <td>   -0.001</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_56</th> <td>    0.1270</td> <td>    0.067</td> <td>    1.906</td> <td> 0.057</td> <td>   -0.004</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_58</th> <td>    0.4250</td> <td>    0.054</td> <td>    7.805</td> <td> 0.000</td> <td>    0.318</td> <td>    0.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_60</th> <td>    0.2199</td> <td>    0.062</td> <td>    3.560</td> <td> 0.000</td> <td>    0.099</td> <td>    0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_61</th> <td>   -0.3582</td> <td>    0.069</td> <td>   -5.174</td> <td> 0.000</td> <td>   -0.494</td> <td>   -0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_64</th> <td>   -0.2461</td> <td>    0.072</td> <td>   -3.406</td> <td> 0.001</td> <td>   -0.388</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_66</th> <td>    0.2478</td> <td>    0.055</td> <td>    4.483</td> <td> 0.000</td> <td>    0.139</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_69</th> <td>    0.1847</td> <td>    0.056</td> <td>    3.298</td> <td> 0.001</td> <td>    0.075</td> <td>    0.294</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Churn   No. Observations:                22884\n",
       "Model:                            GLM   Df Residuals:                    22835\n",
       "Model Family:                Binomial   Df Model:                           48\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -5031.2\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       10062.\n",
       "Time:                        21:09:11   Pearson chi2:                 1.25e+06\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.9180      0.071    -54.825      0.000      -4.058      -3.778\n",
       "PC_1          -0.8977      0.019    -48.418      0.000      -0.934      -0.861\n",
       "PC_2           0.1376      0.009     15.820      0.000       0.121       0.155\n",
       "PC_4           0.1648      0.017      9.824      0.000       0.132       0.198\n",
       "PC_5          -0.2127      0.018    -11.642      0.000      -0.248      -0.177\n",
       "PC_7           0.6665      0.021     32.295      0.000       0.626       0.707\n",
       "PC_8          -0.0822      0.024     -3.477      0.001      -0.128      -0.036\n",
       "PC_9           0.6114      0.024     25.590      0.000       0.565       0.658\n",
       "PC_10         -0.3775      0.023    -16.524      0.000      -0.422      -0.333\n",
       "PC_14          0.1808      0.026      6.983      0.000       0.130       0.232\n",
       "PC_16         -0.1540      0.033     -4.616      0.000      -0.219      -0.089\n",
       "PC_17         -0.1491      0.031     -4.876      0.000      -0.209      -0.089\n",
       "PC_18          0.3301      0.026     12.659      0.000       0.279       0.381\n",
       "PC_19         -0.7771      0.026    -30.452      0.000      -0.827      -0.727\n",
       "PC_20          0.4345      0.037     11.649      0.000       0.361       0.508\n",
       "PC_21         -0.0967      0.038     -2.576      0.010      -0.170      -0.023\n",
       "PC_22         -0.1276      0.026     -4.857      0.000      -0.179      -0.076\n",
       "PC_23          0.3035      0.036      8.480      0.000       0.233       0.374\n",
       "PC_24          0.2537      0.033      7.779      0.000       0.190       0.318\n",
       "PC_25         -0.1983      0.037     -5.409      0.000      -0.270      -0.126\n",
       "PC_26         -0.1863      0.040     -4.630      0.000      -0.265      -0.107\n",
       "PC_28         -0.1006      0.031     -3.275      0.001      -0.161      -0.040\n",
       "PC_29         -0.4217      0.044     -9.611      0.000      -0.508      -0.336\n",
       "PC_31         -0.4882      0.041    -11.865      0.000      -0.569      -0.408\n",
       "PC_32         -0.1153      0.050     -2.320      0.020      -0.213      -0.018\n",
       "PC_33          0.1382      0.034      4.057      0.000       0.071       0.205\n",
       "PC_34         -0.3538      0.037     -9.615      0.000      -0.426      -0.282\n",
       "PC_35          0.1487      0.041      3.647      0.000       0.069       0.229\n",
       "PC_38         -0.1269      0.036     -3.564      0.000      -0.197      -0.057\n",
       "PC_39          0.1129      0.042      2.677      0.007       0.030       0.196\n",
       "PC_40         -0.3542      0.036     -9.885      0.000      -0.424      -0.284\n",
       "PC_41         -0.1910      0.044     -4.339      0.000      -0.277      -0.105\n",
       "PC_42         -0.0960      0.041     -2.337      0.019      -0.176      -0.015\n",
       "PC_44          0.2322      0.053      4.418      0.000       0.129       0.335\n",
       "PC_45          0.1089      0.042      2.614      0.009       0.027       0.191\n",
       "PC_46          0.1354      0.043      3.166      0.002       0.052       0.219\n",
       "PC_48          0.3041      0.043      7.100      0.000       0.220       0.388\n",
       "PC_50          0.3684      0.046      8.071      0.000       0.279       0.458\n",
       "PC_51          0.1053      0.054      1.956      0.051      -0.000       0.211\n",
       "PC_52         -0.4399      0.048     -9.192      0.000      -0.534      -0.346\n",
       "PC_53         -0.5140      0.050    -10.367      0.000      -0.611      -0.417\n",
       "PC_54          0.1050      0.054      1.943      0.052      -0.001       0.211\n",
       "PC_56          0.1270      0.067      1.906      0.057      -0.004       0.258\n",
       "PC_58          0.4250      0.054      7.805      0.000       0.318       0.532\n",
       "PC_60          0.2199      0.062      3.560      0.000       0.099       0.341\n",
       "PC_61         -0.3582      0.069     -5.174      0.000      -0.494      -0.223\n",
       "PC_64         -0.2461      0.072     -3.406      0.001      -0.388      -0.104\n",
       "PC_66          0.2478      0.055      4.483      0.000       0.139       0.356\n",
       "PC_69          0.1847      0.056      3.298      0.001       0.075       0.294\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm3 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm3.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping PC_56 due to high p value equal to 0.057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('PC_56')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Churn</td>      <th>  No. Observations:  </th>  <td> 22884</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22836</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    47</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -5033.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  10066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:10:05</td>     <th>  Pearson chi2:      </th> <td>1.22e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.9125</td> <td>    0.071</td> <td>  -54.936</td> <td> 0.000</td> <td>   -4.052</td> <td>   -3.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_1</th>  <td>   -0.8962</td> <td>    0.018</td> <td>  -48.512</td> <td> 0.000</td> <td>   -0.932</td> <td>   -0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_2</th>  <td>    0.1366</td> <td>    0.009</td> <td>   15.750</td> <td> 0.000</td> <td>    0.120</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_4</th>  <td>    0.1677</td> <td>    0.017</td> <td>   10.096</td> <td> 0.000</td> <td>    0.135</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_5</th>  <td>   -0.2130</td> <td>    0.018</td> <td>  -11.677</td> <td> 0.000</td> <td>   -0.249</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_7</th>  <td>    0.6619</td> <td>    0.020</td> <td>   32.430</td> <td> 0.000</td> <td>    0.622</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_8</th>  <td>   -0.0809</td> <td>    0.024</td> <td>   -3.430</td> <td> 0.001</td> <td>   -0.127</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_9</th>  <td>    0.6070</td> <td>    0.024</td> <td>   25.701</td> <td> 0.000</td> <td>    0.561</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_10</th> <td>   -0.3810</td> <td>    0.023</td> <td>  -16.838</td> <td> 0.000</td> <td>   -0.425</td> <td>   -0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_14</th> <td>    0.1883</td> <td>    0.025</td> <td>    7.404</td> <td> 0.000</td> <td>    0.138</td> <td>    0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_16</th> <td>   -0.1539</td> <td>    0.033</td> <td>   -4.622</td> <td> 0.000</td> <td>   -0.219</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_17</th> <td>   -0.1429</td> <td>    0.030</td> <td>   -4.709</td> <td> 0.000</td> <td>   -0.202</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_18</th> <td>    0.3321</td> <td>    0.026</td> <td>   12.761</td> <td> 0.000</td> <td>    0.281</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_19</th> <td>   -0.7739</td> <td>    0.025</td> <td>  -30.434</td> <td> 0.000</td> <td>   -0.824</td> <td>   -0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_20</th> <td>    0.4404</td> <td>    0.037</td> <td>   11.928</td> <td> 0.000</td> <td>    0.368</td> <td>    0.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_21</th> <td>   -0.0929</td> <td>    0.037</td> <td>   -2.487</td> <td> 0.013</td> <td>   -0.166</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_22</th> <td>   -0.1279</td> <td>    0.026</td> <td>   -4.871</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_23</th> <td>    0.3008</td> <td>    0.036</td> <td>    8.415</td> <td> 0.000</td> <td>    0.231</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_24</th> <td>    0.2520</td> <td>    0.033</td> <td>    7.743</td> <td> 0.000</td> <td>    0.188</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_25</th> <td>   -0.1944</td> <td>    0.036</td> <td>   -5.338</td> <td> 0.000</td> <td>   -0.266</td> <td>   -0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_26</th> <td>   -0.1824</td> <td>    0.040</td> <td>   -4.550</td> <td> 0.000</td> <td>   -0.261</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_28</th> <td>   -0.0997</td> <td>    0.031</td> <td>   -3.249</td> <td> 0.001</td> <td>   -0.160</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_29</th> <td>   -0.4197</td> <td>    0.044</td> <td>   -9.576</td> <td> 0.000</td> <td>   -0.506</td> <td>   -0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_31</th> <td>   -0.4866</td> <td>    0.041</td> <td>  -11.836</td> <td> 0.000</td> <td>   -0.567</td> <td>   -0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_32</th> <td>   -0.1101</td> <td>    0.050</td> <td>   -2.221</td> <td> 0.026</td> <td>   -0.207</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_33</th> <td>    0.1386</td> <td>    0.034</td> <td>    4.071</td> <td> 0.000</td> <td>    0.072</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_34</th> <td>   -0.3528</td> <td>    0.037</td> <td>   -9.591</td> <td> 0.000</td> <td>   -0.425</td> <td>   -0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_35</th> <td>    0.1490</td> <td>    0.041</td> <td>    3.652</td> <td> 0.000</td> <td>    0.069</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_38</th> <td>   -0.1254</td> <td>    0.036</td> <td>   -3.522</td> <td> 0.000</td> <td>   -0.195</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_39</th> <td>    0.1184</td> <td>    0.042</td> <td>    2.823</td> <td> 0.005</td> <td>    0.036</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_40</th> <td>   -0.3560</td> <td>    0.036</td> <td>   -9.938</td> <td> 0.000</td> <td>   -0.426</td> <td>   -0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_41</th> <td>   -0.1842</td> <td>    0.044</td> <td>   -4.204</td> <td> 0.000</td> <td>   -0.270</td> <td>   -0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_42</th> <td>   -0.0951</td> <td>    0.041</td> <td>   -2.322</td> <td> 0.020</td> <td>   -0.175</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_44</th> <td>    0.2346</td> <td>    0.052</td> <td>    4.476</td> <td> 0.000</td> <td>    0.132</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_45</th> <td>    0.1080</td> <td>    0.042</td> <td>    2.594</td> <td> 0.009</td> <td>    0.026</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_46</th> <td>    0.1373</td> <td>    0.043</td> <td>    3.214</td> <td> 0.001</td> <td>    0.054</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_48</th> <td>    0.3047</td> <td>    0.043</td> <td>    7.110</td> <td> 0.000</td> <td>    0.221</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_50</th> <td>    0.3684</td> <td>    0.046</td> <td>    8.073</td> <td> 0.000</td> <td>    0.279</td> <td>    0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_51</th> <td>    0.1008</td> <td>    0.054</td> <td>    1.873</td> <td> 0.061</td> <td>   -0.005</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_52</th> <td>   -0.4391</td> <td>    0.048</td> <td>   -9.180</td> <td> 0.000</td> <td>   -0.533</td> <td>   -0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_53</th> <td>   -0.5141</td> <td>    0.050</td> <td>  -10.380</td> <td> 0.000</td> <td>   -0.611</td> <td>   -0.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_54</th> <td>    0.1056</td> <td>    0.054</td> <td>    1.956</td> <td> 0.050</td> <td>   -0.000</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_58</th> <td>    0.4245</td> <td>    0.054</td> <td>    7.806</td> <td> 0.000</td> <td>    0.318</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_60</th> <td>    0.2184</td> <td>    0.062</td> <td>    3.532</td> <td> 0.000</td> <td>    0.097</td> <td>    0.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_61</th> <td>   -0.3526</td> <td>    0.069</td> <td>   -5.106</td> <td> 0.000</td> <td>   -0.488</td> <td>   -0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_64</th> <td>   -0.2459</td> <td>    0.072</td> <td>   -3.429</td> <td> 0.001</td> <td>   -0.386</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_66</th> <td>    0.2458</td> <td>    0.055</td> <td>    4.456</td> <td> 0.000</td> <td>    0.138</td> <td>    0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_69</th> <td>    0.1827</td> <td>    0.056</td> <td>    3.261</td> <td> 0.001</td> <td>    0.073</td> <td>    0.293</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Churn   No. Observations:                22884\n",
       "Model:                            GLM   Df Residuals:                    22836\n",
       "Model Family:                Binomial   Df Model:                           47\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -5033.0\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       10066.\n",
       "Time:                        21:10:05   Pearson chi2:                 1.22e+06\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.9125      0.071    -54.936      0.000      -4.052      -3.773\n",
       "PC_1          -0.8962      0.018    -48.512      0.000      -0.932      -0.860\n",
       "PC_2           0.1366      0.009     15.750      0.000       0.120       0.154\n",
       "PC_4           0.1677      0.017     10.096      0.000       0.135       0.200\n",
       "PC_5          -0.2130      0.018    -11.677      0.000      -0.249      -0.177\n",
       "PC_7           0.6619      0.020     32.430      0.000       0.622       0.702\n",
       "PC_8          -0.0809      0.024     -3.430      0.001      -0.127      -0.035\n",
       "PC_9           0.6070      0.024     25.701      0.000       0.561       0.653\n",
       "PC_10         -0.3810      0.023    -16.838      0.000      -0.425      -0.337\n",
       "PC_14          0.1883      0.025      7.404      0.000       0.138       0.238\n",
       "PC_16         -0.1539      0.033     -4.622      0.000      -0.219      -0.089\n",
       "PC_17         -0.1429      0.030     -4.709      0.000      -0.202      -0.083\n",
       "PC_18          0.3321      0.026     12.761      0.000       0.281       0.383\n",
       "PC_19         -0.7739      0.025    -30.434      0.000      -0.824      -0.724\n",
       "PC_20          0.4404      0.037     11.928      0.000       0.368       0.513\n",
       "PC_21         -0.0929      0.037     -2.487      0.013      -0.166      -0.020\n",
       "PC_22         -0.1279      0.026     -4.871      0.000      -0.179      -0.076\n",
       "PC_23          0.3008      0.036      8.415      0.000       0.231       0.371\n",
       "PC_24          0.2520      0.033      7.743      0.000       0.188       0.316\n",
       "PC_25         -0.1944      0.036     -5.338      0.000      -0.266      -0.123\n",
       "PC_26         -0.1824      0.040     -4.550      0.000      -0.261      -0.104\n",
       "PC_28         -0.0997      0.031     -3.249      0.001      -0.160      -0.040\n",
       "PC_29         -0.4197      0.044     -9.576      0.000      -0.506      -0.334\n",
       "PC_31         -0.4866      0.041    -11.836      0.000      -0.567      -0.406\n",
       "PC_32         -0.1101      0.050     -2.221      0.026      -0.207      -0.013\n",
       "PC_33          0.1386      0.034      4.071      0.000       0.072       0.205\n",
       "PC_34         -0.3528      0.037     -9.591      0.000      -0.425      -0.281\n",
       "PC_35          0.1490      0.041      3.652      0.000       0.069       0.229\n",
       "PC_38         -0.1254      0.036     -3.522      0.000      -0.195      -0.056\n",
       "PC_39          0.1184      0.042      2.823      0.005       0.036       0.201\n",
       "PC_40         -0.3560      0.036     -9.938      0.000      -0.426      -0.286\n",
       "PC_41         -0.1842      0.044     -4.204      0.000      -0.270      -0.098\n",
       "PC_42         -0.0951      0.041     -2.322      0.020      -0.175      -0.015\n",
       "PC_44          0.2346      0.052      4.476      0.000       0.132       0.337\n",
       "PC_45          0.1080      0.042      2.594      0.009       0.026       0.190\n",
       "PC_46          0.1373      0.043      3.214      0.001       0.054       0.221\n",
       "PC_48          0.3047      0.043      7.110      0.000       0.221       0.389\n",
       "PC_50          0.3684      0.046      8.073      0.000       0.279       0.458\n",
       "PC_51          0.1008      0.054      1.873      0.061      -0.005       0.206\n",
       "PC_52         -0.4391      0.048     -9.180      0.000      -0.533      -0.345\n",
       "PC_53         -0.5141      0.050    -10.380      0.000      -0.611      -0.417\n",
       "PC_54          0.1056      0.054      1.956      0.050      -0.000       0.211\n",
       "PC_58          0.4245      0.054      7.806      0.000       0.318       0.531\n",
       "PC_60          0.2184      0.062      3.532      0.000       0.097       0.340\n",
       "PC_61         -0.3526      0.069     -5.106      0.000      -0.488      -0.217\n",
       "PC_64         -0.2459      0.072     -3.429      0.001      -0.386      -0.105\n",
       "PC_66          0.2458      0.055      4.456      0.000       0.138       0.354\n",
       "PC_69          0.1827      0.056      3.261      0.001       0.073       0.293\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm4 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm4.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping PC_51 due to high p value equal to 0.061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('PC_51')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Churn</td>      <th>  No. Observations:  </th>  <td> 22884</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22837</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    46</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -5034.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  10070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:11:06</td>     <th>  Pearson chi2:      </th> <td>1.43e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.9087</td> <td>    0.071</td> <td>  -54.942</td> <td> 0.000</td> <td>   -4.048</td> <td>   -3.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_1</th>  <td>   -0.8960</td> <td>    0.018</td> <td>  -48.526</td> <td> 0.000</td> <td>   -0.932</td> <td>   -0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_2</th>  <td>    0.1364</td> <td>    0.009</td> <td>   15.711</td> <td> 0.000</td> <td>    0.119</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_4</th>  <td>    0.1686</td> <td>    0.017</td> <td>   10.167</td> <td> 0.000</td> <td>    0.136</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_5</th>  <td>   -0.2111</td> <td>    0.018</td> <td>  -11.618</td> <td> 0.000</td> <td>   -0.247</td> <td>   -0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_7</th>  <td>    0.6617</td> <td>    0.020</td> <td>   32.488</td> <td> 0.000</td> <td>    0.622</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_8</th>  <td>   -0.0786</td> <td>    0.024</td> <td>   -3.341</td> <td> 0.001</td> <td>   -0.125</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_9</th>  <td>    0.6066</td> <td>    0.024</td> <td>   25.697</td> <td> 0.000</td> <td>    0.560</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_10</th> <td>   -0.3799</td> <td>    0.023</td> <td>  -16.791</td> <td> 0.000</td> <td>   -0.424</td> <td>   -0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_14</th> <td>    0.1901</td> <td>    0.025</td> <td>    7.475</td> <td> 0.000</td> <td>    0.140</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_16</th> <td>   -0.1473</td> <td>    0.033</td> <td>   -4.481</td> <td> 0.000</td> <td>   -0.212</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_17</th> <td>   -0.1440</td> <td>    0.030</td> <td>   -4.750</td> <td> 0.000</td> <td>   -0.203</td> <td>   -0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_18</th> <td>    0.3286</td> <td>    0.026</td> <td>   12.710</td> <td> 0.000</td> <td>    0.278</td> <td>    0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_19</th> <td>   -0.7727</td> <td>    0.025</td> <td>  -30.407</td> <td> 0.000</td> <td>   -0.822</td> <td>   -0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_20</th> <td>    0.4388</td> <td>    0.037</td> <td>   11.911</td> <td> 0.000</td> <td>    0.367</td> <td>    0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_21</th> <td>   -0.0859</td> <td>    0.037</td> <td>   -2.323</td> <td> 0.020</td> <td>   -0.158</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_22</th> <td>   -0.1273</td> <td>    0.026</td> <td>   -4.845</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_23</th> <td>    0.3018</td> <td>    0.036</td> <td>    8.441</td> <td> 0.000</td> <td>    0.232</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_24</th> <td>    0.2505</td> <td>    0.032</td> <td>    7.714</td> <td> 0.000</td> <td>    0.187</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_25</th> <td>   -0.1931</td> <td>    0.036</td> <td>   -5.311</td> <td> 0.000</td> <td>   -0.264</td> <td>   -0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_26</th> <td>   -0.1899</td> <td>    0.040</td> <td>   -4.794</td> <td> 0.000</td> <td>   -0.268</td> <td>   -0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_28</th> <td>   -0.1005</td> <td>    0.031</td> <td>   -3.272</td> <td> 0.001</td> <td>   -0.161</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_29</th> <td>   -0.4200</td> <td>    0.044</td> <td>   -9.586</td> <td> 0.000</td> <td>   -0.506</td> <td>   -0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_31</th> <td>   -0.4895</td> <td>    0.041</td> <td>  -11.919</td> <td> 0.000</td> <td>   -0.570</td> <td>   -0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_32</th> <td>   -0.1093</td> <td>    0.050</td> <td>   -2.204</td> <td> 0.028</td> <td>   -0.207</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_33</th> <td>    0.1416</td> <td>    0.034</td> <td>    4.168</td> <td> 0.000</td> <td>    0.075</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_34</th> <td>   -0.3487</td> <td>    0.037</td> <td>   -9.490</td> <td> 0.000</td> <td>   -0.421</td> <td>   -0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_35</th> <td>    0.1503</td> <td>    0.041</td> <td>    3.689</td> <td> 0.000</td> <td>    0.070</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_38</th> <td>   -0.1218</td> <td>    0.036</td> <td>   -3.429</td> <td> 0.001</td> <td>   -0.191</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_39</th> <td>    0.1227</td> <td>    0.042</td> <td>    2.929</td> <td> 0.003</td> <td>    0.041</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_40</th> <td>   -0.3581</td> <td>    0.036</td> <td>  -10.001</td> <td> 0.000</td> <td>   -0.428</td> <td>   -0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_41</th> <td>   -0.1809</td> <td>    0.044</td> <td>   -4.137</td> <td> 0.000</td> <td>   -0.267</td> <td>   -0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_42</th> <td>   -0.1022</td> <td>    0.041</td> <td>   -2.511</td> <td> 0.012</td> <td>   -0.182</td> <td>   -0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_44</th> <td>    0.2172</td> <td>    0.050</td> <td>    4.315</td> <td> 0.000</td> <td>    0.119</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_45</th> <td>    0.1037</td> <td>    0.041</td> <td>    2.501</td> <td> 0.012</td> <td>    0.022</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_46</th> <td>    0.1425</td> <td>    0.043</td> <td>    3.352</td> <td> 0.001</td> <td>    0.059</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_48</th> <td>    0.3130</td> <td>    0.043</td> <td>    7.346</td> <td> 0.000</td> <td>    0.229</td> <td>    0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_50</th> <td>    0.3534</td> <td>    0.045</td> <td>    7.887</td> <td> 0.000</td> <td>    0.266</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_52</th> <td>   -0.4381</td> <td>    0.048</td> <td>   -9.170</td> <td> 0.000</td> <td>   -0.532</td> <td>   -0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_53</th> <td>   -0.5087</td> <td>    0.049</td> <td>  -10.301</td> <td> 0.000</td> <td>   -0.606</td> <td>   -0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_54</th> <td>    0.1072</td> <td>    0.054</td> <td>    1.984</td> <td> 0.047</td> <td>    0.001</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_58</th> <td>    0.4285</td> <td>    0.054</td> <td>    7.904</td> <td> 0.000</td> <td>    0.322</td> <td>    0.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_60</th> <td>    0.2123</td> <td>    0.062</td> <td>    3.444</td> <td> 0.001</td> <td>    0.091</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_61</th> <td>   -0.3528</td> <td>    0.069</td> <td>   -5.119</td> <td> 0.000</td> <td>   -0.488</td> <td>   -0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_64</th> <td>   -0.2436</td> <td>    0.072</td> <td>   -3.398</td> <td> 0.001</td> <td>   -0.384</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_66</th> <td>    0.2481</td> <td>    0.055</td> <td>    4.503</td> <td> 0.000</td> <td>    0.140</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_69</th> <td>    0.1818</td> <td>    0.056</td> <td>    3.247</td> <td> 0.001</td> <td>    0.072</td> <td>    0.291</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Churn   No. Observations:                22884\n",
       "Model:                            GLM   Df Residuals:                    22837\n",
       "Model Family:                Binomial   Df Model:                           46\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -5034.8\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       10070.\n",
       "Time:                        21:11:06   Pearson chi2:                 1.43e+06\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.9087      0.071    -54.942      0.000      -4.048      -3.769\n",
       "PC_1          -0.8960      0.018    -48.526      0.000      -0.932      -0.860\n",
       "PC_2           0.1364      0.009     15.711      0.000       0.119       0.153\n",
       "PC_4           0.1686      0.017     10.167      0.000       0.136       0.201\n",
       "PC_5          -0.2111      0.018    -11.618      0.000      -0.247      -0.176\n",
       "PC_7           0.6617      0.020     32.488      0.000       0.622       0.702\n",
       "PC_8          -0.0786      0.024     -3.341      0.001      -0.125      -0.032\n",
       "PC_9           0.6066      0.024     25.697      0.000       0.560       0.653\n",
       "PC_10         -0.3799      0.023    -16.791      0.000      -0.424      -0.336\n",
       "PC_14          0.1901      0.025      7.475      0.000       0.140       0.240\n",
       "PC_16         -0.1473      0.033     -4.481      0.000      -0.212      -0.083\n",
       "PC_17         -0.1440      0.030     -4.750      0.000      -0.203      -0.085\n",
       "PC_18          0.3286      0.026     12.710      0.000       0.278       0.379\n",
       "PC_19         -0.7727      0.025    -30.407      0.000      -0.822      -0.723\n",
       "PC_20          0.4388      0.037     11.911      0.000       0.367       0.511\n",
       "PC_21         -0.0859      0.037     -2.323      0.020      -0.158      -0.013\n",
       "PC_22         -0.1273      0.026     -4.845      0.000      -0.179      -0.076\n",
       "PC_23          0.3018      0.036      8.441      0.000       0.232       0.372\n",
       "PC_24          0.2505      0.032      7.714      0.000       0.187       0.314\n",
       "PC_25         -0.1931      0.036     -5.311      0.000      -0.264      -0.122\n",
       "PC_26         -0.1899      0.040     -4.794      0.000      -0.268      -0.112\n",
       "PC_28         -0.1005      0.031     -3.272      0.001      -0.161      -0.040\n",
       "PC_29         -0.4200      0.044     -9.586      0.000      -0.506      -0.334\n",
       "PC_31         -0.4895      0.041    -11.919      0.000      -0.570      -0.409\n",
       "PC_32         -0.1093      0.050     -2.204      0.028      -0.207      -0.012\n",
       "PC_33          0.1416      0.034      4.168      0.000       0.075       0.208\n",
       "PC_34         -0.3487      0.037     -9.490      0.000      -0.421      -0.277\n",
       "PC_35          0.1503      0.041      3.689      0.000       0.070       0.230\n",
       "PC_38         -0.1218      0.036     -3.429      0.001      -0.191      -0.052\n",
       "PC_39          0.1227      0.042      2.929      0.003       0.041       0.205\n",
       "PC_40         -0.3581      0.036    -10.001      0.000      -0.428      -0.288\n",
       "PC_41         -0.1809      0.044     -4.137      0.000      -0.267      -0.095\n",
       "PC_42         -0.1022      0.041     -2.511      0.012      -0.182      -0.022\n",
       "PC_44          0.2172      0.050      4.315      0.000       0.119       0.316\n",
       "PC_45          0.1037      0.041      2.501      0.012       0.022       0.185\n",
       "PC_46          0.1425      0.043      3.352      0.001       0.059       0.226\n",
       "PC_48          0.3130      0.043      7.346      0.000       0.229       0.397\n",
       "PC_50          0.3534      0.045      7.887      0.000       0.266       0.441\n",
       "PC_52         -0.4381      0.048     -9.170      0.000      -0.532      -0.344\n",
       "PC_53         -0.5087      0.049    -10.301      0.000      -0.606      -0.412\n",
       "PC_54          0.1072      0.054      1.984      0.047       0.001       0.213\n",
       "PC_58          0.4285      0.054      7.904      0.000       0.322       0.535\n",
       "PC_60          0.2123      0.062      3.444      0.001       0.091       0.333\n",
       "PC_61         -0.3528      0.069     -5.119      0.000      -0.488      -0.218\n",
       "PC_64         -0.2436      0.072     -3.398      0.001      -0.384      -0.103\n",
       "PC_66          0.2481      0.055      4.503      0.000       0.140       0.356\n",
       "PC_69          0.1818      0.056      3.247      0.001       0.072       0.291\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm5 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm5.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping PC_54 due to high p value equal to 0.047 (approximately equal to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=col.drop('PC_54')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Churn</td>      <th>  No. Observations:  </th>  <td> 22884</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22838</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -5036.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 27 Jan 2020</td> <th>  Deviance:          </th> <td>  10074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:12:18</td>     <th>  Pearson chi2:      </th> <td>1.48e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.9015</td> <td>    0.071</td> <td>  -55.043</td> <td> 0.000</td> <td>   -4.040</td> <td>   -3.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_1</th>  <td>   -0.8944</td> <td>    0.018</td> <td>  -48.568</td> <td> 0.000</td> <td>   -0.930</td> <td>   -0.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_2</th>  <td>    0.1353</td> <td>    0.009</td> <td>   15.636</td> <td> 0.000</td> <td>    0.118</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_4</th>  <td>    0.1661</td> <td>    0.017</td> <td>   10.047</td> <td> 0.000</td> <td>    0.134</td> <td>    0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_5</th>  <td>   -0.2095</td> <td>    0.018</td> <td>  -11.545</td> <td> 0.000</td> <td>   -0.245</td> <td>   -0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_7</th>  <td>    0.6606</td> <td>    0.020</td> <td>   32.499</td> <td> 0.000</td> <td>    0.621</td> <td>    0.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_8</th>  <td>   -0.0803</td> <td>    0.024</td> <td>   -3.410</td> <td> 0.001</td> <td>   -0.126</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_9</th>  <td>    0.6063</td> <td>    0.024</td> <td>   25.708</td> <td> 0.000</td> <td>    0.560</td> <td>    0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_10</th> <td>   -0.3807</td> <td>    0.023</td> <td>  -16.865</td> <td> 0.000</td> <td>   -0.425</td> <td>   -0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_14</th> <td>    0.1890</td> <td>    0.025</td> <td>    7.440</td> <td> 0.000</td> <td>    0.139</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_16</th> <td>   -0.1455</td> <td>    0.033</td> <td>   -4.427</td> <td> 0.000</td> <td>   -0.210</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_17</th> <td>   -0.1392</td> <td>    0.030</td> <td>   -4.612</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_18</th> <td>    0.3318</td> <td>    0.026</td> <td>   12.866</td> <td> 0.000</td> <td>    0.281</td> <td>    0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_19</th> <td>   -0.7694</td> <td>    0.025</td> <td>  -30.369</td> <td> 0.000</td> <td>   -0.819</td> <td>   -0.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_20</th> <td>    0.4395</td> <td>    0.037</td> <td>   11.951</td> <td> 0.000</td> <td>    0.367</td> <td>    0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_21</th> <td>   -0.0856</td> <td>    0.037</td> <td>   -2.311</td> <td> 0.021</td> <td>   -0.158</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_22</th> <td>   -0.1277</td> <td>    0.026</td> <td>   -4.859</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_23</th> <td>    0.3047</td> <td>    0.036</td> <td>    8.534</td> <td> 0.000</td> <td>    0.235</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_24</th> <td>    0.2496</td> <td>    0.033</td> <td>    7.680</td> <td> 0.000</td> <td>    0.186</td> <td>    0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_25</th> <td>   -0.1933</td> <td>    0.036</td> <td>   -5.318</td> <td> 0.000</td> <td>   -0.264</td> <td>   -0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_26</th> <td>   -0.1929</td> <td>    0.040</td> <td>   -4.870</td> <td> 0.000</td> <td>   -0.270</td> <td>   -0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_28</th> <td>   -0.0997</td> <td>    0.031</td> <td>   -3.248</td> <td> 0.001</td> <td>   -0.160</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_29</th> <td>   -0.4249</td> <td>    0.044</td> <td>   -9.716</td> <td> 0.000</td> <td>   -0.511</td> <td>   -0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_31</th> <td>   -0.4963</td> <td>    0.041</td> <td>  -12.139</td> <td> 0.000</td> <td>   -0.576</td> <td>   -0.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_32</th> <td>   -0.1118</td> <td>    0.050</td> <td>   -2.259</td> <td> 0.024</td> <td>   -0.209</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_33</th> <td>    0.1395</td> <td>    0.034</td> <td>    4.112</td> <td> 0.000</td> <td>    0.073</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_34</th> <td>   -0.3486</td> <td>    0.037</td> <td>   -9.495</td> <td> 0.000</td> <td>   -0.421</td> <td>   -0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_35</th> <td>    0.1464</td> <td>    0.041</td> <td>    3.598</td> <td> 0.000</td> <td>    0.067</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_38</th> <td>   -0.1209</td> <td>    0.035</td> <td>   -3.404</td> <td> 0.001</td> <td>   -0.190</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_39</th> <td>    0.1197</td> <td>    0.042</td> <td>    2.869</td> <td> 0.004</td> <td>    0.038</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_40</th> <td>   -0.3563</td> <td>    0.036</td> <td>   -9.955</td> <td> 0.000</td> <td>   -0.426</td> <td>   -0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_41</th> <td>   -0.1831</td> <td>    0.044</td> <td>   -4.190</td> <td> 0.000</td> <td>   -0.269</td> <td>   -0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_42</th> <td>   -0.1049</td> <td>    0.041</td> <td>   -2.579</td> <td> 0.010</td> <td>   -0.185</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_44</th> <td>    0.2208</td> <td>    0.050</td> <td>    4.383</td> <td> 0.000</td> <td>    0.122</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_45</th> <td>    0.1024</td> <td>    0.041</td> <td>    2.469</td> <td> 0.014</td> <td>    0.021</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_46</th> <td>    0.1426</td> <td>    0.042</td> <td>    3.358</td> <td> 0.001</td> <td>    0.059</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_48</th> <td>    0.3118</td> <td>    0.043</td> <td>    7.317</td> <td> 0.000</td> <td>    0.228</td> <td>    0.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_50</th> <td>    0.3503</td> <td>    0.045</td> <td>    7.824</td> <td> 0.000</td> <td>    0.263</td> <td>    0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_52</th> <td>   -0.4381</td> <td>    0.048</td> <td>   -9.175</td> <td> 0.000</td> <td>   -0.532</td> <td>   -0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_53</th> <td>   -0.5080</td> <td>    0.049</td> <td>  -10.311</td> <td> 0.000</td> <td>   -0.605</td> <td>   -0.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_58</th> <td>    0.4307</td> <td>    0.054</td> <td>    7.952</td> <td> 0.000</td> <td>    0.325</td> <td>    0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_60</th> <td>    0.2099</td> <td>    0.062</td> <td>    3.408</td> <td> 0.001</td> <td>    0.089</td> <td>    0.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_61</th> <td>   -0.3457</td> <td>    0.069</td> <td>   -5.031</td> <td> 0.000</td> <td>   -0.480</td> <td>   -0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_64</th> <td>   -0.2460</td> <td>    0.072</td> <td>   -3.429</td> <td> 0.001</td> <td>   -0.387</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_66</th> <td>    0.2528</td> <td>    0.055</td> <td>    4.596</td> <td> 0.000</td> <td>    0.145</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_69</th> <td>    0.1746</td> <td>    0.056</td> <td>    3.132</td> <td> 0.002</td> <td>    0.065</td> <td>    0.284</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Churn   No. Observations:                22884\n",
       "Model:                            GLM   Df Residuals:                    22838\n",
       "Model Family:                Binomial   Df Model:                           45\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -5036.8\n",
       "Date:                Mon, 27 Jan 2020   Deviance:                       10074.\n",
       "Time:                        21:12:18   Pearson chi2:                 1.48e+06\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.9015      0.071    -55.043      0.000      -4.040      -3.763\n",
       "PC_1          -0.8944      0.018    -48.568      0.000      -0.930      -0.858\n",
       "PC_2           0.1353      0.009     15.636      0.000       0.118       0.152\n",
       "PC_4           0.1661      0.017     10.047      0.000       0.134       0.199\n",
       "PC_5          -0.2095      0.018    -11.545      0.000      -0.245      -0.174\n",
       "PC_7           0.6606      0.020     32.499      0.000       0.621       0.700\n",
       "PC_8          -0.0803      0.024     -3.410      0.001      -0.126      -0.034\n",
       "PC_9           0.6063      0.024     25.708      0.000       0.560       0.652\n",
       "PC_10         -0.3807      0.023    -16.865      0.000      -0.425      -0.336\n",
       "PC_14          0.1890      0.025      7.440      0.000       0.139       0.239\n",
       "PC_16         -0.1455      0.033     -4.427      0.000      -0.210      -0.081\n",
       "PC_17         -0.1392      0.030     -4.612      0.000      -0.198      -0.080\n",
       "PC_18          0.3318      0.026     12.866      0.000       0.281       0.382\n",
       "PC_19         -0.7694      0.025    -30.369      0.000      -0.819      -0.720\n",
       "PC_20          0.4395      0.037     11.951      0.000       0.367       0.512\n",
       "PC_21         -0.0856      0.037     -2.311      0.021      -0.158      -0.013\n",
       "PC_22         -0.1277      0.026     -4.859      0.000      -0.179      -0.076\n",
       "PC_23          0.3047      0.036      8.534      0.000       0.235       0.375\n",
       "PC_24          0.2496      0.033      7.680      0.000       0.186       0.313\n",
       "PC_25         -0.1933      0.036     -5.318      0.000      -0.264      -0.122\n",
       "PC_26         -0.1929      0.040     -4.870      0.000      -0.270      -0.115\n",
       "PC_28         -0.0997      0.031     -3.248      0.001      -0.160      -0.040\n",
       "PC_29         -0.4249      0.044     -9.716      0.000      -0.511      -0.339\n",
       "PC_31         -0.4963      0.041    -12.139      0.000      -0.576      -0.416\n",
       "PC_32         -0.1118      0.050     -2.259      0.024      -0.209      -0.015\n",
       "PC_33          0.1395      0.034      4.112      0.000       0.073       0.206\n",
       "PC_34         -0.3486      0.037     -9.495      0.000      -0.421      -0.277\n",
       "PC_35          0.1464      0.041      3.598      0.000       0.067       0.226\n",
       "PC_38         -0.1209      0.035     -3.404      0.001      -0.190      -0.051\n",
       "PC_39          0.1197      0.042      2.869      0.004       0.038       0.201\n",
       "PC_40         -0.3563      0.036     -9.955      0.000      -0.426      -0.286\n",
       "PC_41         -0.1831      0.044     -4.190      0.000      -0.269      -0.097\n",
       "PC_42         -0.1049      0.041     -2.579      0.010      -0.185      -0.025\n",
       "PC_44          0.2208      0.050      4.383      0.000       0.122       0.320\n",
       "PC_45          0.1024      0.041      2.469      0.014       0.021       0.184\n",
       "PC_46          0.1426      0.042      3.358      0.001       0.059       0.226\n",
       "PC_48          0.3118      0.043      7.317      0.000       0.228       0.395\n",
       "PC_50          0.3503      0.045      7.824      0.000       0.263       0.438\n",
       "PC_52         -0.4381      0.048     -9.175      0.000      -0.532      -0.344\n",
       "PC_53         -0.5080      0.049    -10.311      0.000      -0.605      -0.411\n",
       "PC_58          0.4307      0.054      7.952      0.000       0.325       0.537\n",
       "PC_60          0.2099      0.062      3.408      0.001       0.089       0.331\n",
       "PC_61         -0.3457      0.069     -5.031      0.000      -0.480      -0.211\n",
       "PC_64         -0.2460      0.072     -3.429      0.001      -0.387      -0.105\n",
       "PC_66          0.2528      0.055      4.596      0.000       0.145       0.361\n",
       "PC_69          0.1746      0.056      3.132      0.002       0.065       0.284\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train_res[col])\n",
    "logm6 = sm.GLM(y_train_res,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm6.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the p values are less than 0.05. Thus, we proceed with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted values on the train set\n",
    "y_train_pred = res.predict(X_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Churn':y_train_res, 'Churn_Prob':y_train_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  predicted\n",
       "0      0    0.108761          0\n",
       "1      0    0.138344          0\n",
       "2      0    0.416209          0\n",
       "3      0    0.336189          0\n",
       "4      0    0.038326          0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Churn, y_train_pred_final.Churn_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAFNCAYAAABSVeehAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3xUZdbA8d9JDyR0pPcigoIoVtAFhAgIooACay+L61pZWRVBF0VlV19FWd1VxK4rNhBUXJogmHVFBJS2dKRKC4SQnpnz/nEn2SGkTMrkZpLz/XwCc8s899wpZ557n3ufR1QVY4wxpRfmdgDGGBPqLJEaY0wZWSI1xpgyskRqjDFlZInUGGPKyBKpMcaUkSXSIBCR60RkgdtxuE1EWorICREJr8BtthYRFZGIitpmMInIehHpXYrnVdnPoIj0FpE9bsfhr8onUhHZKSLpvi/0ryLylojEBXObqvq+qiYEcxuVke+17pc7raq7VDVOVT1uxuUWX0JvX5YyVLWLqi4tZjun/HhU18+gW6p8IvUZoqpxwNlAd2C8y/GUipu1rKpSwysJe71NoKpLIgVAVX8F5uMkVABEJFpE/k9EdonIARF5RURi/ZYPFZE1InJcRLaJyADf/Noi8rqI7BeRvSLyZO4hrIjcLCLf+h6/IiL/5x+HiMwRkT/6HjcVkU9F5JCI7BCRe/3WmyQin4jIeyJyHLg5/z754njH9/xfRGSiiIT5xZEoIn8TkWQR+a+IXJbvuUXtQ6KITBWRJGCSiLQTka9F5IiIHBaR90Wkjm/9d4GWwOe+2v+D+WtKIrJURCb7yk0RkQUi0sAvnht9+3BERB7NX8PNt9+xIvKcb/1kEfnW/30DrvO9p4dFZILf884Xke9E5Jhvv18SkSi/5Soid4nIFmCLb96LIrLb9xn4UUQu8Vs/XEQe8X02UnzLW4jIMt8qP/lej5G+9Qf7Pk/HROTfItLVr6ydIvKQiPwMpIpIhP9r4It9pS+OAyLyvO+puds65tvWRf6fQd9zu4jIQhFJ8j33kUJe10K/D77Y/uP3ft4pzqmHGN/0x+Ic9SWLyDIR6eJX7lsi8ncR+coXY6KINBaRF0TkqO+z2T3fazFeRDb4lr+Zu50CYi70O1RhVLVK/wE7gX6+x82BtcCLfstfAOYC9YB44HNgim/Z+UAy0B/nR6cZ0Mm37DPgVaAmcBqwArjDt+xm4Fvf40uB3YD4pusC6UBTX5k/Ao8BUUBbYDtwuW/dSUA2cJVv3dgC9u8dYI4v9tbAZuA2vzhygLFAJDDStz/1AtyHHOAeIAKIBdr7XotooCHOF/iFgl5r33RrQIEI3/RSYBvQ0VfeUuAvvmWdgRNAL99r8X++fe9XyPv6su/5zYBw4GJfXLnbfM23jW5AJnCG73nnAhf69qk1sBG4369cBRbifB5iffOuB+r7nvMA8CsQ41v2J5zP1OmA+LZX36+s9n5lnwMcBC7wxXyT7zWL9nv91gAt/Lad95oC3wE3+B7HARcW9DoX8BmMB/b7Yo/xTV9QyOta1PchzPeeTwI6AEeB7n7PvdX3nGhfOWv8lr0FHPa9/jHA18AO4Ebfa/EksCTfZ2md77WoByQCT/qW9Qb2+MVU6HeowvKM24ku6DvovCEngBTfh20xUMe3TIBUoJ3f+hcBO3yPXwWmFlBmI5wvZ6zfvNG5H4R8H2IBdgGX+qZ/B3zte3wBsCtf2eOBN32PJwHLiti3cF8cnf3m3QEs9YtjH74k7pu3ArghwH3YVdi2fetcBazO91oXl0gn+i3/A/Av3+PHgA/8ltUAsiggkfq+POlAtwKW5W6zeb59HlXIPtwPzPabVqBvMft9NHfbwCZgaCHr5U+k/wAm51tnE/Abv9fv1gI+v7mJdBnwONCgkH0uLJGO9n+fitivIr8PfttKwvkBGl9EWXV8MdX2Tb8FvOa3/B5go9/0WcCxfPv9e7/pQcA23+Pe/C+RFvkdqqi/6nIe5ipVXSQivwH+CTQAjuHUqmoAP4pI7rqCk6DA+TWcV0B5rXBqePv9nheGU/M8iaqqiMzE+TAvA34LvOdXTlMROeb3lHBgud/0KWX6aYDzK/yL37xfcGppufaq79Plt7xpgPtw0rZF5DRgGnAJTs0jDCeplMSvfo/TcGpW+GLK256qponIkULKaIBTq9lW0u2ISEfgeaAHznsfgVOj8Zd/vx8AbvfFqEAtXwzgfEaKisNfK+AmEbnHb16Ur9wCt53PbcATwH9FZAfwuKp+EcB2A42xuO8DqrpTRJbgJLaX81ZyTgk9BVzjK8frW9QA5ygI4IDfttILmM7fCOz/WuR+bvML5DsUdNXtHOk3OL+MuecsD+O8gV1UtY7vr7Y6DVPgvJHtCihqN05troHf82qpapcC1gX4ABghIq1wfkE/9Stnh18ZdVQ1XlUH+YddxC4dxjn8beU3ryWw12+6mfh9K3zL9wW4D/m3PcU3r6uq1sI55JUi1i+J/TinXgDnHCjO4XRBDgMZFPzeFOcfwH+BDr59eIST9wH89sN3PvQh4FqgrqrWwUkMuc8p7DNSkN3AU/ne7xqq+kFB285PVbeo6mic0zB/BT4RkZpFPaeEMRb3fUBEBuHUUhcDz/o997fAUKAfUBun5gqnvrYl0cLvce7nNr9AvkNBV60Sqc8LQH8ROVtVvTjn0qb6aluISDMRudy37uvALSJymYiE+ZZ1UtX9wALgORGp5VvWzlfjPYWqrgYOATOA+aqa++u5AjjuO4kf62u4OFNEzgtkR9S5rOgj4CkRifcl6j/yvxovOF+6e0UkUkSuAc4A5pV0H3zicU6THBORZjjnB/0dwDlHVRqfAENE5GJxGn8ep5Avoe99ewN43tfQEO5rYIkOYDvxwHHghIh0Au4MYP0cnPcvQkQew6mR5poBTBaRDuLoKiK5PwD5X4/XgN+LyAW+dWuKyBUiEh9A3IjI9SLS0Lf/uZ8hjy82L4W/9l8AjUXkfl9jUryIXJB/peK+D+I0DL6OUzu/Cef9yk1Y8Tg/zEdwarVPB7JPxbhLRJqLSD2cH7wPC1inTN+h8lLtEqmqHsJpoHnUN+shYCvwH3FaxhfhNBygqiuAW4CpOLWQb/hf7e9GnMOyDTiHt58ATYrY9Ac4v9b/9IvFAwzBuYpgB06NYAbOL3qg7sE5r7Ud+NZX/ht+y7/HaRg4jHPoNUJVcw+ZS7oPj+M0mCQDXwKz8i2fAkwUp0V6XAn2AVVd79uXmTi10xSchpnMQp4yDqeR5wecc3Z/JbDP8zic2lMKTtIo6Mvpbz7wFU4j3i84NWH/Q87ncX7MFuAk6NdxGrnAOcf9tu/1uFZVV+KcI38J5/XeSgFXYhRhALBeRE4AL+Kc981Q1TSc9zbRt60L/Z+kqik4jYRDcE55bAH6FLKNQr8PwHRgjqrO832GbgNm+H443vG9PntxPk//KcF+FeafOK/rdt/fk/lXKKfvUJnltiSbKkhEbgZuV9VebsdSUuLcNHEM5xB8h9vxmIolIjtxPruL3I4lENWuRmoqLxEZIiI1fOf9/g+nxrnT3aiMKZ4lUlOZDMVpUNiHczpilNohkwkBdmhvjDFlZDVSY4wpI0ukxhhTRiF3Z1ODBg20devWbodhjKlifvzxx8Oq2rA0zw25RNq6dWtWrlzpdhjGmCpGRH4pfq2C2aG9McaUkSVSY4wpI0ukxhhTRpZIjTGmjCyRGmNMGVkiNcaYMrJEaowxZRS0RCoib4jIQRFZV8hyEZFpIrJVRH4WkXOCFYsxxgRTMGukb+F0RFuYgTg9/HQAxuAMAWGMMSEnaIlUVZfh9FxemKHAO+r4D1BHRIrqnd0YYyolN28RbcbJQzbs8c3b7044xrhDVfF4lRyvku3xkpHtRVXxKnh9y9T3OPcv26OkZeUAgleVHI8zP8erHDmRSUxkOKqgqO///23L+d9ZlvfYt07ect8/uc/PnVdQmelZOaRleagRFe5XTu5z/J6vetLyk8rx227+ZbnTe5LSqR8Xhcerea+Lx+u8LmlZORxKySQ+JpKMbA/bDqXSMD66TCPvlYSbibSgfSywc1QRGYNz+E/Lli2DGZOphnI8XjJyvBxPzyYrx0uWx8uxtGw8XiXL4yUpNZPsHOVwaibpWR4AMnO8bD+USp0akWR7vOxPzgCFsDDI9ih7jqYRFRFGmIjzxfcqHnW++Dlep/ww3zfAa10C5xFxEoOI+P4HwZmZleOM8Fy/ZhRhYUK4COFhQlgYhImQluUhLjqbhnHRtGlQg8wcL6fFxxS5Pa8nh/8umUWnPsPKFLebiXQPJw+32pyCh1tFVafjDLxFjx497GNXhagqmb7kdSIjh5SMHLJyvBxJdca8y8zxsu9YOtER4eR4vWT5Et7xjBx2J6URFxNBtsdLVo6y/fAJGtSMxuOrmXm9//t/x+FU6sdF5dVkcryKx6OkZOaUKu6o8DA8qoQJNK0TS2R4GEmpWbRpUJPYyHA6N6nFwZRM2jWMIyJM8r74YWFCeBh5NchGtWIIEyEiTAgPd9Y5npFN0zqxhIkQJk5ScZ7rJIzc6dSsHE6LjyYiLIywMIgICyPct06YCDGR4X6JCXLrLvmT1f/mCf4Dd4ucnNCcEiTv+eQmOSAiTIiMCDsp+Z1Slt9zT0qUJ40WXnEyMjIYPXo03332GQ+N6MmbZSjLzUQ6F7hbRGbijPWe7Bsi2IQwr1fZfjiVLQdSSM/2sO9YOiLC9kOphIfBvmMZHE3LIik1y6nFlUFEmJMwWtWvQUR4GHHREew+mka7hnGEhUne8ogwof1pcRxKyaRtw5qE+5ZFhIcRJnAi00PbBjVJzcqhZb0aREWEERkehqrSMD6aqPBwIiOE+jWjiYuOICYyzLUvvykfKSkpDB06lCVLljBt2jSGDh1apvKClkhF5AOgN9BARPYAfwYiAVT1FWAeMAhn6Nc0nGGPTSWS4ztk3XIwhR2H0wgT2Hk4ldioCDJzPGw/lMqR1EyiwsPYlZROtsdLcnp2kWWe2awWDeKiadswjvo1ozienk270+KIjggjKiKMOjWiiI0MJyrCaQdtEBdFdEQ40RFh1IgKJyI8jKhwZ93wMEtmpuQOHz7MoEGDWLVqFe+++y7XX399mcsMWiJV1dHFLFfgrmBt3xRMVUnN8rDzcCrH07PJzPGy9eAJADYfSOG/v6YgvoR5PKPww9746AgiI8I4lpZFvZrRnNuqDoLQpmFNmtWJJT4mgrOa1aZGVARxMRHUjAq3WpypFHbu3MmOHTuYPXs2Q4YMKZcyQ65jZ1M0j1f5YWcS329PYu+xNLI9yrZDJzhyIotfj2fgCaBlo0ZUOFd2a0rN6AjqxEZSPy6a89vUo37NKGKjnNqhJUUTao4ePUrdunXp0aMHO3bsIC4urtzKtkQawjJzPKzbm8yG/Sn8cjiV73cksXZv8inrtW1YE49XObtFHRrXjuHMprVpGB9NzahwTqsVQ3REGC3q1aCm79DZmKpm9erVDBgwgMmTJzNmzJhyTaJgiTQkZOV4+TU5gwMpGfxn2xF+2pPMoo0HClw3TODuPu0ZeFYTTm8UT5idRzTV3PLlyxk8eDC1a9emd+/eQdmGJdJKJsfjZeP+FL7fcYRth06weONBDqZknrJeszqxtKpfgyu7NeX0xvG0rFeD+nHRLkRsTOX15ZdfMmLECFq3bs2CBQto0aJF8U8qBUukLjuekc3cNfuYv/5X9hxNZ8fh1JOWn9+6Hld0bULHRvHERIbRtHYs3VrUISYy3KWIjQkNO3fu5Oqrr6Zr16589dVXNGxYqgFCA2KJtIJtOZBC4tbD7E/OYN2+ZBK3Hjlp+TXnNqd+XDSXnXEa3VvUsXOWxpRS69atee+99xgwYAC1atUK6rYskQaZqnOB+pc/7+eVb7aR5rvFMFfjWjHc1acdI89rmXftpDGmdFSVKVOmcPHFF9O7d2+uvfbaCtmuJdIgUFW+236E9/+ziy/Xnnyz1lnNajO2fwcuaFOfmtH28htTXrxeL2PHjmXatGncddddQWtYKoh9k8tRepaHBRt+5b6Za/LmtWlQk85NanHteS3o1b6B3Y1jTBBkZ2dz22238e6773L//ffz3HPPVej2LZGWUVpWDp//tI9pi7ey91h63vwh3Zpya8/WdG9Z18XojKn6MjMzufbaa5k7dy6TJ09mwoQJFX7DiCXSUlBV3kjcydyf9vHT7mN58/t3bsRvOjZkxLnNrVXdmAoSGRlJrVq1eOmll7jrLnfuOrdEWgIHUzL42+KtfLVuP4dPZAFwRdcmnN+6Htf0aE6NKHs5jakohw4dIj09nZYtW/LOO++4etuyffOLcSglkw9W7GLRxgPsOJRKSmYOXZvX5u4+7RnRowVx1mBkTIXbvXs3/fv3JyYmhlWrVhEW5u4VL5YFCpCZ4+HNxJ0s2nCAlb8czZsfHRHGvHsvoXPT4F6TZowp3KZNm+jfvz/Jycl88cUXridRsER6ilW7jjLs7//Omz6/TT2uObc5I85tbj0eGeOyVatWMWDAAESEpUuX0r17d7dDAiyR5knJyOaR2ev4/CdntJM7e7fjvss6WKORMZWEqjJu3Dhq1KjBwoUL6dChg9sh5bFECjw7/79MX7adbI9ySYcGTLyiM6c3jnc7LGOMj6oiInz44YdkZmbSvHlzt0M6SbVOpBnZHm58fQUrdiYB8PpNPbjsjEYuR2WM8ffuu+/yySef8PHHHwe145GycP8srUt2J6VxzuSFrNiZxMXt6vPfyQMsiRpTyUybNo0bb7yREydOkJWV5XY4haqWifT77Ue45JklpGV5SOjciH/+7kI7F2pMJaKqTJo0ifvuu4+rr76aL7/8stx7tS9P1e7QfuP+44yc/h8AxvbryH39Ks8Ja2OM489//jOTJ0/mlltuYfr06UREVO5UVbmjC4KHP/0ZgDdvOY8+p5/mcjTGmIJcffXVeL1eJk+eHBKXHVarQ/sPVuzipz3JXH9hS0uixlQy6enpvPfeewB0796dJ598MiSSKFSjRHooJZOnvtxIfEwEEwZ1djscY4yf5ORkBgwYwI033shPP/3kdjglVi0O7VWVO95dyYnMHN6+9Xxio6xhyZjK4uDBgwwYMIC1a9fywQcf0K1bN7dDKrFqkUifX7iZVbuOMeq8FvymY+W8Ds2Y6uiXX34hISGB3bt3M3fuXAYOHOh2SKVS5RPpur3J/O3rrfRq34Apw85yOxxjjJ+VK1dy+PBhFi5cSM+ePd0Op9Sq/DnSCbPXAjB+UKeQOXFtTFWXkpICwPDhw9m2bVtIJ1Go4ol01a6j/LQnmSHdmtKlaW23wzHGAEuWLKFNmzZ8/fXXANSpU8fliMquSifSR2atJTxMeHLomW6HYowBPvvsMwYOHEjjxo3p1KmT2+GUmyqbSGeu2MV/f03h2h7NqV0j0u1wjKn23n77bYYPH87ZZ5/NsmXLaNq0qdshlZsqmUhVlQmfrUMEHh1s14wa47bly5dz880307dvXxYtWkS9evXcDqlcVclE+umqvXi8yuShZ9qAdMZUAr169eKVV17hiy++qNSdj5RWlUyk/1i6FYCruzdzORJjqi+v18uECRPYtm0bIsIdd9xBdHS022EFRZVLpGv3JLPtUCr39+tATRvh0xhXZGdnc/311/P0008za9Yst8MJuiqXaaZ8tRGAa3u0cDkSY6qntLQ0rrnmGubNm8df/vIX/vSnP7kdUtBVqUTq8Sr/3naE5nVjaVon1u1wjKl2kpOTGTx4MImJiUyfPp3f/e53bodUIapUIt30q3O3xBVdm7gciTHVU3h4OGFhYcycOZNrr73W7XAqTJVKpAs3HADgkvbWMYkxFemXX36hXr16xMfHs3Tp0mp3O3aVamyas2YvzerE0rN9fbdDMaba2LBhAxdffDG33norQLVLolCFEmlKRjbbD6dyaceG1fKNNMYNK1as4JJLLsHr9fLYY4+5HY5rqkwi/fe2IwCc2ayWy5EYUz0sXryYvn37UqdOHRITEznrrOrbTWWVSaTr9yYDMPyc5i5HYkzVl5WVxe9+9zvatGnDt99+S9u2bd0OyVVBTaQiMkBENonIVhF5uIDlLUVkiYisFpGfRWRQabe1bMthGteKsfHpjakAUVFRzJs3j2+++YYmTewqmaAlUhEJB14GBgKdgdEikr8HkYnAR6raHRgF/L2029u4/zhxMVXqIgRjKp3nnnuOP/7xj6gqnTp1qnKdj5RWMGuk5wNbVXW7qmYBM4Gh+dZRIPekZm1gX2k2lJ7lITPHS8921lpvTDCoKhMmTGDcuHHs2bMHj8fjdkiVSjCrcM2A3X7Te4AL8q0zCVggIvcANYF+pdnQxl+PA3B6Y2toMqa8eTwe7rrrLl599VXGjBnD3//+d8LD7RSav2DWSAu6BknzTY8G3lLV5sAg4F0ROSUmERkjIitFZOWhQ4dOKXTbwRMAnN+mbpmDNsac7NZbb+XVV19l/PjxvPLKK5ZECxDMGukewL/nkOaceuh+GzAAQFW/E5EYoAFw0H8lVZ0OTAfo0aNH/mTMih1JALSoV6OcQjfG5Bo6dChnnXUW48aNczuUSiuYifQHoIOItAH24jQm/TbfOruAy4C3ROQMIAY4tcpZjF+OpBEZLkRH2C+lMeXh6NGjfPfddwwaNIhhw4a5HU6lF7REqqo5InI3MB8IB95Q1fUi8gSwUlXnAg8Ar4nIWJzD/ptV9ZQaZ3FW7Eyiz+l2f70x5WH//v1cfvnlbNu2jR07dnDaaae5HVKlF9TrhVR1HjAv37zH/B5vAMo0oPXxjGwA2jSoesMXGFPRtm/fTv/+/Tlw4ABz5syxJBqgkL/w8tfkDAC6Nrdx640pi3Xr1pGQkEBGRgaLFy/mggvyX2RjChPyiTS3xf60WlVzLBhjKsrcuXMREZYvX06XLl3cDiekhPy99odPZALQpLb1iG9MaaSnpwMwfvx41qxZY0m0FEI+kW7x1Uib1olxORJjQs8nn3xC+/bt2bRpEyJCw4bWaFsaIZ9IdxxOpWZUuF36ZEwJvfbaa4wcOZLWrVtbo1IZhXwiPZ6RQ4N4Oz9qTEn89a9/ZcyYMSQkJLBgwQLq1rW7Assi5BPp1gMpNIq3w3pjAvXOO+/w8MMPM2rUKObMmUPNmjXdDinkhXyrfVq2h5rRdlhvTKCuueYakpKSuOeee+y++XIS0jXSrBwvqnYxvjHFyczM5JFHHuHYsWPExsZy//33WxItRyGdSPcdcy7bqFMj0uVIjKm8Tpw4wZAhQ5gyZQr/+te/3A6nSgrpQ/vMHC8A7RpajdSYgiQlJXHFFVewYsUK3njjDUaNGuV2SFVSSCfS3IvxI8Nt+GVj8tu/fz8JCQls3ryZTz75hKuvvtrtkKqskE6kWR6nRhofY4f2xuSXk5OD1+vlq6++om/fvm6HU6WFdCLdnZQGQO1YS6TG5NqxYwctW7akRYsW/Pzzz9aoVAFCurEpMtwJv25NS6TGAPz73//mnHPO4bHHnN4qLYlWjJBOpDsOpwIQa2PZG8P8+fPp378/DRs2ZMyYMW6HU62EdCKNi4446X9jqquPPvqIIUOG0LFjR5YvX06rVq3cDqlaCelEejw9m/AwISI8pHfDmDI5dOgQt956KxdeeCFLly6lUaNGbodU7YR0VW730bQCx3w2pjpp2LAhixYtomvXrtSoYSPpuiGkq3JZOV5q2mG9qYZUlQcffJAZM2YAcOGFF1oSdVFIJ9LUTI9djG+qnZycHG6//XaeffZZ1q5d63Y4hgATqYhEiUj7YAdTUtGRYZxmXeiZaiQzM5ORI0fyxhtv8Nhjj/HCCy+4HZIhgEQqIlcAa4GFvumzRWR2sAMLhMer1oWeqTZycnIYPHgws2bNYurUqTz++OOI2BFZZRDICcYngAuAJQCquqay1E5zPEp4mH2QTPUQERFB3759ueGGG7jxxhvdDsf4CSSRZqvqsXy/fBqkeEok2+slLtIam0zVtnfvXvbt28d5553H+PHj3Q7HFCCQLLRRRK4FwkSkDXAf8J/ghhWY7YdS6d6yjtthGBM0W7ZsoX///qgqW7ZsISoqyu2QTAECaWy6GzgX8AKzgAycZOq6+jWjOJ6e7XYYxgTFmjVr6NWrF6mpqcyaNcuSaCUWSCK9XFUfUtXuvr+HgYHBDiwQ2w+n0v4069TZVD3ffvstvXv3JioqiuXLl3Puuee6HZIpQiCJdGIB8yaUdyClERkupGTkuB2GMeXu1VdfpVGjRiQmJtKpUye3wzHFKPQcqYhcDgwAmonI836LauEc5rvOq9C2oQ0la6qOrKwsoqKimDFjBikpKTRo0MDtkEwAiqqRHgTW4ZwTXe/3t4BKcGifmePB41ViIuw6UlM1/OMf/+Dcc88lKSmJ6OhoS6IhpNAaqaquBlaLyPuqmlGBMQXkaKrTyJTtrRRXYhlTaqrK008/zcSJExkyZAixsbFuh2RKKJDLn5qJyFNAZyDvfkxV7Ri0qAJwJNUZ+K5BnLVkmtDl9XoZN24cU6dO5YYbbuD1118nMtJGfAg1gTQ2vQW8CQjOIf1HwMwgxlQidq+9CWWTJ09m6tSp3Hvvvbz11luWRENUIDXSGqo6X0T+T1W3ARNFZHmwAyuO19fcFWG3iJoQNmbMGOrUqcO9995r982HsEBqpJnivMPbROT3IjIEOC3IcRUrx5dJw60bPRNiUlJSmDx5Mjk5OTRp0oT77rvPkmiIC6RGOhaIA+4FngJqA7cGM6hAeHyNTOH2ATQh5PDhwwwcOJDVq1fTt29fevbs6XZIphwUm0hV9XvfwxTgBgARaR7MoAKRm0jt0N6Eit27d5OQkMDOnTv57LPPLIlWIUUe2ovIeSJylYg08E13EZF3qASdlqRmOXc0WTd6JhRs3ryZXr16sW/fPubPn8/gwYPdDsmUo0ITqYhMAd4HrgP+JSITcPok/Qlw9dIngKwcp0bqUbuO1FR+R48eJTw8nKVLl3LppZe6HY4pZ0Ud2g8FuqlquojUA/b5pjdVTGiBqR1rl4uYymv37t20aNGCCy64gE2bNtnlTVVUUYf2GaqaDqCqScB/K3c3hbMAACAASURBVFMSzW21j7Ix7U0l9eWXX9KxY0feffddAEuiVVhRNdK2IjLL91iA1n7TqOqwoEZWjGyPk0gjLZGaSuj999/n5ptv5uyzz2bgQNe7pjBBVlQiHZ5v+qWSFi4iA4AXgXBghqr+pYB1rgUm4Qxf8pOq/jaQsvcdc27/t8YmU9m89NJL3HPPPfTp04c5c+YQHx/vdkgmyIrqtGRxWQoWkXDgZaA/sAf4QUTmquoGv3U6AOOBnqp6VEQCvtA/NtLp9Sk+xsZsMpXHTz/9xD333MPQoUOZOXMmMTF2C3N1EMwsdD6wVVW3A4jITJwGrA1+6/wOeFlVjwKo6sFACz9w3KmRxkZZN3qm8ujWrRtfffUV/fr1IyLCfuSri2CeYGwG7Pab3uOb568j0FFEEkXkP75TAacQkTEislJEVh46dAiAjGwPYI1Nxn3Z2dmMGTOGb775BoABAwZYEq1mAs5CIhJdwrILOnmZ/6LPCKAD0BsYDcwQkVOGBVXV6araQ1V7NGzYEIDMHC9x0RF2j7JxVXp6OsOHD+e1115jxYoVbodjXFJsIhWR80VkLbDFN91NRP4WQNl7gBZ+081xrkXNv84cVc1W1R3AJpzEWqy9x9ILzNTGVJTjx48zcOBAvvjiC15++WX+9Kc/uR2ScUkgNdJpwGDgCICq/gT0CeB5PwAdRKSNiEQBo4C5+db5LLcs322oHYHtgQReKyaSGDs/alySnJxMnz59SExM5P333+cPf/iD2yEZFwWSSMNU9Zd88zzFPUlVc4C7gfnARuAjVV0vIk+IyJW+1eYDR0RkA87tp39S1SOBBJ6Z46VBXEnPNhhTPuLj4+nevTtz5sxh9OjRbodjXBbIGfHdInI+oL5Lmu4BNgdSuKrOA+blm/eY32MF/uj7K5FDKRlEWV+kpoJt2rSJmJgYWrVqxYwZM9wOx1QSgdRI78RJdC2BA8CFvnmuyvIox21Me1OBfvzxR3r16sUNN9yAWmc5xk8gNdIcVR0V9EhKKDJcqFfTLnY2FWPp0qVceeWV1KtXj9dff92uFjEnCaRG+oOIzBORm0Sk0tzrlpntpWaUXatngm/u3LkMGDCAFi1akJiYSIcOAV1YYqqRYhOpqrYDngTOBdaKyGci4noNdeuhE3afvQk6r9fLU089RdeuXVm2bBnNmuW/p8SYAC/IV9V/q+q9wDnAcZwOn13VMC6a1KxiLx4wptRycnIICwvjiy++YPHixdSvX9/tkEwlFcgF+XEicp2IfA6sAA4BFwc9smJ4VWla286RmvKnqjz22GMMHTqUrKwsGjZsaD04mSIFUiNdh9NS/4yqtlfVB/wGxHONV9UO7U2583q93HvvvUyePJnGjRsTFmZ9OZjiBdJa01ZVvUGPpIRyvJZITfnKzs7mlltu4f333+eBBx7g2WeftdZ5E5BCE6mIPKeqDwCfisgpF8253UO+x6uE2YfclKMxY8bw/vvv8/TTT/Pwww9bEjUBK6pG+qHv/xL3jF8RvF61Me1Nubr33nu5+OKL+d3vfud2KCbEFHoCSFVz+wQ7Q1UX+/8BZ1RMeIVLzfLYob0ps4MHD/L3v/8dgO7du1sSNaUSyJn0WwuYd1t5B1ISubfnHU3LcjMME+J++eUXevXqxbhx49i5c6fb4ZgQVtQ50pE4Xd+18R89FIgHjgU7sKJk+UYQbVW/ppthmBC2YcMGEhISSE1NZeHChbRu3drtkEwIK+oc6QqcPkib4wxilysFWB3MoIqT7XFqpDbMiCmNH374gYEDBxIREcE333xD165d3Q7JhLiiRhHdAewAFlVcOIHJHa8p0rrRM6Wwbds2ateuzfz582nfvr3b4ZgqoNAqnYh84/v/qIgk+f0dFZGkigvxVOm+W0Mzcird5a2mEjtw4AAAo0aNYv369ZZETbkp6tg4dziRBkBDv7/cadfk1kib1411MwwTQt566y3atGlDYmIigI03b8pVUZc/5Vb3WgDhquoBLgLuAFxt5UlKdVrra0ZbN3qmeM8//zy33HILvXr1olu3bm6HY6qgQFprPsMZZqQd8A7ONaT/DGpUxdhzNB2A+jWj3AzDVHKqysSJE3nggQcYMWIEn3/+OXFxcW6HZaqgQBKpV1WzgWHAC6p6D+Bqp4we33WkNWwUUVOE2bNn89RTT3H77bczc+ZMoqNtsEQTHAENNSIi1wA3AFf55kUGL6Tieb1OIrVDe1OUq6++mo8//pjhw4fbffMmqAK9s6kPTjd620WkDfBBcMMqWu4F+ZF2HanJJy0tjZtvvplt27YhIowYMcKSqAm6QIYaWQfcC6wUkU7AblV9KuiRFSH3HGlUhCVS8z/Hjh0jISGBd955h++/d73LXFONFHtsLCKXAO8CewEBGovIDaqaGOzgChPvO6SPtkRqfA4cOMDll1/Ohg0b+PDDD7nmmmvcDslUI4GcZJwKDFLVDQAicgZOYu0RzMCKkts5aoT1Xm6A3bt307dvX/bt28cXX3xBQkKC2yGZaiaQTBSVm0QBVHUj4Op1Rx5fY5P1omcA6tatS4cOHVi0aJElUeOKQGqkq0TkVZxaKMB1uNxpiaoigjUiVHOrV6+mffv2xMfHM2/ePLfDMdVYIDXS3wPbgAeBh4DtOHc3ucajNsxIdbdo0SIuueQS7r//frdDMaboGqmInAW0A2ar6jMVE1LxvArhlkirrVmzZjF69GhOP/10nnzySbfDMabI3p8ewbk99DpgoYgU1FO+K7xe59DeVD9vvPEG11xzDeeeey7ffPMNTZo0cTskY4qskV4HdFXVVBFpCMwD3qiYsIrmsaGYq6WUlBQeffRR+vfvz6effkrNmjZCgqkcikqkmaqaCqCqh0Sk0lxr5FXsHGk1kjtGV3x8PMuXL6d58+ZERVmHNabyKCqRtvUbq0mAdv5jN7k5rv2upDS3Nm0qmMfj4a677qJGjRo899xztG3b1u2QjDlFUYl0eL7pSjO+fd0akZzIzHE7DBNkWVlZ3HDDDXz00UeMHz/e7XCMKVRRYzYtrshASmLLwRO0bWjnx6qy1NRUhg8fzvz583n22WcZN26c2yEZU6iQ7IcuPibCDu+rMFVlyJAhfPPNN8yYMYPbbrvN7ZCMKVKlaUAqCa8qbRpYjbSqEhHuvvtuPvroI0uiJiQEXCMVkWhVzQxmMIHK9igRdvlTlbN9+3bWrFnDsGHDGDbMtbZMY0qs2BqpiJwvImuBLb7pbiLyt6BHVoQcj9c6da5i1q5dS69evfjDH/7AiRMn3A7HmBIJJBtNAwYDRwBU9Sf+N1SzK9KyPHZBfhXy3XffcemllyIifP311zZAnQk5gSTSMFX9Jd88TzCCCdTBlMy8se1NaFuwYAH9+vWjQYMGJCYm0rlzZ7dDMqbEAkmku0XkfJwhmcNF5H5gc5DjKlKdGpF2aF9FJCYm0r59e5YvX07r1q3dDseYUgkkG90J/BFoCRwALvTNK5aIDBCRTSKyVUQeLmK9ESKiIhJQr/uqUM/GtA9pSUlJAEyaNIl///vfNG7c2OWIjCm9QAa/O6iqo1S1ge9vlKoeLu55IhIOvAwMBDoDo0XklOM2EYnHGVwv4NHKcrxeO0cawv7617/SqVMnduzYgYhY5yMm5AUy+N1r/G+YpDyqOqaYp54PbFXV7b5yZgJDgQ351psMPAMEfOuK14sl0hCkqjz88MM888wzjB49mmbNmrkdkjHlIpBD+0XAYt9fInAaEMj1pM2A3X7Te3zz8ohId6CFqn4RULQ+OV6vdewcYjweD2PGjOGZZ57hzjvv5L333rMenEyVUWyNVFU/9J8WkXeBhQGUXVCmy6vZ+rrlmwrcXGxBImOAMQAtW7akoRfCwy2RhpKpU6cyY8YMJk6cyBNPPGHjbZkqpTT32rcBWgWw3h6ghd90c2Cf33Q8cCaw1PelagzMFZErVXWlf0GqOh2YDtCjRw89fCLTRhANMXfddRfNmzdn1KhRbodiTLkL5M6moyKS5Ps7hlMbfSSAsn8AOohIGxGJAkYBc3MXqmqyr/Gqtaq2Bv4DnJJECxIVEcbRtOwAQjBuSkpK4vbbbyc5OZnY2FhLoqbKKjKRilNV7AY09P3VVdW2qvpRcQWrag5wNzAf2Ah8pKrrReQJEbmyTFErtKxXo0xFmODat28fl156Ke+++y6rVq1yOxxjgqrIQ3tVVRGZrarnlqZwVZ2HM9aT/7zHClm3d6DlZnu91mlJJbZt2zb69evH4cOH+eqrr+jTx9U7io0JukBa7VeIyDlBj6QEVCEizO5sqozWrVtHr169SElJ4euvv6Zv375uh2RM0BU1HHNubbUXTjLdJCKrRGS1iLh2rOYbB40Ia7WvlGrVqkXbtm1Zvnw55513ntvhGFMhijq0XwGcA1xVQbEExOvLpMnp1thUmaxatYpu3brRsmVLvv32W7u8yVQrRR0fC4Cqbivor4LiO0XuhajN6sS6FYLJ58MPP+TCCy/k2WefBbAkaqqdomqkDUXkj4UtVNXngxBP8XyZ1G4RrRxeffVV7rzzTnr16sWddwbUl40xVU5RNdJwIA7nwvmC/lyhvkxqrfbuUlWmTJnC73//e6644grmz59P7dq13Q7LGFcUVSPdr6pPVFgkAVKrkVYKO3bs4IknnuC6667jzTffJDIy0u2QjHFNUYm0Umaq3HOk1mrvDlVFRGjbti0rVqygS5cuhNmlaKaaK+obcFmFRVECua32mdlelyOpfjIyMhgxYgSvv/46AGeddZYlUWMoIpGqalJFBlJStWLtULIipaSkcMUVVzBr1ixSU1PdDseYSqU0vT+5KvccaWxkuLuBVCNHjhxh4MCBrFq1irfffpsbb7zR7ZCMqVRCLpHmniW1xqaKkZaWxqWXXsq2bduYNWsWV15Ztv5mjKmKQi6R2i2iFatGjRrccsst9OjRg969e7sdjjGVUsglUo/XyaQ2HHNwrVmzhoyMDC688ELGjQt4OC1jqqWQS6S5vN5TxuMz5WT58uUMHjyY1q1bs3r1amuZN6YYIfcNyU2ftWtYq30wfPnllyQkJNC4cWM+//xzS6LGBCDkviW550jt0L78/fOf/+Sqq66ic+fOLF++nJYtW7odkjEhIeSykfoyaZQl0nKlqnz22Wf07NmTJUuWcNppp7kdkjEhI+TOkWZ7lTCs1b68qCopKSnUqlWLd999F6/XS2ysdVFoTEmEXLUu9/LRGpEh9xtQ6Xi9XsaOHcvFF19McnIy0dHRlkSNKYWQS6S550ijIkIu9EolJyeHW2+9lRdffJHLLruM+HjXekY0JuSFXDb633WkdmhfWrmdj7z99ts8/vjjvPDCC9Y6b0wZhNzxsUeVCCDCGptKbezYscyZM4e//e1v3H333W6HY0zIC7lEGmbjAZXZo48+Sr9+/Rg+fLjboRhTJYRktS4uOuTyv+v27NnDAw88QE5ODk2bNrUkakw5CrlEqqpYx08ls3nzZnr27MmMGTPYvHmz2+EYU+WEXCIF60KvJFatWkWvXr1IT09n6dKldO7c2e2QjKlyQi6RKpZIA7V8+XL69OlDbGws3377Ld27d3c7JGOqpJBLpKg1OAUqMjKSjh07kpiYSMeOHd0Ox5gqK+QSabbXa4m0GOvWrQPgwgsvZMWKFTRv3tzliIyp2kIukQrCkdRMt8OotP72t7/RtWtXZs2aBYDYj44xQRd6iVSgRb0abodR6agqjz/+OPfeey9Dhw5l0KBBbodkTLURchdkqloXevnldj4ybdo0br75Zl577TUiIkLurTUmZIVcRlLUOnXOZ9myZUybNo2xY8fy+uuvWxI1poKF3DfO41W7/MlHVRERevfuzXfffccFF1xg50SNcUHIVe08XiUtK8ftMFyXnJzMoEGDWLZsGeC00FsSNcYdIZdIw8OEGlEhV5EuVwcPHqRPnz4sWrSI/fv3ux2OMdVeyGUkVagdW31HEN21axf9+/dn9+7dzJkzx1rnjakEQi6RAkRU03Oke/fupWfPnqSkpLBgwQJ69erldkjGGELw0F61+t5r36RJE66++mq++eYbS6LGVCIhVyNVql+r/bJly2jVqhWtWrVi2rRpbodjjMnHaqSV3Ny5c0lISOD+++93OxRjTCFCLpFme7xkZHvdDqNCvPPOOwwbNoxu3boxY8YMt8MxxhQiqIlURAaIyCYR2SoiDxew/I8iskFEfhaRxSLSqrgyw8OE6nBj04svvshNN91E7969Wbx4MfXr13c7JGNMIYKWkkQkHHgZGAh0BkaLSP7u2VcDPVS1K/AJ8EwgZderGV2eoVY6mZmZvP322wwbNowvv/ySuLg4t0MyxhQhmI1N5wNbVXU7gIjMBIYCG3JXUNUlfuv/B7i+uEKdHvLLN9DKwuv1kpWVRUxMDIsXLyY+Pt7umzcmBAQzJTUDdvtN7/HNK8xtwFfFlqoQXgVvhczOzubGG29k+PDheDwe6tata0nUmBARzERaULbTAlcUuR7oATxbyPIxIrJSRFZ6VQkPq1pV0rS0NK6++mref/99LrnkEsKq2P4ZU9UFs8qzB2jhN90c2Jd/JRHpB0wAfqOqBXZ9r6rTgekAsU07alU6tD927BhDhgwhMTGRV199lTFjxrgdkjGmhIKZSH8AOohIG2AvMAr4rf8KItIdeBUYoKoHAynUq0pYFbqOdOTIkXz//ffMnDmTa6+91u1wjDGlELREqqo5InI3MB8IB95Q1fUi8gSwUlXn4hzKxwEf+7qA26WqVxZX9vH07GCFXeGmTJnCoUOHuPzyy90OxRhTSkFtzVDVecC8fPMe83vcrzTltqpfs4yRuWvjxo18+eWXjBs3jnPOOcftcIwxZRSSzcLREaF7kvSHH35g4MCBREZGcvPNN9OgQQO3QzLGlFFIZqTUzNDsIX/x4sX07duXWrVq8e2331oSNaaKCMlE2qhWjNshlNjs2bMZNGgQrVu35ttvv6Vdu3Zuh2SMKSchmUhDsfentLQ0evTowTfffEPTpk3dDscYU44skQbZ1q1bAbjuuutYtmwZ9erVczkiY0x5C8lEGhYCt4iqKhMnTqRLly6sXr0agPDwcJejMsYEQ0i22lf2GqnH4+Huu+/mlVde4fbbb6dr165uh2SMCSKrkZazrKwsrrvuOl555RUeeughpk+fbjVRY6o4q5GWs3feeYcPP/yQv/71rzz44INuh2OMqQAhmUgzczxuh1Co2267jfbt29O7d2+3QzHGVJCQPLRvEFe5esj/9ddfGTBgANu2bUNELIkaU82EZCKNrET96O3YsYNevXqxfPlydu3a5XY4xhgXhOShfWW51379+vX079+fjIwMFi9ezIUXXuh2SMYYF4RkIq0M1q5dS+/evYmOjmbZsmWceeaZbodkjHFJ5ajalVDNaPfzf5s2bUhISODbb7+1JGpMNReSidTNwe8WLlzIiRMniIuL44MPPqBt27auxWKMqRxCMpG6lUdff/11BgwYwOOPP+5OAMaYSikkE6kbF+Q/++yz3H777SQkJDBp0qQK374xpvIKyURakbeIqirjx4/nwQcfZOTIkcyZM4eaNUN7qBNjTPkKzURagVEfPHiQt99+mzvuuIP333+fqKioitu4MSYkuN/8XQoV0diUnZ1NeHg4jRo14scff6Rx48ZIJe4sxRjjntCskQY5oaWmpjJ48GD+9Kc/AdCkSRNLosaYQoVmIg1iY1NSUhL9+/dn0aJFdOnSJWjbMcZUHSF5aB+sW0T3799PQkICmzdv5uOPP2bYsGFB2Y4xpmoJyUQajEP7nJwcLrvsMnbt2sW8efO47LLLyn0b5mTZ2dns2bOHjIwMt0Mx1UhMTAzNmzcnMjKy3MoM0URa/mVGRETw9NNP06RJEy644ILy34A5xZ49e4iPj6d169Z2DtpUCFXlyJEj7NmzhzZt2pRbuSF5jrQ8L8j/7rvv+PDDDwG46qqrLIlWoIyMDOrXr29J1FQYEaF+/frlfhQUkom0vL548+fPp1+/fjz++ONkZ2eXS5mmZCyJmooWjM9cSCbS8vDRRx8xZMgQOnbsyJIlS8r1fIkxpnoJuURaHr8l06dPZ9SoUVxwwQUsWbKERo0alUOpJhSFh4dz9tlnc+aZZzJkyBCOHTuWt2z9+vX07duXjh070qFDByZPnoyq5i3/6quv6NGjB2eccQadOnVi3LhxbuxCkVavXs3tt9/udhhFmjJlCu3bt+f0009n/vz5Ba7z9ddfc84553DmmWdy0003kZOTAzh9YJx99tl572F4eDhJSUlkZWVx6aWX5q0XdKoaUn/RjdtrWU2YMEEHDhyoqampZS7LlN6GDRvcDkFr1qyZ9/jGG2/UJ598UlVV09LStG3btjp//nxVVU1NTdUBAwboSy+9pKqqa9eu1bZt2+rGjRtVVTU7O1tffvnlco0tOzu7zGWMGDFC16xZU6HbLIn169dr165dNSMjQ7dv365t27bVnJyck9bxeDzavHlz3bRpk6qqPvroozpjxoxTypo7d6726dMnb3rSpEn63nvvFbjdgj57wEotZV4KuVb70p7fUFX27NlDixYtmDx5Mh6Ph4iIkNv9Kuvxz9ezYd/xci2zc9Na/HlI4DdVXHTRRfz8888A/POf/6Rnz54kJCQAUKNGDV566SV69+7NXXfdxTPPPMOECRPo1KkT4Fz18Yc//OGUMk+cOME999zDypUrERH+/Oc/M3z4cOLi4jhx4gQAn3zyCV988QVvvfUWN998M/Xq1WP16tWcffbZzJ49mzVr1lCnTh0A2rdvT2JiImFhYfz+97/PGyfshRdeoGfPnidtOyUlhZ9//plu3boBsGLFCu6//37S09OJjY3lzTff5PTTT+ett97iyy+/JCMjg9TUVL7++mueffZZPvroIzIzM7n66qvzuo686qqr2L17NxkZGdx3332MGTMm4Ne3IHPmzGHUqFFER0fTpk0b2rdvz4oVK7jooovy1jly5AjR0dF07NgRgP79+zNlyhRuu+22k8r64IMPGD16dN70VVddxfjx47nuuuvKFGMgQi6TqN+hVaA8Hg933HEHc+bM4eeff6ZJkyaWRM1JPB4Pixcvzvtyrl+/nnPPPfekddq1a8eJEyc4fvw469at44EHHii23MmTJ1O7dm3Wrl0LwNGjR4t9zubNm1m0aBHh4eF4vV5mz57NLbfcwvfff0/r1q1p1KgRv/3tbxk7diy9evVi165dXH755WzcuPGkclauXHnS6A2dOnVi2bJlREREsGjRIh555BE+/fRTwLl65eeff6ZevXosWLCALVu2sGLFClSVK6+8kmXLlnHppZfyxhtvUK9ePdLT0znvvPMYPnw49evXP2m7Y8eOZcmSJafs16hRo3j44YdPmrd3796Txjpr3rw5e/fuPWmdBg0akJ2dzcqVK+nRoweffPIJu3fvPmmdtLQ0/vWvf/HSSy/lzTvzzDP54Ycfin29y0PIZZOSptHMzEyuu+46Pv30UyZOnEjjxo2DEpcpm5LUHMtTeno6Z599Njt37uTcc8+lf//+gPODXdjRT0mOihYtWsTMmTPzpuvWrVvsc6655hrCw8MBGDlyJE888QS33HILM2fOZOTIkXnlbtiwIe85x48fJyUlhfj4+Lx5+/fvp2HDhnnTycnJ3HTTTWzZsgUROelKlf79+1OvXj0AFixYwIIFC+jevTvg1Kq3bNnCpZdeyrRp05g9ezYAu3fvZsuWLack0qlTpwb24lBwxSj/6ysizJw5k7Fjx5KZmUlCQsIpFaHPP/+cnj175u0DOOe/o6KiTnldgiHkEmlJnDhxgmHDhrFw4UKmTp3K/fff73ZIppKJjY1lzZo1JCcnM3jwYF5++WXuvfdeunTpwrJly05ad/v27cTFxREfH0+XLl348ccf8w6bC1NYQvafl/+aRv/+bi+66CK2bt3KoUOH+Oyzz5g4cSIAXq+X7777jtjY2CL3zb/sRx99lD59+jB79mx27txJ7969C9ym+vrgveOOO04qb+nSpSxatIjvvvuOGjVq0Lt37wKvxyxJjbR58+Yn1S737NlD06ZNT3nuRRddxPLlywEn0W/evPmk5TNnzjzpsD5XZmYmMTExp8wvd6U9uerWX42mHQo8eVyQhx56SMPDw/Wtt94K+Dmm4lS2xqZVq1ZpixYtNCsrS9PS0rRNmza6cOFCVXUan6644gqdNm2aqqr+9NNP2q5du7wGEI/Ho88999wp5T/00EN633335U0nJSWpqmq7du10w4YN6vF4dNiwYXrTTTepqupNN92kH3/88UlljBs3Tq+//nodOHBg3rzRo0frM888kze9evXqU7a9ceNG7dmzZ970VVddpZ988omqqv75z3/WVq1aqarqm2++qXfddVfeevPnz9fzzz9fU1JSVFV1z549euDAAf3ss8908ODBeWVHR0frkiVLTtluSaxbt+6kxqY2bdqc0tikqnrgwAFVVc3IyNC+ffvq4sWL85YdO3ZM69atqydOnDjpOYcPH9ZOnToVuN3ybmwKucufSuKxxx5j4cKF3HTTTW6HYkJA9+7d6datGzNnziQ2NpY5c+bw5JNPcvrpp3PWWWdx3nnncffddwPQtWtXXnjhBUaPHs0ZZ5zBmWeeyf79+08pc+LEiRw9epQzzzyTbt265dXU/vKXvzB48GD69u1LkyZNioxr5MiRvPfee3mH9QDTpk1j5cqVdO3alc6dO/PKK6+c8rxOnTqRnJxMSkoKAA8++CDjx4+nZ8+eeDyeQreXkJDAb3/7Wy666CLOOussRowYQUpKCgMGDCAnJ4euXbvy6KOPnnRus7S6dOnCtddeS+fOnRkwYAAvv/xy3mmNQYMGsW/fPsC5zOmMM86ga9euDBkyhL59++aVMXv2bBISEk4ZuWLJkiUMGjSozDEGQrQUjTduimt2HZm4lwAADeRJREFUup7Yu6nQ5Vu3buXBBx/kzTffpHbt2hUYmSmpjRs3csYZZ7gdRpU2depU4uPjK/21pMEwbNgwpkyZwumnn37KsoI+eyLyo6r2KM22Qq9GWsR5/p9++olevXqxbNmyvMtCjKnO7rzzTqKjo90Oo8JlZWVx1VVXFZhEgyH0EmkhEhMT+c1vfkNkZCTLly/nrLPOcjskY1wXExPDDTfc4HYYFS4qKoobb7yxwrZXJRLp119/Tf/+/WnUqBGJiYl2uBhCQu3Ukgl9wfjMhVwiLejIvn379vTv35/ly5fTsmXLCo/JlE5MTAxHjhyxZGoqjKrTH2l5XxIVco1N8c1P15Q9TmPTwoULueyyywiryPGZTbmxHvKNGwrrIb8sjU1BvSBfRAYALwLhwAxV/Uu+5dHAO8C5wBFgpKruLLpM51dlypQpTJgwgVdeeeWUC4dNaIiMjCzXXsqNcUvQqnIiEg68DAwEOgOjRaRzvtVuA46qantgKvDXQMoeN24cEyZM4Prrr+fWW28tz7CNMabEgnlMfD6wVVW3q2oWMBMYmm+docDbvsefAJdJMTcyZyT9yvPPP88999zD22+/bR0yG2NcF8xE2gzw76Jlj29egeuoag6QDNSnCNlpKUyaNIkXX3zRzo0aYyqFYJ4jLahmmb9lK5B1EJExQG7Hh5mTJk1aN2nSpLJFV3k1AA67HUQQVeX9q8r7BlV//0p99X4wE+keoIXfdHNgXyHr7BGRCKA2kJS/IFWdDkwHEJGVpW1ZCwW2f6GrKu8bVI/9K+1zg3ls/APQQUTaiEgUMAqYm2+duUBujyIjgK811K7HMsZUe0GrkapqjojcDczHufzpDVVdLyJP4HRXNRd4HXhXRLbi1ERHBSseY4wJlqBeR6qq84B5+eY95vc4A7imhMVOL4fQKjPbv9BVlfcNbP8KFXJ3NhljTGVj1w8ZY0wZVdpEKiIDRGSTiGwVkYcLWB4tIh/6ln8vIq0rPsrSC2D//igiG0TkZ/n/9s4/2KqqiuOfr6LyQ33AIJozIimg4i8idcgfWYpOWoPZMIrzEDFfDeSPqMHSYJSsHDV/MKKEpg5aaE9KkDRFMX6JPNHkpwxqqZlGSCNRpDkkqz/Wer7D8773zn33vnffo/2ZuXP32Xefvdc659x91t77rHWkZyQdXAk5W0NLumXKjZRkkjrVSnAe/SSdF+fvZUkPtreMpZDj2uwnaaGklXF9tk8Y+jIg6T5J70pa18TvknR76L5G0tBcFbf2HSVt+cEXp/4EHALsCawGBjcq8y1gRqRHAbWVlrvM+n0R6B7p8Z1Fvzy6Rbl9gCVAHXBcpeUu87kbCKwEesV230rLXWb97gbGR3ow8Gal5S5Cv88DQ4F1Tfx+NvAE/oz7MOD5PPV2VIu0TdxLOxAt6mdmC83s/disw5/D7QzkOXcAPwJuAjpb6Kc8+n0DuNPMtgCY2bvtLGMp5NHPgH0jXcUnnw/vsJjZEgo8q57hHOABc+qAnpKaf6kWHXdo3ybupR2IPPpluQS/S3YGWtRN0meAg8zssfYUrEzkOXeDgEGSlkmqiyhonYU8+k0BRkt6G38q5/L2Ea1dKPa/CXTc99qXzb20g5JbdkmjgeOAU9tUovLRrG6SdsMjfY1tL4HKTJ5z1wUf3n8BH0kslXSUmf2jjWUrB3n0uwCYaWa3SPoc/iz4UWa2o+3Fa3Na1a90VIu0GPdSmnMv7aDk0Q9Jw4FJwAgz+7CdZCuVlnTbBzgKWCTpTXweal4nWnDKe20+ambbzewN4BW8Y+0M5NHvEuBhADNbDnTF/fB3BXL9NxvTUTvSXd29tEX9Yvh7F96JdqY5tmZ1M7OtZtbHzPqbWX98/neEmbXaz7mdyXNtzsUXC5HUBx/qv96uUraePPq9BZwOIOkIvCPd3K5Sth3zgDGxej8M2GpmG1vcq9KraM2srp0NvIqvIE6KvOvwPx34yZsN/BFYARxSaZnLrN8CYBOwKj7zKi1zuXRrVHYRnWjVPue5E3ArsB5YC4yqtMxl1m8wsAxf0V8FnFlpmYvQ7SFgI7Adtz4vAcYB4zLn7s7QfW3eazN5NiUSiUSJdNShfSKRSHQaUkeaSCQSJZI60kQikSiR1JEmEolEiaSONJFIJEokdaQFkPSRpFWZT/9myvZvKpJMkW0uiog7q8O1sOgXcUkaJ2lMpMdKOjDz2z2SBpdZzhckDcmxzwRJ3UttO0c7UyS9E29hQNLhkpZL+lDSxCLrOjpz/t+T9EakF7SB3DWSdkg6MpO3QVJZ4ytIGpp1V5V0rqQry1BvjaTNcXw2SLoixz6nxXOaLZWrjkhMc0uVsy3pqC6ileYDM2uxg2gDqs3sRflbU38KjChmZzObkdkcC6wjvDLMrKZcQtIg58W4nGe0UH4C8Evg/RbKFYWkLuZxFrLcZmY3R/o94Argq8XWbWZrgSHRzkzgMTP7dU4ZWsPbwA+A6jLU1RRDca+yJwHMbE4Z655lZhMk7Qe8Imm2Nf8g+2n4G0nrmqvUzGZJ2gRcVkZZy06ySHMSludSSS/F58QCZY6UtCLuzGskDYz80Zn8uyTt3kJzS4ABse/p8riPa+WxFPeK/BvUEK/05sibImmipJG4f/6saLNbWJLHSRov6aaMzGMlTWulnMvJBHSQ9DNJL8pjcP4w8q4ADgQWSloYeWeGpfiSpNmS9i5wLIfIA36skTRHUq/IXyTpekmLgW83J5yZvWtmL+APX5cNScMlLZD0K2ClpAGSVmV+v0rS5EgPlDRf0h8kLZE0qIlq5wJDJQ0o0N5ZmeNVK6lH5I+I0cFSSdPqrTZJw6L8SvnoZqCkbsA1QHWc35FhSU6V1DssbsX+e0t6S1KXIuQHwMw2415cn4q6zpHHC14p6SlJfSUdCtQAV4YsJ0raX9Ijcf2syGOtdigq7WnQET/ARzR4FM2JvO5A10gPxF/gB9CfiG0ITMOtNfBYjt2AI4DfAntE/nRgTIE2FxFeFMCVQC3uvfUXYFDkP4Bbd71x/+16h4qe8T0FmNi4vuw2sB8eJq0+/wng5FbKOQG4PvNb7/jePcodE9tvAn0i3Qe/UfSI7e8D1xRoZw1waqSvA6Zm2p/exHn7WP88+UVcDzOBkZnt4cA2oF9sDwBWZX6/Cpgc6YXAoZE+CXiqQP01wFTg68C9kbcB9/PuCyymITbtJNxy7Y5bsQfj3jizgblRpgrYPdJfImLZ1rfTuN1IPw6cEulqGmL95pY/839YCewZ271ouE7HATdG+sfAhEwdtcCwxv+pzPGeW+l+oblPGtoXptDQfg/gDvmc4Ee4/3RjlgOT5HNbj5jZa5JOBz4LvBA3/G5AU77zsyR9gHc8lwOHAW+Y2avx+/3ApcAdeBzPeyQ9DuQOR2dmmyW9Hnf816KNZVFvMXL2wDvMbATx8+TTEl1wi2Qw3iFmGRb5y6KdPfHj9jGSqvCbw+KM3rMzRWrz6tuGLDezt5orIKknru9v1BAqt7n/3C+AqyX1y+SdiB+v5zLH69nIe8XM/hxtPQSMiX16Ag+E5ZeXWuB8YCnuX39rkfJXSzoDv54uNo9lCtAPeFjSAcBeuOtpIYYDh2Xa6SWpm5l9UIQOFSN1pPn5Du77fiw+JfKJgMRm9qCk54EvA/Ml1eDWwv1mdnWONqotE7xDUsH4quavuj4BDxwxCp8/Oq0IXWqB83CrZ46ZWQzrcsuJ+1nfgPslf03Sp4GJwPFmtkU+r9i1wL4CnjazC4qQtzH/LmHfnYWRzgWujc0ayx88JSvDf9l5mqxr5An4e4GbckHMbLuk24DvZUUEnjSzCxvJfXwzVf0EmG9m02Oq4Mkczc8FrpN0LXA0bgVXFSF//RzpyXg0r/nmwXbuxEctv5NHM2vq1TMCTsh0wJ2KNEeanypgo3nMxQtxa2wnJB0CvG5mt+NRZI4BngFGSuobZXor//uXNgD9M/NmFwKLY06xyvx11xOIRZFG/AsPWVeIR/AFmAtosO6KktPMtgOTgWHyCED74p3LVkn7A2c1IUsdcFK9TpK6N553M7OtwBZJp2T1bkqWUjCzOWY2JD6tjUD1N+BASb0kdcVvpJhHyN8YnTWSdpN0bAt13Ysfu96x/RxwalxbSOohn3t/GbfgDoqb4PmZOqqAdyI9NpPf5DVhZv/Eh+RT8QA5O1ojv5k9iwcGqQ/2XAW8EzJelCnaWJYF+KiIaKsSi72tJnWk+ZkOXCSpDh/WF7KKzgfWyRceDsdfWbAe73CekrQGeJqYiG8JM/sPcDEwW9JaYAcwA78AH4v6FuPWcmNmAjNiMr9bo3q34JGJDjazFZFXtJwx7LoFn39cjf8RXwbuw6cL6rkbeELSQvPFiLHAQ9FOHX6sGnMR8NMoMwSfJy0KSQfIo7h/F5gs6W1J+7a0X7HEeboeD0E3Dz+29YwCxklajR+br7RQ14e4FbdfbG/CIxTVRh3P4XPm7+MjkQX4cPyv+FsiAG7Ej92yRtX/Hjg2Fn5GFmi+FhjNzlMnRckf3ADUxPTPFGAOfp1uypR5FJ8KWilfuL0Uv8GukbQef11LpyFFf0rsMkiaAmyzhsefdmkk7W1m28LauwtYa2bTKi1XuYkpgcvMrOjH2NqLZJEmdiW2Ad9UPJD/f8D4GP2sxxcHf15hecqOpGrgdmBLpWVpjmSRJhKJRIkkizSRSCRKJHWkiUQiUSKpI00kEokSSR1pIpFIlEjqSBOJRKJEUkeaSCQSJfI/+SR/yJy8kEAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_roc(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under ROC curve is pretty high almost equal to 0.97."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  \\\n",
       "0      0    0.108761          0    1    1    0    0    0    0    0    0    0   \n",
       "1      0    0.138344          0    1    1    0    0    0    0    0    0    0   \n",
       "2      0    0.416209          0    1    1    1    1    1    0    0    0    0   \n",
       "3      0    0.336189          0    1    1    1    1    0    0    0    0    0   \n",
       "4      0    0.038326          0    1    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   0.9  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create columns with different probability cutoffs (0 < x < 1)\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14168   154]\n",
      " [ 3569  4993]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.axvline(x=0.41,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our optimal cutoff will be 0.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>final_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  \\\n",
       "0      0    0.108761          0    1    1    0    0    0    0    0    0    0   \n",
       "1      0    0.138344          0    1    1    0    0    0    0    0    0    0   \n",
       "2      0    0.416209          0    1    1    1    1    1    0    0    0    0   \n",
       "3      0    0.336189          0    1    1    1    1    0    0    0    0    0   \n",
       "4      0    0.038326          0    1    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   0.9  final_predicted  \n",
       "0    0                0  \n",
       "1    0                0  \n",
       "2    0                1  \n",
       "3    0                0  \n",
       "4    0                0  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.41 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9172"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "round(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9163"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(metrics.recall_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.axvline(x=0.49,color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us choose our optimal cut off as 0.49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>final_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  \\\n",
       "0      0    0.108761          0    1    1    0    0    0    0    0    0    0   \n",
       "1      0    0.138344          0    1    1    0    0    0    0    0    0    0   \n",
       "2      0    0.416209          0    1    1    1    1    1    0    0    0    0   \n",
       "3      0    0.336189          0    1    1    1    1    0    0    0    0    0   \n",
       "4      0    0.038326          0    1    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   0.9  final_predicted  \n",
       "0    0                0  \n",
       "1    0                0  \n",
       "2    0                0  \n",
       "3    0                0  \n",
       "4    0                0  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.49 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9233"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "round(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8965"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(metrics.recall_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, we want our recall score to be high, we go with cutoff as 0.41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>final_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  \\\n",
       "0      0    0.108761          0    1    1    0    0    0    0    0    0    0   \n",
       "1      0    0.138344          0    1    1    0    0    0    0    0    0    0   \n",
       "2      0    0.416209          0    1    1    1    1    1    0    0    0    0   \n",
       "3      0    0.336189          0    1    1    1    1    0    0    0    0    0   \n",
       "4      0    0.038326          0    1    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   0.9  final_predicted  \n",
       "0    0                0  \n",
       "1    0                0  \n",
       "2    0                1  \n",
       "3    0                0  \n",
       "4    0                0  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.41 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test[col])\n",
    "y_test_pred = res.predict(X_test_sm)\n",
    "y_test_pred = y_test_pred.values.reshape(-1)\n",
    "\n",
    "#Creating a DataFrame of the original target variable and Purchase Probability \n",
    "y_test_pred_final = pd.DataFrame({'Churn':y_test.values, 'Churn_Prob':y_test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final['final_predicted'] = y_test_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.41 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8449"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "round(metrics.accuracy_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#roc_auc score\n",
    "round(metrics.roc_auc_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8617"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the sensitivity.\n",
    "round(metrics.recall_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1601"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the precision.\n",
    "round(metrics.precision_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression without PCA with sampling</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.871596</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.186470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest without PCA without sampling</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.954237</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.234681</td>\n",
       "      <td>0.035750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA without Sampling</td>\n",
       "      <td>0.770948</td>\n",
       "      <td>0.774503</td>\n",
       "      <td>0.798305</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.106706</td>\n",
       "      <td>0.107047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA without sampling</td>\n",
       "      <td>0.983591</td>\n",
       "      <td>0.945665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438735</td>\n",
       "      <td>0.669694</td>\n",
       "      <td>0.290576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost with PCA with sampling</td>\n",
       "      <td>0.968366</td>\n",
       "      <td>0.938034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513834</td>\n",
       "      <td>0.512598</td>\n",
       "      <td>0.271967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with PCA with Sampling</td>\n",
       "      <td>0.899624</td>\n",
       "      <td>0.897908</td>\n",
       "      <td>0.796076</td>\n",
       "      <td>0.715415</td>\n",
       "      <td>0.925207</td>\n",
       "      <td>0.204520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost with PCA</td>\n",
       "      <td>0.991485</td>\n",
       "      <td>0.962110</td>\n",
       "      <td>0.783051</td>\n",
       "      <td>0.292490</td>\n",
       "      <td>0.952577</td>\n",
       "      <td>0.404372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Logistic Regression with PCA with sampling</td>\n",
       "      <td>0.917191</td>\n",
       "      <td>0.844889</td>\n",
       "      <td>0.916258</td>\n",
       "      <td>0.861660</td>\n",
       "      <td>0.869445</td>\n",
       "      <td>0.160059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Training Accuracy  \\\n",
       "Logistic Regression without PCA with sampling           0.864997   \n",
       "Random Forest without PCA without sampling              0.894948   \n",
       "Random Forest with PCA without Sampling                 0.770948   \n",
       "AdaBoost with PCA without sampling                      0.983591   \n",
       "AdaBoost with PCA with sampling                         0.968366   \n",
       "Random Forest with PCA with Sampling                    0.899624   \n",
       "XGBoost with PCA                                        0.991485   \n",
       "Logistic Regression with PCA with sampling              0.917191   \n",
       "\n",
       "                                               Test Accuracy  Training Recall  \\\n",
       "Logistic Regression without PCA with sampling       0.871596         0.864501   \n",
       "Random Forest without PCA without sampling          0.112485         0.954237   \n",
       "Random Forest with PCA without Sampling             0.774503         0.798305   \n",
       "AdaBoost with PCA without sampling                  0.945665         1.000000   \n",
       "AdaBoost with PCA with sampling                     0.938034         1.000000   \n",
       "Random Forest with PCA with Sampling                0.897908         0.796076   \n",
       "XGBoost with PCA                                    0.962110         0.783051   \n",
       "Logistic Regression with PCA with sampling          0.844889         0.916258   \n",
       "\n",
       "                                               Test Recall  \\\n",
       "Logistic Regression without PCA with sampling     0.849802   \n",
       "Random Forest without PCA without sampling        0.988142   \n",
       "Random Forest with PCA without Sampling           0.786561   \n",
       "AdaBoost with PCA without sampling                0.438735   \n",
       "AdaBoost with PCA with sampling                   0.513834   \n",
       "Random Forest with PCA with Sampling              0.715415   \n",
       "XGBoost with PCA                                  0.292490   \n",
       "Logistic Regression with PCA with sampling        0.861660   \n",
       "\n",
       "                                               Training Precision  \\\n",
       "Logistic Regression without PCA with sampling            0.865359   \n",
       "Random Forest without PCA without sampling               0.234681   \n",
       "Random Forest with PCA without Sampling                  0.106706   \n",
       "AdaBoost with PCA without sampling                       0.669694   \n",
       "AdaBoost with PCA with sampling                          0.512598   \n",
       "Random Forest with PCA with Sampling                     0.925207   \n",
       "XGBoost with PCA                                         0.952577   \n",
       "Logistic Regression with PCA with sampling               0.869445   \n",
       "\n",
       "                                               Test Precision  \n",
       "Logistic Regression without PCA with sampling        0.186470  \n",
       "Random Forest without PCA without sampling           0.035750  \n",
       "Random Forest with PCA without Sampling              0.107047  \n",
       "AdaBoost with PCA without sampling                   0.290576  \n",
       "AdaBoost with PCA with sampling                      0.271967  \n",
       "Random Forest with PCA with Sampling                 0.204520  \n",
       "XGBoost with PCA                                     0.404372  \n",
       "Logistic Regression with PCA with sampling           0.160059  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics.loc['Logistic Regression with PCA with sampling','Training Accuracy']=metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression with PCA with sampling','Test Accuracy']=metrics.accuracy_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression with PCA with sampling','Training Recall']=metrics.recall_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression with PCA with sampling','Test Recall']=metrics.recall_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression with PCA with sampling','Training Precision']=metrics.precision_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)\n",
    "model_metrics.loc['Logistic Regression with PCA with sampling','Test Precision']=metrics.precision_score(y_test_pred_final.Churn, y_test_pred_final.final_predicted)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f31075ca_4110_11ea_b298_0897987296f8row0_col0 {\n",
       "            background-color:  #97d385;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row0_col1 {\n",
       "            background-color:  #006335;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row0_col2 {\n",
       "            background-color:  #acdd8e;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row0_col3 {\n",
       "            background-color:  #14783e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row0_col4 {\n",
       "            background-color:  #006234;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row0_col5 {\n",
       "            background-color:  #9fd788;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row1_col0 {\n",
       "            background-color:  #5db96b;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row1_col1 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row1_col2 {\n",
       "            background-color:  #177b3f;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row1_col3 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row1_col4 {\n",
       "            background-color:  #f1fab5;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row1_col5 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row2_col0 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row2_col1 {\n",
       "            background-color:  #1a7d40;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row2_col2 {\n",
       "            background-color:  #fbfdce;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row2_col3 {\n",
       "            background-color:  #2d914b;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row2_col4 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row2_col5 {\n",
       "            background-color:  #e7f6ad;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row3_col0 {\n",
       "            background-color:  #004f2d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row3_col1 {\n",
       "            background-color:  #00492b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row3_col2 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row3_col3 {\n",
       "            background-color:  #e3f4aa;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row3_col4 {\n",
       "            background-color:  #379e54;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row3_col5 {\n",
       "            background-color:  #31974f;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row4_col0 {\n",
       "            background-color:  #006234;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row4_col1 {\n",
       "            background-color:  #004d2c;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row4_col2 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row4_col3 {\n",
       "            background-color:  #c1e698;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row4_col4 {\n",
       "            background-color:  #81ca7d;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row4_col5 {\n",
       "            background-color:  #3da559;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row5_col0 {\n",
       "            background-color:  #53b466;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row5_col1 {\n",
       "            background-color:  #005a31;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row5_col2 {\n",
       "            background-color:  #fbfed0;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row5_col3 {\n",
       "            background-color:  #49af61;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row5_col4 {\n",
       "            background-color:  #004e2d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row5_col5 {\n",
       "            background-color:  #89ce80;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row6_col0 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row6_col1 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row6_col2 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row6_col3 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row6_col4 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row6_col5 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row7_col0 {\n",
       "            background-color:  #389f55;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row7_col1 {\n",
       "            background-color:  #036b38;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row7_col2 {\n",
       "            background-color:  #45ad5f;\n",
       "            color:  #000000;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row7_col3 {\n",
       "            background-color:  #10743c;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row7_col4 {\n",
       "            background-color:  #006034;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f31075ca_4110_11ea_b298_0897987296f8row7_col5 {\n",
       "            background-color:  #bae394;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_f31075ca_4110_11ea_b298_0897987296f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Training Accuracy</th>        <th class=\"col_heading level0 col1\" >Test Accuracy</th>        <th class=\"col_heading level0 col2\" >Training Recall</th>        <th class=\"col_heading level0 col3\" >Test Recall</th>        <th class=\"col_heading level0 col4\" >Training Precision</th>        <th class=\"col_heading level0 col5\" >Test Precision</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f31075ca_4110_11ea_b298_0897987296f8level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression without PCA with sampling</th>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row0_col0\" class=\"data row0 col0\" >0.864997</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row0_col1\" class=\"data row0 col1\" >0.871596</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row0_col2\" class=\"data row0 col2\" >0.864501</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row0_col3\" class=\"data row0 col3\" >0.849802</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row0_col4\" class=\"data row0 col4\" >0.865359</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row0_col5\" class=\"data row0 col5\" >0.18647</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f31075ca_4110_11ea_b298_0897987296f8level0_row1\" class=\"row_heading level0 row1\" >Random Forest without PCA without sampling</th>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row1_col0\" class=\"data row1 col0\" >0.894948</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row1_col1\" class=\"data row1 col1\" >0.112485</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row1_col2\" class=\"data row1 col2\" >0.954237</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row1_col3\" class=\"data row1 col3\" >0.988142</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row1_col4\" class=\"data row1 col4\" >0.234681</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row1_col5\" class=\"data row1 col5\" >0.03575</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f31075ca_4110_11ea_b298_0897987296f8level0_row2\" class=\"row_heading level0 row2\" >Random Forest with PCA without Sampling</th>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row2_col0\" class=\"data row2 col0\" >0.770948</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row2_col1\" class=\"data row2 col1\" >0.774503</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row2_col2\" class=\"data row2 col2\" >0.798305</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row2_col3\" class=\"data row2 col3\" >0.786561</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row2_col4\" class=\"data row2 col4\" >0.106706</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row2_col5\" class=\"data row2 col5\" >0.107047</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f31075ca_4110_11ea_b298_0897987296f8level0_row3\" class=\"row_heading level0 row3\" >AdaBoost with PCA without sampling</th>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row3_col0\" class=\"data row3 col0\" >0.983591</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row3_col1\" class=\"data row3 col1\" >0.945665</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row3_col3\" class=\"data row3 col3\" >0.438735</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row3_col4\" class=\"data row3 col4\" >0.669694</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row3_col5\" class=\"data row3 col5\" >0.290576</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f31075ca_4110_11ea_b298_0897987296f8level0_row4\" class=\"row_heading level0 row4\" >AdaBoost with PCA with sampling</th>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row4_col0\" class=\"data row4 col0\" >0.968366</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row4_col1\" class=\"data row4 col1\" >0.938034</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row4_col3\" class=\"data row4 col3\" >0.513834</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row4_col4\" class=\"data row4 col4\" >0.512598</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row4_col5\" class=\"data row4 col5\" >0.271967</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f31075ca_4110_11ea_b298_0897987296f8level0_row5\" class=\"row_heading level0 row5\" >Random Forest with PCA with Sampling</th>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row5_col0\" class=\"data row5 col0\" >0.899624</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row5_col1\" class=\"data row5 col1\" >0.897908</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row5_col2\" class=\"data row5 col2\" >0.796076</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row5_col3\" class=\"data row5 col3\" >0.715415</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row5_col4\" class=\"data row5 col4\" >0.925207</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row5_col5\" class=\"data row5 col5\" >0.20452</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f31075ca_4110_11ea_b298_0897987296f8level0_row6\" class=\"row_heading level0 row6\" >XGBoost with PCA</th>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row6_col0\" class=\"data row6 col0\" >0.991485</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row6_col1\" class=\"data row6 col1\" >0.96211</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row6_col2\" class=\"data row6 col2\" >0.783051</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row6_col3\" class=\"data row6 col3\" >0.29249</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row6_col4\" class=\"data row6 col4\" >0.952577</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row6_col5\" class=\"data row6 col5\" >0.404372</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f31075ca_4110_11ea_b298_0897987296f8level0_row7\" class=\"row_heading level0 row7\" >Logistic Regression with PCA with sampling</th>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row7_col0\" class=\"data row7 col0\" >0.917191</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row7_col1\" class=\"data row7 col1\" >0.844889</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row7_col2\" class=\"data row7 col2\" >0.916258</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row7_col3\" class=\"data row7 col3\" >0.86166</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row7_col4\" class=\"data row7 col4\" >0.869445</td>\n",
       "                        <td id=\"T_f31075ca_4110_11ea_b298_0897987296f8row7_col5\" class=\"data row7 col5\" >0.160059</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26f3ac40308>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics.style.background_gradient(cmap='YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_02334c2c_4111_11ea_87e6_0897987296f8row0_col0 {\n",
       "            background-color:  #00472a;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row0_col1 {\n",
       "            background-color:  #006034;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row0_col2 {\n",
       "            background-color:  #00502d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row0_col3 {\n",
       "            background-color:  #004a2b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row0_col4 {\n",
       "            background-color:  #00512e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row0_col5 {\n",
       "            background-color:  #004f2d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row0_col6 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row0_col7 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row1_col0 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row1_col1 {\n",
       "            background-color:  #fafdc9;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row1_col2 {\n",
       "            background-color:  #004e2d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row1_col3 {\n",
       "            background-color:  #005a31;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row1_col4 {\n",
       "            background-color:  #005c32;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row1_col5 {\n",
       "            background-color:  #004f2d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row1_col6 {\n",
       "            background-color:  #00502d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row1_col7 {\n",
       "            background-color:  #005f34;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row2_col0 {\n",
       "            background-color:  #00472a;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row2_col1 {\n",
       "            background-color:  #004f2d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row2_col2 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row2_col3 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row2_col4 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row2_col5 {\n",
       "            background-color:  #0e743c;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row2_col6 {\n",
       "            background-color:  #2f934d;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row2_col7 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row3_col0 {\n",
       "            background-color:  #004e2d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row3_col1 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row3_col2 {\n",
       "            background-color:  #00492b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row3_col3 {\n",
       "            background-color:  #e3f4aa;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row3_col4 {\n",
       "            background-color:  #bce395;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row3_col5 {\n",
       "            background-color:  #2d914b;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row3_col6 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row3_col7 {\n",
       "            background-color:  #005931;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row4_col0 {\n",
       "            background-color:  #00472a;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row4_col1 {\n",
       "            background-color:  #e3f4aa;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row4_col2 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row4_col3 {\n",
       "            background-color:  #69bf72;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row4_col4 {\n",
       "            background-color:  #bde496;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row4_col5 {\n",
       "            background-color:  #004529;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row4_col6 {\n",
       "            background-color:  #00542f;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row4_col7 {\n",
       "            background-color:  #005730;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row5_col0 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row5_col1 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row5_col2 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row5_col3 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row5_col4 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row5_col5 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row5_col6 {\n",
       "            background-color:  #eff9b3;\n",
       "            color:  #000000;\n",
       "        }    #T_02334c2c_4111_11ea_87e6_0897987296f8row5_col7 {\n",
       "            background-color:  #ffffe5;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_02334c2c_4111_11ea_87e6_0897987296f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Logistic Regression without PCA with sampling</th>        <th class=\"col_heading level0 col1\" >Random Forest without PCA without sampling</th>        <th class=\"col_heading level0 col2\" >Random Forest with PCA without Sampling</th>        <th class=\"col_heading level0 col3\" >AdaBoost with PCA without sampling</th>        <th class=\"col_heading level0 col4\" >AdaBoost with PCA with sampling</th>        <th class=\"col_heading level0 col5\" >Random Forest with PCA with Sampling</th>        <th class=\"col_heading level0 col6\" >XGBoost with PCA</th>        <th class=\"col_heading level0 col7\" >Logistic Regression with PCA with sampling</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_02334c2c_4111_11ea_87e6_0897987296f8level0_row0\" class=\"row_heading level0 row0\" >Training Accuracy</th>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row0_col0\" class=\"data row0 col0\" >0.864997</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row0_col1\" class=\"data row0 col1\" >0.894948</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row0_col2\" class=\"data row0 col2\" >0.770948</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row0_col3\" class=\"data row0 col3\" >0.983591</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row0_col4\" class=\"data row0 col4\" >0.968366</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row0_col5\" class=\"data row0 col5\" >0.899624</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row0_col6\" class=\"data row0 col6\" >0.991485</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row0_col7\" class=\"data row0 col7\" >0.917191</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02334c2c_4111_11ea_87e6_0897987296f8level0_row1\" class=\"row_heading level0 row1\" >Test Accuracy</th>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row1_col0\" class=\"data row1 col0\" >0.871596</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row1_col1\" class=\"data row1 col1\" >0.112485</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row1_col2\" class=\"data row1 col2\" >0.774503</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row1_col3\" class=\"data row1 col3\" >0.945665</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row1_col4\" class=\"data row1 col4\" >0.938034</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row1_col5\" class=\"data row1 col5\" >0.897908</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row1_col6\" class=\"data row1 col6\" >0.96211</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row1_col7\" class=\"data row1 col7\" >0.844889</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02334c2c_4111_11ea_87e6_0897987296f8level0_row2\" class=\"row_heading level0 row2\" >Training Recall</th>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row2_col0\" class=\"data row2 col0\" >0.864501</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row2_col1\" class=\"data row2 col1\" >0.954237</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row2_col2\" class=\"data row2 col2\" >0.798305</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row2_col5\" class=\"data row2 col5\" >0.796076</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row2_col6\" class=\"data row2 col6\" >0.783051</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row2_col7\" class=\"data row2 col7\" >0.916258</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02334c2c_4111_11ea_87e6_0897987296f8level0_row3\" class=\"row_heading level0 row3\" >Test Recall</th>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row3_col0\" class=\"data row3 col0\" >0.849802</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row3_col1\" class=\"data row3 col1\" >0.988142</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row3_col2\" class=\"data row3 col2\" >0.786561</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row3_col3\" class=\"data row3 col3\" >0.438735</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row3_col4\" class=\"data row3 col4\" >0.513834</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row3_col5\" class=\"data row3 col5\" >0.715415</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row3_col6\" class=\"data row3 col6\" >0.29249</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row3_col7\" class=\"data row3 col7\" >0.86166</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02334c2c_4111_11ea_87e6_0897987296f8level0_row4\" class=\"row_heading level0 row4\" >Training Precision</th>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row4_col0\" class=\"data row4 col0\" >0.865359</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row4_col1\" class=\"data row4 col1\" >0.234681</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row4_col2\" class=\"data row4 col2\" >0.106706</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row4_col3\" class=\"data row4 col3\" >0.669694</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row4_col4\" class=\"data row4 col4\" >0.512598</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row4_col5\" class=\"data row4 col5\" >0.925207</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row4_col6\" class=\"data row4 col6\" >0.952577</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row4_col7\" class=\"data row4 col7\" >0.869445</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02334c2c_4111_11ea_87e6_0897987296f8level0_row5\" class=\"row_heading level0 row5\" >Test Precision</th>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row5_col0\" class=\"data row5 col0\" >0.18647</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row5_col1\" class=\"data row5 col1\" >0.03575</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row5_col2\" class=\"data row5 col2\" >0.107047</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row5_col3\" class=\"data row5 col3\" >0.290576</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row5_col4\" class=\"data row5 col4\" >0.271967</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row5_col5\" class=\"data row5 col5\" >0.20452</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row5_col6\" class=\"data row5 col6\" >0.404372</td>\n",
       "                        <td id=\"T_02334c2c_4111_11ea_87e6_0897987296f8row5_col7\" class=\"data row5 col7\" >0.160059</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26f3c0ffa08>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics.T.style.background_gradient(cmap='YlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After PCA, the best model to use is Random Forest without Sampling using class_weight='balanced' argument since it has the maximum recall score and minimal overfitting. \n",
    "<br>\n",
    "<br>\n",
    "***Note:*** \n",
    "- ***We compensate with low precision score since the cost of False Positives is low. Our Ultimate Goal is to retain high value customers. Thus, even if we introduce some special schemes for the customers who are not churning, we are just treating our good customers well and the revenue of these customers would be high.***\n",
    "- ***However, if our recall is low and we lose high revenue customers, the company faces significant loss. Hence, we do not want to falsely predict churners as non-churn. Thus, we have to minimize our False Negatives and thus maximize Recall Score.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we go with rf_final (Random Forest without sampling using class_weight='balanced') model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAQwCAYAAAATlK4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzde7hddX3n8feHBEG5XyLFhBhUtFqmqESaDp1WQRGoNY5XaAfRUqNWrY7VKuoz1Ja2Wu+XSo2CQEdBCziggwpyqdUxSIKAXLRERIhQCPeLgCR854+9IpvkJDknOXuvtc95v55nP2et3/qttT+hBFe/53dJVSFJkiRJktRlW7QdQJIkSZIkaWMsYEiSJEmSpM6zgCFJkiRJkjrPAoYkSZIkSeo8CxiSJEmSJKnzZrYdYFB23XXXmjdvXtsxJEma8pYtW3ZrVc1qO8eg+W4hSdLgbei9YsoWMObNm8fSpUvbjiFJ0pSX5OdtZxgG3y0kSRq8Db1XOIVEkiRJkiR1ngUMSZIkSZLUeRYwJEmSJElS51nAkCRJkiRJnWcBQ5IkSZIkdZ4FDEmSJEmS1HkWMCRJkiRJUudZwJAkSZIkSZ1nAUOSJEmSJHXezLYDSOP1taU/Xaftj+Y/uYUkkiRJktq06u6bmbn9bm3H0JA5AkOSJEmSNDIe+Pkybvz4C3jg+kvajqIhs4AhSZIkSRoJ9fAqbjvzfUBx+5nvpR5e1XYkDZEFDEmSJEnSSLjnB1/i4ftuA2D1vbdxz8WntJxIw2QBQ5IkSZLUeavvvZW7Lvg09dD9ANRD93PX+Z9i9b23tpxMw+IinpIkSZp2xlocHFwgXOqy+644m6rVj2qrWs19V3yD7Rcc0VIqDZMjMCRJkiRJnbfN3oeSzHhUWzKDbfY+pKVEGjYLGJIkSZKkzpux7a7s8Lw3ky0fC0C2fCw7HPAWZmy7a8vJNCwWMCRJkiRJI2G7/f6YGdvuAvQKGts95/CWE2mYLGBIkiRJkkZCtpjJzi8+Fgg7LzyWbOGyjtPJQAsYSU5IckuSK8a49o4klWTX5jxJPplkeZLLkzy7r++RSa5pPkcOMrMkSZIkqbu2fuK+POFt57L13GdvvLOmlEGPwDgROHjtxiR7AC8Aru9rPgTYq/ksAo5r+u4MHAP8DrAfcEySnQaaWpIkSZLUWTO3363tCGrBQAsYVfUd4PYxLn0M+Cug+toWAidXzxJgxyS7Ay8Ezq2q26vqDuBcxiiKSJIkSZKkqWvoa2AkeTHwi6q6bK1Ls4Eb+s5XNG3ra5ckSZIkSdPEUFc8SfI44L3AQWNdHqOtNtA+1vMX0Zt+wty5czcxpSRJkiRJ6pphj8B4MrAncFmS64A5wCVJfoPeyIo9+vrOAW7cQPs6qmpxVc2vqvmzZs0aQHxJkiRJktSGoRYwqupHVfX4qppXVfPoFSeeXVX/CZwFvLrZjWQBcFdV3QR8CzgoyU7N4p0HNW2SJEmSJGmaGPQ2qqcA3weelmRFkqM20P1s4FpgOfA54M8Bqup24G+Bi5vP3zRtkiRJkiRpmhjoGhhVdfhGrs/rOy7gTevpdwJwwqSGkyRJkiRJI2Pou5BIkiRJkiRNlAUMSZIkSZLUeRYwJEmSJElS51nAkCRJU1qS/5nkyiRXJDklydZJ9kxyUZJrknw5yWPazilJkjbMAoYkSZqykswG/gKYX1V7AzOAw4APAh+rqr2AO4AN7ZQmSZI6wAKGJEma6mYCj00yE3gccBNwAHBac/0k4CUtZZMkSeNkAUOSJE1ZVfUL4MPA9fQKF3cBy4A7q2pV020FMLudhJIkabwsYEiSpCkryU7AQmBP4AnANsAhY3St9dy/KMnSJEtXrlw5uKCSJGmjZrYdQNqQz55z2bivv/6gfQYdR5I0ep4P/KyqVgIkOQP4r8COSWY2ozDmADeOdXNVLQYWA8yfP3/MIockSRoOR2BIkqSp7HpgQZLHJQlwIHAVcAHw8qbPkcCZLeWTJEnjZAFDkiRNWVV1Eb3FOi8BfkTv3Wcx8C7g7UmWA7sAx7cWUpIkjYtTSCRJ0pRWVccAx6zVfC2wXwtxJEnSJnIEhiRJkiRJ6jwLGJIkSZIkqfMsYEiSJEmSpM6zgCFJkiRJkjrPAoYkSZIkSeo8CxiSJEmSJKnzLGBIkiRJkqTOG2gBI8kJSW5JckVf24eS/DjJ5Um+mmTHvmtHJ1me5CdJXtjXfnDTtjzJuweZWZIkSZIkdc/MAT//RODTwMl9becCR1fVqiQfBI4G3pXkGcBhwG8BTwC+neSpzT3/BLwAWAFcnOSsqrpqwNklSZI0hXz2nMsm1Of1B+0zyDiSpAka6AiMqvoOcPtabedU1armdAkwpzleCJxaVQ9W1c+A5cB+zWd5VV1bVb8CTm36SpIkSZKkaaLtNTD+FPhGczwbuKHv2oqmbX3t60iyKMnSJEtXrlw5gLiSJEmSJKkNrRUwkrwXWAV8cU3TGN1qA+3rNlYtrqr5VTV/1qxZkxNUkiRJkiS1btBrYIwpyZHAi4ADq2pNMWIFsEdftznAjc3x+tolSZIkSdI0MPQRGEkOBt4FvLiqftl36SzgsCRbJdkT2Av4AXAxsFeSPZM8ht5Cn2cNO7ckSZIkSWrPQEdgJDkFeC6wa5IVwDH0dh3ZCjg3CcCSqnpDVV2Z5CvAVfSmlrypqlY3z3kz8C1gBnBCVV05yNySJEmSJKlbBlrAqKrDx2g+fgP9/w74uzHazwbOnsRokiRJkiRphLS9C4kkSZIkSdJGWcCQJEmSJEmdZwFDkiRJkiR1ngUMSZIkSZLUeRYwJEmSJElS51nAkCRJkiRJnWcBQ5IkSZIkdZ4FDEmSJEmS1HkWMCRJkiRJUudZwJAkSZIkSZ1nAUOSJEmSJHWeBQxJkiRJktR5FjAkSZIkSVLnWcCQJEmdl2Rm3/G2SeYn2bnNTJIkabgsYEiSpE5L8hrg5iT/keQQ4HLgg8BlSQ5vNZwkSRqamRvvIkmS1Kq/BJ4GbAdcBjyrqn6aZDfgXOCUNsNJkqThsIAhSZK6bnVV3QrcmuTeqvopQFXdnKTlaJIkaVgsYEiSpK67Psk/0BuB8eMkHwHOAJ4P3NRqMkmSNDQDXQMjyQlJbklyRV/bzknOTXJN83Onpj1JPplkeZLLkzy7754jm/7XJDlykJklSVLn/A/gbmAF8GLg/wFHA48HXtNeLEmSNEyDXsTzRODgtdreDZxXVXsB5zXnAIcAezWfRcBx0Ct4AMcAvwPsBxyzpughSZKmvqq6u6r+oao+UFX3VtXpVfWiqnpTVf16BEaST7WZU5IkDdZACxhV9R3g9rWaFwInNccnAS/paz+5epYAOybZHXghcG5V3V5Vd9BbrGvtoogkSdL+YzUm2THJaUl+nOTqJL+7vhGhkiSpu9rYRnW3Nb8taX4+vmmfDdzQ129F07a+9nUkWZRkaZKlK1eunPTgkiRpJH0C+GZV/SawD3A16x8RKkmSOqqNAsb6jLWMeG2gfd3GqsVVNb+q5s+aNWtSw0mSpNGTZHvg94HjAarqV1V1J+sfESpJkjqqjV1Ibk6ye1Xd1EwRuaVpXwHs0ddvDnBj0/7ctdovHEJODdExX/7ewJ7x/leNOaJYkjT1jPVLjycBK4EvJNkHWAa8lbVGhCZ5/Bj3kmQRvbW5mDt37kBCS5Kk8WljBMZZwJqdRI4Ezuxrf3WzG8kC4K7mxeJbwEFJdmrmpx7UtEmSJPX7xBhtM4FnA8dV1bOA+5jAdBFHd0qS1B3jGoGRZC5wd1XdmWQeMB/4cVVdsZH7TqE3emLXJCvo7SbyAeArSY4Crgde0XQ/GzgUWA78EngtQFXdnuRvgYubfn9TVWsvDCpJkqa4JBcwxjTSqjqg+XniGLetAFZU1UXN+Wn0ChjrGxEqSZI6aqMFjCTvBl4PPJjkw8A7gO8B709yfFV9dH33VtXh67l04Bh9C3jTep5zAnDCxrJKkqQp7R19x1sDLwNWbeiGqvrPJDckeVpV/YTeO8hVzedIer9Y6R8RKkmSOmo8IzCOAJ4BPA64DnhSVa1Msg1wEbDeAoYkSdJkqaplazV9L8m/jePWtwBfTPIY4Fp6ozy3YOwRoZIkqaPGU8BYXVX3J/kVcD9wG0BV3ZeMtVaWJEnS5Euyc9/pFsC+wG9s7L6qupTe9Ne1rTMiVJIkddd4ChiXJPkSsA29fdJPSvJN4AB6wy8lSZKGYRmPbLG+CvgZcFSriSRJ0tCMp4DxZ/SGVRa9ha/2A/4Y+AnwT4OLJkmS9Iiq2rPtDJIkqT0bLWBU1SrglL6m/9d8HiXJ6VX1sknMJkmS9GtJtgTeCPx+03Qh8Nmqeqi1UJIkaWjGtY3qOD1pEp8lSZK0tuOALYHPNOdHNG1/1loiSZI0NJNZwFhnX3ZJkqRJ9Jyq2qfv/Pwkl7WWRpIkDdUWbQeQJEkap9VJnrzmJMmTgNUt5pEkSUM0mSMw3FNVkiQN0juBC5JcS++944nAa9uNJEmShmUyCxjvmsRnSZIkPUpVnZdkL+Bp9AoYP66qB1uOJUmShmTcBYwkP2OMdS6q6knNz3MmMZckSdKjJJkBvBCYR+8d5sAkVNVHWw0mSZKGYiIjMOb3HW8NvALYeXLjSJIkrdfXgAeAHwEPt5xFkiQN2bgLGFV121pNH0/yXeB/TW4kSZKkMc2pqt9uO4QkSWrHRKaQPLvvdAt6IzK2m/REkiRJY/tGkoOctipJ0vQ0kSkkH+k7XgVcB7xyUtNIkiSt3xLgq0m2AB6it5BnVdX27caSJEnDMJEpJM8bZBBJkqSN+Ajwu8CPqmqdhcUlSdLUtsV4OybZIclHkyxtPh9JssMgw0mSJPW5BrjC4oUkSdPTRKaQnABcwSPTRo4AvgC8dLJDSZIkjeEm4MIk3wAeXNPoNqqSJE0PEylgPLmqXtZ3/v4kl27qFyf5n8CfAUVvO7TXArsDp9LbnvUS4Iiq+lWSrYCTgX2B24BXVdV1m/rdkiRpJP2s+Tym+UiSpGlkIgWM+5P8XlV9FyDJ/sD9m/KlSWYDfwE8o6ruT/IV4DDgUOBjVXVqkn8GjgKOa37eUVVPSXIY8EHgVZvy3ZIkaTRV1fs3dD3Jp6rqLcPKI0mShmsiBYw3Aic1614EuB14zWZ+92OTPAQ8jt6w0AOAP26unwT8Nb0CxsLmGOA04NNJ4hxYSZLUZ/+2A6gbjvny9wb6nPe/yn/VJKkNE9mF5FJgnyTbN+d3b+qXVtUvknwYuJ7eKI5zgGXAnVW1qum2ApjdHM8GbmjuXZXkLmAX4Nb+5yZZBCwCmDt37qbGkyRJkiRJHTPuAkaSHYFXA/OAmUkAqKq/mOiXJtmJ3qiKPYE7gX8FDhmj65oRFtnAtUcaqhYDiwHmz5/v6AxJkiRJkqaIiUwhORtYQm/BzYc383ufD/ysqlYCJDkD+K/AjklmNqMw5gA3Nv1XAHsAK5LMBHagN4VFkiRpjbF+4SFJkqaIiRQwtq6qt0/S914PLEjyOHpTSA4ElgIXAC+ntxPJkcCZTf+zmvPvN9fPd/0LSZKmhyT/UlVHJHlrVX1iA103dE2SJI24LSbQ91+SvC7J7kl2XvPZlC+tqovoLcZ5Cb0RHVvQm/rxLuDtSZbTW+Pi+OaW44Fdmva3A+/elO+VJEkjad8kTwT+NMlO/e8h/e8iVXViexElSdKgTWQExq+ADwHv5ZH1Jwp40qZ8cVUdAxyzVvO1wH5j9H0AeMWmfI8kqRtW3X0zM7ffre0YGk3/DHyT3jvHMh49VWST30UkSdJomcgIjLcDT6mqeVW1Z/PxhUGStFEP/HwZN378BTxw/SVtR9EIqqpPVtXTgROq6kl97yG+i0iSNI1MpIBxJfDLQQWRJE1N9fAqbjvzfUBx+5nvpR5etdF7pLFU1RvbziBJktozkQLGauDSJJ9N8sk1n0EFkyRNDff84Es8fN9tAKy+9zbuufiUlhNp1CT57SRLktyQZHGzHfuaaz9oM5skSRqeiayB8X+aj7RRrzvunLYj/NpEs3zujQcNKIk0/ay+91buuuDT1EP3A1AP3c9d53+KbX7rEGZsu2vL6TRCPgP8Nb3t3P8M+G6SF1fVT4Et2wwmSZKGZ9wFjKo6aUPXk5xeVS/b/EiSpKnivivOpmr1o9qqVnPfFd9g+wVHtJRKI2jbqvpmc/zhJMuAbyY5gkcWFpckSVPcRKaQbIyLaEmSHmWbvQ8lmfGotmQG2+x9SEuJNKKSZIc1J1V1AfAy4F+AJ7aWSpIkDdVkFjD8DYgk6VFmbLsrOzzvzWTLxwKQLR/LDge8xekjmqgPAk/vb6iqy4EDgTNaSSRJkoZuMgsYkiStY7v9/pgZ2+4C9Aoa2z3n8JYTadRU1ZeqakmSV6zVfj3QnUWXJEnSQE1mASOT+CxJ0hSRLWbyhLd8Awg7LzyWbDGR9aOlRzl6nG2SJGkKGvdbZJJtgPur6uHmfAtg66r6ZdPlXQPIJ0maIp7wtnOZuf1ubcfQCEpyCHAoMHutLdy3B1a1k0qSJA3bREZgnAc8ru/8ccC315xUlUM4JUnrZfFCm+FGYCnwALCs73MW8MIWc0mSpCGayDjeravq3jUnVXVvksdt6AZJkqTNVVWXAZcl+VJVPbS+fhva0j297XCWAr+oqhcl2RM4FdgZuAQ4oqp+NYD4kiRpkkxkBMZ9SZ695iTJvsD9kx9JkiRpXRsqXjQ2tKX7W4Gr+84/CHysqvYC7gCO2sx4kiRpwCZSwHgb8K9J/j3JvwNfBt48mFiSJEkTNuaW7knmAH8IfL45D3AAcFrT5STgJcMIKEmSNt24p5BU1cVJfhN4Gr0dR348jt+ESJLEqjtvBGDmjk9oOYmmqY8DfwVs15zvAtxZVWsWAF0BzB7rxiSLgEUAc+fOHXBMSZK0IRsdgZHkgObnS4E/Ap4K7AX8UdMmSZLUBets6Z7kRcAtVbVsQ/1Yz+iNqlpcVfOrav6sWbMmKaYkSdoU4xmB8QfA+fSKF2sr4IxJTSRJkrRpxtrSfX/gxUkOBbamt/Xqx4Edk8xsRmHMobfTiSRJ6rCNFjCq6pjm52s31C/JkVV10mQFkyRJ6pfkR6w7UuIueruLHDvWlu5VdTRwdHP/c4F3VNWfJPlX4OX0diI5EjhzgNElSdIkmMginhvz1ol0TrJjktOS/DjJ1Ul+N8nOSc5Nck3zc6emb5J8MsnyJJf374YiSZKmjW8A/xf4k+bzNeA7wH8CJ07wWe8C3p5kOb01MY6fvJiSJGkQxr2I5ziMNZ90Qz4BfLOqXp7kMcDjgPcA51XVB5K8G3g3vReMQ+itu7EX8DvAcc1PSZI0fexfVfv3nf8oyfeqav8k/2NjN1fVhcCFzfG1wH4DSSlJkgZiMkdgjLn41ViSbA/8Ps1vO6rqV1V1J7CQ3lZm8OgtzRYCJ1fPEnrzVneftOSSJGkUbJvk17/ASLIfsG1zumrsWyRJ0lTR1giMJwErgS8k2QdYRm8Kym5VdRNAVd2U5PFN/9nADX33r9nu7KbNTi1JkkbFnwEnJNmW3nvH3cBRSbYB/qHVZJIkaeAms4DxvQl+77OBt1TVRUk+QW+6yPqMa7sz92qXJGnqqqqLgf+SZAcgzejNNb7SUixJkjQk455CkuTvk+zYd75TkmPXnFfVmyfwvSuAFVV1UXN+Gr2Cxs1rpoY0P2/p679H3/1jbnfmXu2SJE1dSXZI8lHgPODbST7SFDMkSdI0MJE1MA7p/01HVd0BHLopX1pV/wnckORpTdOBwFXAWfS2MoNHb2l2FvDqZjeSBcBda6aaSJKkaeME4B7glc3nbuALrSaSJElDM5EpJDOSbFVVDwIkeSyw1WZ891uALzY7kFwLvJZeQeUrSY4Crgde0fQ9m16xZDnwy6avJEmaXp5cVS/rO39/kktbSyNJkoZqIgWM/w2cl+QL9Naf+FMe2TFkwqrqUmD+GJcOHKNvAW/a1O+SJElTwv1Jfq+qvguQZH/g/pYzSZKkIRl3AaOq/jHJ5cDzm6a/rapvDSaWJEnSOt4AnNy37sUdPDL1VJIkTXET3YXkh8CW9EZg/HDy40iSJI2tqi4D9kmyfXN+d//1JEdW1SaPDpUkSd02kV1IXgn8AHg5vYWzLkry8kEFkyRJGktV3b128aLx1qGHkSRJQzORERjvBZ5TVbcAJJkFfJveFqiSJEltS9sBJEnS4EykgLHFmuJF4zYmtg2rJGkaeuC6i399PHPHJ7SYRNNAtR1AkiQNzkQKGN9M8i3glOb8VfS2N9UIetHfn9F2hM4a9D+br7/npQN9viRNY47AkCRpCpvILiTvTPIyYH96LwiLq+qrA0smSZI0Md9rO4AkSRqcCe1CUlWnA6cPKIskSdJ6Jfl74B+r6s7mfCfgL6vqfQBV9eY280mSpMHa6BoWSe5JcvcYn3uSjLUCuCRJ0iAcsqZ4AVBVdwCHtphHkiQN0UZHYFTVdsMIIkmStBEzkmxVVQ8CJHkssFXLmSRJ0pBMaAqJJElSi/43cF6SL9DbceRPgZPajSRJkobFAoYkSRoJVfWPSS4Hnt80/W1VfavNTJKkdqy680a3Z5+GLGBIkqRR8kNgS3ojMH7YchZJkjREFjAkSdJISPJK4EPAhfS2dP9UkndW1WmtBtPAve64c9qO8CgTzfO5Nx40oCSSNL1YwJAkSaPivcBzquoWgCSzgG8DFjAkSZoGNrqNqiRJUkdssaZ40bgN32UkSZo2HIEhSZJGxTeTfAs4pTl/FXB2i3kkSdIQWcCQJA3MfZedOeb5NvssbCOORlxVvTPJy4D96a2BsbiqvtpyLEmSNCQWMCRJ0sioqtOB09vOIUmShq/VeaNJZiT5YZKvN+d7JrkoyTVJvpzkMU37Vs358ub6vDZzS5Kk4UlyT5K7x/jck+TutvNJkqThaHvhq7cCV/edfxD4WFXtBdwBHNW0HwXcUVVPAT7W9JMkSdNAVW1XVduP8dmuqrZvO58kSRqO1goYSeYAfwh8vjkPcACPbIV2EvCS5nhhc05z/cCmvyRJkiRJmgbaHIHxceCvgIeb812AO6tqVXO+ApjdHM8GbgBort/V9H+UJIuSLE2ydOXKlYPMLkmSJEmShqiVAkaSFwG3VNWy/uYxutY4rj3SULW4quZX1fxZs2ZNQlJJkiRJktQFbe1Csj/w4iSHAlsD29MbkbFjkpnNKIs5wI1N/xXAHsCKJDOBHYDbhx9bkiRJkiS1oZURGFV1dFXNqap5wGHA+VX1J8AFwMubbkcCZzbHZzXnNNfPr6p1RmBIkiRJkqSpqe1dSNb2LuDtSZbTW+Pi+Kb9eGCXpv3twLtbyidJkiRJklrQ1hSSX6uqC4ELm+Nrgf3G6PMA8IqhBpMkSZIkSZ3RtREYkiRJkybJHkkuSHJ1kiuTvLVp3znJuUmuaX7u1HZWSZK0YRYwJEnSVLYK+MuqejqwAHhTkmfQm456XlXtBZyH01MlaWQ8cN3FrLrzFzxw3cVtR9GQWcCQJElTVlXdVFWXNMf3AFcDs4GFwElNt5OAl7STUJIkjVfra2CMqn3feXLbETSiRv3fnWUfenXbESRpkySZBzwLuAjYrapugl6RI8njW4wmSZLGwQKGJGlS3fVvn5lQnx3+4M8HGUcCIMm2wOnA26rq7iTjvW8RsAhg7ty5gwsoSZI2yikkkiRpSkuyJb3ixRer6oym+eYkuzfXdwduGeveqlpcVfOrav6sWbOGE1iSJI3JAoYkSZqy0htqcTxwdVV9tO/SWcCRzfGRwJnDziZJkibGKSSSJGkq2x84AvhRkkubtvcAHwC+kuQo4HrgFS3lkyRJ42QBQ5IkTVlV9V1gfQteHDjMLJIkafM4hUSSJEmSJHWeBQxJkiRJktR5FjAkSZIkSVLnuQaGJEmSJKnz7rts3Q2j7rvsTLbZZ2ELadQGR2BIkiRJkqTOcwSGJGmT3Hbm+wb6nF0WHjspz5ckSdLUYAFDkiRJm+VFf39G2xE6bdD/fL7+npcO9PmS1BVOIZEkSZIkSZ1nAUOSJEmSJHVeKwWMJHskuSDJ1UmuTPLWpn3nJOcmuab5uVPTniSfTLI8yeVJnt1GbkmSJEmS1I62RmCsAv6yqp4OLADelOQZwLuB86pqL+C85hzgEGCv5rMIOG74kSVJkiRJUltaKWBU1U1VdUlzfA9wNTAbWAic1HQ7CXhJc7wQOLl6lgA7Jtl9yLElSZIkSVJLWl8DI8k84FnARcBuVXUT9IocwOObbrOBG/puW9G0rf2sRUmWJlm6cuXKQcaWJEmSJElD1GoBI8m2wOnA26rq7g11HaOt1mmoWlxV86tq/qxZsyYrpiRJkiRJallrBYwkW9IrXnyxqtZsjn3zmqkhzc9bmvYVwB59t88BbhxWVkmSJEmS1K62diEJcDxwdVV9tO/SWcCRzfGRwJl97a9udiNZANy1ZqqJJEmSJEma+ma29L37A0cAP0pyadP2HuADwFeSHAVcD7yiuXY2cCiwHPgl8Nrhxn20JUuW8NAvrmozgtSaJUuWsGDBgrZjSJIkSZpmWilgVNV3GXtdC4ADx+hfwJsGGkqSJEmSJHVWWyMwRtqCBQvY8vT/aDuG1ApHX0xdN5/U6uC2dUw0z25HfmFASSRJktQFrW+jKkmSJEmStDGOwJAkSZIkddJd//aZCfXZ4Q/+fJBx1DJHYEiSJEmSpM6zgCFJkiRJkjrPAoYkSZIkSeo8CxiSJEmSJKnzLGBIkiRJkqTOcxcSSRoRN37ihW1H6LRB/vN5wlu/NbBnS5IkaXwsYEiSJHXAvu88ue0IGlGj/O/Osg+9uu0IkkaIU0gkSZIkSVLnWcCQJEmSJEmd5xSSTTTqw91e9PdntB1h2vr6e17adgRJkiRJGjkWMCRJkiRJrbrtzPcN9Dm7LDx2Up6vdjmFRJIkSZIkdZ4FDEmSJEmS1HlOIZE0bVz/N/+l7QgaUaP+787c//WjtiNIkiRtNgsY09SgF5J83XHnDPT5g/S5Nx7UdgRJkiRJ0lpGqoCR5GDgE8AM4PNV9YGWI0mSpBHle4UkDdbNJ7227Qi/NtEsux35hQEl0eYYmQJGkj5WBlMAACAASURBVBnAPwEvAFYAFyc5q6quajeZJEkaNV17r1iyZAkP/cJXGk0/S5YsYcGCBW3HkDQiRqaAAewHLK+qawGSnAosBPxf+w6a6DSMY778vQElgfe/av+BPVujY8mSJfzHdavbjiG14qn+Pwhj8b1C0mZZsmQJt99+e9sxOu3Oq25tO8Im2/Hss9uO0Gk777xzK+8Wo1TAmA3c0He+Avid/g5JFgGLAObOnTu8ZNpsFhk0DLu+/MNtR5DUHRt9r4DhvVssWLCAyy0ySZpidvyDN7YdQVPMKBUwMkZbPeqkajGwGGD+/Pk1Rn9J05S/fZa0lo2+V4DvFpLWz3cLafi2aDvABKwA9ug7nwPc2FIWSZI02nyvkCRpxIxSAeNiYK8keyZ5DHAYcFbLmSRJ0mjyvUKSpBEzMlNIqmpVkjcD36K33dkJVXVly7EkSdII8r1CkqTRMzIFDICqOhtwOVhJkrTZfK+QJGm0jNIUEkmSJEmSNE1ZwJAkSZIkSZ1nAUOSJEmSJHWeBQxJkiRJktR5FjAkSZIkSVLnparazjAQSVYCP287hwZmV+DWtkNImhD/3k5dT6yqWW2HGDTfLaY0//skjR7/3k5d632vmLIFDE1tSZZW1fy2c0gaP//eSuoq//skjR7/3k5PTiGRJEmSJEmdZwFDkiRJkiR1ngUMjarFbQeQNGH+vZXUVf73SRo9/r2dhlwDQ5IkSZIkdZ4jMCRJkiRJUudZwNBISXJwkp8kWZ7k3W3nkbRxSU5IckuSK9rOIklr891CGi2+V0xvFjA0MpLMAP4JOAR4BnB4kme0m0rSOJwIHNx2CElam+8W0kg6Ed8rpi0LGBol+wHLq+raqvoVcCqwsOVMkjaiqr4D3N52Dkkag+8W0ojxvWJ6s4ChUTIbuKHvfEXTJkmStCl8t5CkEWIBQ6MkY7S5jY4kSdpUvltI0gixgKFRsgLYo+98DnBjS1kkSdLo891CkkaIBQyNkouBvZLsmeQxwGHAWS1nkiRJo8t3C0kaIRYwNDKqahXwZuBbwNXAV6rqynZTSdqYJKcA3weelmRFkqPaziRJ4LuFNIp8r5jeUuU0P0mSJEmS1G2OwJAkSZIkSZ1nAUOSJEmSJHWeBQxJkiRJktR5FjAkSZIkSVLnWcCQJEmSJEmdZwFD0kAk+Y0kpyb5aZKrkpydZFGSr7edTZIkjR7fLSRZwJA06ZIE+CpwYVU9uaqeAbwH2G0znztzMvJJkqTR4ruFJLCAIWkwngc8VFX/vKahqi4F/h3YNslpSX6c5IvNCwlJrkuya3M8P8mFzfFfJ1mc5Bzg5CSvSXJGkm8muSbJPw79TydJkobNdwtJWHGUNAh7A8vWc+1ZwG8BNwLfA/YHvruR5+0L/F5V3Z/kNcAzm+c8CPwkyaeq6obJCC5JkjrJdwtJjsCQNHQ/qKoVVfUwcCkwbxz3nFVV9/edn1dVd1XVA8BVwBMHkFOSJI0G3y2kacIChqRBuJLebzbG8mDf8WoeGQm2ikf+m7T1WvfcN85nSJKkqcl3C0kWMCQNxPnAVklet6YhyXOAP9jAPdfxyIvJywYXTZIkjSDfLSRZwJA0+aqqgP8OvKDZ6uxK4K/pzU1dn/cDn0jy7/R+8yFJkgT4biGpJ73/FkiSJEmSJHWXIzAkSZIkSVLnWcCQJEmSJEmdZwFDkiRJkiR1ngUMSZIkSZLUeRYwJEmSJElS51nAkCRJkiRJnWcBQ5IkSZIkdZ4FDEmSJEmS1HkWMCRJkiRJUudZwJAkSZIkSZ1nAUOSJEmSJHWeBQxJkiRJktR5M9sOMCi77rprzZs3r+0YkiRNecuWLbu1qma1nWPQfLeQJGnwNvReMWULGPPmzWPp0qVtx5AkacpL8vO2MwyD7xaSJA3eht4rnEIiSZIkSZI6zwKGJEmSJEnqPAsYkiRJkiSp8yxgSJIkSZKkzrOAIUmSJEmSOs8ChiRJkiRJ6jwLGJIkSZIkqfMsYEiSJEmSpM6b2XYAaby+tvSn67T90fwnt5BEEsBtZ75voM/fZeGxA32+pOltrPcK8N1CkrrMERiSJEmSJKnzLGBIkiRJkqTOs4AhSZIkSZI6zwKGJEmSJEnqPAsYkiRJkiSp8yxgSJIkSZKkzrOAIUmSJEmSOs8ChiRJkiRJ6jwLGJIkSZIkqfMsYEiSJEmSpM6zgCFJkkZGkhOS3JLkir62Lye5tPlcl+TSpn1ekvv7rv1z3z37JvlRkuVJPpkkbfx5JEmbZtXdN7cdQS2wgCFJkkbJicDB/Q1V9aqqemZVPRM4HTij7/JP11yrqjf0tR8HLAL2aj6PeqYkqbse+Pkybvz4C3jg+kvajqIhs4AhSZJGRlV9B7h9rGvNKIpXAqds6BlJdge2r6rvV1UBJwMvmeyskqTJVw+v4rYz3wcUt5/5XurhVW1H0hBZwJAkSVPFfwNurqpr+tr2TPLDJP+W5L81bbOBFX19VjRt60iyKMnSJEtXrlw5mNSSpHG75wdf4uH7bgNg9b23cc/FG6xZa4qxgCFJkqaKw3n06IubgLlV9Szg7cCXkmwPjLXeRY31wKpaXFXzq2r+rFmzJj2wJGn8Vt97K3dd8GnqofsBqIfu567zP8Xqe29tOZmGxQKGJEkaeUlmAi8FvrymraoerKrbmuNlwE+Bp9IbcTGn7/Y5wI3DSytJ2hT3XXE2Vasf1Va1mvuu+EZLiTRsM9sOIEnqhptPem3bER5lonl2O/ILA0qiEfF84MdV9eupIUlmAbdX1eokT6K3WOe1VXV7knuSLAAuAl4NfKqV1JKkcdtm70N7IzD62pIZbLP3Ia1l0nA5AkOSJI2MJKcA3weelmRFkqOaS4ex7uKdvw9cnuQy4DTgDVW1ZgHQNwKfB5bTG5nhr+8kqeNmbLsrOzzvzWTLxwKQLR/LDge8hRnb7tpyMg2LIzAkSdLIqKrD19P+mjHaTqe3repY/ZcCe09qOEnSwG233x9z78WnsOqOFczYdle2e86Y/7OgKcoRGJIkSZKkkZAtZrLzi48Fws4LjyVb+Dv56cT/a0uSJEmSRsbWT9yXJ7ztXGZuv1vbUTRkjsCQJEmSJI0UixfTkwUMSZIkSZLUeRYwJEmSJElS57VawEgyI8kPk3y9Od8zyUVJrkny5SSPadq3as6XN9fntZlbkiRJkiQNV9sjMN4KXN13/kHgY1W1F3AHsGZv96OAO6rqKcDHmn6SJEmSJGmaaK2AkWQO8IfA55vzAAcApzVdTgJe0hwvbM5prh/Y9JckSZIkSdNAmyMwPg78FfBwc74LcGdVrWrOVwCzm+PZwA0AzfW7mv6PkmRRkqVJlq5cuXKQ2SVJkiRJ0hC1UsBI8iLglqpa1t88Rtcax7VHGqoWV9X8qpo/a9asSUgqSZIkSZK6YGZL37s/8OIkhwJbA9vTG5GxY5KZzSiLOcCNTf8VwB7AiiQzgR2A24cfW5IkSZIktaGVAkZVHQ0cDZDkucA7qupPkvwr8HLgVOBI4MzmlrOa8+8318+vqnVGYEiSJEnr89lzLptQn9cftM8g40iSJqjtXUjW9i7g7UmW01vj4vim/Xhgl6b97cC7W8onSZIkSZJa0NYUkl+rqguBC5vja4H9xujzAPCKoQaTJEmSJEmd0bURGJIkSZIkSeuwgCFJkiRJkjrPAoYkSZIkSeo8CxiSJEmSJKnzLGBIkqSRkeSEJLckuaKv7a+T/CLJpc3n0L5rRydZnuQnSV7Y135w07Y8ibubSZI0AixgSJKkUXIicPAY7R+rqmc2n7MBkjwDOAz4reaezySZkWQG8E/AIcAzgMObvpIkqcNa30ZVkiRpvKrqO0nmjbP7QuDUqnoQ+FmS5TyyXfvyZvt2kpza9L1qkuNKkqRJ5AgMSZI0Fbw5yeXNFJOdmrbZwA19fVY0betrX0eSRUmWJlm6cuXKQeSWJEnjZAFDkiSNuuOAJwPPBG4CPtK0Z4y+tYH2dRurFlfV/KqaP2vWrMnIKkmSNpFTSCRJ0kirqpvXHCf5HPD15nQFsEdf1znAjc3x+tolSVJHOQJDkiSNtCS7953+d2DNDiVnAYcl2SrJnsBewA+Ai4G9kuyZ5DH0Fvo8a5iZJUnSxDkCQ5IkjYwkpwDPBXZNsgI4BnhukmfSmwZyHfB6gKq6MslX6C3OuQp4U1Wtbp7zZuBbwAzghKq6csh/FEmSNEEWMCRJ0sioqsPHaD5+A/3/Dvi7MdrPBs6exGiSJGnAnEIiSZIkSZI6zwKGJEmSJEnqPAsYkiRJkiSp8yxgSJIkSZKkzrOAIUmSJEmSOs8ChiRJkiRJ6jwLGJIkSZIkqfMsYEiSJEmSpM6zgCFJkiRJkjrPAoYkSZIkSeo8CxiSJEmSJKnzLGBIkiRJkqTOs4AhSZIkSZI6zwKGJEmSJEnqPAsYkiRJkiSp8yxgSJIkSZKkzrOAIUmSJEmSOs8ChiRJkiRJ6rxNLmAkeVKSE5Icm2TbJJ9LckWSf00yb/IiSpIk9TTvHrckuaKv7UNJfpzk8iRfTbJj0z4vyf1JLm0+/9x3z75JfpRkeZJPJkkbfx5JkjR+mzMC40TgYuBeYAnwY+AQ4JvACZudTJIkaV0nAgev1XYusHdV/TbwH8DRfdd+WlXPbD5v6Gs/DlgE7NV81n6mJEnqmM0pYGxXVcdV1QeA7avqI1V1Q1UdD+w0SfkkSZJ+raq+A9y+Vts5VbWqOV0CzNnQM5LsTu/d5ftVVcDJwEsGkVeSJE2emZtx78NJngrsADwuyfyqWprkKcCMyYmn6e6z51w27uuvP2ifQceRJHXfnwJf7jvfM8kPgbuB91XVvwOzgRV9fVY0betIsojeSA3mzp07kMCSJGl8NqeA8VfA14CH6f3W4ugk+wDbA6/b0I1Jtga+A2zVZDitqo5JsidwKrAzcAlwRFX9KslW9H47si9wG/CqqrpuM7JLkqQpJsl7gVXAF5umm4C5VXVbkn2B/5Pkt4Cx1ruosZ5ZVYuBxQDz588fs48kSRqOTZ5CUlXnVdXTqurpVfXdqnoZsADYvarOXNMvyQvGuP1B4ICq2gd4JnBwkgXAB4GPVdVewB3AUU3/o4A7quopwMeafpIkSQAkORJ4EfAnzbQQqurBqrqtOV4G/BR4Kr0RF/3TTOYANw43sSRJmqhJ3Ua1qm6tqtVrNa9TbKiee5vTLZtPAQcApzXtJ/HIfNSFzTnN9QNdLVySJAEkORh4F/DiqvplX/usJDOa4yfRW6zz2qq6CbgnyYLmfeLVwJljPFqSJHXIpBYw1mPMQkOSGUkuBW6ht3r4T4E7+xbh6p+POhu4AaC5fhewyxjPXJRkaZKlK1eunNw/hSRJal2SU4DvA09LsiLJUcCnge2Ac9faLvX3gcuTXEbvFyBvqKo1C4C+Efg8sJzeO8g3hvnnkCRJE7c5a2CM1/rmlK4Gntns1f5V4OkbuHdcc1WdpypJ0tRWVYeP0Xz8evqeDpy+nmtLgb0nMZokSRqwYYzA2KCquhO4kN76GTsmWVNU6Z+PugLYA6C5vgNrbaEmSZIkSZKmrmEUMK5bu6GZk7pjc/xY4PnA1cAFwMubbkfyyHzUs5pzmuvnr1mgS5IkSZIkTX2bPYUkyavHaq+qk5ufLx3j8u7ASc3CWlsAX6mqrye5Cjg1ybHAD3lkSOjxwL8kWU5v5MVhm5tbkiS1J8mzx2i+C/h533pYkiRJvzYZa2A8p+94a+BA4BLg5PXdUFWXA88ao/1aYL8x2h8AXrHZSSVJUld8Bng2cDm9ta72bo53SfKGqjqnzXCSJKl7NruAUVVv6T9PsgPwL5v7XEmSNKVdBxxVVVcCJHkG8E7gb4EzAAsYkiTpUQaxBsYv6e2zLkmStD6/uaZ4AVBVVwHPakZjSpIkrWMy1sD4Go9saTqD3naoX9nc50qSpCntJ0mOA05tzl8F/EeSrYCH2oulqeCYL39voM95/6v2n5TnS5ImZjLWwPhw3/EqeotvrZiE50qSpKnrNcCfA2+jtwbGd4F30CtePK+9WJIkqasmYw2Mf0uyG48s5nnN5j5TkiRNbVV1P/CR5rO2e4ccR5I0YlbdeSMzd3xC2zE0ZJu9BkaSVwI/oLdLyCuBi5K8fHOfK0mSpp4kv5nkG0n+b5InJzkxyR1JfpDk6W3nkyRJ3TUZU0jeCzynqm4BSDIL+DZw2iQ8W5IkTS2LgQ8B2wLnA+8CXgu8CPg0ve3YJUmS1jEZu5BssaZ40bhtkp4rSZKmnu2q6mtVdQrwUFWdWj1fA3ZqO5wkSequ/8/evYfbVdX3/n9/uCitcgtEyi2Ftuiv2AroLk0P/VWRIwh6jFpRaSsRqbEVFau1gMcj3ov1dtAqNQgYPFZFhUI5KEQKUi+xBkUuohKRQgxNoghSrQj4PX+suWUTdq577jXn2vv9ep71zDnHHHPM786THQbfNS5tjMD4bJJLgY81188DPtNCu5IkaebZesL5u9e597BhBiJJkkZLG4t4vibJHwOHMFhFfHFVXTDlyCRJ0kz0/iSPrKr/rKoPjBcm+S0GU1AlSZIm1cYIDKrq00mWjreXZE5V3dFG25Ikaeaoqg+up3wFgy1VAUhySlX97dACkyRJvdfGLiQvSbIauBZYDlzdHCVJkrbU0V0HIEmS+qWNERh/DTy2qn7QQluSJEkwmJYqSZL0S23sFvJd4KcttCNJkjSuug5AkiT1SxsjME4BvpTkK8A944VV9YoW2pYkSbOTIzAkSdKDtDEC44PAvwDLGKx/Mf6RJEnaUp+crDDJ2UnWJLl+QtmcJEuT3NQcd27Kk+S9SVYkuTbJ4yc8s7Cpf1OShdP/40iSpKlqI4FxX1W9qqrOqaol458W2pUkSTNUkiVJdppwvXOSs8evq+pt63n0w8BT1yk7Gbi8qvYDLm+uAY4E9ms+i4AzmnfNAU4Ffh84GDh1POkhSZL6q40ExhVJFiXZvfkGZE7TMZAkSVqfx1XVneMXVfUj4KCNPVRVVwHrbtW+ABj/8mQJ8MwJ5efWwDJgpyS7A0cAS6vqjua9S3loUkSSJPVMG2tg/ElzPGVCWQG/0ULbkqTGqtOP6DqEXpvOP589Trx02tqexbZKsnOTQBgfFbGl/ZLdqup2gKq6PcmjmvI9gdsm1FvZlK2v/CGSLGIweoN58+ZtYXiSJKkNU05gVNW+G7qf5ClVtXSq75EkSTPKuxgsAv6p5vpo4K0tv2OyhUBrA+UPLaxaDCwGGBsbc2cUSZI61MYUko15+xDeIUmSRkhVnQv8MbC6+Ty7qj6yhc2tbqaG0BzXNOUrgb0n1NsLWLWBckmS1GPDSGC4DZokSZrMdsDWDPoK202hnYuA8Z1EFgIXTig/ttmNZD5wVzPV5FLg8Gbh0J2Bw5sySZLUY8NIYDjcUpIkPUiS1zNYcHNnYFfgnCSv24TnPgZ8GXhMkpVJjgdOA56S5CbgKc01wCXAzcAK4EzgpQBVdQfwZuCrzedNTZkkSeqxNhbxlCRJ2lzHAAdV1c8AkpwGfA14y4Yeqqpj1nPrsEnqFnDCeto5Gzh7snuSJKmfhjEC45YhvEOSJI2WW3jwtJGHA9/tJhRJkjQKpjwCI8mzJym+C7iuqtZU1WT3JUnSLJTkfQyml94D3JBkaXP9FOALXcYmSZL6rY0pJMcDfwBc0Vw/CVgGPDrJm6aworgkSZp5ljfHq4ELJpRfOfxQJEnSKGkjgfEL4LerajVAkt2AM4DfB64CTGBIkiQAqmoJQJJnAZdU1T0dhyRJkkZEG2tg7DOevGisAR7drOZ9bwvtS5KkmecZwHeSfCTJ05K4sLgkaZP87Javct+d3+dnt3y161A0ZG10Fv41ycXAJ5vr5wBXJXkEcGcL7UuSpBmmqo5Lsi1wJPAnwAeSLK2qP+84NEmS1FNtJDBOAJ4N/CEQBnu6f7rZuuzQFtqXJEkzUFXdm+QzDBbx/BVgAWACQ5IkTWrKCYyqqiRfAH7OoAPyb03yQpIkaVJJngo8n8GXHVcCHwKe22VMkiSp36a8BkaS5wL/xmDqyHOBryR5zlTblSRJM9oLgX9isG7Wwqq6pKru6zgmSZLUY21MIfmfwO9V1RqAJHOBzwGfaqFtSZI0A1XV8zd0P8mXq+oPhhWPJEnqvzZ2IdlqPHnR+GFL7UqSpNlru64DkCRJ/dJGouGzSS5N8sIkLwT+L3DJhh5IsneSK5LcmOSGJCc25XOSLE1yU3PcuSlPkvcmWZHk2iSPbyFuSZLUX66nJUmSHmTKCYyqeg3wQeBxwAHA4qo6aSOP3Qe8uqp+G5gPnJBkf+Bk4PKq2g+4vLmGwRZr+zWfRcAZU41bkiRJkiSNjjbWwKCqzgfOn+zeZHNYq+p24Pbm/O4kNwJ7Mtg+7UlNtSUMViU/qSk/t9ndZFmSnZLs3rQjSZJmnnQdgCRJ6pdhrFWxwTmsSfYBDgK+Auw2npRojo9qqu0J3DbhsZVN2bptLUqyPMnytWvXTj1ySZLUlRd0HYAkSeqXYSQw1juHNckjgU8Dr6yqH2+gjcm+hXlIu1W1uKrGqmps7ty5mx+pJEkaiiR3J/nxOp/bklyQ5Deq6vquY5QkSf3SyhSSLZFkWwbJi482U1AAVo9PDUmyOzC+u8lKYO8Jj+8FrBpetJIkqWXvZvDf8n9k8EXF84FfA74NnM0DU0olSZKA4YzAeMjoiSQBzgJurKp3T7h1EbCwOV8IXDih/NhmN5L5wF2ufyFJ0kh7alV9sKrurqofV9Vi4Kiq+gSwc9fBSZKk/mktgZFkh2Yb1DlJ5ky4Ndkc1kOa8icnuab5HAWcBjwlyU3AU5prGGzLejOwAjgTeGlbcUuSpE78Islzk2zVfJ474d5mb6Ga5DET+hTXNFNSXpnkDUm+v05/Y/yZU5ot2r+d5IhWfipJkjRtpjyFJMlLgDcB/8UDHY4CfgNgsjmsVfUF1r+6+GGT1C/ghKnGKkmSeuNPgdOBDzDoNywD/izJrwAv29zGqurbwIEASbYGvg9cABwHvKeq3jmxfrN9+/OBxwJ7AJ9L8uiqun+LfyJJkjSt2lgD46+Bx1bVD1poS5IkzQJVdTPwP9Zz+wtTbP4w4LtV9e+DWauTWgB8vKruAb6XZAVwMPDlKb5bkiRNkzYSGN8FftpCO5IkaZZIcg6T7yj2ohaafz7wsQnXL0tyLLAceHVV/YjBduzLJtRZ7xbtwCKAefPmtRCatsSLz7is6xAeZHPjOfMvD5+mSKTZ5SffuHDSskccsKCDaNSFNhIYpwBfSvIV4J7xwqp6RQttS5KkmeniCefbAc+ihR3GkjwMeAaD/gnAGcCbGSRL3gy8C3gRm7FFO7AYYGxsbLPX5pAkSe1pI4HxQeBfgOuAX7TQnmahUz/xxWlr443PO2TKbUuS2lVVn554neRjwOdaaPpI4GtVtbp5z+oJ7ziTBxInbtEuSdKIaSOBcV9VvaqFdiRJ0uy1H9DGHI1jmDB9JMnuE7ZefxYwvrj4RcA/Jnk3g0U89wP+rYX3S5KkadJGAuOKZn7oP/PgKSR3tNC2JEmagZLczYN3L1sN/M0U2/xVBtuwv2RC8d8lObB5xy3j96rqhiTnAd8E7gNOcAcSSZL6rY0Exp80x1MmlP1yG1VJkqR1VdX2SeYwGPmw3XjxFNv8KbDLOmUv2ED9twJvnco7JUnS8Ew5gVFV+7YRiCRJmj2S/DlwIoO1J64B5jPYwvTJXcYlSZL6q40RGCT5HWB/HvgGhao6t422JUnSjHQi8HvAsqo6NMn/B7yx45gkSVKPTTmBkeRU4EkMEhiXMFj9+wuACQxJkrQ+P6uqnyUhycOr6ltJHtN1UJIkqb+2aqGN5wCHAf9RVccBBwAPb6FdSZI0c61MshPwT8DSJBfiNqaSJGkD2phC8l9V9Ysk9yXZAViDC3hKkqQNqKpnNadvSHIFsCPw2Q5DkiRJPddGAmN58w3KmcDVwH/iPuqSJGkTVdXnu45BkiT1Xxu7kLy0Of2HJJ8Fdqiqa6fariRJkiRJ0ri2diF5BvBHzeXnARMYkiRJkiSpNVNexDPJaQy2Qvtm83lFkr+daruSJEmSJEnj2hiBcRRwYFX9AiDJEuDrwCkttC1JkiRJktTKNqoAO00437GlNiVJkiRJkoApjsBIEuCdwNebLdDCYC0MR19IkiRJkqTWTCmBUVWV5ERgPvB7DBIYJ1XVf7QRnCRJkiRJErSzBsYyYK+quqiFtiRJkiRJkh6ijQTGocBLkvw78BMGozCqqh7XQtuSJEmSJEmtJDCObKENSZIkSZKk9ZpyAqOq/r2NQCRJkiRJktanrW1UJUmSJEmSpo0JDEmSNCMkuSXJdUmuSbK8KZuTZGmSm5rjzk15krw3yYok1yZ5fLfRS5KkjTGBIUmSZpJDq+rAqhprrk8GLq+q/YDLm2sYrOG1X/NZBJwx9EglSdJmMYEhSZJmsgXAkuZ8CfDMCeXn1sAyYKcku3cRoCRJ2jQmMCRJ0kxRwGVJrk6yqCnbrapuB2iOj2rK9wRum/DsyqbsQZIsSrI8yfK1a9dOY+iSJGlj2thGVZIkqQ8OqapVSR4FLE3yrQ3UzSRl9ZCCqsXAYoCxsbGH3JckScPjCAxJkjQjVNWq5rgGuAA4GFg9PjWkOa5pqq8E9p7w+F7AquFFK0mSNpcJDEmSNPKSPCLJ9uPnwOHA9cBFwMKm2kLgwub8IuDYZjeS+cBd41NNJElSPzmFRJIkzQS7ARckgUH/5h+r6rNJvgqcl+R44Fbg6Kb+JcBRwArgp8Bxww9ZkiRtDhMYkiRp5FXVzcABk5T/EDhskvICThhCaJIkqSVOIZEkSZIkSb3X2QiMJGcDTwfWVNXvNGVzgE8A+wC3AM+tqh9lMB70dAZDPX8KvLCqvtZF3JJG161v+t2uQ9CIGvW/O/Nef13XIUiSJE1ZlyMwD53JrwAAIABJREFUPgw8dZ2yk4HLq2o/4PLmGuBIYL/mswg4Y0gxSpIkSZKkHuhsBEZVXZVkn3WKFwBPas6XAFcCJzXl5zbzVZcl2SnJ7q4WLkmSJEkz112f/8Bm1dnxiS+dznDUsb6tgbHbeFKiOT6qKd8TuG1CvZVNmSRJkiRJmgX6lsBYn0xSVg+plCxKsjzJ8rVr1w4hLEmSJEmSNAx9S2CsTrI7QHNc05SvBPaeUG8vYNW6D1fV4qoaq6qxuXPnTnuwkiRJkiRpOPqWwLgIWNicLwQunFB+bAbmA3e5/oUkSZIkSbNHl9uofozBgp27JlkJnAqcBpyX5HjgVuDopvolDLZQXcFgG9Xjhh6wJEmSJvX0t53fdQi9Nt1/Phe/9tnT2r4k9UWXu5Acs55bh01St4ATpjciSZIkSZLUV32bQiJJkiRJkvQQJjAkSZIkSVLvdTaFRDPbi8+4rOsQfmlzYznzLw+fpkgkSZIkSVvKERiSJEmSJKn3TGBIkiRJkqTeM4EhSZIkSZJ6zwSGJEmSJEnqPRMYkiRJkiSp90xgSJKkkZdk7yRXJLkxyQ1JTmzK35Dk+0muaT5HTXjmlCQrknw7yRHdRS9JkjaF26hKkqSZ4D7g1VX1tSTbA1cnWdrce09VvXNi5ST7A88HHgvsAXwuyaOr6v6hRi1JkjaZIzAkSdLIq6rbq+przfndwI3Anht4ZAHw8aq6p6q+B6wADp7+SCVJ0pYygSFJkmaUJPsABwFfaYpeluTaJGcn2bkp2xO4bcJjK9lwwkOSJHXMBIYkSZoxkjwS+DTwyqr6MXAG8JvAgcDtwLvGq07yeE3S3qIky5MsX7t27TRFLUmSNoUJDEmSNCMk2ZZB8uKjVXU+QFWtrqr7q+oXwJk8ME1kJbD3hMf3Alat22ZVLa6qsaoamzt37vT+AJIkaYNMYEiSpJGXJMBZwI1V9e4J5btPqPYs4Prm/CLg+UkenmRfYD/g34YVryRJ2nzuQiJJkmaCQ4AXANcluaYpey1wTJIDGUwPuQV4CUBV3ZDkPOCbDHYwOcEdSCRJ6jcTGJIkaeRV1ReYfF2LSzbwzFuBt05bUJIkqVVOIZEkSZIkSb3nCAxJkiRJUqd+eOHrprWdXRa8pZX21S1HYEiSJEmSpN4zgSFJkiRJknrPBIYkSZIkSeo9ExiSJEmSJKn3XMRT0qywbNkyvnPL/V2HIXXi0cuWMX/+/K7DkCRJmhJHYEiSJEmSpN5zBIakWWH+/PnscdnWXYchdWKeoy8kSdIM4AgMSZIkSZLUeyYwJEmSJElS75nAkCRJkiRJvWcCQ5IkSZIk9Z4JDEmSJEmS1HvuQjJLPf1t53cdQm9N95/Nxa999rS2L0mSJEkzkSMwJEmSJElS75nAkCRJkiRJvWcCQ5IkSZIk9Z4JDEmSJEmS1HsjtYhnkqcCpwNbAx+qqtM6DknSCJn3+uu6DmFKVp1+RNchzFp7nHhp1yFoGvStX/GE15zb5es1wkb5787V7zi26xA0jVYvOa7rEH5pc2PZbeE50xSJpmJkRmAk2Rp4P3AksD9wTJL9u41KkiSNIvsVkiSNnlEagXEwsKKqbgZI8nFgAfDNYQeybNky7rjjjmG/tlV3f+/arkOYtS65ZLuuQ5iSOXPmMH/+/K7DmJWmexRAn74l2RJ+U6LN1Jt+BQz6Fvd+v5NXS51atmzZyPYrZsL/E0y3O7/5g65D2GI7XXJJ1yH0Wlf/TzBKCYw9gdsmXK8Efn9ihSSLgEUA8+bNG15kI+ikZx3cdQiSesYEgGaZjfYrYLh9i9P+7I+mtX1JGradnviXXYegGWaUEhiZpKwedFG1GFgMMDY2VpPUb8WoZoklSdIvbbRfAfYtJK2fv7fS8I3MGhgMvhnZe8L1XsCqjmKRJEmjzX6FJEkjZpQSGF8F9kuyb5KHAc8HLuo4JkmSNJrsV0iSNGJGZgpJVd2X5GXApQy2Ozu7qm7oOCxJkjSC7FdIkjR6RiaBAVBVlwAuBytJkqbMfoUkSaNllKaQSJIkSZKkWcoEhiRJkiRJ6j0TGJIkSZIkqfdMYEiSJEmSpN5LVXUdw7RIshb4967j0LTZFfhB10FI2iz+3s5cv15Vc7sOYrrZt5jR/PdJGj3+3s5c6+1XzNgEhma2JMuraqzrOCRtOn9vJfWV/z5Jo8ff29nJKSSSJEmSJKn3TGBIkiRJkqTeM4GhUbW46wAkbTZ/byX1lf8+SaPH39tZyDUwJEmSJElS7zkCQ5IkSZIk9Z4JDEmSJEmS1HsmMDRSkjw1ybeTrEhyctfxSNq4JGcnWZPk+q5jkaR12beQRov9itnNBIZGRpKtgfcDRwL7A8ck2b/bqCRtgg8DT+06CElal30LaSR9GPsVs5YJDI2Sg4EVVXVzVf0c+DiwoOOYJG1EVV0F3NF1HJI0CfsW0oixXzG7mcDQKNkTuG3C9cqmTJIkaUvYt5CkEWICQ6Mkk5S5D7AkSdpS9i0kaYSYwNAoWQnsPeF6L2BVR7FIkqTRZ99CkkaICQyNkq8C+yXZN8nDgOcDF3UckyRJGl32LSRphJjA0MioqvuAlwGXAjcC51XVDd1GJWljknwM+DLwmCQrkxzfdUySBPYtpFFkv2J2S5XT/CRJkiRJUr85AkOSJEmSJPWeCQxJkiRJktR7JjAkSZIkSVLvmcCQJEmSJEm9ZwJDkiRJkiT1ngkMSdMiya8l+XiS7yb5ZpJLkixKcnHXsUmSpNFj30KSCQxJrUsS4ALgyqr6zaraH3gtsNsU292mjfgkSdJosW8hCUxgSJoehwL3VtU/jBdU1TXAvwKPTPKpJN9K8tGmQ0KSW5Ls2pyPJbmyOX9DksVJLgPOTfLCJOcn+WySm5L83dB/OkmSNGz2LSRhxlHSdPgd4Or13DsIeCywCvgicAjwhY209wTgD6vqv5K8EDiwaece4NtJ3ldVt7URuCRJ6iX7FpIcgSFp6P6tqlZW1S+Aa4B9NuGZi6rqvyZcX15Vd1XVz4BvAr8+DXFKkqTRYN9CmiVMYEiaDjcw+GZjMvdMOL+fB0aC3ccD/yZtt84zP9nENiRJ0sxk30KSCQxJ0+JfgIcnefF4QZLfA564gWdu4YGOyR9PX2iSJGkE2beQZAJDUvuqqoBnAU9ptjq7AXgDg7mp6/NG4PQk/8rgmw9JkiTAvoWkgQz+LZAkSZIkSeovR2BIkiRJkqTeM4EhSZIkSZJ6zwSGJEmSJEnqPRMYkiRJkiSp90xgSJIkSZKk3jOBIUmSJEmSes8EhiRJkiRJ6j0TGJIkSZIkqfdMYEiSJEmSpN4zgSFJkiRJknrPBIYkSZIkSeq9bboOYLrsuuuutc8++3QdhiRJM97VV1/9g6qa23Uc082+hSRJ029D/YoZm8DYZ599WL58eddhSJI04yX5965jGAb7FpIkTb8N9SucQiJJkiRJknrPBIYkSZIkSeo9ExiSJEmSJKn3TGBIkiRJkqTeM4EhSZIkSZJ6zwSGJEmSJEnqPRMYkiRJkiSp90xgSJIkSZKk3tum6wCkTfXPy7/7kLL/MfabHUQiaVP95BsXTlr+iAMWDDkSSXqwyfoVYN9C6pu7Pv+Bzaq/4xNfOk2RqA8cgSFJkiRJknrPBIYkSZIkSeo9ExiSJEmSJKn3TGBIkiRJkqTeM4EhSZIkSZJ6z11I1GsfvOwbm3z/JYcfMN3hSJIkSZI64ggMSZIkSZLUeyYwJEmSJElS75nAkCRJkiRJvWcCQ5IkSZIk9Z4JDEmSJEmS1HsmMCRJkiRJUu+ZwJAkSZIkSb1nAkOSJEmSJPWeCQxJkiRJktR7JjAkSZIkSVLvmcCQJEmSJEm9t03XAUiSJEnD8MHLvrFZdV5y+AHTGY6kCX544eumtZ1dFryllfbVLUdgSJIkSZKk3jOBIUmSJEmSeq+zBEaSW5Jcl+SaJMubsjlJlia5qTnu3JQnyXuTrEhybZLHdxW3JEmSJEkavq5HYBxaVQdW1VhzfTJweVXtB1zeXAMcCezXfBYBZww9UkmSJEmS1JmuExjrWgAsac6XAM+cUH5uDSwDdkqyexcBSpIkSZKk4esygVHAZUmuTrKoKdutqm4HaI6Pasr3BG6b8OzKpuxBkixKsjzJ8rVr105j6JIkaRQk2TvJFUluTHJDkhOb8kmnrUqSpP7qMoFxSFU9nsH0kBOS/NEG6maSsnpIQdXiqhqrqrG5c+e2FackSRpd9wGvrqrfBuYz6HPsz/qnrUqSpJ7qLIFRVaua4xrgAuBgYPX41JDmuKapvhLYe8LjewGrhhetJEkaRVV1e1V9rTm/G7iRwSjO9U1blSRJPdVJAiPJI5JsP34OHA5cD1wELGyqLQQubM4vAo5tdiOZD9w1PtVEkiRpUyTZBzgI+Arrn7a67jNOT5UkqSe26ei9uwEXJBmP4R+r6rNJvgqcl+R44Fbg6Kb+JcBRwArgp8Bxww9ZkiSNqiSPBD4NvLKqftz0QTaqqhYDiwHGxsYeMn1VkiQNTycJjKq6GThgkvIfAodNUl7ACUMITZIkzTBJtmWQvPhoVZ3fFK9OsntV3b7OtFVJktRTfdtGVZIkqTUZDLU4C7ixqt494db6pq1KkqSe6moKiSRJ0jAcArwAuC7JNU3Za4HTmHzaqiRJ6ikTGJIkacaqqi8w+XbsMMm0VUmS1F9OIZEkSZIkSb1nAkOSJEmSJPWeCQxJkiRJktR7JjAkSZIkSVLvmcCQJEmSJEm9ZwJDkiRJkiT1ngkMSZIkSZLUeyYwJEmSJElS75nAkCRJkiRJvWcCQ5IkSZIk9Z4JDEmSJEmS1HsmMCRJkiRJUu+ZwJAkSZIkSb1nAkOSJEmSJPWeCQxJkiRJktR7JjAkSZIkSVLvmcCQJEmSJEm9ZwJDkiRJkiT1ngkMSZIkSZLUeyYwJEmSJElS75nAkCRJkiRJvWcCQ5IkSZIk9Z4JDEmSJEmS1HsmMCRJkiRJUu9tcQIjyZwkr0/y5xn4n0kuTvKOJDtvYhtbJ/l6koub632TfCXJTUk+keRhTfnDm+sVzf19tjRuSZIkSZI0eqYyAuP/AI8AngBcAfwa8Hbgv4APb2IbJwI3Trh+O/CeqtoP+BFwfFN+PPCjqvot4D1NPUmSJEmSNEtMJYGxR1WdBLwU2K+qXl5V/1pVrwd+fWMPJ9kLeBrwoeY6wJOBTzVVlgDPbM4XNNc09w9r6kuSJEmSpFlgKgmMrZqpInsDjxyf1pFkF+Bhm/D8/wb+BvhFc70LcGdV3ddcrwT2bM73BG4DaO7f1dR/kCSLkixPsnzt2rVb8jNJkiRJkqQemkoC42+BbwFfBV4EfCjJUuBaBsmJ9UrydGBNVV09sXiSqrUJ9x4oqFpcVWNVNTZ37txN+BEkSZIkSdIo2GZLH6yqjyU5D0hV3ZfkQuBA4PtVdft4vSSPraob1nn8EOAZSY4CtgN2YJD02CnJNs0oi72AVU39lQxGeqxMsg2wI3DHlsYuSZIkSZJGyxYnMACq6v4J5/cByyep9hHg8es8dwpwCkCSJwF/XVV/muSTwHOAjwMLgQubRy5qrr/c3P+XqnrICAxJkiTp1E98cVrbeePzDmmlfWmmW73kuK5D+KXNjWW3hedMUySaiqlMIdlUm7PY5knAq5KsYLDGxVlN+VnALk35q4CT2w1RkiRJkiT12ZRGYGyiDY6UqKorgSub85uBgyep8zPg6GmITZIkSZIkjYBhjMCQJEmSJEmakmEkMH4+hHdIkiRJkqQZbMoJjCSXb6isquZP9R2SJElbIsnZSdYkuX5C2RuSfD/JNc3nqC5jlCRJm2aL18BIsh3wq8CuSXbmgcU6dwD2aCE2SZKkqfow8PfAueuUv6eq3jn8cCRJ0paayiKeLwFeySBZcTUPJDB+DLx/inFJkiRNWVVdlWSfruOQJElTt8VTSKrq9KraF/jrqvqNqtq3+RxQVX/fYoySJElte1mSa5spJjt3HYwkSdq4NrZR/UCSZwD7TGyvqt7dQtuSJEltOwN4M4Ot3t8MvAt40WQVkywCFgHMmzdvWPFJkqRJtLELyT8DLwR2Abaf8JEkSeqdqlpdVfdX1S+AM4GDN1B3cVWNVdXY3LlzhxekJEl6iDZGYOxVVY9roR1JkqRpl2T3qrq9uXwWcP2G6kuSpH5oI4HxmSSHV9VlLbQlSZLUmiQfA57EYNe0lcCpwJOSHMhgCsktDBYmlyRJPddGAmMZcEGSrYB7GexGUlW1QwttS5IkbbGqOmaS4rOGHogkSZqyNhIY7wL+ALiuqqqF9iRJkiRJkh6kjQTGTcD1Ji80Fad+4ovT1sYbn3fIlNuWJEmSJHWrjQTG7cCVST4D3DNe6DaqkjQ73fX5D2xWnR2f+NLpDEczQJIx4B3A94FTgLMZ7BzyHWBRVX29w/AkSdKQtJHA+F7zeVjzkSRJatMHGCy+uRPwJeCvquopSQ5r7v1Bl8FJkqThmHICo6re2EYgkiRJ67FtVX0GIMnbq+pTAFV1eZJ3dhuaJEkaliknMJLMBf4GeCyw3Xh5VT15qm1LkiQBP0tyOLAjUEmeWVX/lOSJwP0dxyZJkoZkqxba+CjwLWBf4I0M9lP/agvtSpIkAfwF8GrgRcARwKFJ7mQwfeQVXQYmSZKGp40Exi5VdRZwb1V9vqpeBMxvoV1JkiSq6htVdURVHVlV36qqE6tqp6p6bFV9abxekoVdxilJkqZXGwmMe5vj7UmeluQgYK8W2pUkSdocJ3YdgCRJmj5t7ELyliQ7Mhja+T5gB+CvWmhXkiRpc6TrACRJ0vRpYxeSi5vTu4BD172f5JSq+tupvkeSJGkjqusAJEnS9GljCsnGHD2Ed0iSJDkCQ5KkGWwYCQw7E5IkacqSbL2RKl8cSiCSJKkTw0hgOJxTkiS1YUWSdyTZf7KbVfWyYQckSZKGxxEYkiRpVDwO+A7woSTLkixKskPXQUmSpOEYRgLjk0N4hyRJmuGq6u6qOrOq/hvwN8CpDLZxX5LktzoOT5IkTbMp70KSZC7wYmCfie1V1Yua49smeWY74Crg4c0zn6qqU5PsC3wcmAN8DXhBVf08ycOBc4EnAD8EnldVt0w1dkmSNDqaNTCeBhzHoN/xLuCjwP8PXAI8urPgJEnStJtyAgO4EPhX4HPA/Zv4zD3Ak6vqP5NsC3whyWeAVwHvqaqPJ/kH4HjgjOb4o6r6rSTPB94OPK+F2CVJ0ui4CbgCeEdVfWlC+aeS/FFHMUmSpCFpI4Hxq1V10uY8UFUF/GdzuW3zKeDJwJ805UuANzBIYCxozgE+Bfx9kjTtSJKk2eFxVfWfk92oqlcMOxhJkjRcbayBcXGSozb3oSRbJ7kGWAMsBb4L3FlV9zVVVgJ7Nud7ArcBNPfvAnaZpM1FSZYnWb527drN/0kkSVKfvT/JTuMXSXZOcnaXAUmSpOHZ4hEYSe5mMGoiwGuT3APc21xXVW1wVfCquh84sOmIXAD89mTVxl+3gXsT21wMLAYYGxtzdIYkSTPL46rqzvGLqvpRkoO6DEiSJA3PFicwqmr7NgKoqjuTXAnMB3ZKsk0zymIvYFVTbSWwN7AyyTbAjsAdbbxfkiSNjK2S7FxVPwJIMod2psOq5158xmVdh/AgmxvPmX95+DRFIkmzy5SnkCR5VpIdJ1zvlOSZG3lm7vgQ0CS/Avx34EYGC3M9p6m2kMECoQAXNdc09//F9S8kSZp13gV8Kcmbk7wZ+BLwdx3HJEmShqSNNTBOraq7xi+aoZ2nbuSZ3YErklwLfBVYWlUXAycBr0qygsEaF2c19c8CdmnKXwWc3ELckiRphFTVuQy+yFjNYA2tZ1fVR7qNSpIkDUsbwy4nS4JssN2quhZ4yJzVqroZOHiS8p8BR29pgJIkacb4FvAjmr5GknlVdWu3IUmSpGFoI4GxPMm7gfczWFjz5cDVLbQrSZL0S0lezmCU52rgfpqFw4HHdRmXJEkajjYSGC8H/hfwieb6MuB1LbQrSZI00YnAY6rqh10HIkmShm9KCYwkWwNvqKrXtBSPJEnS+twG3LXRWpIkaUaaUgKjqu5P8oS2gpEkSdqAm4Erk/xf4J7xwqp6d3chSZKkYWljCsnXk1wEfBL4yXhhVZ3fQtuSJEnjbm0+D2s+kiRpFmkjgTEH+CHw5AllBZjAkCRJramqNwIkeURV/WRj9SVJG7bq9CO6DqG3pvvPZo8TL53W9meqKScwquq4Dd1PckpV/e1U3yNJkma3JH8AnAU8EpiX5ADgJVX10m4jkyRJw7DVEN5x9BDeIUmSZr7/DRzBYOQnVfUN4I86jUiSJA3NMBIYGcI7JEnSLFBVt61TdH8ngUiSpKFrYw2MjakhvEOSJM18tyX5b0AleRjwCuDGjmOSJElD4ggMSZI0Kv4COAHYE1gJHNhcS5KkWWDKIzCSzKmqOzZQ5ZNTfYckSVJV/QD40815JsnZwNOBNVX1O03ZHOATwD7ALcBzq+pHrQYrSZJa18YUkq8kuQY4B/hMVT1oykhVva2Fd2jEvPiMy7oO4Zc2N5Yz//LwaYpEkjQVSZYAJ1bVnc31zsC7qupFG3jsw8DfA+dOKDsZuLyqTktycnN90vRELUmS2tLGFJJHA4uBFwArkrwtyaNbaFeSJGmix40nLwCaURMHbeiBqroKWHek6AJgSXO+BHhmm0FKkqTpMeURGM2Ii6XA0iSHAv8HeGmSbwAnV9WXp/oOSVL//PDC101rO7sseEsr7WtG2SrJzuPTPZqpIFvSl9mtqm4HqKrbkzxqfRWTLAIWAcybN28LXiVJktrSxhoYuwB/xmAExmrg5cBFDBbW+iSw71TfIUmSBLwL+FKSTzHY5ey5wFun84VVtZjBSFPGxsbcWU2SpA61sQbGl4GPAM+sqpUTypcn+YcW2pckSaKqzk2yHHgyg13Onl1V39yCplYn2b0ZfbE7sKbVQCVJ0rRoI4HxmHUX7hxXVW9voX1JkqRxc4CfVNU5SeYm2beqvreZbVwELAROa44Xth2kJElqXxsJjF2T/A3wWGC78cKqenILbUuSJAGQ5FRgDHgMg93PtmWw9tYhG3jmY8CTGPRXVgKnMkhcnJfkeOBW4OjpjVySJLWhjQTGRxnspf504C8YfJOxtoV2JUmSJnoWg11HvgZQVauSbL+hB6rqmPXcOqzl2CRJ0jRrYxvVXarqLODeqvp8sxf7/BbalSRJmujnzbTVAkjyiI7jkSRJQ9RGAuPe5nh7kqclOQjYq4V2JUmSJjovyQeBnZK8GPgc8KGOY5IkSUPSxhSStyTZEXg18D5gB+CvWmhXkiTpl6rqnUmeAvyYwToYr6+qpR2HJUmShmTKCYyqurg5vQs4dKrtSZIkrU+TsFgKkGTrJH9aVR/tOCxJkjQEW5zASPI+mjmok6mqV2xp25IkSeOS7ACcAOzJYAvUpc31a4BrGCwoLkmSZriprIGxHLiawdapjwduaj4HAvdPPTRJkiQAPsJgysh1wJ8DlzHY+nRBVS3oMjBJkjQ8WzwCo6qWACR5IXBoVd3bXP8Dg46FJElSG36jqn4XIMmHgB8A86rq7m7DkiRJw9TGLiR7ABP3YH9kU7ZeSfZOckWSG5PckOTEpnxOkqVJbmqOOzflSfLeJCuSXJvk8S3ELUmSRsP4jmdU1f3A90xeSJI0+7SxC8lpwNeTXNFcPxF4w0aeuQ94dVV9Lcn2wNVJlgIvBC6vqtOSnAycDJwEHAns13x+HzijOUqSpJnvgCQ/bs4D/EpzHaCqaofuQpMkScPSxi4k5yT5DA8kFE6uqv8Yv5/ksVV1wzrP3A7c3pzfneRGBgtzLQCe1FRbAlzJIIGxADi3qgpYlmSnJLs37UiSpBmsqrbuOgZJktS9NkZg0CQsLlzP7Y8wWORzUkn2AQ4CvgLsNp6UqKrbkzyqqbYncNuEx1Y2ZSYwJEmSJEmaBVpJYGxE1nsjeSTwaeCVVfXjZP1VJyl7yBauSRYBiwDmzZu3+ZHOIk9/2/ldh9Bb0/1nc/Frnz2t7UuSJEnSTNTGIp4b85BEA0CSbRkkLz5aVeP/x7g6ye7N/d2BNU35SmDvCY/vBax6yIuqFlfVWFWNzZ07t634JUmSJElSx4aRwHiIDIZanAXcWFXvnnDrImBhc76QB6alXAQc2+xGMh+4y/UvJEmSJEmaPYYxheTnk5QdArwAuC7JNU3ZaxnsaHJekuOBW4Gjm3uXAEcBK4CfAsdNa8SSJEmSJKlXppzASHJ5VR22vrKqmr/uM1X1Bda/NsZh6xY0u4+cMNVYJUmS1D7X1tow19eSpHZscQIjyXbArwK7JtmZBxISOwB7tBCbJEmSJEkSMLURGC8BXskgWXE1DyQwfgy8f4pxSZIkSZIk/dIWJzCq6nTg9CQvr6r3tRiTJEmSJEnSg7SxC8l/JNkeIMnrkpyf5PEttCtJkiRJkgS0k8D4X1V1d5I/BI4AlgBntNCuJEmSJEkS0M42qvc3x6cBZ1TVhUne0EK7kiRJktRbt77pd7sOQSNq1P/uzHv9dZ28t40RGN9P8kHgucAlSR7eUruSJEmSJElAO4mG5wKXAk+tqjuBOcBrWmhXkiRJkiQJaCGBUVU/rarzgbuSzAO2Bb415cgkSZIkSZIaU05gJHlGkpuA7wGfb46fmWq7kiRJkiRJ49qYQvJmYD7wnaraF/jvwBdbaFeSJEmSJAloJ4Fxb1X9ENgqyVZVdQVwYAvtSpIkSZIkAe1so3pnkkcCVwEfTbIGuK+FdiVJkiRJkoB2EhgLgJ8BfwX8KbAj8KYW2pUkDdHqJcd1HcKDbG48uy08Z5oikSRJUh9MOYFRVT+ZcLlkqu1JkiRJkiSta4sTGEnuBmqyW0BV1Q5bHJUkSZIkSdIEW5zAqKrt2wxEkiRJkiRpfdrYhUSSJEmSJGlamcCQJEmSJEm918beB1GhAAAgAElEQVQuJJIkSSMnyS3A3cD9wH1VNdZtRJIkaUNMYGyhJ7zm3K5D0Iga9b87V7/j2K5DmLVWnX5E1yH02nT++exx4qXT1rY6d2hV/aDrICRJ0sY5hUSSJEmSJPWeIzAkSdJsVcBlSQr4YFUt7jogSaNj2bJlfOeW+7sOQ+rEo5ctY/78+UN/rwkMSZI0Wx1SVauSPApYmuRbVXXVxApJFgGLAObNmzetwYz6FEN1Z5T/7jg1VdLmMIEhSZJmpapa1RzXJLkAOBi4ap06i4HFAGNjYzX0ICX11vz589njsq27DkPqxLwORl+Aa2BIkqRZKMkjkmw/fg4cDlzfbVSSJGlDHIEhSZJmo92AC5LAoD/0j1X12W5DkiRJG2ICQ5IkzTpVdTNwQNdxSJKkTdfZFJIkZydZk+T6CWVzkixNclNz3LkpT5L3JlmR5Nokj+8qbkmSJEmSNHxdroHxYeCp65SdDFxeVfsBlzfXAEcC+zWfRcAZQ4pRkiRJkiT1QGcJjGabsjvWKV4ALGnOlwDPnFB+bg0sA3ZKsvtwIpUkSZIkSV3r2y4ku1XV7QDN8VFN+Z7AbRPqrWzKHiTJoiTLkyxfu3bttAcrSZIkSZKGo28JjPXJJGUP2Yu9qhZX1VhVjc2dO3cIYUmSJEmSpGHoWwJj9fjUkOa4pilfCew9od5ewKohxyZJkiRJkjrStwTGRcDC5nwhcOGE8mOb3UjmA3eNTzWRJEmSJEkz3zZdvTjJx4AnAbsmWQmcCpwGnJfkeOBW4Oim+iXAUcAK4KfAcUMPWJIkSZIkdaazBEZVHbOeW4dNUreAE6Y3IkmSJEmS1Fd9m0IiSZIkSZL0ECYwJEmSJElS75nAkCRJkiRJvWcCQ5IkSZIk9Z4JDEmSJEmS1HsmMCRJkiRJUu+ZwJAkSZIkSb23TdcBjKJly5Zx7/e/2XUYUieWLVvG/Pnzuw5DkiRJ0izjCAxJkiRJktR7jsDYAvPnz2fbT3+n6zCkTjj6QpIkSVIXHIEhSZIkSZJ6zxEYkiRJHXN9Lc1Wrq0laXOYwJA0a9z6pt/tOgSNqFH/uzPv9dd1HYIkzUij/u/rqtOP6DqEWWuPEy/tOoSRZAJDkiSpY66vpdnK0ReSNodrYEiSJEmSpN4zgSFJkiRJknrPBIYkSZIkSeo9ExiSJEmSJKn3TGBIkiRJkqTeM4EhSZIkSZJ6zwSGJEmSJEnqvW26DkCSJElw9TuO7TqELfb0t53fdQiz2sWvfXbXIWhE7XHipdPa/uolx01r+9Npt4XndB2CJuEIDEmSJEmS1HuOwNhCo/wtCfhNSZf8lkSSJEmSNp8jMCRJkiRJUu+ZwJAkSZIkSb1nAkOSJEmSJPXeSCUwkjw1ybeTrEhyctfxSJKk0WW/QpKk0TIyCYwkWwPvB44E9geOSbJ/t1FJkqRRZL9CkqTRM0q7kBwMrKiqmwGSfBxYAHyz06gkjYRly5bxnVvu7zoMqROPXraM+fPndx1G39ivkCRpxIxSAmNP4LYJ1yuB359YIckiYBHAvHnzhhfZCHIrT81Guz7nnV2HIKk/NtqvAPsWm8p+haTJ7LbwnK5D0AwzSgmMTFJWD7qoWgwsBhgbG6tJ6kuapfz2WdI6NtqvAPsWkiT1ycisgcHgm5G9J1zvBazqKBZJkjTa7FdIkjRiRimB8f/au/9gver6TuDvT0Ghs7oVS6TyI4btpp1iO2JNMR2d8deKyLZFW7W4q+KPaZxd2dodp7Po7BSttWt/6WBrsTjyq2NFVqGmDlOgVKt2TCVYWglIjRQlBgHFIlstGvzsH/cEruEmuTfc5z7nuXm9Zp55zvmcH8/nZvLcOXnne77n2iTrq+r4qnpkktOTbJ5yTwDAbHJdAQAzZmZuIenuXVV1ZpIrkxyS5Pzu3jbltgCAGeS6AgBmz8wEGEnS3VckuWLafQAAs891BQDMllm6hQQAAAA4SAkwAAAAgNETYAAAAACjJ8AAAAAARq+6e9o9TERV3ZXkS9Pug4k5MsnXpt0EsCS+t6vXE7p7zbSbmDTXFqua308we3xvV6+9Xles2gCD1a2qtnb3hmn3ASye7y0wVn4/wezxvT04uYUEAAAAGD0BBgAAADB6Agxm1XnTbgBYMt9bYKz8foLZ43t7EDIHBgAAADB6RmAAAAAAoyfAAAAAAEZPgMFMqapTqurmqtpeVWdNux9g/6rq/Kq6s6pumHYvAHtybQGzxXXFwU2AwcyoqkOSvDvJ85OckOSlVXXCdLsCFuHCJKdMuwmAPbm2gJl0YVxXHLQEGMySk5Js7+5buvs7SS5JctqUewL2o7s/keTuafcBsADXFjBjXFcc3AQYzJJjktw2b33HUAMAOBCuLQBmiACDWVIL1DwHGAA4UK4tAGaIAINZsiPJcfPWj02yc0q9AACzz7UFwAwRYDBLrk2yvqqOr6pHJjk9yeYp9wQAzC7XFgAzRIDBzOjuXUnOTHJlkpuSXNrd26bbFbA/VfWBJJ9O8uNVtaOqXjPtngAS1xYwi1xXHNyq221+AAAAwLgZgQEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMICJqKofqapLquqLVXVjVV1RVZuq6qPT7g0AmD2uLQABBrDsqqqSXJ7k4939o919QpI3JTnqYZ730OXoDwCYLa4tgESAAUzGs5J8t7vfs7vQ3dcn+WSSR1XVh6rq81X1/uGCJFV1a1UdOSxvqKqPD8tvrqrzquqqJBdX1Sur6rKq+suq+kJV/e6K/3QAwEpzbQFE4ghMwk8muW4v256c5IlJdib52yRPS/Kp/ZzvKUme3t3frqpXJjlxOM99SW6uqj/s7tuWo3EAYJRcWwBGYAAr7jPdvaO7v5fk+iTrFnHM5u7+9rz1a7r7nu7+tyQ3JnnCBPoEAGaDaws4SAgwgEnYlrn/2VjIffOW78+DI8F25cHfSYfvccy/LvIcAMDq5NoCEGAAE/HXSQ6rql/ZXaiqn0nyjH0cc2sevDD5pcm1BgDMINcWgAADWH7d3UlemOS5w6POtiV5c+buTd2btyQ5p6o+mbn/+QAASOLaAphTc78LAAAAAMbLCAwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAo3fotBuYlCOPPLLXrVs37TYAYNW77rrrvtbda6bdBwCwuk00wKiqw5N8Islhw2d9qLvPrqrjk1yS5LFJPpvk5d39nao6LMnFSZ6S5OtJfrm7bx3O9cYkr0lyf5Jf7e4r9/XZ69aty9atWyfzgwEAD6iqL027BwBg9Zv0LST3JXl2dz8pyYlJTqmqjUl+J8k7u3t9km9kLpjI8P6N7v6PSd457JeqOiHJ6UmemOSUJH9cVYdMuHcAAABgJCYaYPSc/zesPmJ4dZJnJ/nQUL8oyQuG5dOG9Qzbn1NVNdQv6e77uvufk2xPctIkewcAAADGY+KTeFbVIVV1fZI7k1yd5ItJ/qW7dw277EhyzLB8TJLbkmTYfk+SH55fX+CY+Z+1qaq2VtXWu+66axI/DgAAADAFEw8wuvv+7j4xybGZGzXxEwvtNrzXXrbtrb7nZ53X3Ru6e8OaNeYSAwAAgNVixR6j2t3/kuTjSTYmeUxV7Z5A9NgkO4flHUmOS5Jh+w8luXt+fYFjAAAAgFVuogFGVa2pqscMyz+Y5D8luSnJx5K8aNjtjCQfGZY3D+sZtv91d/dQP72qDhueYLI+yWcm2TsAAAAwHhN9jGqSxye5aHhiyA8kubS7P1pVNya5pKp+K8nfJ3nfsP/7kvxpVW3P3MiL05Oku7dV1aVJbkyyK8nruvv+CfcOAAAAjETNDXBYfTZs2NBbt26ddhsAsOpV1XXdvWHafQAAq9ukR2DAsvmLrV98SO3nN/zoFDoB9uWev/njJe3/Q8/47xPqBACA1WTFJvEEAAAAOFACDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACj5ykkAByQr3/kf0/0PD982m8ty/kBAFgdjMAAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYvYkGGFV1XFV9rKpuqqptVfX6of7mqvpKVV0/vE6dd8wbq2p7Vd1cVc+bVz9lqG2vqrMm2TcAAAAwLodO+Py7kryhuz9bVY9Ocl1VXT1se2d3//78navqhCSnJ3likqOT/FVV/diw+d1JnptkR5Jrq2pzd9844f4BAACAEZhogNHdtye5fVi+t6puSnLMPg45Lckl3X1fkn+uqu1JThq2be/uW5Kkqi4Z9hVgAAAAwEFgxebAqKp1SZ6c5O+G0plV9Y9VdX5VHTHUjkly27zDdgy1vdX3/IxNVbW1qrbeddddy/wTAAAAANMy6VtIkiRV9agkH07ya939zao6N8lbk/Tw/gdJXp2kFji8s3DQ0g8pdJ+X5Lwk2bBhw0O2M3v+5Kp/WPT21578pEm3AwAAwJRMPMCoqkdkLrx4f3dfliTdfce87e9N8tFhdUeS4+YdfmySncPy3uoAAADAKjfpp5BUkvcluam73zGv/vh5u70wyQ3D8uYkp1fVYVV1fJL1ST6T5Nok66vq+Kp6ZOYm+tw8yd4BAACA8Zj0CIynJXl5ks9V1fVD7U1JXlpVJ2buNpBbk7w2Sbp7W1VdmrnJOXcleV13358kVXVmkiuTHJLk/O7eNuHeAQAAgJGY9FNIPpWF57W4Yh/HvC3J2xaoX7Gv4wAAAIDVa8WeQgIAAABwoAQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGL1Dp90AAONwx0WvmnYL32ep/Rx1xgUT6gQAgDEwAgMAAAAYPQEGAAAAMHoTDTCq6riq+lhV3VRV26rq9UP9sVV1dVV9YXg/YqhXVb2rqrZX1T9W1U/PO9cZw/5fqKozJtk3AAAAMC6THoGxK8kbuvsnkmxM8rqqOiHJWUmu6e71Sa4Z1pPk+UnWD69NSc5N5gKPJGcneWqSk5KcvTv0AAAAAFa/iQYY3X17d392WL43yU1JjklyWpKLht0uSvKCYfm0JBf3nC1JHlNVj0/yvCRXd/fd3f2NJFcnOWWSvQMAAADjsWJzYFTVuiRPTvJ3SY7q7tuTuZAjyeOG3Y5Jctu8w3YMtb3V9/yMTVW1taq23nXXXcv9IwAAAABTsiIBRlU9KsmHk/xad39zX7suUOt91L+/0H1ed2/o7g1r1qw5sGYBAACA0Zl4gFFVj8hcePH+7r5sKN8x3BqS4f3Oob4jyXHzDj82yc591AEAAICDwKSfQlJJ3pfkpu5+x7xNm5PsfpLIGUk+Mq/+iuFpJBuT3DPcYnJlkpOr6ohh8s6ThxoAAABwEDh0wud/WpKXJ/lcVV0/1N6U5O1JLq2q1yT5cpIXD9uuSHJqku1JvpXkVUnS3XdX1VuTXDvs95vdffeEewcAAABGYqIBRnd/KgvPX5Ekz1lg/07yur2c6/wk5y9fd4zJ2R/824md4y2//LSHfW4AAACma7+3kFTVL1TV4SvRDAAAAMBCFjMHxgeT7KiqP62qU6vqkEk3BQAAADDfYgKMzydZn+QTSd6QZGdVvaeqnjHRzgAAAAAGiwkwuru/0d3v7e7nJHlSkhuTvL2qbptsewAAAACLCzC+bxLO7v5qd7+ru382ydMn0xYAAADAgxYTYPzPvW3o7i8tYy8AAAAAC9pvgNHdH1/Miarq0w+7GwAAAIAFLGYExmJ51CoAAAAwEcsZYPQyngsAAADgAcsZYAAAAABMxHIGGLX/XQAAAACWbjkDjJcv47kAAAAAHnDoYnesqnvz4DwXj0zyiCT/2t3/Pkm6+4blbw8AAABgCQFGdz96/npVvSDJScveEQAAAMAeDvgWku7+8yTPXsZeAAAAABa0lFtIfnHe6g8k2RCPTgUAAABWwKIDjCQ/P295V5Jbk5y2rN0AAAAALGApc2C8apKNAAAAAOzNoufAqKpjq+ryqrqzqu6oqg9X1bGTbA4AAAAgWdoknhck2Zzk6CTHJPmLoQYAAAAwUUsJMNZ09wXdvWt4XZhkzYT6AgAAAHjAUgKMr1XVy6rqkOH1siRfn1RjAAAAALstJcB4dZKXJPlqktuTvGioAQAAAEzUUp5C8uUkvzDBXgAAAAAWtOgAo6qOT/I/kqybf1x3CzUAAACAiVp0gJHkz5O8L3NPH/neZNoBAAAAeKilzIHxb939ru7+WHf/ze7Xvg6oqvOr6s6qumFe7c1V9ZWqun54nTpv2xurantV3VxVz5tXP2Woba+qs5b0EwIAAAAzbykjMM6pqrOTXJXkvt3F7v7sPo65MMkfJbl4j/o7u/v35xeq6oQkpyd5YpKjk/xVVf3YsPndSZ6bZEeSa6tqc3ffuITeAQAAgBm2lADjp5K8PMmz8+AtJD2sL6i7P1FV6xZ5/tOSXNLd9yX556ranuSkYdv27r4lSarqkmFfAQYAAAAcJJYSYLwwyX/o7u8sw+eeWVWvSLI1yRu6+xtJjkmyZd4+O4Zakty2R/2pC520qjYl2ZQka9euXYY2OVC/cu5V027hAUvt5b3/7eQJdQIAAMCBWkqA8Q9JHpPkzof5mecmeWvmRm+8NckfJHl1klpg387C83T0Qifu7vOSnJckGzZsWHAfgFm185zn7X+ng9gk/3yOfv2VEzs3AACLs5QA46gkn6+qa/P9c2As6TGq3X3H7uWqem+Sjw6rO5IcN2/XY5PsHJb3VgcAAAAOAksJMM5ejg+sqsd39+3D6guT7H5CyeYkf1ZV78jcJJ7rk3wmcyMz1lfV8Um+krmJPv/LcvQCAAAAzIZFBxiLeGTqp7v7Z/eofSDJM5McWVU7MheCPLOqTszcbSC3JnntcP5tVXVp5ibn3JXkdd19/3CeM5NcmeSQJOd397bF9g0AAADMvqWMwNifw/csdPdLF9jvfXs7QXe/LcnbFqhfkeSKh9UdAAAAMLMWmiDzQJk0EwAAAJiI5QwwAAAAACZiOQOMhR6DCgAAAPCwLWeA8fJlPBcAAADAAxY9iWdV3ZuHznNxT5KtSd7Q3Tc89CgAAACAh28pTyF5R5KdSf4sc7eLnJ7kR5LcnOT8zD0uFQAAAGDZLeUWklO6+0+6+97u/mZ3n5fk1O7+YJIjJtQfAAAAwJICjO9V1Uuq6geG10vmbfMIVQAAAGBilhJg/NfMTdR55/B6eZKXVdUPJjlzAr0BAAAAJFnCHBjdfUuSn9/L5k8tTzsAAAAAD7XoERhVdWxVXV5Vd1bVHVX14ao6dpLNAQAAACRLu4XkgiSbkxyd5JgkfzHUAAAAACZqKQHGmu6+oLt3Da8Lk6yZUF8AAAAAD1hKgPG1qnpZVR0yvF6W5OuTagwAAABgt6UEGK9O8pIkX01ye5IXDTUAAACAiVrKU0i+nOQX9ra9qt7Y3f9nWboCAAAAmGcpIzD258XLeC4AAACAByxngFHLeC4AAACAByxngNHLeC4AAACABxiBAQAAAIzecgYY/3cZzwUAAADwgP0+haSq/jD7uD2ku391eP/tZewLAAAA4AGLGYGxNcl1SQ5P8tNJvjC8Tkxy/+RaAwAAAJiz3xEY3X1RklTVK5M8q7u/O6y/J8lVE+0OAAAAIEubA+PoJI+et/6ooQYAAAAwUfsdgTHP25P8fVV9bFh/RpK3LH9LrISf++3Lpt3CaE36z+ajb/rFiZ4fAABgNVr0CIzuviDJU5NcPrx+trsv3NcxVXV+Vd1ZVTfMqz22qq6uqi8M70cM9aqqd1XV9qr6x6r66XnHnDHs/4WqOmOJPyMAAAAw4xYdYFTVNd391e7+yPD6alVds5/DLkxyyh61s5Jc093rk1wzrCfJ85OsH16bkpw7fO5jk5ydufDkpCRn7w49AAAAgIPDfgOMqjp8CBGOrKojhhEUj62qddnPHBjd/Ykkd+9RPi3JRcPyRUleMK9+cc/ZkuQxVfX4JM9LcnV3393d30hydR4aigAAAACr2GLmwHhtkl/LXFhxXZJK0knuTfJHB/CZR3X37UnS3bdX1eOG+jFJbpu3346htrf6Q1TVpsyN3sjatWsPoDVgNfvyb/7UtFtgRs363521v/G5abcAAPCw7XcERnef093HJ3lbkhOH5QuS3JLk08vYSy308fuoP7TYfV53b+juDWvWrFnG1gAAAIBpWspjVF/U3d+sqqcneW7m5rc49wA+847h1pAM73cO9R1Jjpu337FJdu6jDgAAABwklhJg3D+8/+ck7+nujyR55AF85uYku58kckaSj8yrv2J4GsnGJPcMt5pcmeTkYf6NI5KcPNQAAACAg8Ri5sDY7StV9SdJ/lOS36mqw7KfAKSqPpDkmZmbAHRH5p4m8vYkl1bVa5J8OcmLh92vSHJqku1JvpXkVUnS3XdX1VuTXDvs95vdvefEoAAAAMAqtpQA4yWZe/rH73f3vwy3f/z6vg7o7pfuZdNzFti3k7xuL+c5P8n5S+gVAAAAWEUWHWB097eSXDZv/fYkt0+iKQAAAID5ljIHBgAAAMBUCDAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDoCTAAAACA0RNgAAAAAKN36LQbmFVP+fWLp90CM2rW/+5c93uvmHYLAADAQcgIDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARm9qTyGpqluT3Jvk/iS7untDVT02yQeTrEtya5KXdPc3qqqSnJPk1CTfSvLK7v7sNPoGZtOWLVvyT7feP+02YCp+bMuWbNy4cdptAAA8LNMegfGs7j6xuzcM62cluaa71ye5ZlhPkucnWT+8NiU5d8U7BQAAAKZmaiMw9uK0JM8cli9K8vEk/2uoX9zdnWRLVT2mqh7f3bdPpUtg5mzcuDFHX3XItNuAqVhr9AUAsApMcwRGJ7mqqq6rqk1D7ajdocTw/rihfkyS2+Ydu2OoAQAAAAeBaY7AeFp376yqxyW5uqo+v499a4FaP2SnuSBkU5KsXbt2eboEAAAApm5qIzC6e+fwfmeSy5OclOSOqnp8kgzvdw6770hy3LzDj02yc4FzntfdG7p7w5o1aybZPgAAALCCphJgVNW/q6pH715OcnKSG5JsTnLGsNsZST4yLG9O8oqaszHJPea/AAAAgIPHtG4hOSrJ5XNPR82hSf6su/+yqq5NcmlVvSbJl5O8eNj/isw9QnV75h6j+qqVbxkAAACYlqkEGN19S5InLVD/epLnLFDvJK9bgdYAAACAEZrmU0gAAAAAFkWAAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIzeodNuYBZt2bIl3/3KjdNuA6Ziy5Yt2bhx47TbAAAADjICDOCgsfY3PjftFh6Wnec8b9otHLSOfv2V024BAOCgJ8A4ABs3bswjPvxP024DpsLoCwAAYBrMgQEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOjNVIBRVadU1c1Vtb2qzpp2PwAAAMDKmJkAo6oOSfLuJM9PckKSl1bVCdPtCgAAAFgJMxNgJDkpyfbuvqW7v5PkkiSnTbknAAAAYAUcOu0GluCYJLfNW9+R5KlT6iXX/d4rpvXRy+Lnfvuyabdw0Prom35x2i0AAADMnFkKMGqBWn/fDlWbkmxKkrVr165ETzPLP6Jh9hz9+iun3QIAAEzNLN1CsiPJcfPWj02yc/4O3X1ed2/o7g1r1qxZ0eYAAACAyZmlAOPaJOur6viqemSS05NsnnJPAAAAwAqYmVtIuntXVZ2Z5MokhyQ5v7u3TbktAAAAYAXMTICRJN19RZIrpt0HAAAAsLJm6RYSAAAA4CAlwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwetXd0+5hIqrqriRfmnYfTMyRSb427SaAJfG9Xb2e0N1rpt0EALC6rdoAg9WtqrZ294Zp9wEsnu8tAAAPh1tIAAAAgNETYAAAAACjJ8BgVp037QaAJfO9BQDggJkDAwAAABg9IzAAAACA0RNgAAAAAKMnwGCmVNUpVXVzVW2vqrOm3Q+wf1V1flXdWVU3TLsXAABmlwCDmVFVhyR5d5LnJzkhyUur6oTpdgUswoVJTpl2EwAAzDYBBrPkpCTbu/uW7v5OkkuSnDblnoD96O5PJLl72n0AADDbBBjMkmOS3DZvfcdQAwAAYJUTYDBLaoGa5wADAAAcBAQYzJIdSY6bt35skp1T6gUAAIAVJMBgllybZH1VHV9Vj0xyepLNU+4JAACAFSDAYGZ0964kZya5MslNSS7t7m3T7QrYn6r6QJJPJ/nxqtpRVa+Zdk8AAMye6jaFAAAAADBuRmAAAAAAowEDFiIAAAG9SURBVCfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgxgIqrqR6rqkqr6YlXdWFVXVNWmqvrotHsDAABmjwADWHZVVUkuT/Lx7v7R7j4hyZuSHPUwz3vocvQHAADMHgEGMAnPSvLd7n7P7kJ3X5/kk0keVVUfqqrPV9X7h7AjVXVrVR05LG+oqo8Py2+uqvOq6qokF1fVK6vqsqr6y6r6QlX97or/dAAAwIrzv5nAJPxkkuv2su3JSZ6YZGeSv03ytCSf2s/5npLk6d397ap6ZZITh/Pcl+TmqvrD7r5tORoHAADGyQgMYKV9prt3dPf3klyfZN0ijtnc3d+et35Nd9/T3f+W5MYkT5hAnwAAwIgIMIBJ2Ja5URMLuW/e8v15cCTYrjz4O+nwPY7510WeAwAAWKUEGMAk/HWSw6rqV3YXqupnkjxjH8fcmgdDj1+aXGsAAMAsEmAAy667O8kLkzx3eIzqtiRvzty8F3vzliTnVNUnMzeqAgAA4AE19+8MAAAAgPEyAgMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARu//AwJtttauwVoiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp_col=['loc_ic_mou_8','loc_og_t2f_mou_8','roam_og_mou_8','aug_vbc_3g','last_day_rch_amt_8','Recency_8','std_og_mou_7']\n",
    "i=1\n",
    "plt.figure(figsize=(15,15))\n",
    "for col in imp_col:\n",
    "    plt.subplot(4,2,i)\n",
    "    sns.boxenplot(y=fdf[col],x=fdf['Churn'])\n",
    "    i+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 7 important variables affecting the churn are as follows:\n",
    "\n",
    "- loc_ic_mou_8 (negatively related)\n",
    "- loc_og_t2f_mou_8 (negatively related)\n",
    "- roam_og_mou_8 (positively related)\n",
    "- aug_vbc_3g (negatively related)\n",
    "- last_day_rch_amt_8 (negatively related)\n",
    "- Recency_8 (positively related)\n",
    "- std_og_mou_7 (positively related)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**If the telecom company wants to retain high value customers, the company should provide special schemes or plans for customers in following call situations:**\n",
    "\n",
    "- **Local Outgoing calls from Operator T to fixed lines of T (since loc_og_t2f_mou_8 is negatively related to churn, so as the minutes of usage in this case increase, the probability of retaining these customers increases)**\n",
    "- **We also notice that as mintues of usage of roaming outgoing calls increase in August, the probability of Churn also increases and the customer is also not using special data plans in August since aug_vbc_3g also increases. This happened because possibly the customer has changed his location and needs a new sim card because of the location change. Thus, the company should have provisions to provide a new area connection on the same number or some special plans if a customer changes his/her location.**\n",
    "- **We also notice that the probability to Churn increases as Recency_8 increases,that is, as the number of days since the last recharge in the month of August increases, the probability to Churn increases. Hence, we should identify the customers who have had significant time since last recharge and provide special schemes for them.***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
